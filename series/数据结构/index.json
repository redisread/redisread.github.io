[{"content":"Freenom 是目前为数不多的免费域名提供商，提供 .ga, .ml, .gq, .tk, .cf 五个免费顶级域。当然也有一些付费的域名，对于普通人来说，免费域名就够了。😏\n另外，本文后面还提供了一种自动续租 Freenom 免费域名的方法。\n1 找域名 Freenom 地址：freenom.com\n打开Freenom，登陆后直接在搜索栏搜索自己想要的域名名字，然后系统会返回可以使用的免费域名，选择一个结算即可\n2 配置解析服务 这一步是可选的，也可以直接使用 Freenom 自己的 DNS 解析服务，或者不使用 cloudflare，用其他的 DNS 解析服务也可以。\n使用cloudflare解析服务 Cloudflare 网址：cloudflare.com\n打开cloudflare，首先需要注册一个账号。然后他会要求输入需要解析的域名\n填写相应的 DNS 信息，并且将下面的 NS 信息填写到 freenom 的custom nameservers\n等待个几分钟就好了。Over 🤞\n3 自动续租 参考：\nluolongfei/freenom: Freenom 域名自动续期。Freenom domain name renews automatically. 常见问题：\nfreenom 域名注册失败的解决办法_未名编程的博客-CSDN 博客_some of your domains could not be registered becau 参考这个github 仓库进行下面的操作：\n通过 Koyeb 部署：通过 Koyeb 部署 · luolongfei/freenom Wiki\n注册 Koyeb 账户\n在新标签页打开链接 https://app.koyeb.com/auth/signup ，完成注册，并登录\n一键部署\n右击在新标签页打开链接 ，来到部署画面：\n主要填写 token 和 freenom 的账号和密码，token 是登陆后台的密码，需要自己保存。\n然后点击 deploy 或者 create service。\n点击应用地址，跳到工具管理画面：\n输入 token 值进行验证（点击送信）：\n返回类似下面的结果：\n默认会周期进行定时调用，不需要手动触发，上面只是为了展示进行触发的。\nReference：\nThe fastest way to deploy applications globally - Koyeb ","description":"","id":2,"section":"posts","tags":["域名","freenom"],"title":"Freenom 免费域名申请 \u0026 自动域名续费","uri":"https://hugo.jiahongw.com/posts/usefulpower/freenom-domain/"},{"content":"目前有中文和英文的 Markdown 规范检查工具，目前中文支持的比较少，英文的支持比较多，但是对英文比较友好，对中文支持也较少。\n下面介绍这几个工具\nlint-md github 仓库：https://github.com/lint-md/lint-md\n安装\n1 npm install -g @lint-md/cli@beta 使用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # 校验当前目录下的 test.md 文件 lint-md test.md # 校验当前目录下的 test.md 文件，并修复之 lint-md test.md --fix # 校验 examples 目录下所有的 Markdown 文件，并修复之 lint-md examples/**/* --fix # 校验 examples 目录下所有的 Markdown 文件，指定 config.json 为配置文件（配置文件语法见下文） lint-md examples/**/* --config=config.json # 校验 examples 目录下所有的 Markdown 文件，仅存在 warning 时程序正常退出（warning 不会阻断 CI） lint-md examples/**/* --suppress-warnings # 校验 examples 目录下所有的 Markdown 文件，并开启多线程模式（线程数 === CPU 核心数） lint-md examples/**/* --threads # 校验 examples 目录下所有的 Markdown 文件，并开启多线程模式（线程数 === 8） lint-md examples/**/* --threads=8 markdownlint-cli2 github 仓库：https://github.com/DavidAnson/markdownlint-cli2\n安装\n1 npm install markdownlint-cli2 --global 使用\n1 2 3 4 5 6 7 8 9 # 检查单个文件 markdownlint-cli2 hugo_setup.md # 检查多个文件,hugo文件夹下所有markdown文件 markdownlint-cli2 \u0026#39;hugo/*.md\u0026#39; # 修复 markdownlint-cli2-fix hugo_setup.md markdownlint-cli2-fix \u0026#39;hugo/*.md\u0026#39; Reference:\nMarkdown 书写风格指南 ","description":"通常我们使用编辑器，写出来的Markdown不太符合标准的Markdown格式，例如多个无用的换行和空格，以及图片未添加描述等。通过工具可以让我们写出更标准的Markdown文章。","id":3,"section":"posts","tags":["Markdown"],"title":"使用Markdown规范检查工具","uri":"https://hugo.jiahongw.com/posts/hugo/markdown-lint/"},{"content":" 创建线程池的方法：\n1 2 3 4 ExecutorService executorService = Executors.newCachedThreadPool(); ExecutorService executorService = Executors.newFixedThreadPool(3); ScheduledExecutorService executorService = Executors.newScheduledThreadPool(3); ExecutorService executorService = Executors.newSingleThreadExecutor(); https://www.cnblogs.com/pcheng/p/13540619.html\n多线程的问题 线程任务是实现了Runnable接口，或者直接写个类继承Thread,但是这两种方法只能通过共享对象或者文件来得到返回的结果，无法直接返回。并且Runnable接口中的run方法无法抛出异常。\n回调地狱（Callback hell）问题\nJava 5 提供了执行器框架，其思想类似于一个高层的线程池，可以充分发􏴁线程的能力。执行器使得程序员有机会解􏳽任务的提交与任务的执行。\n无论什么时候，任何任务(或者线程)在方法 调用中启动时，都会在其返回之前调用同一个方法。换句话说，线程创建以及与其匹配的 join() 在调用返回的嵌套方法调用中都以嵌套的方式成对出现。这种思想被称为􏶖􏶗 fork/join。\nJava中的Future代表了什么？\nFuture是Java的接口，类似于容器保存了Callable的返回结果。我们把子任务放入线程池之后，直接返回，进行其他处理，然后再调用Future的get方法来获取结果，Future还可以控制子任务的执行。\nFuture 我们使用Runnable对象来定义在线程内执行的任务。虽然定义任务使用Runnable很方便，但受限于任务不能返回结果。\nJava 提供了一个Callable接口来定义返回结果的任务。Callable类似于Runnable并且它可以返回结果并抛出异常。\nCallable 接口有一个简单的方法call() 用于包含由线程执行的代码。简单的例子：\n1 2 3 4 5 6 7 8 Callable\u0026lt;String\u0026gt; callable = new Callable\u0026lt;String\u0026gt;() { @Override public String call() throws Exception { // Perform some computation Thread.sleep(2000); return \u0026#34;Return some result\u0026#34;; } }; 请注意，使用Callable，您不需要Thread.sleep()被 try/catch 块包围，因为与 Runnable 不同，Callable 可以抛出checked异常。\n更方便的定义一个Callable，使用Lambda表达式：\n1 2 3 4 5 Callable\u0026lt;String\u0026gt; callable = () -\u0026gt; { // Perform some computation Thread.sleep(2000); return \u0026#34;Return some result\u0026#34;; }; Callable的定义如下：\n1 2 3 4 5 6 7 8 9 10 @FunctionalInterface public interface Callable\u0026lt;V\u0026gt; { /** * Computes a result, or throws an exception if unable to do so. * * @return computed result * @throws Exception if unable to compute a result */ V call() throws Exception; } 可以发现它是可以带返回值的，并且能够抛出异常。\nRunnable接口：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 @FunctionalInterface public interface Runnable { /** * When an object implementing interface \u0026lt;code\u0026gt;Runnable\u0026lt;/code\u0026gt; is used * to create a thread, starting the thread causes the object\u0026#39;s * \u0026lt;code\u0026gt;run\u0026lt;/code\u0026gt; method to be called in that separately executing * thread. * \u0026lt;p\u0026gt; * The general contract of the method \u0026lt;code\u0026gt;run\u0026lt;/code\u0026gt; is that it may * take any action whatsoever. * * @see java.lang.Thread#run() */ public abstract void run(); } Runnable接口是没有返回值，也不能抛出异常的。因为run()方法是Runnable接口里面的方法,而Runnable接口在定义run()方法的时候没有抛出任何异常,所以子类在重写run()方法的时候要小于或等于父类(Runnable)的run()方法的异常,所以父类没有抛出异常,子类不能抛出异常。\nThread类中的run方法定义如下：\n1 2 3 4 5 6 @Override public void run() { if (target != null) { target.run(); } } 同理，继承Thread的线程子类也不能够抛出异常，因为如果父类或者接口的方法中，没有异常抛出，那么子类在覆盖方法时，也不可以抛出异常。发生异常必须进行try处理。\n使用（Callable结合Future） 像Runnable一样，你可以submit一个Callable给executor service去执行。executor service的 submit() 方法 会将任务提交给线程执行。但是，它不知道提交的任务什么时候结束。因此，它返回一种称为 Future 的特殊类型的值，可用于在可用时获取任务的结果。\nFuture 的概念类似于 Javascript 等其他语言中的 Promise。它表示将在以后的某个时间点完成的计算结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 import java.util.concurrent.*; public class FutureAndCallableExample { public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newSingleThreadExecutor(); Callable\u0026lt;String\u0026gt; callable = () -\u0026gt; { // Perform some computation System.out.println(\u0026#34;Entered Callable\u0026#34;); Thread.sleep(2000); return \u0026#34;Hello from Callable\u0026#34;; }; System.out.println(\u0026#34;Submitting Callable\u0026#34;); Future\u0026lt;String\u0026gt; future = executorService.submit(callable); // This line executes immediately System.out.println(\u0026#34;Do something else while callable is getting executed\u0026#34;); System.out.println(\u0026#34;Retrieve the result of the future\u0026#34;); // Future.get() 会阻塞知道Future中得到了返回的结果 String result = future.get(); System.out.println(result); executorService.shutdown(); } } 或者可以使用这个例子进行测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 mport java.util.concurrent.*; public class FutureIsDoneExample { public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newSingleThreadExecutor(); Future\u0026lt;String\u0026gt; future = executorService.submit(() -\u0026gt; { Thread.sleep(2000); return \u0026#34;Hello from Callable\u0026#34;; }); while(!future.isDone()) { System.out.println(\u0026#34;Task is still not done...\u0026#34;); Thread.sleep(200); } System.out.println(\u0026#34;Task completed! Retrieving the result\u0026#34;); String result = future.get(); System.out.println(result); executorService.shutdown(); } } 输出结果如下：\n# Output Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task completed! Retrieving the result Hello from Callable 在没有得到结果的时候，isDone()的返回值都是false，这将导致阻塞。\n取消Future 你可以使用Future.cancel()方法取消一个Future。它试图取消任务的执行，如果成功取消则返回true，否则返回false。\n您可以使用isCancelled()方法来检查任务是否被取消。此外，取消任务后，isDone() 将始终为真。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 import java.util.concurrent.*; public class FutureCancelExample { public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newSingleThreadExecutor(); long startTime = System.nanoTime(); Future\u0026lt;String\u0026gt; future = executorService.submit(() -\u0026gt; { Thread.sleep(2000); return \u0026#34;Hello from Callable\u0026#34;; }); while(!future.isDone()) { System.out.println(\u0026#34;Task is still not done...\u0026#34;); Thread.sleep(200); double elapsedTimeInSec = (System.nanoTime() - startTime)/1000000000.0; if(elapsedTimeInSec \u0026gt; 1) { future.cancel(true); } } System.out.println(\u0026#34;Task completed! Retrieving the result\u0026#34;); String result = future.get(); System.out.println(result); executorService.shutdown(); } } 跑上面的代码将会抛出异常，因为已经取消了Future，然后又实用get()方法获取Future的值。\nTask is still not done... Task is still not done... Task is still not done... Task is still not done... Task is still not done... Task completed! Retrieving the result Exception in thread \u0026#34;main\u0026#34; java.util.concurrent.CancellationException at java.util.concurrent.FutureTask.report(FutureTask.java:121) at java.util.concurrent.FutureTask.get(FutureTask.java:192) at com.sankuai.stafftraining.wujiahong.demo.springdemo.concurrency.MainApp.test3(MainApp.java:79) at com.sankuai.stafftraining.wujiahong.demo.springdemo.concurrency.MainApp.main(MainApp.java:12) 最好是通过下面这种方法进行判断：\n1 2 3 4 5 6 7 if(!future.isCancelled()) { System.out.println(\u0026#34;Task completed! Retrieving the result\u0026#34;); String result = future.get(); System.out.println(result); } else { System.out.println(\u0026#34;Task was cancelled\u0026#34;); } invokeAll方法 提交多个任务并等待所有任务完成。\n你可以通过向invokeAll()方法传递一个Callables的集合来执行多个任务。invokeAll()返回一个Futures的列表。任何对future.get()的调用都会被阻止，直到所有的Futures都完成。\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 import java.util.Arrays; import java.util.List; import java.util.concurrent.*; public class InvokeAllExample { public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newFixedThreadPool(5); Callable\u0026lt;String\u0026gt; task1 = () -\u0026gt; { Thread.sleep(2000); return \u0026#34;Result of Task1\u0026#34;; }; Callable\u0026lt;String\u0026gt; task2 = () -\u0026gt; { Thread.sleep(1000); return \u0026#34;Result of Task2\u0026#34;; }; Callable\u0026lt;String\u0026gt; task3 = () -\u0026gt; { Thread.sleep(5000); return \u0026#34;Result of Task3\u0026#34;; }; List\u0026lt;Callable\u0026lt;String\u0026gt;\u0026gt; taskList = Arrays.asList(task1, task2, task3); List\u0026lt;Future\u0026lt;String\u0026gt;\u0026gt; futures = executorService.invokeAll(taskList); for(Future\u0026lt;String\u0026gt; future: futures) { // The result is printed only after all the futures are complete. (i.e. after 5 seconds) System.out.println(future.get()); } executorService.shutdown(); } } 在上面的程序中，第一次调用 future.get() 语句会阻塞，直到所有的期货都完成。即结果将在 5 秒后打印。\n输出的结果为：\nResult of Task1 Result of Task2 Result of Task3 invokeAny方法 提交多个任务并等待其中任何一个完成.\ninvokeAny() 方法接受一个 Callables 集合并返回最快的 Callable 的结果。请注意，它不会返回 Future。\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import java.util.Arrays; import java.util.List; import java.util.concurrent.*; public class InvokeAnyExample { public static void main(String[] args) throws InterruptedException, ExecutionException { ExecutorService executorService = Executors.newFixedThreadPool(5); Callable\u0026lt;String\u0026gt; task1 = () -\u0026gt; { Thread.sleep(2000); return \u0026#34;Result of Task1\u0026#34;; }; Callable\u0026lt;String\u0026gt; task2 = () -\u0026gt; { Thread.sleep(1000); return \u0026#34;Result of Task2\u0026#34;; }; Callable\u0026lt;String\u0026gt; task3 = () -\u0026gt; { Thread.sleep(5000); return \u0026#34;Result of Task3\u0026#34;; }; // Returns the result of the fastest callable. (task2 in this case) String result = executorService.invokeAny(Arrays.asList(task1, task2, task3)); System.out.println(result); executorService.shutdown(); } } 输出如下：\nResult of Task2 Future 的局限 不能手动完成。（Future调用的任务失败了不能手动进行完成） Future 的结果在非阻塞的情况下，不能执行更进一步的操作。（无法给 Future 植入一个回调函数） 多个 Future 不能串联在一起组成链式调用。 不能组合多个 Future 的结果。 没有异常处理。 CompletableFuture简介 并发与并行的区别：\n避免阻塞，应用通过 与各种网络服务通信，替用户实时整合需要的信息，或者将整合的信息作为进一步的网络服务 提供出去。这种工作方式被称为反应式编程。\nCompletableFuture能够解决什么问题？ CompletableFuture是Java8引入的，在Java8之前一般通过Future实现异步。(但是是阻塞的)\nFuture模式可以理解成：我有一个任务，提交给了Future，Future替我完成这个任务。期间我自己可以去做任何想做的事情。一段时间之后，我就便可以从Future那儿取出结果。\nCompletableFuture具备什么功能？ 可组合。（提供thenCompose、thenCombine等各种then开头的方法） 异步。 比较 CompletableFuture是Java8引入的，在Java8之前一般通过Future实现异步。\nFuture用于表示异步计算的结果，只能通过阻塞或者轮询的方式获取结果，而且不支持设置回调方法，Java8之前若要设置回调一般会使用guava的ListenableFuture，回调的引入又会导致臭名昭著的“回调地狱”。\nCompletableFuture对Future进行了扩展，可以通过设置回调的方式处理计算结果，同时也支持组合操作，支持进一步的编排，同时一定程度解决了回调地狱的问题。\n假设有三个操作存在依赖关系，step1 -\u0026gt; step2 -\u0026gt; step3需要前面步骤执行成功再执行后面步骤。\nFuture(ListenableFuture)的实现（回调地狱）如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 ExecutorService executor = Executors.newFixedThreadPool(5); ListeningExecutorService guavaExecutor = MoreExecutors.listeningDecorator(executor); ListenableFuture\u0026lt;Object\u0026gt; future1 = guavaExecutor.submit(() -\u0026gt; { //step 1 System.out.println(\u0026#34;执行step1\u0026#34;); return true; }); Futures.addCallback(future1, new FutureCallback\u0026lt;Object\u0026gt;() { @Override public void onSuccess(Object step1Result) { ListenableFuture\u0026lt;Object\u0026gt; future2 = guavaExecutor.submit(() -\u0026gt; { System.out.println(\u0026#34;执行step 2\u0026#34;); return true; }); Futures.addCallback(future2, new FutureCallback\u0026lt;Object\u0026gt;() { @Override public void onSuccess(Object result) { ListenableFuture\u0026lt;Object\u0026gt; future3 = guavaExecutor.submit(() -\u0026gt; { System.out.println(\u0026#34;执行step 3\u0026#34;); return true; }); Futures.addCallback(future3, new FutureCallback\u0026lt;Object\u0026gt;() { @Override public void onSuccess(Object result) { System.out.println(\u0026#34;这是step 3执行结果\u0026#34;); } @Override public void onFailure(Throwable t) { } }, guavaExecutor); } @Override public void onFailure(Throwable t) { } }, guavaExecutor); System.out.println(\u0026#34;执行step2\u0026#34;); } @Override public void onFailure(Throwable throwable) { } }, guavaExecutor); CompletableFuture的实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 ExecutorService executor = Executors.newFixedThreadPool(5); CompletableFuture .supplyAsync(() -\u0026gt; { System.out.println(\u0026#34;执行step 1\u0026#34;); return new Object(); }, executor) .thenApply(result1 -\u0026gt; { System.out.println(\u0026#34;执行step 2\u0026#34;); return new Object(); }) .thenApply(result1 -\u0026gt; { System.out.println(\u0026#34;执行step 3\u0026#34;); return new Object(); }); 显然，CompletableFuture的实现要更为简洁，可读性更好。\n使用 简单使用 创建CompletableFuture：\n1 CompletableFuture\u0026lt;String\u0026gt; completableFuture = new CompletableFuture\u0026lt;String\u0026gt;(); 表示创建了一个返回值为String的CompletableFuture的对象。\n同样，类似Future，CompletableFuture也使用get方法获取返回结果，这也是阻塞的，当我们直接运行下面的语句：\n1 String result = completableFuture.get() 它将一直处于阻塞状态。\n可以使用CompletableFuture.complete()手工的完成一个 Future:\n1 completableFuture.complete(\u0026#34;Future\u0026#39;s Result\u0026#34;); 所有等待这个 Future 的客户端都将得到一个指定的结果，并且 completableFuture.complete() 之后的调用将被忽略。\nrunAsync() 这个适用于无返回值的异步执行。\nCompletableFuture.runAsync()方法，它持有一个Runnable 对象，并返回 CompletableFuture\u0026lt;Void\u0026gt;。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Run a task specified by a Runnable Object asynchronously. CompletableFuture\u0026lt;Void\u0026gt; future = CompletableFuture.runAsync(new Runnable() { @Override public void run() { // Simulate a long-running Job try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } System.out.println(\u0026#34;I\u0026#39;ll run in a separate thread than the main thread.\u0026#34;); } }); // Block and wait for the future to complete future.get() 或者：\n1 2 3 4 5 6 7 8 9 10 // Using Lambda Expression CompletableFuture\u0026lt;Void\u0026gt; future = CompletableFuture.runAsync(() -\u0026gt; { // Simulate a long-running Job try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } System.out.println(\u0026#34;I\u0026#39;ll run in a separate thread than the main thread.\u0026#34;); }); supplyAsync() 适用于有返回值的异步计算。\nCompletableFuture.supplyAsync() 持有supplier\u0026lt;T\u0026gt; 并且返回CompletableFuture\u0026lt;T\u0026gt;，T 是通过调用 传入的supplier取得的值的类型。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Run a task specified by a Supplier object asynchronously CompletableFuture\u0026lt;String\u0026gt; future = CompletableFuture.supplyAsync(new Supplier\u0026lt;String\u0026gt;() { @Override public String get() { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Result of the asynchronous computation\u0026#34;; } }); // Block and get the result of the Future String result = future.get(); System.out.println(result); 或者：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 // Run a task specified by a Supplier object asynchronously CompletableFuture\u0026lt;String\u0026gt; future = CompletableFuture.supplyAsync(new Supplier\u0026lt;String\u0026gt;() { @Override public String get() { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Result of the asynchronous computation\u0026#34;; } }); // Block and get the result of the Future String result = future.get(); System.out.println(result); 最好加上一个线程池的参数，不然默认从全局的 ForkJoinPool.commonPool()获得一个线程中执行这些任务。\n// Variations of runAsync() and supplyAsync() methods static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable) static CompletableFuture\u0026lt;Void\u0026gt; runAsync(Runnable runnable, Executor executor) static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier) static \u0026lt;U\u0026gt; CompletableFuture\u0026lt;U\u0026gt; supplyAsync(Supplier\u0026lt;U\u0026gt; supplier, Executor executor) 上面的几个方法其实还是阻塞的。它会一直等到Future完成并且在完成后返回结果。这不是我们想要的，我们想要的是在它执行完成之后调用我们自己的逻辑。对于构建异步系统，我们应该附上一个回调给CompletableFuture，当Future完成的时候，自动的获取结果。\n可以使用 thenApply(), thenAccept() 和thenRun()方法附上一个回调给CompletableFuture。\nthenApply() 实现调用链。\n使用 thenApply() 处理和改变CompletableFuture的结果。持有一个Function\u0026lt;R,T\u0026gt;作为参数。Function\u0026lt;R,T\u0026gt;是一个简单的函数式接口，接受一个T类型的参数，产出一个R类型的结果。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 // Create a CompletableFuture CompletableFuture\u0026lt;String\u0026gt; whatsYourNameFuture = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Rajeev\u0026#34;; }); // Attach a callback to the Future using thenApply() CompletableFuture\u0026lt;String\u0026gt; greetingFuture = whatsYourNameFuture.thenApply(name -\u0026gt; { return \u0026#34;Hello \u0026#34; + name; }); // Block and get the result of the future. System.out.println(greetingFuture.get()); // Hello Rajeev thenAccept() 和 thenRun() 如果你不想从你的回调函数中返回任何东西，仅仅想在Future完成后运行一些代码片段，你可以使用thenAccept() 和 thenRun()方法，这些方法经常在调用链的最末端的最后一个回调函数中使用。\nCompletableFuture.thenAccept() 持有一个Consumer\u0026lt;T\u0026gt; ，返回一个CompletableFuture\u0026lt;Void\u0026gt;。它可以访问CompletableFuture的结果：\n1 2 3 4 5 6 // thenAccept() example CompletableFuture.supplyAsync(() -\u0026gt; { return ProductService.getProductDetail(productId); }).thenAccept(product -\u0026gt; { System.out.println(\u0026#34;Got product detail from remote service \u0026#34; + product.getName()) }); 虽然thenAccept()可以访问CompletableFuture的结果，但thenRun()不能访Future的结果，它持有一个Runnable返回CompletableFuture：\n1 2 3 4 5 6 // thenRun() example CompletableFuture.supplyAsync(() -\u0026gt; { // Run some computation }).thenRun(() -\u0026gt; { // Computation Finished. }); thenCompose()-组合 组合两个独立的future。\n原来假设想从一个远程API中获取一个用户的详细信息，一旦用户信息可用，你想从另外一个服务中获取他的贷方。代码是这样的：\n1 2 3 4 5 6 7 8 9 10 11 CompletableFuture\u0026lt;User\u0026gt; getUsersDetail(String userId) { return CompletableFuture.supplyAsync(() -\u0026gt; { UserService.getUserDetails(userId); }); } CompletableFuture\u0026lt;Double\u0026gt; getCreditRating(User user) { return CompletableFuture.supplyAsync(() -\u0026gt; { CreditRatingService.getCreditRating(user); }); } 使用了thenApply()可以进行异步调用，并且代码非常简洁：\n1 2 CompletableFuture\u0026lt;CompletableFuture\u0026lt;Double\u0026gt;\u0026gt; result = getUserDetail(userId) .thenApply(user -\u0026gt; getCreditRating(user)); 在更早的示例中，Supplier函数传入thenApply将返回一个简单的值，但是在本例中，将返回一个CompletableFuture。以上示例的最终结果是一个嵌套的CompletableFuture。\n如果你想获取最终的结果给最顶层future，使用 thenCompose()方法代替\n1 2 CompletableFuture\u0026lt;Double\u0026gt; result = getUserDetail(userId) .thenCompose(user -\u0026gt; getCreditRating(user)); thenCombine()-组合操作 虽然thenCompose()被用于当一个future依赖另外一个future的时候用来组合两个future。thenCombine()被用来当两个独立的Future都完成的时候，用来做一些事情。\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 System.out.println(\u0026#34;Retrieving weight.\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; weightInKgFuture = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return 65.0; }); System.out.println(\u0026#34;Retrieving height.\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; heightInCmFuture = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return 177.8; }); System.out.println(\u0026#34;Calculating BMI.\u0026#34;); CompletableFuture\u0026lt;Double\u0026gt; combinedFuture = weightInKgFuture .thenCombine(heightInCmFuture, (weightInKg, heightInCm) -\u0026gt; { Double heightInMeter = heightInCm/100; return weightInKg/(heightInMeter*heightInMeter); }); System.out.println(\u0026#34;Your BMI is - \u0026#34; + combinedFuture.get()); 当两个Future都完成的时候，传给thenCombine()的回调函数将被调用。\n前面都是组合两个的CompletableFuture方法，可以使用以下两个方法组合任意数量的CompletableFuture。\n1 2 static CompletableFuture\u0026lt;Void\u0026gt; allOf(CompletableFuture\u0026lt;?\u0026gt;... cfs) static CompletableFuture\u0026lt;Object\u0026gt; anyOf(CompletableFuture\u0026lt;?\u0026gt;... cfs) CompletableFuture.allOf()-组合多个（全部） CompletableFuture.allOf的使用场景是当你一个列表的独立future，并且你想在它们都完成后并行的做一些事情。\n一般是一次数据的请求需要调用多个服务进行查询，可以使用这种方法加快操作的速度。但是，对于同一个服务的循环差其实没有实质性的提高。\n定义一个下载页面的方法:\n1 2 3 4 5 CompletableFuture\u0026lt;String\u0026gt; downloadWebPage(String pageLink) { return CompletableFuture.supplyAsync(() -\u0026gt; { // Code to download and return the web page\u0026#39;s content }); } 下载一个网站的100个不同的页面，使用allof方法：\n1 2 3 4 5 6 7 8 9 10 11 12 List\u0026lt;String\u0026gt; webPageLinks = Arrays.asList(...) // A list of 100 web page links // Download contents of all the web pages asynchronously List\u0026lt;CompletableFuture\u0026lt;String\u0026gt;\u0026gt; pageContentFutures = webPageLinks.stream() .map(webPageLink -\u0026gt; downloadWebPage(webPageLink)) .collect(Collectors.toList()); // Create a combined Future using allOf() CompletableFuture\u0026lt;Void\u0026gt; allFutures = CompletableFuture.allOf( pageContentFutures.toArray(new CompletableFuture[pageContentFutures.size()]) ); 使用CompletableFuture.allOf()的问题是它返回CompletableFuture。但是我们可以通过写一些额外的代码来获取所有封装的CompletableFuture结果。\n1 2 3 4 5 6 // When all the Futures are completed, call `future.join()` to get their results and collect the results in a list - CompletableFuture\u0026lt;List\u0026lt;String\u0026gt;\u0026gt; allPageContentsFuture = allFutures.thenApply(v -\u0026gt; { return pageContentFutures.stream() .map(pageContentFuture -\u0026gt; pageContentFuture.join()) .collect(Collectors.toList()); }); 当所有future完成的时候，我们调用了future.join()，因此我们不会在任何地方阻塞。\njoin()方法和get()方法非常类似，这唯一不同的地方是如果最顶层的CompletableFuture完成的时候发生了异常，它会抛出一个未经检查的异常。\n现在让我们计算包含关键字页面的数量。\n1 2 3 4 5 6 7 8 9 // Count the number of web pages having the \u0026#34;CompletableFuture\u0026#34; keyword. CompletableFuture\u0026lt;Long\u0026gt; countFuture = allPageContentsFuture.thenApply(pageContents -\u0026gt; { return pageContents.stream() .filter(pageContent -\u0026gt; pageContent.contains(\u0026#34;CompletableFuture\u0026#34;)) .count(); }); System.out.println(\u0026#34;Number of Web Pages having CompletableFuture keyword - \u0026#34; + countFuture.get()); CompletableFuture.anyOf()-组合多个（任意） CompletableFuture.anyOf()和其名字介绍的一样，当任何一个CompletableFuture完成的时候【相同的结果类型】，返回一个新的CompletableFuture。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 CompletableFuture\u0026lt;String\u0026gt; future1 = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(2); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Result of Future 1\u0026#34;; }); CompletableFuture\u0026lt;String\u0026gt; future2 = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(1); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Result of Future 2\u0026#34;; }); CompletableFuture\u0026lt;String\u0026gt; future3 = CompletableFuture.supplyAsync(() -\u0026gt; { try { TimeUnit.SECONDS.sleep(3); } catch (InterruptedException e) { throw new IllegalStateException(e); } return \u0026#34;Result of Future 3\u0026#34;; }); CompletableFuture\u0026lt;Object\u0026gt; anyOfFuture = CompletableFuture.anyOf(future1, future2, future3); System.out.println(anyOfFuture.get()); // Result of Future 2 当三个中的任何一个CompletableFuture完成， anyOfFuture就会完成。因为future2的休眠时间最少，因此她最先完成，最终的结果将是future2的结果。\nCompletableFuture.anyOf()传入一个Future可变参数，返回CompletableFuture。CompletableFuture.anyOf()的问题是如果你的CompletableFuture返回的结果是不同类型的，这时候你讲会不知道你最终CompletableFuture是什么类型。\n异常处理 1. 使用 exceptionally() 回调处理异常\nexceptionally()回调给你一个从原始Future中生成的错误恢复的机会。你可以在这里记录这个异常并返回一个默认值。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 Integer age = -1; CompletableFuture\u0026lt;String\u0026gt; maturityFuture = CompletableFuture.supplyAsync(() -\u0026gt; { if(age \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Age can not be negative\u0026#34;); } if(age \u0026gt; 18) { return \u0026#34;Adult\u0026#34;; } else { return \u0026#34;Child\u0026#34;; } }).exceptionally(ex -\u0026gt; { // 在此处打印相关的日志，返回值需要特别注意，可以返回一个指定的值，然后在后面进行过滤 System.out.println(\u0026#34;Oops! We have an exception - \u0026#34; + ex.getMessage()); return \u0026#34;Unknown!\u0026#34;; }); System.out.println(\u0026#34;Maturity : \u0026#34; + maturityFuture.get()); 2. 使用 handle() 方法处理异常\nAPI提供了一个更通用的方法 - handle()从异常恢复，无论一个异常是否发生它都会被调用。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 Integer age = -1; CompletableFuture\u0026lt;String\u0026gt; maturityFuture = CompletableFuture.supplyAsync(() -\u0026gt; { if(age \u0026lt; 0) { throw new IllegalArgumentException(\u0026#34;Age can not be negative\u0026#34;); } if(age \u0026gt; 18) { return \u0026#34;Adult\u0026#34;; } else { return \u0026#34;Child\u0026#34;; } }).handle((res, ex) -\u0026gt; { if(ex != null) { System.out.println(\u0026#34;Oops! We have an exception - \u0026#34; + ex.getMessage()); return \u0026#34;Unknown!\u0026#34;; } return res; }); System.out.println(\u0026#34;Maturity : \u0026#34; + maturityFuture.get()); 如果异常发生，res参数将是 null，否则，ex将是 null。\n区别 supplyAsync：\n当只是指定第一个参数，默认使用的线程池是 ForkJoinPool.commonPool() 当指定第二个线程池的参数，使用的是自定义的线程 supplyAsync表示开启一个有返回值的异步任务。\n可以使用 thenAccept 和 thenApply 给它增加回调函数。同样，thenAccept 和 thenApply 也有同样的异步函数thenAcceptAsync 和 thenApplyAsync ，可以让逻辑执行在设定的线程池上。\n同步和异步的区别：\n假设我们想一次向同一个接收者发送两条消息。\n1 2 3 4 CompletableFuture\u0026lt;String\u0026gt; receiver = CompletableFuture.supplyAsync(this::findReceiver); receiver.thenApply(this::sendMsg); receiver.thenApply(this::sendOtherMsg); 在上面的例子中，一切都将在同一个线程上执行。这导致最后一条消息等待第一条消息完成。\n考虑这个代码:\n1 2 3 4 5 CompletableFuture\u0026lt;String\u0026gt; receiver = CompletableFuture.supplyAsync(this::findReceiver); receiver.thenApplyAsync(this::sendMsg); receiver.thenApplyAsync(this::sendMsg); 通过使用async后缀，每个消息被作为单独的任务提交给ForkJoinPool.commonPool()。这导致在完成前面的计算时，sendMsg的回调都被执行。\n一个测试：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 //thenApply和thenApplyAsync的区别 System.out.println(\u0026#34;-------------\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; supplyAsyncWithSleep = CompletableFuture.supplyAsync(()-\u0026gt;{ try { Thread.sleep(10000); } catch (InterruptedException e) { e.printStackTrace(); } return \u0026#34;supplyAsyncWithSleep Thread Id : \u0026#34; + Thread.currentThread(); }); CompletableFuture\u0026lt;String\u0026gt; thenApply = supplyAsyncWithSleep .thenApply(name -\u0026gt; name + \u0026#34;------thenApply Thread Id : \u0026#34; + Thread.currentThread()); CompletableFuture\u0026lt;String\u0026gt; thenApplyAsync = supplyAsyncWithSleep .thenApplyAsync(name -\u0026gt; name + \u0026#34;------thenApplyAsync Thread Id : \u0026#34; + Thread.currentThread()); System.out.println(\u0026#34;Main Thread Id: \u0026#34;+ Thread.currentThread()); System.out.println(thenApply.get()); System.out.println(thenApplyAsync.get()); System.out.println(\u0026#34;-------------No Sleep\u0026#34;); CompletableFuture\u0026lt;String\u0026gt; supplyAsyncNoSleep = CompletableFuture.supplyAsync(()-\u0026gt;{ return \u0026#34;supplyAsyncNoSleep Thread Id : \u0026#34; + Thread.currentThread(); }); CompletableFuture\u0026lt;String\u0026gt; thenApplyNoSleep = supplyAsyncNoSleep .thenApply(name -\u0026gt; name + \u0026#34;------thenApply Thread Id : \u0026#34; + Thread.currentThread()); CompletableFuture\u0026lt;String\u0026gt; thenApplyAsyncNoSleep = supplyAsyncNoSleep .thenApplyAsync(name -\u0026gt; name + \u0026#34;------thenApplyAsync Thread Id : \u0026#34; + Thread.currentThread()); System.out.println(\u0026#34;Main Thread Id: \u0026#34;+ Thread.currentThread()); System.out.println(thenApplyNoSleep.get()); System.out.println(thenApplyAsyncNoSleep.get()); 分别测试执行不同处理速度的代码，thenApply 和 thenApplyAsync 使用的是哪个线程：\n------------- Main Thread Id: Thread[main,5,main] supplyAsyncWithSleep Thread Id : Thread[ForkJoinPool.commonPool-worker-9,5,main]------thenApply Thread Id : Thread[ForkJoinPool.commonPool-worker-9,5,main] supplyAsyncWithSleep Thread Id : Thread[ForkJoinPool.commonPool-worker-9,5,main]------thenApplyAsync Thread Id : Thread[ForkJoinPool.commonPool-worker-9,5,main] -------------No Sleep Main Thread Id: Thread[main,5,main] supplyAsyncNoSleep Thread Id : Thread[ForkJoinPool.commonPool-worker-2,5,main]------thenApply Thread Id : Thread[main,5,main] supplyAsyncNoSleep Thread Id : Thread[ForkJoinPool.commonPool-worker-2,5,main]------thenApplyAsync Thread Id : Thread[ForkJoinPool.commonPool-worker-2,5,main] 可以看到\nsupplyAsync方法执行速度慢的话thenApply方法执行线程和supplyAsync 执行线程相同 supplyAsync 方法执行速度快的话，那么thenApply方法执行线程和Main方法执行线程相同 返回值 方法名 是否可获得前一个任务的返回值 是否有返回值 thenApply 能获得 有 thenAccept 能获得 无 thenRun 不可获得 无 所以一般来说thenAccept 、thenRun 这两个方法在调用链的最末端使用。\n二元依赖 thenCombine:两个异步方法得出来值的情况下才能进行计算 thenCompose:二个定时任务需要用到第一个定时任务的返回值 runAfterBoth 二选一：acceptEither\nfirstSource.acceptEither(secondSource, this::sendMsg);\n总结 CompletableFuture使用get方法和join方法会阻塞后续的操作。 不阻塞的话并且不需要返回值可以直接不显示的使用get方法和join方法。 使用场景 你以前可能接触过 CompletableFuture 对象背后的概念，在其他语言中这被 叫作延迟对象或约定。在Google Guava类库和Spring框架中，这被叫作 ListenableFutures。\n多服务调用 实际的情况可能是这样子\n多线程组装数据。 每一个分片数据都用一个CompletableFuture执行。\nJoin，它的作用和 get 方法 是一样的，而且它没有使用 get 方法时令人倒胃口的检查异常。\njoin抛出unchecker异常，而get抛出checked异常\n混合使Stream和CompletableFuture的时候需要注意⚠️：\n考虑操作之间的延迟特性，如何你在单一流水线中处理流，每个创建CompletableFuture 对象只能在前一个操作结束之后才能创建。\n最好是将CompletableFuture先聚集到一个列表中。然后再屌用join。\n原理 通常，设计和理解并发系统最好的方式是使用图形:\n上面的图形可以使用下面的代码来实现：\n1 2 int t = p(x); System.out.println( r(q1(t), q2(t)) ); 使用Future方法：\n1 2 3 4 int t = p(x); Future\u0026lt;Integer\u0026gt; a1 = executorService.submit(() -\u0026gt; q1(t)); Future\u0026lt;Integer\u0026gt; a2 = executorService.submit(() -\u0026gt; q2(t)); System.out.println( r(a1.get(),a2.get())); CompletableFuture使用的是一种观察者模式进行实现的。\n使用CompletableFuture也是构建依赖树的过程，一个CompletableFuture的完成会触发另外一系列依赖它的CompletableFuture的执行：\nJava实战 我们实际的开发过程中，总是需要调用多个服务，假如没有使用并发进行编程，那么，在一个服务返回结果之前，这都是阻塞的，不能执行其他的任务。然而，你并不希望由于要等待远程服务的响应，阻塞现有的计算任务并白白浪费 CPU 中数十亿个宝贵的时􏲁􏵑期。譬 如，你不应该由于要等待 Facebook 数据的返回而􏵒止对 Twitter 数据的处理。\nJava的并发之路 一开始就提供了锁(通过 synchronized 类和方法)、Runnable 以及线程。 2004 年， Java 5 又引入了 java.util.concurrent 包。（引入ExecutorService、Callable以及 Future） Java 7 为了使用 fork/join 实现分而􏵬之算法，新 增了java.util.concurrent.RecursiveTask Java 8则增加了对流和流的并行处理(依赖于新增的 Lambda 表达式)的支持 Java 8还支持组合式的Future(基于Java 8CompleteFuture实现的Future） Java 9 提供了对分布式异步编程的显式支持。（通过 java.util.concurrent.Flow 接口） CompletableFuture 及 java.util.concurrent.Flow 的关键理念是提供一种程序结构，让相互独立的任务尽可能地并发执行，通过这种方式最大化地利用多核或者多台机器提供的并发能力。\n多线程并发内幕 在一个多核的环境中，单用户登录的笔记本电脑上可能只启动了一个用户进程，这种程序永远不能充分发挥计算机的处理能力，除非使用多线程。虽然每个核可以服务一个或多个进程或线程，但是如果你的程序并未使用多线程，那它同一时刻能有效使用的只有处理器众多核中的一个。\n这需要我们在编写代码的时候注意使用多线程并发编程，以充分发挥计算机的处理能力。\n线程的问题\nJava 线程直接访问操作系统的线程。这里主要的问题在于创建和􏳒除操作系统线程的代价很 大(涉及页表操作)，并且一个系统中能创建的线程数目是有限的。如果创建的线程数超过操作系统的限制，很可能导致 Java 应用莫名其妙地崩溃，因此你需要特别留意，不要在线程运行时 持续不断地创建新线程。并且操作系统(以及 Java)的线程数都远远大于硬件线程数，因此即便一些操作系统线程被阻塞了，或者处于睡眠状态。\n线程池的优势\nJava 的 ExecutorService 提供了一个接口，用户可以提交任务并获取它们的执行结果。新创建 的线程会被放入一个线程池，每次有新任务请求时，以先来先到的􏵼略从线程池中选取未被使用 的线程执行提交的任务请求。任务执行完毕之后，这些线程又会被归还给线程池。这种方式的最大优势在于能以很低的成本向线程池提交上千个任务，同时保证硬件匹配的任务执行。\n线程池的不足\n使用 k 个线程的线程池只能并发地执行 k 个任务\n提交的任务如果超过这个限制，线程池不会创建新线程去执行该任务，这些超限的任务会被加入等待队列，直到现有任务执行 完毕才会重新调度空闲线程去执行新任务。\n采用这种方式时你 需要特别留意任务是否存在会进入睡眠、等待 I/O 结􏰅或者等待网络连接的情况。一旦发 生阻塞式 I/O，这些任务占用了线程，却会由于等待无法执行有价值的工作。\n例如，假如CPU有4个硬件线程，你创建了一个大小为5的线程池，你一次性提交了 20 个执行任务，希望这20个任务并发的执行，直到所有 20 个任务执行完毕。假设首批提交的 线程中有 3 个线程进入了阻塞状态或者在等待 I/O，那就只剩2 个线程可以服务剩下的 15 个任务了。如此一来，你只能取得你之前预期吞吐量的一半(如果你创建的线程池中工 作线程数为 8，那么还是能取得同样预期吞吐量的)。\n通常情况下，Java 从 main 返回之前，都会等待所有的线程执行完毕，从而避免误杀正在执行关键代码的线程。\n实际操作时的一个好习惯是在退出程序执行之前，确保关闭每一个线程池。\n你希望采用线程技术理程序的结构，以便在需要的时候享受程序并行带来的好处，生成足够多的任务以充分利用所有硬件线程。这意味着你需要对程序进行切分。\n使多线程的演进过程 多于函数 f(x) 和 g(x)，分别使用一个线程去并发执行。\n使用Runnable：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class ThreadExample { public static void main(String[] args) throws InterruptedException { int x = 1337; Result result = new Result(); Thread t1 = new Thread(() -\u0026gt; { result.left = f(x); } ); Thread t2 = new Thread(() -\u0026gt; { result.right = g(x); }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(result.left + result.right); } private static class Result { private int left; private int right; } } 使用线程池和Future：\n1 2 3 4 5 6 7 8 9 10 public class ExecutorServiceExample { public static void main(String[] args) throws ExecutionException, InterruptedException { int x = 1337; ExecutorService executorService = Executors.newFixedThreadPool(2); Future\u0026lt;Integer\u0026gt; y = executorService.submit(() -\u0026gt; f(x)); Future\u0026lt;Integer\u0026gt; z = executorService.submit(() -\u0026gt; g(x)); System.out.println(y.get() + z.get()); executorService.shutdown(); } } 然而，这段代码依然受到了显式调用 submit 时使用的模板代码的污染。也就是说，其实这个枯燥的操作其实也是可以省略的。\n解决这个问题的答案是将 API 由同步 API 变为步 API，也就是增加异步的API函数。\n使用线程池和CompletableFuture：\n1 2 3 4 5 6 7 8 9 10 11 public class ExecutorServiceExample { public static void main(String[] args) throws ExecutionException, InterruptedException { int x = 1337; ExecutorService executorService = Executors.newFixedThreadPool(2); CompletableFuture\u0026lt;Integer\u0026gt; y = CompletableFuture.supplyAsync(() -\u0026gt; f(x),executorService); CompletableFuture\u0026lt;Integer\u0026gt; z = CompletableFuture.supplyAsync(() -\u0026gt; g(x),executorService); CompletableFuture\u0026lt;Integer\u0026gt; result = y.thenCombine(z,(y_val,z_val) -\u0026gt; {return y_val + z_val;} ) System.out.println(result.get()); executorService.shutdown(); } } 使用反应式的API：(基于回调函数)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 public class CallbackStyleExample { public static void main(String[] args) { System.out.println((result.left + result.right)); int x = 1337; Result result = new Result(); f(x, (int y) -\u0026gt; { result.left = y; }); g(x, (int z) -\u0026gt; { result.right = z; System.out.println((result.left + result.right)); 7 }); } } 注意，反应式编程允许方法 f 和 g 多次调用它们的回调函数 dealWithResult。而原始版\n本的 f 和 g 使用 return 返回结果，return 只能被调用一次。Future 与此类似，它也只能完 成一次，执行 Future 的计算结果可以通过 get()方法获取。\n可能阻塞线程的因素 阻塞式操作可以分为两类:\n一类是等待另一个任务执行，譬如调用 Future 的 get()方法; 另一类是等待与外部交互的返回，譬如从网络、数据库服务器或者键盘这样的人机接口读取数据。 睡眠也会阻塞。\n学习并发的模式 通常，设计和理解并发系统最好的方式是使用图形。我们将这种技术称线程-管道 (box-and-channel)模型。\n这其实是观察者模式的一种实现。\n使用CompletableFuture CompletableFuture和并行流的实现方式类似的，它们内部都是调用多线程进行执行，然而CompletableFuture可以允许设置线程池，指定线程的数量（线程池的大小），并且支持组合模式。\n并行流是把内容拆分成多个数据块，用不同线程处理每个数据块的数据。这样以来，就可以自动的把工作的负荷分配到多核处理器的所有核，让他们都忙起来。\n使用Async还是同步API的判断标准：\n一般情况下操作不涉及远程服务和I/O操作，可以采用同步API 其他耗时的操作可以使用异步API。 通常而言，名称中不带Async的方法和它的前一个任务一样，在同一个线程中运行，而名称以Async结尾的方法会将后续的任务提交到一个线程池，所以每个任务是由不同的线程处理的。对于不复杂的延迟低的操作，尽量复用同一个进程，减少进程间切换的开销。\nJava中的线程池 参考：《Java并发编程的艺术》\n线程池的好处 降低资源损耗。 提高响应速度。 提高线程的可管理性。 Reference:\n彻底理解Java的Future模式 - 大诚挚 - 博客园 CompletableFuture的原理与实践-记外卖商家端API的异步化 Java 8 CompletableFuture 教程 - SegmentFault 思否 关于实现Runnable接口不能抛异常只能捕获异常原因_小林子的博客-CSDN博客 Java Callable and Future Tutorial | CalliCoder ~ Java可调用和未来教程 | CalliCoder 使用CompletableFuture异步组装数据 Java: Writing asynchronous code with CompletableFuture Java8——异步编程 - Mr.墨斗的博客 | MoDou Blog ","description":"","id":4,"section":"posts","tags":["Java","CompletableFuture"],"title":"CompletableFuture笔记","uri":"https://hugo.jiahongw.com/posts/java/completablefuture/"},{"content":"设计原则 1.单一职责原则\n2.开闭原则\n3.里氏替换原则\n4.依赖注入原则\n5.接口分离原则\n6.迪米特原则\n将变化的东西抽离出来并且封装，一方面和原来的逻辑解耦，另一方面，便于后面进行修改。\n如何判断单一职责？\n代码的函数太多，函数或者属性过多 依赖其他类过多 私有方法过多 比较难给类起一个合适名字，很难用一个业务名词概括，或者只能用一些笼统的 Manager、Context 之类的词语来命名 类中大量的方法都是集中操作类中的某几个属性 如何理解开闭原则？\n只要对原来的代码侵入性不大，不影响主要流水，都是一个合格的拓展代码\n设计模式 简单工厂模式 Simple Factory Pattern\n中文\t英文\n创建型模式：\n1.工厂方法模式\tFactory Method Pattern\n2.抽象工厂模式\tAbstract Factory Pattern\n3.建造者模式\tBuilder Pattern\n4.原型模式\tPrototype Pattern\n5.单例模式\tSingleton Pattern\n结构型模式：\n6.适配器模式\tAdapter Pattern\n7.桥梁模式/桥接模式\tBridge Pattern\n8.组合模式\tComposite Pattern\n9.装饰模式\tDecorator Pattern\n10.门面模式/外观模式\tFacade Pattern\n11.享元模式\tFlyweight Pattern\n12.代理模式\tProxy pattern\n行为模式：\n13.责任链模式\tChain of Responsibility Pattern\n14.命令模式\tCommand Pattern\n15.解释器模式\tInterpreter Pattern\n16.迭代器模式\tIterator Pattern\n17.中介者模式\tMediator Pattern\n18.备忘录模式\tMemento Pattern\n19.观察者模式\tObserver Pattern\n20状态模式\tState Pattern\n21.策略模式\tStrategy Pattern\n22.模板方法模式\tTemplate Method Pattern\n23.访问者模式\tVisitor Pattern\n理论 是否因该为每一个类都定义接口 不应该，应该根据实际的需要。\n“基于接口编程而不是基于实现编程”更详细的说法应该是“基于抽象编程而不是基于实现编程”。因为考虑到有一些语言类戏C和C++都没有接口interface这种结构。（设计的时候不要一开始就和具体的编程语言进行挂钩）\n做任何事情都不要一板子拍死，不要过度使用原则，每个类都定义接口，接口必定满天飞，后期管理也困难。\n从设计初衷来看，如果在我们的业务场景中，某个功能只有一种实现方式，未来也不可能被其他实现方式替换，那我们就没有必要为它设计接口，也没有必要基于接口编程，直接使用实现类就行。（主要看有么有必要进行拓展，要拓展的话使用接口编程会更好）\n实战 基于贫血模型的MVC 业务开发常用的基于贫血模型的MVC框架违背了OOP。\n什么是基于贫血的传统开发模式？\n平时开发Web后端项目的时候，基本上是这么组织代码的：其中Entity和Repository组成了数据访问层，Bo和Service组成了业务逻辑层，Vo和Controller属于接口层。\nBo是一个纯粹的数据结构，只包含数据，不包含任何业务逻辑。业务逻辑集中在Service中。通过Service来操作Bo。像Bo这样，只包含数据，不包含业务逻辑的类，就叫做贫血模型。同理，Entity和Vo也都是基于贫血模型设计的。贫血模型将数据与操作分离，破坏了面向对象的封装性，是一种典型的面相过程的编程风格。\n什么是基于充血模型的DDD开发模式？\n在贫血模型中，数据和操作逻辑被分离到两个类中；充血模型正好相反，数据和对应的业务逻辑被封装到同一个类中。因此，充血模型满足面向对象的封装特性，是典型的面向对象编程风格。\n什么是领域驱动设计？\n领域驱动设计即DDD，主要是用来指导如何解耦业务系统，划分业务模块，定义业务领域模型及其交互。\n实际上，基于充血模型的DDD开发模式实现的代码，也是按照MVC三层架构分层的。Controller还是负责暴露接口，Repository还是负责数据存取，Service层负责核心业务逻辑。它和基于贫血模型的开发模式的区别主要在Service层。\n在基于充血模型的DDD开发模式中，Service层包含Service类和Domain类两部分。Domain类相当于贫血模型中的Bo。但是，Domain和Bo的区别在于Domain是基于充血模型开发的，即包含数据，也包含业务逻辑。而Service类变得非常单薄。总结一下：基于贫血的传统开发模式，重Service轻Bo；基于充血模型的DDD开发模式，轻Service重Domain。\n区别于Domain的职责，Service类主要有下面的几个职责（为什么没有将Service类去掉）：\nService负责和Repository交流。获取数据之后，才转换成领域模型进行操作。或者领域模型计算完成之后，再通过Service调用Repository进行存储。（保证领域模型的独立性） Service类负责跨领域模型的聚合功能。 Service类负责一些非功能性及第三方系统交互的工作。比如幂等、事务、发邮件、发消息、记录日志、调用系统服务的RPC接口等。 Controller层和Repository层还是基于贫血模型，但是没有必要修改成DDD模式，因为这两个层的逻辑本来就比较单一，没必要使用充血模型。\n为什么贫血模型那么受欢迎\n贫血模型简单，业务简单。充血模型难，考虑的地方多。 思维固化，转型有成本。 什么项目应该考虑使用基于充血模型的DDD开发模式？\n基于贫血模型的传统开发模式适合业务逻辑比较简单的项目，而基于充血模型的DDD开发模式适合业务复杂的系统项目。比如，包含各种利息计算模型、还款模型等复杂业务的金融系统。\nDDD开发模式需要我们前期做大量的业务调研、领域模型设计，所以它更适合复杂系统的开发。\n接口鉴权功能面向对象分析 OOA：面向对象分析\nOOD：面向对象设计\nOOP：面向对象编程\n面向对象分析步骤：\n基础分析 分析优化 继续分析优化 面向对象设计步骤：\n划分职责进而识别出有哪些类 定义类及其属性和方法 定义类与类之间的交互关系 将类组装起来并提供执行入口 Reference：\n创建型模式 — Graphic Design Patterns ","description":"设计模式基于设计原则。","id":5,"section":"posts","tags":["设计模式","设计原则"],"title":"设计模式小记","uri":"https://hugo.jiahongw.com/posts/designpattern/design-pattern-note/"},{"content":"定义 代理模式为另一个对象提供一个替身或者占位符以控制这个对象的访问。\n框架 @startuml \u0026#39; 代理模式 interface Subject { request() } class RealSubject implements Subject { + request() } class Proxy implements Subject { + request() } Proxy -\u0026gt; RealSubject : subject @enduml 使用场景 代理的几种模式：\n远程代理：远程代理可以作为另一个JVM上对象的本地代表。常见的是RPC框架。 虚拟代理：虚拟代理作为创建开销大的对象的代表。当对象没有得到的情况下执行一些操作。常见的是图片的加载。 缓存代理：缓存代理会维护之前的对象，在可能的情况下会返回缓存对象。 保护代理：可以根据客户的角色来决定是否允许客户访问特定的方法。（Java动态代理） 其他代理：\n防火墙代理：控制网络资源的访问，保护访问坏网络。 智能引用代理：例如计算一个对象被引用的次数。 同步代理：在多线程的情况下为主题提供安全的访问。 写入时复制代理：用于控制对象的复制，方法是延迟对象的复制，发那个客户真的需要（也就是需要写入时）才进行复制。是虚拟代理的变体。（Java5的CopyOnWriteArrayList） 区别 装饰器模式是为对象增加行为，而代理模式是控制对象的访问。 适配器会改变对象适配的接口，而代理则实现相同的接口。 Reference:\n","description":"代理模式为另一个对象提供一个替身或者占位符以控制这个对象的访问。","id":6,"section":"posts","tags":["设计模式","代理模式"],"title":"代理模式","uri":"https://hugo.jiahongw.com/posts/designpattern/proxypattern/"},{"content":" 组合模式跟我们之前讲的面向对象设计中的“组合关系(通过组合来组装两个类)”，完全是两码事。这里讲的“组合模式”，主要是用来处理树形结构数据。\n定义 组合模式允许你将对象组合成树形结构来表示“整体/部分”的层次结构。组合能够让客户以一致的方式处理个别对象以及对象组合。\n架构 @startuml \u0026#39;https://plantuml.com/class-diagram class Client class Component { + operation() + add(Component) + remove(Component) + getChild(int) } class Leaf extends Component { + operation() } note bottom of Leaf : 叶子节点没有孩子 class Composite extends Component { + operation() + add(Component) + remove(Component) + getChild(int) } note bottom of Composite : 组合节点具有叶子节点，也依赖Component接口 Client -\u0026gt; Component @enduml 使用场景 使用组合模式的前提在于，你的业务场景必须能够表示成树形结构。所以，组合模式的应用场景也比较局限，它并不是一种很常用的设计模式。\n理解“整体和部分”的关系。\nReference:\n","description":"","id":7,"section":"posts","tags":[null],"title":"组合模式","uri":"https://hugo.jiahongw.com/posts/designpattern/compositepattern/"},{"content":" 迭代器模式也叫游标模式。\n定义 迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示。\n迭代器模式封装了遍历。并且迭代器模式还将在元素之间进行游走的责任交给迭代器，使得职责更加单一。\n架构 @startuml class Client interface Collection { + createIterator() } class ConcreteCollection implements Collection { + createIterator() } interface Iterator { + hasNext() + next() + remove() } class ConcreteIterator implements Iterator{ + hasNext() + next() + remove() } Client -left-\u0026gt; Collection Client -right-\u0026gt; Iterator ConcreteCollection -right-\u0026gt; ConcreteIterator @enduml 使用场景 Java Iterator 解耦容器代码和遍历代码，使得职责更加单一 问题 Java中如果使用迭代器的同时删除容器中的元素，会导致迭代器的错误，这是为什么？如何解决呢？\n不只是删除容器，增加元素也可能会出现问题。\n在使用迭代器遍历到后面的元素时，删除了前面的元素，会导致遍历元素少了一个。(2被跳过了)\n在使用迭代器遍历到后面的元素时，在前面增加了元素，会导致前面遍历的一个元素又遍历了一次。（1重复遍历了）\n如何解决？\nJava语言中的解决方法是增删元素之后，让遍历报错。\n在 ArrayList 中定义一个成员变量 modCount，记录集合被修改的次数，集合每调用一次增加或删除元素的函数，就会给 modCount 加 1。当通过调用集合上的 iterator() 函数来创建迭代器的时候，我们把 modCount 值传递给迭代器的 expectedModCount 成员变量，之后每次调用迭代器上的 hasNext()、next()、currentItem() 函数，我们都会检查集合上的 modCount 是否等于 expectedModCount，也就是看，在创建完迭代器之后，modCount 是否改变过。\n如果两个值不相同，那就说明集合存储的元素已经改变了，要么增加了元素，要么删除了元 素，之前创建的迭代器已经不能正确运行了，直接抛出错误让程序员解决。\n迭代器内部也实现了一个remove() 方法，能够在遍历集合的同时，安全地删除集合中的元素。它作用有限，只能删除游标指向的前一个元素，而且一个 next() 函数之后，只能跟着最多一个 remove() 操 作，多次调用 remove() 操作会报错。\n区别和关系 你可以使用迭代器模式来遍历组合模式树。 Reference:\n","description":"迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示。","id":8,"section":"posts","tags":["设计模式","迭代器模式"],"title":"迭代器模式","uri":"https://hugo.jiahongw.com/posts/designpattern/iteratorpattern/"},{"content":" 定义 模板方法模式在一个方法中定义一个算法的架构，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。\n模板方法模式体现了好莱坞原则：别调用我们，我们会调用你。简单的说，模板方法的抽象类会告诉子类，你不要调用我们，我们会调用你。\n使用场景 模板方法模式还可以在抽象类中定义一个什么都不做的函数步骤，子类根据情况考虑是否实现这个接口，而这个接口就是一个钩子，可以在模板步骤的指定位置做一些事。\nJava中的排序算法也是一种模板方法，排序的列表元素类型需要实现compareTo方法，这就类似模板方法里面的一个步骤。实现了之后，才能完成排序的过程。\n1 复用\n因为模板方法是基于继承实现，可以将固定的算法步骤封装在抽象类，抽象类可以实现一些固定的步骤，子类直接进行复用就可以了。\n例子：Java中的InputStream的read()函数(子类实现参数不同的read函数)和AbstractList的addAll()函数(子类实现add函数)。\n2 框架拓展性\nHttpServlet的service()方法就是一个模板方法，它实现了整个http请求的执行流程，而doGet()和doPost()是模板中可以由子类自定义的部分。相当于框架为用户提供了拓展点，使得不需要修改框架源码就能将拓展点添加到框架中。 Junit框架也提供了一些功能拓展点setUp()和setDown()，可以在开始和结束的时候做一些事情，而runBase()函数是一个模板方法，定义了执行测试用例的整体流程。 架构 @startuml \u0026#39;https://plantuml.com/class-diagram abstract class AbstractClass { + templateMethod() + stepOperation1() + {abstract} stepOperation2() + stepOperation3() } note right of AbstractClass::templateMethod 模板方法定义算法步骤： stepOperation1(); stepOperation2(); stepOperation3(); end note class ConcreteClassB extends AbstractClass { + stepOperation2() } class ConcreteClassA extends AbstractClass { + stepOperation2() } note right of ConcreteClassB::stepOperation2 子类实现一个或者多个具体的步骤 end note @enduml 模板方法可以配合范型进行使用：\n1 2 3 4 5 6 7 8 9 public class AbstractService\u0026lt;T, L\u0026gt; { protected abstract T getData(int x); public void calAndSaveTransaction(T t,L l); } public ConcreteService implements AbstractService\u0026lt;String, Integer\u0026gt; { ... } 区别 策略模式和模板方法模式都封装算法，但是一个组合，一个继承。 工厂方法是模板方法的一个特殊版本。 Reference:\n","description":"模板方法模式是对抽象的有一种体现，这次，抽象的是算法流程。模板方法定义了一个算法的步骤，将允许子类为一个或者多个步骤提供实现。","id":9,"section":"posts","tags":["设计模式","模板方法模式"],"title":"模板方法模式","uri":"https://hugo.jiahongw.com/posts/designpattern/templatemethodpattern/"},{"content":" 定义 外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。\n外观模式可以解决接口的复用性和易用性的问题，并且，外观模式可以让层级更加清晰，满足最少知识原则，让暴露的接口或者函数更加少。\n使用场景 1 解决易用性\n当接口越来越多，越来越复杂的时候，提供一层更加简单易用，更加高层的接口。例子：Linux系统调用函数封装了Linux内核调用、Linux的Shell命令封装了复杂的系统调用。\n单独起起一个API网关层服务做转发和聚合也很类似门面设计模式。\n2 解决性能问题\n将多个接口调用封装成一个简单的门面接口，在一些需要多次请求的网络通信中可以减少通信的次数，降低网络通信的成本，提高APP响应的速度。\n经验：\n如果门面接口不多，此时可以将门面接口和原来的接口放在同一个类中，不需要特殊的标记；如果门面接口很多，可以在已有的接口之上，再重新抽象出一层，转门放置门面接口，可以新建一个类或者包；如果门面接口特别多了，并且很多都是跨多个子系统的，可以将门面系统接口放到一个新的子系统中。\n3 解决分布式事务问题\n门面接口可以将一个事务的多个接口封装在一个接口中，方面进行事务的回滚或者重试。\n架构 @startuml \u0026#39;https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026#34;子系统\u0026#34; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml 比较 适配器是做接口转换，解决的是原接口和目标接口不匹配的问题。门面模式做接口整合，解决的是多接口调用带来的问题。 适配器模式注重的是兼容性，而门面模式注重的是易用性。 Reference:\n","description":"外观模式也叫做门面模式，外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。","id":10,"section":"posts","tags":["设计模式","外观模式","门面模式"],"title":"外观模式","uri":"https://hugo.jiahongw.com/posts/designpattern/facadepattern/"},{"content":" 定义 适配器将一个类的接口，转换成客户端期望的另一个接口。适配器让原本不兼容的类达到兼容。\n（可以让客户从实现的接口解耦）\n适配器模式下必须有一个接口的”转换“过程。\n形象的比喻：USB转接头就是一个适配器！\n架构 @startuml \u0026#39; 适配器模式 class client interface Targert { + request() } note top of Targert : 目标接口 class Adaptor implements Targert { + request() } note bottom of Adaptor : 适配器实现目标接口 class Adaptee { + specificRequest() } Adaptor -\u0026gt; Adaptee : 并且包含被适配的接口对象 client -\u0026gt; Targert @enduml 上面的是对象适配器的架构，在支持多重继承的语言中，可以使用类适配器：\n@startuml \u0026#39; 适配器模式 class client interface Targert { + request() } note top of Targert : 目标接口 class Adaptor implements Targert,Adaptee { + request() } class Adaptee { + specificRequest() } client -\u0026gt; Targert @enduml 使用场景 一般来说，适配器模式可以看作是一宗“补偿模式”，用来补救设计上的缺陷，也是一种无奈之举。一般也不会优先推荐使用这种模式。\n主要场景 1 封装有缺陷的接口设计\n例如外部引入的接口都是静态方法，会影响代码的可测试性。此时使用适配器进行适配接口，将静态方法都“封装“起来，这样就可以进行测试了。\n2 替换依赖的外部系统\n当需要将外部依赖的一个系统替换成另一个系统的时候，也就是一些系统迁移或者接口切换的场景，使用适配器模式可以减少对代码的改动。\n@startuml \u0026#39; 适配器模式 interface IA { + fa() } note top of IA : 系统A interface IB { + fb() } note top of IB : 系统B class Client class BAdaptor implements IA { IB b + fa() } note left of BAdaptor : 实际fa函数调用fb函数 BAdaptor -\u0026gt; IB Client -\u0026gt; IA @enduml 3 兼容老版本的接口\n在进行一些版本升级的时候，对于一些废弃的接口，我们不会直接删除，而是暂时保留，并且标注为deprecate，并且将内部实现逻辑委托为新的实现逻辑。\n例如JDK中包含一个遍历集合容器的类Enumeration，JDK2.0对这个类进行了重构，将它改名为Iterator类，并且对它的代码实现做了优化。但是如果将Enumeration直接从JDK2.0删除，那么那些从JDK1.0升级到JDK2.0的项目，就会编译报错。但是修改散落在各处的Enumeration调用又多又杂，导致升级困难。为了避免这种情况，可以暂时保留Enumeration类，并且将其内部实现替换为Iterator的实现。下面是一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Collections { public static Emueration emumeration(final Collection c) { return new Enumeration() { Iterator i = c.iterator(); public boolean hasMoreElments() { return i.hashNext(); } public Object nextElement() { return i.next(): } } } } 适配器模式在Java日志中的应用 Slf4j这个日志框架相当于JDBC规范，提供了一套打印日志的统一接口规范。但是，它只定义了接口，没有具体的实现，需要配合其他日志框架(log4j、logback、JUL)来使用。Slf4j的出现稍晚于这些框架，为了适配原来的日志框架，Slf4j框架不仅提供可统一的接口定义，还提供了针对不同日志框架的适配器。对不同的日志框架接口进行二次封装，适配成统一的Slf4j接口定义。\n比较 装饰器和适配器的区别：\n装饰器包装一个实现同一个接口的类对象，添加一些责任，并且接口不变；适配器则包装实现不同接口的被适配的对象，进行接口的转换和适配，以达到兼容的效果。\n实现都差不多，主要还是设计的思想大不同。\nReference:\n《Head First 设计模式》 ","description":"适配器使得新的调用可以适配老的接口而不需要修改旧的代码。达到了对拓展开发，对修改关闭的设计原则。","id":11,"section":"posts","tags":["设计模式","适配器模式"],"title":"适配器模式","uri":"https://hugo.jiahongw.com/posts/designpattern/adaptorpattern/"},{"content":" 定义 命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。\n命令模式主要是将“命令的请求者”从“命令的执行者”对象中解耦。\n应用场景 异步、延迟、排队执行命令、撤销重做命令、存储命令、命令记录日志 Hystix熔断框架就用到了命令模式 redis使用命令模式处理指令 架构 @startuml class client class Invoker { + setCommand() } interface Command { + execute() + undo() } class ConcreteCommand implements Command{ + execute() + undo() } class Receiver { + action() } Invoker -\u0026gt; Command Receiver \u0026lt;- ConcreteCommand client -\u0026gt; Receiver client -\u0026gt; ConcreteCommand @enduml 命令模式对象可以包含接受者的引用，也可以不包含，因为在远程调用的情况下，不能获取引用。\nReference:\n","description":"命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。","id":12,"section":"posts","tags":["设计模式","命令模式"],"title":"命令模式","uri":"https://hugo.jiahongw.com/posts/designpattern/commandpattern/"},{"content":" 类图绘制 参考：【程序员小知识】使用 PlantUML 画 UML（上）类图 - 掘金\n一览：\n需要注意，一组@startuml/@enduml 对应一张 png，如果一个文件中有多组，则生成的 png 文件名会添加自增数字后缀。 此外也可以紧跟在 @startuml 之后指定文件名：\n@startuml foo class Foo @enduml @startuml bar class Bar @enduml @startuml baz class Baz @enduml 注释 \u0026#39; 这是注释 可以使用 note left of , note right of , note top of , note bottom of 等关键字定义相对于对象位置的注释。\n标题 \u0026#39; 标题为Hello Title title Hello Title 图注 caption 图１ 脚注 footer World 放大率 @startuml scale-1.5 scale 1.5 Hello \u0026lt;|-- World @enduml 定义常见结构 \u0026#39; 定义类hello class Hello \u0026#39; 定义接口hello interface Hello \u0026#39; 定义抽象类hello abstract Hello \u0026#39; 定义枚举 enum HelloWorld { ONE TWO THREE } @startuml \u0026#39; 定义类hello class Hello \u0026#39; 定义接口hello interface Hello \u0026#39; 定义抽象类hello abstract Hello \u0026#39; 定义枚举 enum HelloWorld { ONE TWO THREE } @enduml UML中类型之间有六大关系：\n泛化（Generalization） 实现（Realization） 关联（Association) 聚合（Aggregation） 组合(Composition) 依赖(Dependency) 泛化（继承） \u0026lt;|-- --|\u0026gt; 指定继承关系\n@startuml Child --|\u0026gt; Parent Parent2 \u0026lt;|-- Child2 @enduml @startuml Child --|\u0026gt; Parent Parent2 \u0026lt;|-- Child2 @enduml 使用extends 关键字也可以\n实现 ..|\u0026gt;, \u0026lt;|.. ， 圆点表示虚线\n@startuml Plane ..|\u0026gt; Flyable Flyable \u0026lt;|.. Plane @enduml @startuml Plane ..|\u0026gt; Flyable Flyable \u0026lt;|.. Plane @enduml 使用implements 关键字也可以。\n依赖 @startuml Chef ..\u0026gt; Recipe @enduml @startuml Chef ..\u0026gt; Recipe @enduml 依赖表示使用关系，java中, 被依赖的对象/类, 以方法参数, 局部变量和静态方法调用的形式出现。比如, 厨师在烹饪的时候看了一眼菜谱, 厨师\u0026quot;使用\u0026quot;了菜谱, 照着它炒完菜后，这种使用关系就结束了(临时性).\n关联 关联关系，表示\u0026quot;拥有\u0026quot;。 相比依赖关系的临时性和单向性，关联关系具有长期性、平等性(可双向)，所以关联表示的关系比依赖更强。比如现实生活中的夫妻, 师生等关系。长期存在并且是相互的关系。 此外关联可以表示一对一，一对多，多对一，多对多等各种关系。\n@startuml Address \u0026lt;-- Husband Husband \u0026lt;--\u0026gt; Wife Husband2 -- Wife2 @enduml @startuml Address \u0026lt;-- Husband Husband \u0026lt;--\u0026gt; Wife Husband2 -- Wife2 @enduml 聚合 聚合关系相对于组合弱一些，整体与部分是可分离的。 比如部门与员工，部门有许多员工，员工离职了部门仍然存在，不受影响。反之部门解散了，员工可以去其他部门(整体与部分可分离)\n@startuml Department o-- Employee @enduml o 表示空心菱形\n@startuml Department o-- Employee @enduml 组合 组合关系中，整体与部分是不可分离的，整体与部分的生命周期保持一致，少了对方自己的存在无意义。例如人体是有四肢组成的，四肢不能脱离人体存在，人体少了四肢也难言完整。\n@startuml Body \u0026#34;1\u0026#34; *-- \u0026#34;2\u0026#34; Arm Body \u0026#34;1\u0026#34; *-- \u0026#34;2\u0026#34; Leg @enduml * 表示实心菱形\n@startuml Body \u0026#34;1\u0026#34; *-- \u0026#34;2\u0026#34; Arm Body \u0026#34;1\u0026#34; *-- \u0026#34;2\u0026#34; Leg @enduml 抽象方法和静态方法 @startuml class Hello { {abstract} one: int {abstract} two(): int } @enduml @startuml class Hello { {static} ONE: int {static} two(): int } @enduml @startuml class Hello { {abstract} one: int {abstract} two(): int } @enduml @startuml class Hello { {static} ONE: int {static} two(): int } @enduml 泛型 @startuml class Hello\u0026lt;H\u0026gt; class World\u0026lt;W\u0026gt; @enduml @startuml class Hello\u0026lt;H\u0026gt; class World\u0026lt;W\u0026gt; @enduml 包图 @startuml package one.two { class Hello } package three.four { World -- Hello } @enduml @startuml package one.two { class Hello } package three.four { World -- Hello } @enduml 包可以使用颜色和替换样式：\n@startuml \u0026#39;https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026#34;子系统\u0026#34; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml @startuml \u0026#39;https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026#34;子系统\u0026#34; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml 样式列表：\n@startuml scale 750 width package foo1 \u0026lt;\u0026lt;Node\u0026gt;\u0026gt; { class Class1 } package foo2 \u0026lt;\u0026lt;Rectangle\u0026gt;\u0026gt; { class Class2 } package foo3 \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; { class Class3 } package foo4 \u0026lt;\u0026lt;Frame\u0026gt;\u0026gt; { class Class4 } package foo5 \u0026lt;\u0026lt;Cloud\u0026gt;\u0026gt; { class Class5 } package foo6 \u0026lt;\u0026lt;Database\u0026gt;\u0026gt; { class Class6 } @enduml @startuml scale 750 width package foo1 \u0026lt;\u0026lt;Node\u0026gt;\u0026gt; { class Class1 } package foo2 \u0026lt;\u0026lt;Rectangle\u0026gt;\u0026gt; { class Class2 } package foo3 \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; { class Class3 } package foo4 \u0026lt;\u0026lt;Frame\u0026gt;\u0026gt; { class Class4 } package foo5 \u0026lt;\u0026lt;Cloud\u0026gt;\u0026gt; { class Class5 } package foo6 \u0026lt;\u0026lt;Database\u0026gt;\u0026gt; { class Class6 } @enduml note笔记 一般可以使用下面的语句进行在组件的上下左右添加笔记：\n@startuml class A class B class C class D ‘ 在组件A左边添加笔记 note left of A : 笔记A ‘ 在组件B右边添加笔记 note right of B : 笔记B ‘ 在组件C上边添加笔记 note top of C : 笔记C ‘ 在组件D下边添加笔记 note bottom of D : 笔记D @enduml @startuml class A class B class C class D ‘ 在组件A左边添加笔记 note left of A : 笔记A ‘ 在组件B右边添加笔记 note right of B : 笔记B ‘ 在组件C上边添加笔记 note top of C : 笔记C ‘ 在组件D下边添加笔记 note bottom of D : 笔记D @enduml 可以在字段（field、attribute、member）或方法上添加注释。 这不能与命名空间分隔符(namespaceSeparator) :: 一起使用\n注释属性和方法：\n@startuml class A { {static} int counter +void {abstract} start(int timeout) } note left of A::counter 该成员已注释 end note note right of A::start 在 UML 注释了此方法 end note @enduml @startuml class A { {static} int counter +void {abstract} start(int timeout) } note left of A::counter 该成员已注释 end note note right of A::start 在 UML 注释了此方法 end note @enduml 注释同名方法：\n@startuml class A { {static} int counter +void {abstract} start(int timeoutms) +void {abstract} start(Duration timeout) } note left of A::counter 该成员已注释 end note note right of A::\u0026#34;start(int timeoutms)\u0026#34; 这个start方法的参数是int类型 end note note right of A::\u0026#34;start(Duration timeout)\u0026#34; 这个start方法的参数是Duration类型 end note @enduml @startuml class A { {static} int counter +void {abstract} start(int timeoutms) +void {abstract} start(Duration timeout) } note left of A::counter 该成员已注释 end note note right of A::\u0026#34;start(int timeoutms)\u0026#34; 这个start方法的参数是int类型 end note note right of A::\u0026#34;start(Duration timeout)\u0026#34; 这个start方法的参数是Duration类型 end note @enduml 时序图 序列图是仅次于类图的最常用 UML 图。 序列图将交互关系表示为一个二维图，纵向是时间轴，时间沿竖线向下延伸；横向轴代表了在协作中各个角色，一般是一个 Class 的对象，用一条虚线代表各角色的生命线，生命线上用矩形竖条表示是否处于活跃状态。对象之间可以发送同步或异步消息。\n序列图的基本内容构成：\n\u0026lt;角色\u0026gt; \u0026lt;消息类型\u0026gt; \u0026lt;角色\u0026gt; : \u0026lt;消息内容\u0026gt;\n消息类型中 -\u0026gt; 表示同步消息 --\u0026gt; 虚线表示返回消息 同步消息 @startuml Alice -\u0026gt; Bob: Hi Bob --\u0026gt; Alice: Hi Alice -\u0026gt; Bob: Is this a pen? Bob --\u0026gt; Alice: No! This is an apple!! @enduml @startuml Alice -\u0026gt; Bob: Hi Bob --\u0026gt; Alice: Hi Alice -\u0026gt; Bob: Is this a pen? Bob --\u0026gt; Alice: No! This is an apple!! @enduml 异步消息 @startuml Alice -\u0026gt;\u0026gt; Bob: Hi Alice -\u0026gt;\u0026gt; Bob: Is this a pen? Alice -\u0026gt;\u0026gt; Bob: Is this a pen?? Alice -\u0026gt;\u0026gt; Bob: Is this a pen??? Alice -\u0026gt;\u0026gt; Bob: Is this a pen???? Bob -\u0026gt; Alice: This is an apple!!! @enduml 角色生命线 多个participant 会按照从左往右的顺序显示各角色生命线 如果没有任何 participant, 则会角色出现的顺序显示从左往右显示其生命线 角色图例 @startuml actor Actor boundary Boundary control Control entity Entity database Database collections Collections @enduml @startuml actor Actor boundary Boundary control Control entity Entity database Database collections Collections @enduml 箭头样式 @startuml Bob -\u0026gt;x Alice Bob -\u0026gt; Alice Bob -\u0026gt;\u0026gt; Alice Bob -\\ Alice Bob \\\\- Alice Bob //-- Alice Bob -\u0026gt;o Alice Bob o\\\\-- Alice Bob \u0026lt;-\u0026gt; Alice Bob \u0026lt;-\u0026gt;o Alice @enduml @startuml Bob -\u0026gt;x Alice Bob -\u0026gt; Alice Bob -\u0026gt;\u0026gt; Alice Bob -\\ Alice Bob \\\\- Alice Bob //-- Alice Bob -\u0026gt;o Alice Bob o\\\\-- Alice Bob \u0026lt;-\u0026gt; Alice Bob \u0026lt;-\u0026gt;o Alice @enduml 发给自己的消息 @startuml Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself @enduml @startuml Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself @enduml 消息序号 添加关键字autonumber\n@startuml Alice -\u0026gt; Bob: Hi autonumber Bob -\u0026gt; Carol: Hi Carol -\u0026gt; Dave: Hi Bob -\u0026gt; Dave: Hi @enduml autonumber stop: 自动序号暂停 autonumber resume: 自动序号继续 @startuml Alice -\u0026gt; Bob: Hi autonumber Bob -\u0026gt; Carol: Hi Carol -\u0026gt; Dave: Hi Bob -\u0026gt; Dave: Hi @enduml 消息组 @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: No! This is an apple!!!!! end @enduml @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: No! This is an apple!!!!! end @enduml 有时候需要多个消息表示一组相关的逻辑，此时可以使用预置的关键字来表示各种逻辑，例如\nalt/else opt loop par break critical 关键词之后添加表示逻辑的文字，例如 yes， no等\n消息信息的缩进不是必须的，但是加上可读性更好\n消息组嵌套\n@startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: Noooooooo! This is an apple!!!!! loop ∞ Alice -\u0026gt; Bob: Oh sorry! By the way, is this a pen? Alice \u0026lt;-- Bob: No!!!! end end @enduml @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: Noooooooo! This is an apple!!!!! loop ∞ Alice -\u0026gt; Bob: Oh sorry! By the way, is this a pen? Alice \u0026lt;-- Bob: No!!!! end end @enduml 自定义消息组\n@startuml group copy Alice -\u0026gt; Bob: Is this a pen? Alice \u0026lt;-- Bob: No! This is an apple!! end @enduml @startuml group copy Alice -\u0026gt; Bob: Is this a pen? Alice \u0026lt;-- Bob: No! This is an apple!! end @enduml group 之后添加消息组的名字\n生命线活跃状态 activate \u0026lt;name\u0026gt; 指定name的生命线进入活跃状态 deactive \u0026lt;name\u0026gt; 指定name的生命线退出活跃状态 @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml 嵌套活跃状态 @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml ​ activate 中继续 activate 可以嵌套活跃状态\n创建角色和生命线 @startuml Alice -\u0026gt; Bob create Carol Bob -\u0026gt; Carol: new Bob -\u0026gt; Carol Bob \u0026lt;-- Carol Alice \u0026lt;-- Bob @enduml @startuml Alice -\u0026gt; Bob create Carol Bob -\u0026gt; Carol: new Bob -\u0026gt; Carol Bob \u0026lt;-- Carol Alice \u0026lt;-- Bob @enduml create \u0026lt;name\u0026gt; 用来创建一个角色和其生命线，此时消息箭头会执行角色图例\n参考、引用 @startuml Alice -\u0026gt; Bob ref over Bob, Carol: ... Alice \u0026lt;-- Bob ref over Alice ... ... end ref @enduml ref over \u0026lt;生命线名称\u0026gt; : \u0026lt;内容\u0026gt; : reference 的范围和参考内容 ref over ... end ref: 可以换行写参考内容 @startuml Alice -\u0026gt; Bob ref over Bob, Carol: ... Alice \u0026lt;-- Bob ref over Alice ... ... end ref @enduml 边界线 @startuml == Foo == Alice -\u0026gt; Bob Alice \u0026lt;-- Bob == Bar == Bob -\u0026gt; Carol Bob \u0026lt;-- Carol @enduml == \u0026lt;name\u0026gt; == 添加边界线，跨越所有角色的生命线\n@startuml == Foo == Alice -\u0026gt; Bob Alice \u0026lt;-- Bob == Bar == Bob -\u0026gt; Carol Bob \u0026lt;-- Carol @enduml 外部消息 @startuml [-\u0026gt; Alice: Hello Alice -\u0026gt;]: Hello @enduml 消息箭头的前后使用 [ ， ] ，表示一个来自外部或者指向外部的消息\n@startuml [-\u0026gt; Alice: Hello Alice -\u0026gt;]: Hello @enduml 消息间隔 @startuml Alice -\u0026gt; Bob Alice \u0026lt;-- Bob Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||80|| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob @enduml 消息之间加 ||| , 会适当拉开消息间隔 ||\u0026lt;pixel\u0026gt;||：pixel可以指定具体间隔的像素数 @startuml Alice -\u0026gt; Bob Alice \u0026lt;-- Bob Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||80|| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob @enduml 备注 @startuml Alice -\u0026gt; Bob note left: Hello Alice \u0026lt;-- Bob note right: World Alice -\u0026gt; Alice note left Hello World end note @enduml @startuml Alice -\u0026gt; Bob note left: Hello Alice \u0026lt;-- Bob note right: World Alice -\u0026gt; Alice note left Hello World end note @enduml 组件\u0026amp;部署图 箭头方向 -\u0026gt;表示向右， --\u0026gt;表示向下。还可以使用关键字left, right, up or down改变箭头方向。-left-\u0026gt;或-l-\u0026gt;表示向左。\n@startuml component componentA as A component componentB as B component componentC as C component componentD as D \u0026#39; 表示箭头向右 A -\u0026gt; B \u0026#39; 表示箭头向下 C --\u0026gt; D @enduml @startuml component componentA as A component componentB as B component componentC as C component componentD as D \u0026#39; 表示箭头向右 A -\u0026gt; B \u0026#39; 表示箭头向下 C --\u0026gt; D @enduml 还有虚线(..)、直线(--)\n组件 关键字component定义一个组件。\n@startuml component componentA as A component componentB as B component componentGroup as group { component componentC as C component componentD as D } @enduml @startuml component componentA as A component componentB as B component componentGroup as group { component componentC as C component componentD as D } @enduml 接口 接口可以使用()来定义，也可以使用关键字interface来定义接口。\n@startuml () \u0026#34;interfaceA\u0026#34; as iA interface interfaceB as iB @enduml @startuml () \u0026#34;interfaceA\u0026#34; as iA interface interfaceB as iB @enduml 组合组件 可以使用多个关键字将组件和接口组合在一起。\npackage node folder frame cloud database @startuml package \u0026#34;Some Group\u0026#34; { HTTP - [First Component] [Another Component] } node \u0026#34;Other Groups\u0026#34; { FTP - [Second Component] [First Component] --\u0026gt; FTP } cloud { [Example 1] } database \u0026#34;MySql\u0026#34; { folder \u0026#34;This is my folder\u0026#34; { [Folder 3] } frame \u0026#34;Foo\u0026#34; { [Frame 4] } } [Another Component] --\u0026gt; [Example 1] [Example 1] --\u0026gt; [Folder 3] [Folder 3] --\u0026gt; [Frame 4] @enduml @startuml package \u0026#34;Some Group\u0026#34; { HTTP - [First Component] [Another Component] } node \u0026#34;Other Groups\u0026#34; { FTP - [Second Component] [First Component] --\u0026gt; FTP } cloud { [Example 1] } database \u0026#34;MySql\u0026#34; { folder \u0026#34;This is my folder\u0026#34; { [Folder 3] } frame \u0026#34;Foo\u0026#34; { [Frame 4] } } [Another Component] --\u0026gt; [Example 1] [Example 1] --\u0026gt; [Folder 3] [Folder 3] --\u0026gt; [Frame 4] @enduml 长描述 可以用方括号\u0026quot;[ ]\u0026ldquo;在连线上添加描述。\n@startuml component comp1 [ This component has a long comment on several lines ] @enduml @startuml component comp1 [ This component has a long comment on several lines ] @enduml 颜色 在声明一个组件时加上颜色的声明，在后面加上#颜色名可以改变颜色/\n@startuml component [Web Server] #yellow @enduml @startuml component [Web Server] #yellow @enduml 声明元素 @startuml actor actor actor/ \u0026#34;actor/\u0026#34; agent agent artifact artifact boundary boundary card card circle circle cloud cloud collections collections component component control control database database entity entity file file folder folder frame frame interface interface label label node node package package queue queue rectangle rectangle stack stack storage storage usecase usecase usecase/ \u0026#34;usecase/\u0026#34; @enduml @startuml actor actor actor/ \u0026#34;actor/\u0026#34; agent agent artifact artifact boundary boundary card card circle circle cloud cloud collections collections component component control control database database entity entity file file folder folder frame frame interface interface label label node node package package queue queue rectangle rectangle stack stack storage storage usecase usecase usecase/ \u0026#34;usecase/\u0026#34; @enduml 分隔符 @startuml folder folder [ 这是个 \u0026lt;b\u0026gt;文件夹 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] node node [ 这是个 \u0026lt;b\u0026gt;结点 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] database database [ 这是个 \u0026lt;b\u0026gt;数据库 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] usecase usecase [ 这是个 \u0026lt;b\u0026gt;用例 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] @enduml @startuml folder folder [ 这是个 \u0026lt;b\u0026gt;文件夹 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] node node [ 这是个 \u0026lt;b\u0026gt;结点 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] database database [ 这是个 \u0026lt;b\u0026gt;数据库 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] usecase usecase [ 这是个 \u0026lt;b\u0026gt;用例 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] @enduml 隐藏线 -[hidden]-可以画一条隐藏的线条，常常用于布局。\n排列 可以添加下面的一行进行竖排列：\nleft to right direction 相关配置 安装graphviz Mac执行：\nbrew install graphviz 然后在IDEA进行设置。\nReference:\n开源工具，使用简单的文字描述画UML图。 程序员必备画图技能之——时序图 - 程序员自由之路 - 博客园 【程序员小知识】使用 PlantUML 画 UML（上）类图 - 掘金 在 Hugo 博客上使用 PlantUML – Mogeko\u0026rsquo;s Blog https://crashedmind.github.io/PlantUMLHitchhikersGuide/layout/layout.html ","description":"使用plantUML表示一些关系和状态图更加清晰。","id":13,"section":"posts","tags":["工具","plantUML"],"title":"plantUML使用笔记","uri":"https://hugo.jiahongw.com/posts/efficient/plantuml-note/"},{"content":" 定义 装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案。\n架构（类图） classDiagram class Component { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateComponent { + methodA() + methodB() } class Decrator { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateDecratorA { + methodA() + methodB() + newMethod() } class ConcreateDecratorB { + methodA() + methodB() } ConcreateComponent --|\u0026gt; Component : 继承 Decrator --|\u0026gt; Component : 继承 ConcreateDecratorA --|\u0026gt; Decrator : 继承 ConcreateDecratorB --|\u0026gt; Decrator : 继承 装饰的技巧可以在不修改任何底层代码的情况下增强功能。\nKey：\n装饰者和被装饰者有相同的超类型 使用场景 Java IO类库（InputStream、OutputStream）\n装饰器模式可以很好的使用韦恩图进行解释，装饰器的包装对象类似于递归调用的形式，一层套一层去调用被包装对象的操作。\n在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。\n使用缺点 使用装饰器模式，常常造成设计中有大量的类。 Reference:\n《Head First 设计模式》 装饰设计（装饰者模式 / 装饰器模式） ","description":"装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案。","id":14,"section":"posts","tags":["装饰器模式","设计模式"],"title":"设计模式-装饰器模式","uri":"https://hugo.jiahongw.com/posts/designpattern/decoratorpattern/"},{"content":" 定义 观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并且自动更新。\n一个比喻：报纸订阅（出版者和订阅者）\n架构 classDiagram class Subject { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + registerObserver() + removeObserver() + notifyObserver() } class ConcreteSubject { - List\u0026lt;Observer\u0026gt; observers + registerObserver() + removeObserver() + notifyObserver() } class Observer { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + update() } class ConcreteObeserver { - Subject subject + update() } Subject --\u0026gt; Observer : 多个观察者 ConcreteSubject ..|\u0026gt; Subject : 实现 ConcreteObeserver ..|\u0026gt; Observer : 实现 ConcreteObeserver --\u0026gt; ConcreteSubject : 订阅主题 观察者依赖主题。观察者模式提供了一种对象设计，让主题和观察者之间松耦合。他们依然可以交互，但是不必清楚彼此的细节。\n主题主动推数据和观察者自己拉数据都可以，但是关键在于主题必须得通知观察者。\nQ \u0026amp; A：\n为什么观察者要包含一个主题（subject）的引用？\n以后可能需要取消注册，保存一个引用会更加方便。\n“生产者-消费者”模型和观察者模式的区别和联系？\n生产-消费模型，是多对多的关系，一般以异步的方式实现；而观察者模式（发布-订阅模型），是一对多的关系，可以以同步的方式实现，也可以以异步的方式实现。\n发布订阅和生产消费模型最大的区别在于：发布者（可观测对象）是知道订阅者（观察对象）的存在，因为它需要遍历订阅列表去发布事件；而生产消费模型因为有中间消息代理的存在，生产者和消费者完全不知道对方的存在，完全解耦！\nJava内置的观察者模式 java.util包下的Observable和Observer。\nGoogle EventBus 异步非阻塞观察者模式的实现。\n简单的实现方法：\n在可观察对象了里面对各个观察者的通知改成异步操作。（可用线程池） 在观察者内部的处理消息改为异步操作。（不可用线程池） 两者都能够开启线程去跑，很快就返回，不阻塞。\n针对异步非阻塞观察者模式的实现，抽象的EventBus框架可以让我们聚焦于业务。\n使用场景 消息队列 回调就是一种观察者模式 Google EventBus 邮件订阅 RSS 反应式RxJava JDK(CompletableFuture) Reference:\n极客时间-观察者模式 观察者设计模式 ","description":"一个比喻：报纸订阅（出版者和订阅者）。","id":15,"section":"posts","tags":["观察者模式","行为模式"],"title":"观察者模式","uri":"https://hugo.jiahongw.com/posts/designpattern/observerpattern/"},{"content":"1 SequenceDiagram 序列化图\n2 JRebel 简介：\n热部署工具。在我们每次修改代码后，不用重启程序，JRebel 会自动将所有的代码变更生效。这样，相当于“跳过”频繁的 Java 代码的编译、启动的过程，大大的提升了我们的开发效率。\n参考链接：\nhttps://www.iocoder.cn/Fight/IDEA-JRebel-plug-in-hot-deployment/?self https://www.jianshu.com/p/882872a7339d 配置：\n激活JRebel 配置信息 快捷键：Commond + shift + F9 3 Maven Helper 简介：可以查看 Maven 的依赖树和列表\n使用参考：\n要想查看maven的依赖树就要使用Maven命令maven dependency:tree来查看依赖\n当Maven Helper 插件安装成功后，打开项目中的pom文件，下面就会多出一个试图\n4 LeetCode Editor 胖友可以后续看看 LeetCode Editor 插件的作者写的 https://git.io/JLMce 指南。\n5 Alibaba Java Coding Guidelines Alibaba Java Coding Guidelines 插件，基于 《阿里巴巴 Java 开发手册》 的代码规范的检测工具。\n6 Translation 简介：Translation 插件，翻译神器，支持有道、百度、谷歌三种翻译引擎。\n功能：\n选中一个单词，进行翻译\n输入一个单词，进行翻译\n翻译框的呼出，Windows 使用 ctrl + shift + o 快捷键，MacOS 使用 control + command + i 快捷键。\n7 GenerateAllSetter 简介：GenerateAllSetter 插件，一键调用一个对象的所有的 setter 方法。\n功能：\n生成对象，并设置默认值 生成对象，并设置传入参数作为值 生成 List / Set / Map 返回结果 快捷键：Mac：alt + Enter\nMore IDEA多线程调试，参考：\nIdea debug调试时获取异步调用栈 - 简书 (1条消息) java高并发实战（十）——并发调试和JDK8新特性_平凡之路无尽路的博客-CSDN博客_jdk8并发新特性 (!(Thread.currentThread().getName().equals(\u0026#34;main\u0026#34;))) 只能使用IDEA自带的Debugger\nReference:\n","description":"IDEA实用的插件列表","id":16,"section":"talks","tags":["IDEA"],"title":"IDEA实用的插件列表","uri":"https://hugo.jiahongw.com/talks/idea-plugins/"},{"content":"安装更新卸载 参考：https://nvchad.github.io/getting-started/setup\n参考指令 参考：https://neovim.io/doc/user/quickref.html\n自定义 自定义需要在目录lua/custom/,防止在更新的时候覆盖了。\n一开始该目录只有下面两个文件：\n要根据您的需要开始设置 NvChad，请复制这些模板文件：\n1 2 cp example_init.lua init.lua cp example_chadrc.lua chadrc.lua custom/init.lua 在 NeoVim 设置期间运行，这是一种运行通用代码并运行大量 NvChad 修改的方法 custom/chadrc.lua用于覆盖core/default_config.lua，您只需要包含您希望从默认文件更改的值 切换主题 \u0026lt;leader\u0026gt; + th\nLua笔记 编译器使用IDEA + EmmyLua插件\n输出和评论 1 2 -- a comment print(\u0026#34;hi\u0026#34;) -- another comment 变量的定义 1 2 3 4 5 -- Different types local x = 10 -- number local name = \u0026#34;Sid\u0026#34; -- string local isAlive = true -- boolean local a = nil --no value or invalid value local的作用域只在当前的函数内，在外部的话就是文件内。\n字符串操作 1 2 3 4 5 6 7 -- 字符串拼接 local name_first = \u0026#34;Victor\u0026#34; local name_Second = \u0026#34;Hong\u0026#34; print(name_first .. name_Second) -- 多个字符串拼接 print(name_first .. \u0026#34;and\u0026#34; .. name_Second) 输出为：\nVictorHong VictorandHong 比较判断 多了一个不等的符号~= ,其他的和其他语言一样。\n另外，使用not表示!，常在条件判断语句使用。\n条件判断语法 类似shell语言，条件判断语句不需要花括号，但是增加了两个关键字then和end\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 -- number comparisions local age = 10 if age \u0026gt; 18 then print(\u0026#34;over 18\u0026#34;) -- this will not be executed end -- elseif and else age = 20 if age \u0026gt; 18 then print(\u0026#34;over 18\u0026#34;) elseif age == 18 then print(\u0026#34;18 huh\u0026#34;) else print(\u0026#34;kiddo\u0026#34;) end 复合判断语句：\n1 2 3 4 5 6 7 8 9 local age = 22 if age == 10 and x \u0026gt; 0 then -- both should be true print(\u0026#34;kiddo!\u0026#34;) elseif x == 18 or x \u0026gt; 18 then -- 1 or more are true print(\u0026#34;over 18\u0026#34;) end --result: over 18 函数 函数定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 function num(a) print(a) end -- or local num = function(a) print(a) end -- 多参数函数定义 function sum(a,b) local result = a + b print(result) end 函数调用：\n1 2 num(5) sum(2,3) 循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 -- while loop local i = 0 while i \u0026lt;= 3 do print(\u0026#34;hi\u0026#34;) i = i + 1 end OR --for loop for i = 0, 3 do print(\u0026#34;hi\u0026#34;) i = i + 1 end -- result hi hi hi tables（数组） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 -- basic table local colors = { \u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34; } print(colors[1]) --red print(colors[2]) --green print(colors[3]) --blue -- use a loop to iterate though the table for i=1, #colors do print(colors[i]) end --tables within tables local data = { { \u0026#34;billy\u0026#34;, 12 }, { \u0026#34;john\u0026#34;, 20 }, } for i = 1, #data do print(data[i][1] .. \u0026#34; is \u0026#34; .. data[i][2] .. \u0026#34; years old\u0026#34;) end 模块 使用模块\n1 require(\u0026#34;otherfile\u0026#34;) 自定配置 目录树：\nNvchad的配置目录下有一个 lua 文件夹和一个 init.lua 文件， 而 init.lua 主要加载核心的配置。\n假如你在 chadir 目录下有一个自定义文件 test.lua ,你可以在 init.lua 文件中加载使用它：\n1 require(\u0026#34;chadir.test\u0026#34;) or require \u0026#34;chadir.test\u0026#34;. 你也可以将 test.lua 重命名为 init.lua ，这样你就可以直接：\n1 2 require \u0026#34;chadir\u0026#34;. -- which calls the init.lua present in the chadir 颜色 颜色配置目录 lua/colors/ ,该目录有两个文件 init.lua 和 highlight.lua ,主题是用nvim-base16.lua 插件完成的.\n使用 空格 + th更换主题。\ncustom配置 添加插件，在 custom/init.lua 取消注释包含“install_plugins”内容的 hooks.add 行,添加：\n1 2 3 4 5 6 7 8 9 10 11 12 hooks.add(\u0026#34;install_plugins\u0026#34;, function(use) use { \u0026#34;folke/which-key.nvim\u0026#34; event = \u0026#34;something\u0026#34;, config = function() require(\u0026#34;custom.plugin_confs.whichkey\u0026#34;) end } end) -- so the path of the config here basically is in the custom/plugin_confs/whichkey.lua 然后使用 :PackSync 进行同步\n添加Markdown预览插件：\n1 2 3 4 hooks.add(\u0026#34;install_plugins\u0026#34;, function(use) use { \u0026#34;davidgranstrom/nvim-markdown-preview\u0026#34;, } 相关插件的使用 文件浏览器： kyazdani42/nvim-tree.lua: A file explorer tree for neovim written in lua\n触发条件：:NvimTreeToggle 或者 Ctrl + n\n刷新文件树：:NvimTreeRefresh 或者 \u0026lt;leader\u0026gt;r\n寻找文件：:NvimTreeFindFile 或者 \u0026lt;leader\u0026gt;n\n键入s将使用系统默认的软件打开文件，Ctrl+t将在新标签页打开\nReference:\nNvChad ","description":"","id":17,"section":"posts","tags":["Nvchad","nvim","vim"],"title":"Nvchad使用","uri":"https://hugo.jiahongw.com/posts/efficient/nvchad%E4%BD%BF%E7%94%A8/"},{"content":" 当我们使用new创建一个对象的时候，需要指定一个具体类，这就是针对实现进行编程。当我们将创建对象的过程封装成一个方法或者接口的时候，就可以避免针对实现编程，变成针对接口编程。\n针对接口编程，可以隔离掉以后系统可能发生的一大堆改变。为什么呢？\n通过多态，可以让任何实现类实现改接口。 然后替换掉你原来的实现。 对拓展开放，对修改关闭。\n定义 工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法将实例化推迟到子类。\n核心在将创建对象的过程解耦出来。\n架构 @startuml interface Product class ConcreteProduct implements Product abstract class Creator { * factoryMethod() + anyOperation() } class ConcreteCreator extends Creator { * factoryMethod() + anyOperation() } note top of Creator: Creator是一个类，实现所有操作产品的方法，但是不实现工厂方法 note bottom of ConcreteProduct: 所有产品必须实现共同接口 note bottom of ConcreteCreator: 实现工厂方法，以实际制造出产品 ConcreteProduct \u0026lt;-r- ConcreteCreator @enduml 工厂模式体现了一个原则：依赖倒置原则。（Spring叫依赖反转）\n原来依赖具体类，现在依赖一个抽象的接口。\n@startuml abstract class \u0026#34;抽象接口类\u0026#34; as abstractClass { } class \u0026#34;实现类A\u0026#34; extends abstractClass class \u0026#34;实现类B\u0026#34; extends abstractClass class \u0026#34;实现类C\u0026#34; extends abstractClass class \u0026#34;Factory\u0026#34; as factory factory --\u0026gt; abstractClass @enduml Key:\n工厂只有一个功能——创建指定的类。（单一职责） 将原来的if-else判断，转换成对象进行处理。 抽象成一个方法 -》 抽象成一个类 -〉 抽象成一个接口 抽象工厂模式 定义：抽象工厂模式提供一个接口，用于创建相关或者依赖对象的家族，而不需要明确指定具体类。\n架构：\nclassDiagram class AbstractFactory { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + createProductA() + createProductB() } class ConcreteFactoory1 { + createProductA() + createProductB() } class ConcreteFactoory2 { + createProductA() + createProductB() } class AbstractProductA { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttA1 class ProducttA2 ProducttA1 ..|\u0026gt; AbstractProductA : 实现 ProducttA2 ..|\u0026gt; AbstractProductA : 实现 class AbstractProductB { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttB1 class ProducttB2 ProducttB1 ..|\u0026gt; AbstractProductB : 实现 ProducttB2 ..|\u0026gt; AbstractProductB : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory1 : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory2 : 实现 ConcreteFactoory1 --\u0026gt;ProducttA1 : 创建 ConcreteFactoory1 --\u0026gt;ProducttB1 : 创建 ConcreteFactoory2 --\u0026gt;ProducttA2 : 创建 ConcreteFactoory2 --\u0026gt;ProducttB2 : 创建 抽象工厂模式类似于一个二维的分类，将更加复杂的系统进行整理并且划分。以达到解耦的效果。\n一个披萨商店的例子，可以很清晰的解释这种架构：\nclassDiagram class PizzaIngredientFactory { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } class NYPizzaIngredientFactory { + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } class ChicagoPizzaIngredientFactory { + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } PizzaIngredientFactory \u0026lt;|.. NYPizzaIngredientFactory PizzaIngredientFactory \u0026lt;|.. ChicagoPizzaIngredientFactory class Dough { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ThickCrustDough class ThinCrustDough ThickCrustDough ..|\u0026gt; Dough ThinCrustDough ..|\u0026gt; Dough class Sauce { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class PlumTomatoSauce class MarinaraSauce PlumTomatoSauce ..|\u0026gt; Sauce MarinaraSauce ..|\u0026gt; Sauce class Cheese { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class MozzarellaCheese class ReggianoCheese MozzarellaCheese ..|\u0026gt; Cheese ReggianoCheese ..|\u0026gt; Cheese class Clams { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class FrozenClams class FreshClams FrozenClams ..|\u0026gt; Clams FreshClams ..|\u0026gt; Clams ChicagoPizzaIngredientFactory --\u0026gt; ThickCrustDough ChicagoPizzaIngredientFactory --\u0026gt; PlumTomatoSauce ChicagoPizzaIngredientFactory --\u0026gt; MozzarellaCheese ChicagoPizzaIngredientFactory --\u0026gt; FrozenClams NYPizzaIngredientFactory --\u0026gt; ThinCrustDough NYPizzaIngredientFactory --\u0026gt; MarinaraSauce NYPizzaIngredientFactory --\u0026gt; ReggianoCheese NYPizzaIngredientFactory --\u0026gt; FreshClams 工厂方法就隐含在抽象工厂里面。\n问题 什么是静态工厂方法，和静态工厂有什么区别？\n静态工厂方法有不需要创建对象就能够调用静态方法的优势，但是缺点是不能通过继承来改变创建的方法。\nReference:\nFactory Design Pattern in Java - JournalDev ","description":"相对于直接new来创建对象，用工厂模式来创建究竟有什么好处呢？","id":18,"section":"posts","tags":["设计模式","工厂方法","抽象工厂","简单工厂"],"title":"工厂方法模式","uri":"https://hugo.jiahongw.com/posts/designpattern/factorymethodpattern/"},{"content":"什么是单例 单例设计模式（Singleton Design Pattern）理解起来非常简单。一个类只允许创建一个对象（或者实例），那这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。\n为什么使用单例 同一个类创建了多个对象，然后干的事情是一样的，在多线程环境下还需要考虑线程同步。而单例模式：\n不用创建那么多Logger对象，一方面节省内存空间。 另一方面节省系统文件句柄。 单例加锁的时候只需要添加对象锁即可，不用像之前使用类锁。\n从业务概念上，如果有些数据在系统中只应保存一份，那就比较适合设计为单例类。\n另外一种使用场景是需要一个全局唯一类，比如配置信息类，唯一递增ID号码生成器。\n单例的实现 各种单例模式的实现如下：\n饿汉单例\ninstance的创建过程是线程安全的。但是不支持延迟加载，因为在类创建的时候就将单例创建了。\n懒汉单例（支持延迟加载）\n静态阻塞初始化单例\n线程安全单例（并发度低）\n双重检测单例（支持高并发和延迟加载）\n内部静态类单例（既保证了线程安全，又能做到延迟加载）\nEnum 单例\n序列化单例\nCode：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 package com.sankuai.stafftraining.wujiahong.demo.springdemo.designpattern.creational; import java.io.Serializable; /** * 单例模式 */ public class SingletonPattern { public static void main(String[] args) { // Enum 单例模式使用 String myField = \u0026#34;Singleton\u0026#34;; EnumSingleton.INSTANCE.setField(myField); System.out.println(EnumSingleton.INSTANCE.getField()); } /** * 1.饿汉单例模式 这样的实现方式不支持延迟加载（在真正用到IdGenerator的时候，再创建实例） */ static class SingletonV1 { private static SingletonV1 instance = new SingletonV1(); private SingletonV1() { } public static SingletonV1 getInstance() { return instance; } } /** * 2.懒汉单例模式 */ static class SingletonV2 { private static SingletonV2 instance; private SingletonV2() { } public static SingletonV2 getInstance() { if (instance == null) { instance = new SingletonV2(); } return instance; } } /** * 3.静态阻塞初始化 */ static class SingletonV3 { private static SingletonV3 instance; private SingletonV3() { } static { try { instance = new SingletonV3(); } catch (Exception e) { throw new RuntimeException(\u0026#34;Exception occured in creating singleton instance\u0026#34;); } } public static SingletonV3 getInstance() { return instance; } } /** * 线程安全单例 */ static class SingletonV4 { private static SingletonV4 instance; private SingletonV4() { } public static synchronized SingletonV4 getInstance() { if (instance == null) { instance = new SingletonV4(); } return instance; } } /** * 双重检查并且加锁避免额外的开销 */ static class SingletonV5 { private static SingletonV5 instance; private SingletonV5() { } public static SingletonV5 getInstance() { if (instance == null) { // 只有在第一次创建对象的时候才会进行同步锁定，其他情况不需要，提高了性能 synchronized (SingletonV5.class) { if (instance == null) { instance = new SingletonV5(); } } } return instance; } } /** * 内部静态类单例模式,不需要同步 */ static class SingletonV6 { private SingletonV6() { } private static class SingletonHelper { private static final SingletonV6 INSTANCE = new SingletonV6(); } public SingletonV6 getInstance() { return SingletonHelper.INSTANCE; } } /** * Enum 单例模式 */ public enum EnumSingleton { INSTANCE; private String field; public String getField() { return field; } public void setField(String field) { this.field = field; } } /** * 序列化单例模式 */ static class SerializedSingleton implements Serializable { private static final long serialVersionUID = -7604766932017737115L; private SerializedSingleton() { } private static class SingletonHelper { private static final SerializedSingleton instance = new SerializedSingleton(); } public static SerializedSingleton getInstance() { return SingletonHelper.instance; } protected Object readResolve() { return getInstance(); } } } question ❓\n为什么使用双检锁？\n避免额外的开销。在两次判断instance是否为null的中间加入synchronized关键字，将synchronize的返回从整个方法降到判断里面。\n单例的问题 对OOP对象不友好\n封装、继承、多态、抽象这些面向对象的的特性，单例这种设计模式对于其中的抽象、继承、多态都支持得不好。\n隐藏子类之间的依赖关系\n构造函数是private的，因为不能够显示的在外部调用构造函数，所以我们不知道单例道到底需要依赖那些东西。如果代码比较复杂，这种调用关系就会非常隐蔽。\n对拓展不好\n单例只有一个对象，如果后面需要创建多个实例，就需要对代码有较大的改动。（常常在多线程并发的情况下有这种需求）\n可测试性不好\n不支持带参数的构造函数\n使用辅助函数进行set 将参数上放至getInstance 使用全局变量Config 单例的替代方法 静态方法。 工厂模式、IOC容器（比如Spring IOC容器）来保证 程序员自己保证 理解单例的唯一性 唯一的维度：\n同一线程唯一\n同一进程唯一\n分布式系统唯一\n进程内唯一，进程间也唯一。\n具体来说，我们需要把这个单例对象序列化并存储到外部共享存储区（比如文件）。进程在使用这个单例对象的时候，需要先从外部共享存储区中将它读取到内存，并反序列化成对象，然后再使用，使用完成之后还需要再存储回外部共享存储区。\n为了保证任何时刻，在进程间都只有一份对象存在，一个进程在获取到对象之后，需要对对象加锁，避免其他进程再将其获取。在进程使用完这个对象之后，还需要显式地将对象从内存中删除，并且释放对对象的加锁。\n使用场景 线程池 缓存 对话框 注册表对象 日志对象 Reference:\n单例设计模式 43 42 | 单例模式（中）：我为什么不推荐使用单例模式？又有何替代方案？ Java Singleton Design Pattern Example Best Practices - JournalDev Design Patterns for Humans ","description":"单例模式是一种创建型设计模式， 让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。","id":19,"section":"posts","tags":["设计模式","单例模式"],"title":"单例模式","uri":"https://hugo.jiahongw.com/posts/designpattern/singletonpattern/"},{"content":" 建造者模式也称为生成器模式或者Builder模式。\n建造者模式主要是为了解决调用构造函数的时候，参数太多，并且有一些是可选参数不填的情况。这种情况下，使用建造者模式会更加灵活。\n最简单的一个比喻就是建房子，一个房子由多个组件组成，可以有墙、门、窗户、屋顶、垃圾桶等等，但是窗和垃圾桶都是可选的，建一个房子不一定需要。此时假如我们要将房子进行分类抽象，子类将会派生出多种，非常复杂。而建造者模式将对象的参数构造从类中抽离，放在一个独立的构建器里面，可以让我们按需构建，最后再返回房子的对象。\n不同生成器以不同方式执行相同的任务。\n使用建造者模式的步骤：\n在类的内部新建一个静态公有类Builder。 Builder类中保存了和原来的类一样的成员变量，并且实习爱你setter方法，返回值是Builder本身。 类仅设置一个私有的构造函数，参数是Builder类的一个实例。 新建一个Builder，使用Builder类中的 build 函数调用类的构造函数，返回实例。 生成器模式建议将对象构造代码从产品类中抽取出来， 并将其放在一个名为生成器的独立对象中。\n详细的代码样子\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 package com.sankuai.stafftraining.wujiahong.demo.springdemo.designpattern.creational; import java.util.Optional; /** * 建造者模式（生成器模式｜Builder模式） */ public class BuilderPattern { /** * 必要参数 */ private Integer number; private String name; /** * 可选参数 使用Optional修饰可选参数，但是一定要设置初始值 */ private Optional\u0026lt;Integer\u0026gt; weight; private Optional\u0026lt;Integer\u0026gt; height; private BuilderPattern(Builder builder) { // 外部类可以直接访问内部类的数据 this.number = builder.number; this.name = builder.name; this.weight = builder.weight; this.height = builder.height; } @Override public String toString() { return \u0026#34;number = \u0026#34; + this.number + \u0026#34;\\nname = \u0026#34; + this.name + \u0026#34;\\nweight = \u0026#34; + ( this.weight.isPresent() ? weight.get() : \u0026#34;empty\u0026#34;) + \u0026#34;\\nheight = \u0026#34; + (this.height.isPresent() ? height.get() : \u0026#34;empty\u0026#34;); } public static class Builder { /** * 必要参数 */ private Integer number; private String name; /** * 可选参数 */ private Optional\u0026lt;Integer\u0026gt; weight; private Optional\u0026lt;Integer\u0026gt; height; public Builder(Integer number, String name) { this.number = number; this.name = name; this.weight = Optional.empty(); this.height = Optional.empty(); } public Builder weight(Integer weight) { this.weight = Optional.of(weight); return this; } public Builder height(Integer height) { this.height = Optional.of(height); return this; } public BuilderPattern build() { return new BuilderPattern(this); } } public static void main(String[] args) { Integer number = 101; String name = \u0026#34;Victor\u0026#34;; Integer height = 160; BuilderPattern builderPattern = new Builder(number,name).height(height).build(); System.out.println(builderPattern); } } 优点：\n你可以分步创建对象， 暂缓创建步骤或递归运行创建步骤。 生成不同形式的产品时， 你可以复用相同的制造代码。 单一职责原则。 你可以将复杂构造代码从产品的业务逻辑中分离出来。（避免 “重叠构造函数 （telescopic constructor）” 的出现） 缺点：\n由于该模式需要新增多个类， 因此代码整体复杂程度会有所增加。 和工厂模式的区别：\n顾客走进一家餐馆点餐，我们利用工厂模式，根据用户不同的选择，来制作不同的食物，比如披萨、汉堡、沙拉。对于披萨来说，用户又有各种配料可以定制，比如奶酪、西红柿、起司，我们通过建造者模式根据用户选择的不同配料来制作披萨。\n建造者模式可以进行一些特殊的组合操作，其中一些内部对象可有也可无。\nReference:\nEffective-Java-3rd-edition-Chinese-English-bilingual/Chapter-2-Item-2-Consider-a-builder-when-faced-with-many-constructor-parameters.md at dev · clxering/Effective-Java-3rd-edition-Chinese-English-bilingual 建造者设计模式（生成器模式） ","description":"建造者模式主要是为了解决调用构造函数的时候，参数太多，并且有一些是可选参数不填的情况。这种情况下，使用建造者模式会更加灵活.","id":20,"section":"posts","tags":["设计模式","建造者模式"],"title":"建造者模式","uri":"https://hugo.jiahongw.com/posts/designpattern/builderpattern/"},{"content":" 什么是软件架构 软件架构的三种定义：\n维基百科：软件架构可以和建筑物的架构相比拟。软件架构是构建计算机，开发系统以及计划进行的基础，可以列出开发团队的需要完成的任务。 IEEE：架构是环境中该系统一组基础概念和属性，具体表现是它的元素、关系，以及设计演进的基本原则。 《clean architecture》：架构是创建者给予该系统的形态（shape）。这个形态的具体形式来源于对系统组件（components）的划分和排列，以及这些组件之间互相通讯的方式。 架构体现的是一个整体的结构，以及组件（元素）之间的关系。\n软件架构的要素 元素：将系统拆分为一组元素（模块、组件、结构体、子系统） 属性：每个元素具备的属性（名称、职责、接口、实现限制等） 关系：不同元素之间的关系（交互、依赖、继承、组合、聚合） 原理：为什么这么设计（拆分依据、设计原则、决策原因等） 架构域分类（TOGAF） 4A架构\n业务架构图：\n商业模式画布 业务能力图 价值流 + 业务能力 + 热点图 用例图 价值链图 流程图 数据架构图：\n数据库：ES、Redis、MySQL、Tail\n其中：\n业务架构是软件架构的灵魂。有业务架构才有技术架构。\n业务架构是一种对组织如何利用其基本能力实现其战略意图和目标的正式描述。\n应用架构是系统设计的顶层。\n应用架构是一组应用系统及其交互关系的描述，其中的每个应用系统都是一个逻辑功能组，用于支撑业务功能、管理数据资产。只关注支持业务和处理数据需要那些应用系统，不关注应用本身的架构和实现的技术。\n数据架构是数据资产管理蓝图。\n数据架构定义了用来支持业务的各种数据，以及他们之间的关系，关注点是持久化数据的组织。关注点在：系统需要什么数据、数据间有什么关系、如何存储这些数据\n技术架构是比特世界的布局。\n技术架构是将产品需求转变为技术实现的过程。关注点在于识别技术需求、技术选型、非功能性需求设计。\n架构师也分为多种，有业务架构师和技术架构师。在开发一套系统的时候，首先是由公司管理层定下一个战略，然后业务架构师根据战略绘制业务架构图，然后技术架构师拿到业务架构图，进行识别技术需求和技术选型，编写出技术架构图，若还有数据架构师和应用架构师，那么也是在技术架构生成之前要设计相关的数据架构和应用架构，总之，技术架构总是在最后一步进行设计，而业务架构总是在前面设计。\n为什么需要软件架构图 两种开发流程：\n瀑布流程。 迭代流程 架构是系统实现的蓝图。\n架构是沟通协作的桥梁。\n架构是产品质量的基础。\n重要在哪：\n促进协作 增强沟通 描绘愿景 提供指导 描述架构的方式 文字（标准、详尽、易于版本管理） 图（直观、形象、表达能力强） 尽管人们日常的工作场所大多是语言性或非图示化的（口语、文字和数字等），但事实上人脑的80%功能都是用于处理视觉信息的，人们对接受视觉信息具有天生的敏感度。——罗伯特-豪恩《VisualLanguage》\n最好使用图来描述架构。\n如何画软件架构图 “法”：架构设计原则\u0026amp;模式 “术”：常用制图方法 “器”：常用制图工具 “道”：架构制图方法论 “法”：架构设计原则\u0026amp;模式 SOLID原则 设计模式原则 架构模式（C/S模式、主从模式、管道模式、微服务模式、云原生模式） 设计模式（观察者模式\u0026hellip;） 常见的架构模式设计图：\nMVC架构：\n分层架构：\n微服务架构：\n洋葱架构：\n微内核架构：\n还有事务驱动架构、云化架构、六边形架构。\n“术”：常用制图方法 UML 统一建模语言（Unified Modeling Language，缩写UML）是一种用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。\n主要模型：\n功能模型：用例图 对象模型：类图 动态模型：时序图、活动图、状态图 UML的学习成本有点高。\n4+1ViewModel 哪四个视图？\n逻辑视图：关注系统提供给终端用户的功能，一般会通过UML中的类图和状态图来表示 流程视图：关注系统的动态部分、运行时行为，包括系统的执行流程和交互方式，一般会通过UML中的时序图、活动图和通讯图来表示。 开发视图：也称为实现视图，以程序员视角阐述系统的组件等，一般会通过UML中的组件图和包图来表示。 物理视图：也称为部署视图，以系统工程师角度描述系统各组件在物理层的拓扑，一般会通过UML中的部署图来表示。 哪一个场景？\n场景：也称为用例视图，通过一组用例（场景）描述系统中对象和流程之间的交互与时序。\n实际是一种模型，不限制使用哪种方法实现。\nC4Model 第 1 层：系统上下文图（System Context diagram）\n在这一层级中细节并不重要，只需要显示系统概况。 重点应该放在人员（角色）和软件系统上，而不是技术，协议和其他低层级细节上，从而使非技术人员也能够看得懂。这个图也是明确需求的重要图示。\n第 2 层：容器图（Container diagram）\n“容器”类似于服务器端Web应用程序，单页应用程序，桌面应用程序，移动应用程序，数据库架构，文件系统等。本质上，容器是可单独运行/可部署的单元（例如，单独的进程空间） ）执行代码或存储数据。容器图显示了软件体系结构的高层结构以及如何在其间分配职责。 它还显示了主要的技术选择以及容器之间的通信方式。\n第 3 层：组件图（Component diagram）\n组件图显示了容器如何由多个“组件”组成，每个组件是什么，它们的职责以及技术/实现接口（API）或者细节。\n第 4层：（Code）\n这一层是可选的，可以使用UML类图，实体关系图或类似的图。理想情况下，该图可以使用工具（例如IDE或UML建模工具）自动生成。\n关键思想：\n自顶向下对系统的静态结构进行逐级拆分，描述各层次对象的职责、关系和外部依赖。 对于关键链路，使用动态视图描述运行时的交互行为和时序关系。 面向部署实施，使用部署视图描述系统逻辑节点与物理资源之间的映射关系。 “器”：常用制图工具 可视化制图工具有这些：\ndraw.io ProcessOn Visio 代码化制图：\nPlantUML Structurizr Graphviz “道”：架构制图方法论 什么是一张好的架构图？\n准确：错的图比没有图还糟糕 完整：覆盖架构的核心要素和关键信息 清晰：清晰的图例（形状、颜色、箭头）、标注（内部系统or外部依赖） 一致：同一类型的图，使用相同的记号风格 简洁：不要企图用一张图讲清楚所有，化繁为简，更容易被理解 ","description":"如何做好系统设计，架构制图是重要的一环。","id":21,"section":"posts","tags":["架构"],"title":"架构制图","uri":"https://hugo.jiahongw.com/posts/systemarchitecture/architecture-drawing/"},{"content":"出发前的准备 我这里列了一个大致的攻略（虽然最后崂山没去成）：\n青岛攻略\n还准备了一个行程路线：\n第一站 我们下车的地方是青岛站，一下来，就是一种欧式建筑的感觉，这就是青岛的特色吗\n看海 来青岛怎么能不看海，青岛三面环海，来的这几天，海浪还挺大，吹着挺舒服\n波涛汹涌\n有意境的一瞬间\n青岛标志性建筑——栈桥\n吃海鲜 在青岛吃海鲜🦞，喝🍺啤酒。\n买海鲜\n找别人加工\n逛青岛街头 在十月份的青岛树木非常绿，而且青岛的街道也很有特色，就是那种林荫道的感觉，让人很舒服\n青岛的道路命名很有意思，都是拿其他省名作为道路名，据说青岛的版图就是一个小型的中国\n夜晚在教堂还有人组织一起看电影，好久没有这样的文艺活动了\n光圈内的人\n夜晚的街道和行人\n总结 青岛是一个非常漂亮的城市，非常适合旅游。青岛不仅有海，有海鲜，还有很多美女。此行前前后后也做了一些攻略，其实攻略是次要的，不一定非要将攻略中的各个景点都逛了才算完美，在行程中享受过程才是更重要的。\n彩蛋～\n","description":"国庆期间，去了一趟青岛。","id":22,"section":"posts","tags":["青岛","Life"],"title":"青岛之旅","uri":"https://hugo.jiahongw.com/posts/life/qingdao-travel/"},{"content":"The photo about Beijing with me.📹\n","description":"记录北京的照片生活","id":23,"section":"gallery","tags":[null],"title":"北京的日子","uri":"https://hugo.jiahongw.com/gallery/beijing/"},{"content":"✌️cxc\n《Java实战》笔记\nstream的使用注意 一个 Stream pipeline 中包含一个源 Stream，接着是 0个或者多个中间操作( intermediat巳 operation)和一个终止操作( terminal operation)。 每个中间操作都会通过某种方式对 Stream 进行转换，例如将每个元素映射到该元素的函数，或者过滤掉不满足某些条件的所有元素 。 所有的中间操作都是将一个 Stream 转换成另 一个 Stream，其元素类型可能与输入的 Stream 一样，也可能不同 。 终止操作会在最后 一个中间操作 产生的 Stream 上执行一个最终的计算， 例如将其元素保存到一个集合中，并返回某一个元素，或者打印出所有元素等。\nStream pipeline通常是 lazy 的 : 直到调用终止操作时才会开始计算 ，对于完成终止操作 不需要的数据元素，将永远都不会被计算 。 正是这种 lazy 计算，使无限 Stream 成为可能 。 注意，没有终止操作的 Stream pipeline将是一个静默的无操作指令 ，因此千万不能忘记终止操作。\n**滥用Stream会使程序更难以读懂和维护。**最好的方法是，不要过度的使用Stream，适当的使用Stream。\nStream方法经常会使用Lambda表达式，在对没有类型的变量命名需要更加清晰，增加其可读性。\n在 Streamn pipeline 中使 用 helpe方法（指的是常规的函数方法而不是Lambda表达式）可以增强代码的可读性。\n最好避免使用Stream处理Char值，因为Char Stream返回的元素是int类型的而不是char类型的。如：\n1 \u0026#34;Hello World!\u0026#34;.chars().forEach(System.out::print); Out:\n72101108108111328711111410810033 如果实在不确定用 Stream 还是用迭代比较好，那么就两种都试试，看看哪一种更好用。\n优先选择Stream中无副作用的函数。（什么是无副作用的函数呢？指其结果只取决于输入的函数 : 它不依赖任何可 变的状态，也不更新任何状态 ）\n终止操作中的 forEach 应该只用来报告由 Stream 执行的计 算结果，而不是让它执行计算。\nStream 要优先用 Collection 作为返回类型。如果返回的序列足够小，容易存储，或许最好返回标准的集合实现，如 ArrayList或者HashSet。 但是千万别在内存中保存巨大的序列，将它作为集合返回。\n流只能使用一次，使用完（完成终端操作）就会被销毁：\n1 2 3 4 List\u0026lt;String\u0026gt; title = Arrays.asList(\u0026#34;Modern\u0026#34;, \u0026#34;Java\u0026#34;, \u0026#34;In\u0026#34;, \u0026#34;Action\u0026#34;); Stream\u0026lt;String\u0026gt; s = title.stream(); s.forEach(System.out::println); s.forEach(System.out::println); Out(报错，不能再使用已经使用过的流):\nModern Java In Action Exception in thread \u0026#34;main\u0026#34; java.lang.IllegalStateException: stream has already been operated upon or closed at java.util.stream.AbstractPipeline.sourceStageSpliterator(AbstractPipeline.java:279) at java.util.stream.ReferencePipeline$Head.forEach(ReferencePipeline.java:580) at com.sankuai.stafftraining.wujiahong.demo.springdemo.usages.MainApp.main(MainApp.java:22) 中间操作和终端操作 中间操作会返回另一个流，除非流水线上触发一个终端操作，否则中间操作不会执行任何处理。（中间操作一般都可以合并起来，在终端操作时一次性全部处理）。\n终端操作会从流的流水线生成结果，其结果是任何不是流的值，比如 List、Integer，甚至void。\n中间操作函数：\n操作 参数描述符 作用 filter T -\u0026gt; boolean 保留表达式中为true的元素 map T -\u0026gt; R 转换元素的类型 flatMap 各个数组并不是分别映􏲡成一个流，而是映射成流的内容 limit 限制返回元素的个数，参数为元素的个数 sorted （T，T）-\u0026gt; int 对元素进行排序 distinct 对所有元素去重，不需要参数.(根据流所生成元素的 hashCode 和 equals 方法实现) skip 返回扔掉前n个元素的流 skip和limit操作是互补的。\n终端操作函数：\n操作 返回类型 作用 forEach void 使用Lambda消费流中的每个元素 count long 返回流最后元素的数量 collect generic 把流规约成一个集合，比如List、Map，甚至是Integer anyMatch boolean 检查谓词是否至少匹配一个元素 allMatch boolean 检查谓词是否匹配所有元素 noneMatch boolean 检查谓词是否全都不匹配 findAny Optional 对象 返回当前流中的任意元素 findFirst 查找第一个元素 reduce 归约，将多个元素合成一个 flatMap例子：\n1 2 3 4 5 6 7 8 9 List\u0026lt;String\u0026gt; arrayOfWords = Lists.newArrayList(\u0026#34;Goodbye\u0026#34;, \u0026#34;World\u0026#34;); List\u0026lt;String\u0026gt; uniqueCharacters = arrayOfWords.stream() .map(word -\u0026gt; word.split(\u0026#34;\u0026#34;)) .flatMap(Arrays::stream) .distinct() .collect(Collectors.toList()); System.out.println(uniqueCharacters); out：\n[G, o, d, b, y, e, W, r, l] reduce实现循环相加求和：\n1 int sum = numbers.stream().reduce(0, (a, b) -\u0026gt; a + b); 更优雅的写法：\n1 int product = nums.stream().reduce(0, Integer::sum); 找最大值和最小值：\n1 2 Optional\u0026lt;Integer\u0026gt; max = numbers.stream().reduce(Integer::max); Optional\u0026lt;Integer\u0026gt; min = numbers.stream().reduce(Integer::min); 消除非受检的警告 用泛型编程时会遇到讲多编译器警告 : 非受检转换警告( unchecked cast warning)、非受检方法调用警告、非受检参数化可变参数类型警告( unchecked parameterized vararg type warning)，以及非受检转换警告( unchecked conversion warning)。\n如果消除了所有警告，就可以确 保代码是类型安全的 这是一件很好的事情。\n应该始终在尽可能小的范围内使用 SuppressWarnings 注解。\n1 @SuppressWarnings (“unchecked\u0026#34;) 列表优于数组 列表使用范型，而范型能够在编译时期就检查出类型的额问题。数组类型可能在运行时才报错。\nenum使用 使用enum代替int Java的枚举类型是功能十分齐全的类，其功能比其他语言中的对应类强大 得多， Java的枚举本质上是Int值\nJava枚举类型的基本想法非常简单:这些类通过公有的静态 final域为每个枚举常量导 出一个实例。 枚举类型没有可以访问的构造器，所以它是真正的 final类。 客户端不能创建 枚举类型的实例，也不能对它进行扩展，因此不存在实例，而只存在声明过的枚举常 量 。 换 句话说，枚举类型是实例受控的(详见第 6 页) 。 它们是单例( Singleton) 的泛 型化，本质上是单元素的枚举 。\n模版使用 如果你需要采用某个算法的框架，同时又希望有一定的灵活度，能对它的某些部分进行改进， 那么采用模板方法设计模式是比较通用的方案。换句话说，模板 方法模式在你**“希望使用这个算法，但是需要对其中的某些行进行改进**，才能达到希望的效果” 时是非常有用的。\n好的 API 文档应该描述一个给定的方法做了什么工作，而不 是描述它是如何做到的 。\n模版设计方法\nJava并发 CompletableFuture的原理与实践-记外卖商家端API的异步化\nCompletableFuture功能介绍与原理分析_尘间絮的专栏-CSDN博客\n同步模型的问题：\n会有阻塞的时间。\n异步主要是：减少线程池的调度开销和阻塞时间\nCompletableFuture的优势：\n可异步 可组合（编排） 应用场景：\n使用CompletableFuture异步执行循环中的任务 | localhost\n现在有一个需求：给你一批商品编号查询出商品的所有相关信息，这些商品信息并不能通过一条sql就直接获取到，需要对每一件商品调用很多接口来获取相关，因此查一件商品的耗时较长，如果查询的商品较多使用循环来执行的话，所耗费的时间肯定是特别长的。\nCompletableFuture处理工具类：\nFutureUtils 两个或者多个任务的异步执行。\nUseful方法 computeifAbsent Java 8 中新增的 computeifAbsent 方法 。 这个方法会在映射中查找一个键:如果 这个键存在，该方法只会返回与之关联的值\n1 2 3 4 5 Map\u0026lt;Long, List\u0026lt;Long\u0026gt;\u0026gt; mm = Maps.newHashMap(); mm.computeIfAbsent(1L,key-\u0026gt;Lists.newArrayList()).add(2L); for (Entry\u0026lt;Long,List\u0026lt;Long\u0026gt;\u0026gt; kv:mm.entrySet()) { System.out.println(kv.getKey() +\u0026#34;---\u0026#34; +kv.getValue()); } 输出：\n1---[2] 要是使用原始的方法，类似下面这样：\n1 2 3 4 5 6 7 Map\u0026lt;Long, List\u0026lt;Long\u0026gt;\u0026gt; mm = Maps.newHashMap(); if(CollectionUtils.isEmpty(mm.get(1))) { mm.put(1L,Lists.newArrayList()); } for (Entry\u0026lt;Long,List\u0026lt;Long\u0026gt;\u0026gt; kv:mm.entrySet()) { System.out.println(kv.getKey() +\u0026#34;---\u0026#34; +kv.getValue()); } 这样没有使用computeIfAbsent方法简洁。\nMap.uniqueIndex 根据key对列表创建Map映射。\ngroupby \u0026amp; groupingBy groupingBy()是Stream API中最强大的收集器Collector之一，提供与SQL的GROUP BY子句类似的功能。\n使用形式：\n1 .collect(groupingBy(...)); https://blog.csdn.net/daobuxinzi/article/details/100190366\n分组：\n1 2 3 4 5 // 重新分组 Map\u0026lt;String, List\u0026lt;CompareStockVO\u0026gt;\u0026gt; detailMap = afterFilter.stream() .collect(Collectors.groupingBy(compareStockVO -\u0026gt; StringUtils .joinWith(\u0026#34;-\u0026#34;, compareStockVO.getPoiId(), compareStockVO.getSkuId(), compareStockVO.getSupplierId()))); 另外一种聚合的方法：\n1 2 3 4 5 6 // 聚合 Map\u0026lt;String, WmsStockSkuLotExpiryPO\u0026gt; poiLot2Expire = lotExpiryPOS.stream().collect( Collectors.toMap( lotExpiryPO -\u0026gt; expirySyncService .getExpiryEsKey(lotExpiryPO.getLotId(), lotExpiryPO.getPoiId()), a -\u0026gt; a, (k1, k2) -\u0026gt; k1)); 聚合：\n// 重新聚合 List\u0026lt;CompareStockVO\u0026gt; result = Lists.newArrayList(); for (List\u0026lt;CompareStockVO\u0026gt; compareStockVOList : detailMap.values()) { Optional\u0026lt;CompareStockVO\u0026gt; compareStockVO = compareStockVOList.stream() .reduce((left, right) -\u0026gt; { left.setQuantity(left.getQuantity().add(right.getQuantity())); left.setLockQuantity(left.getLockQuantity().add(right.getLockQuantity())); return left; }); if (compareStockVO.isPresent()) { result.add(compareStockVO.get()); } } partition 将一个列表划分成多个列表，参数是每个列表的大小：\n1 2 List\u0026lt;List\u0026lt;Long\u0026gt;\u0026gt; subLists = Lists.partition(result,20); List\u0026lt;List\u0026lt;Integer\u0026gt;\u0026gt; subSets = ListUtils.partition(intList, 3); flatMap Java8 Stream使用flatMap合并List\nCompletableFuture CompletableFuture的使用\nJava语法糖 函数式接口 Supplier接口(供应接口)\njava.util.function.Supplier 接口仅包含一个无参的方法： T get() 。用来获取一个泛型参数指定类型的对象数据。由于这是一个函数式接口，\n这也就意味着对应的Lambda表达式需要“对外提供”一个符合泛型类型的对象数据。\nConsumer接口\njava.util.function.Consumer 接口则正好与Supplier接口相反，它不是生产一个数据，而是消费一个数据，其数据类型由泛型决定\n抽象方法：accept\nConsumer 接口中包含抽象方法 void accept(T t) ，意为消费一个指定泛型的数据。\nPredicate接口\nFunction接口\njava.util.function.Function\u0026lt;T,R\u0026gt; 接口用来根据一个类型的数据得到另一个类型的数据，前者称为前置条件，后者称为后置条件\nSupplier 的一个主要用例是延迟执行（deferred execution）\nJava 利用Supplier创建日志消息|极客教程\n","description":"记录Effective Java的一些重点","id":24,"section":"posts","tags":["Java","Effective Java"],"title":"java8笔记📒","uri":"https://hugo.jiahongw.com/posts/java/java8-note/"},{"content":"Bash Shell 命令行通用快捷键：\n快捷键 作用 删除前一个字符 删除前一个单词 删除至行首 \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; \u0026lt;++\u0026gt; Key Mapping:\nmap表示递归的映射 unmap表示删除某个映射 key explain map nore 表示非递归 noremap n 表示在普通模式下生效 nmap v 表示在可视和选择模式下生效 vmap i 表示在插入模式下生效 imap c 表示在命令模式下生效 cmap x 可视模式下生效 xmap vim配置快捷键参考：\n快捷键 作用 助记 Ctrl j 下移当前行或者段落 Ctrl k 上移当前行或者段落 Ctrl h Ctrl l 清空高亮 r 调出替换命令 rc 调出替换命令（需要确认） su 上分屏 鼠标在上分屏 split up se 下分屏 鼠标在下分屏 split end sn 右分屏 鼠标在右分屏 S 保存 :w save Q 退出 :q quit tu 创建新的标签页 tn 左移标签页 ti 右移标签页 tmn 交换左边标签页 tmi 交换右边标签页 ev 编辑.vimrc文件 sv 使.vimrc生效 cp 拷贝当前的缓存路径到剪切板 自动显示所有的空格 拼写检查 设置相对行 f 查找文件 原始快捷键\n键位 作用 Ctrl w 删除前一个单词 Ctrl h 删除前一个字符 Ctrl u 删除至行首 切换普通模式 Ctrl [ 切换普通模式 Ctrl o 切换到插入-普通模式 数字+1 18表示数字+180 数字-1 g~ 反转大小写 配合aw使用 gu 转化为小写 配合aw使用 gU 转化为答谢 配合aw使用 \u0026gt; 增加缩进 \u0026lt; 减小缩进 向下翻一页 向上翻一页 回到上次修改的地方 撤销撤销 常见的等效命令：\n符合命令 等效的长命令 C c$ s cl S ^c I ^i A $a o A O ko 尽量使用符合命令，减少敲击键盘的次数。\nvim-markdown快捷键参考：\n快捷键 作用 ,b 加粗 ,p 斜体 ,q 行内代码块 ,c 代码块 ,g todo ,p 图片 ,a 链接 ,n 几号 标题 vim-table-mode插件参考使用:\nvim中写table\n按键 功能 \\tm 开启或者关闭table mode \\T 将内容转化为表哥 \\tdd 删除某一行 \\tdc 删除当前列 \\tfa 添加公式 \\tfe 计算公式 \\ts 对某一列排序 其他参考：\n可视模式 Vim 有 3 种不同的可可视模式，分别用于操作字符文本、行文本和块文本。\n面向字符 适合操作单词和短语。激活：v\n行文本 适合操作行文本。激活：V。\n选择多行执行命令：\n例如：Vj + \u0026gt;. 表示将下面两行进行两次缩进\n块文本 适合操作表格或者csv文件。激活：\n在长短不一的高亮块后面添加文本。操作： + 2j + $ + A + “添加的字符串” + 命令 作用 viw 高亮一个词(然后按c进行修改) or v 可以在可视模式和选择模式之间切换 b 选择前一个词 w 选择后一个词 o 回到选择的初始位置 e 选择到末尾 vit 高亮选中标签内部的内容 U 选中的字符变为大写(普通模式使用gUit更为准确) u 选中的字符变为小写 r+字符 选择区域替换为字符 使用点命令最好避免可视模式。\n命令行模式 待补充。。。\nvim实用技巧：\n把撤销单元切成块。 从进入插入模式开始，直到返回普 通模式为止，在此期间输入或删除的任何内容都被当成一次修改。因此，只要我们控制 好对 键的使用，就可使撤销命令作用于单词、句子或段落 当处于插入模式时，如果光标位于行尾的话，另起一行最快的方式是按。不 过有时我更喜欢按 o，这是因为我有预感，也许在撤销时我想拥有更细的粒度 124 坑 打开vim回到上次的位置：https://www.dyxmq.cn/linux/vim-setting-mouse-place.html ","description":"","id":25,"section":"posts","tags":["vim"],"title":"vim使用笔记","uri":"https://hugo.jiahongw.com/posts/efficient/vim/"},{"content":"不经意间看见了下面的这篇博文，联想到自己，我自己和父亲的关系就非常类似下面博主和他父亲的关系。\n文章链接(可能需要翻墙) 我自己对待父亲其实一直以来都很冷漠，之前有段时间还经常的吵架，因为一些事。仔细想一下，很多东西是失去了之后才懂得珍惜，也有很多东西，是自己亲身体验了之后才知道里面的苦楚。我对父亲的不理解，或许只是我没有经历过他经历的，也或许是我自己的傲慢。\n但是不管怎么说，这篇文章都直接给了我一个警示，让我思考和父亲相处的方式。我的父亲也将近五十岁了，一路走来也不容易，我还是应该感谢他，为我付出了这么多，而且可能很多背后的付出是我没有看到的。我都应该在接下来的日子里面好好的回馈他。以前我没有什么可以给他，但是现在我工作了，至少还是能够有一些资本可以给他买点东西或者让他生活的更好，也希望之后的他能够更加的快乐。\n同时，这篇博文也说了，健康才是最重要的，要过就过有意义的生活，比起他什么都重要。下面引用文章作者的一句话，我觉得非常有道理：\n如果说我从这段亲子关系里学到了什么，那就是自己的身体健康，和重要的人度过有质量、有意义的时光，比什么狗屁成绩、职位、收入，都重要的多，你必须自己照顾好自己。 ","description":"生活中很少注意一些东西，错过了就将不复存在。珍惜当下！","id":26,"section":"posts","tags":["Life"],"title":"一篇文章想到父亲","uri":"https://hugo.jiahongw.com/posts/life/myfather-some/"},{"content":"Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否解决一些初级的编程问题，解决问题的能够得到100美元，非常有意思。对于我们来说这些问题非常的简单，但是对于普通人来说，还是有一定的难度的。似乎在芝加哥的街头上也会编程的也不是挺多人，或者，程序猿都在上班吧🐶。\n在第二期的问题变得比较难一点，是college水平的，解决问题的能够得到200美元。后面那个熟悉的判断回文串😄。\n想象这个活动要是在中国试一试，感觉街头很多人能够做出来，因为中国的程序员越来越多了。\n","description":"Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否姐姐一些初级的编程问题。","id":27,"section":"posts","tags":["FunnySharing"],"title":"街头代码编程","uri":"https://hugo.jiahongw.com/posts/life/code-problem-solving-onstreet/"},{"content":"Java语言虽然号称一切都是对象，但原始数据类型是例外。\n在Java 5中，引入了自动装箱和自动拆箱功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大地简化了相关编程。\n自动装箱实际上算是一种语法糖 。就是保证不同的写法在运行时是等价的。它们发生在编译阶段 ，也就是生成的字节码是一致的。\n装箱表示将原始数据类型进行封装起来，然后添加一些操作例如数学计算和字符串转换等。\n拆箱表示将一个封装了原始数据类型的对象转回为原始数据类型。\nJava的8个原始数据类型（boolean、byte 、short、char、int、float、double、long)分别对应的8个封装对象为Boolean、Byte、Short、Character、Integer、Float、Double、Long。\n在Java中，几乎所有的基本类型封装类在进行自动装箱的时候都实现了缓存。\nInteger，缓存了-128到127之间的数值\nBoolean，缓存了true/false对应实例，确切说，只会返回两个常量实例Boolean.TRUE/FALSE。\nShort，同样是缓存了-128到127之间的数值。\nByte，数值有限，所以全部都被缓存。\nCharacter，缓存范围’u0000’ 到 ‘u007F’\n这在一定程度能够节省内存，提高性能。但是原则上，建议避免无意中的装箱、拆箱行为 ，尤其是在性能敏感的场合，创建10万个Java对象和10万个整数的开销可不是一个数量级的 ，不管是内存使用还是处理速度，光是对象头的空间占用就已经是数量级的差距了。一些追求极致性能的产品或者类库，会极力避免创建过多对象。当然，在大多数产品代码里，并没有必要这么做，还是以开发效率优先。需要权衡利弊。\nInteger例子 javac替我们自动把装箱转换为Integer.valueOf()，把拆箱替换为Integer.intValue()，既然调用的是Integer.valueOf，自然能够得到缓存的好处。\n下面的调用了自动装箱和自动拆箱：\n1 2 Integer integer = 1;// 自动装箱 int unboxing = integer ++;//自动拆箱 反编译得到：\n1 2 3 4 1: invokestatic #2 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 8: invokevirtual #3 // Method java/lang/Integer.intValue:()I 即装箱转换为Integer.valueOf()，把拆箱替换为Integer.intValue()，在Java源码可见这个值默认缓存是-128到127之间。\n源码\n缓存范围：\n装箱操作\n拆箱操作\n","description":"在Java 5中，引入了自动装箱和自动拆箱功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大地简化了相关编程。","id":28,"section":"posts","tags":["Java"],"title":"Java装箱拆箱","uri":"https://hugo.jiahongw.com/posts/java/boxing-unboxing/"},{"content":"极化编码的基本思想是：只在$Z\\left( W_{N}^{\\left( i \\right)} \\right)$近于0的坐标信道$W_{N}^{\\left( i \\right)}$上发送数据比特。极化码具有一般的二元线性分组码的基本编码要素，因而可以通过显示地写出其生成矩阵来完成编码：\n$$\nx_{1}^{N}=u_{1}^{N}{G_{N}}\n$$\n其中，编码生成矩阵${G_{N}}\\text{=}{B_{N}}{F^{\\otimes n}}$，$B_{N}$是排序矩阵，完成比特的反序操作，$F^{\\otimes n}$表示矩阵$F$进行$n$次$Kronecker$积操作，有递归公式${F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}$且${F^{\\otimes 1}}\\text{=}F=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]$。\n主要的步骤为：\n可靠性估计 可靠性估计就是极化码的构造，这个过程我们选出信道容量高的子信道进行传输，信道容量低的子信道传输冻结比特。\n常见的几种可靠性估计的方法（极化码构造方法）有：\n巴士参数估计法。\n蒙特卡洛法。\n密度进化法。\n高斯近似法。\n比特混合 假设通过错误概率进行极化码构造之后得到极化序列为$\\left{ 3,5,6,7,0,1,2,4 \\right}$ ，选择前面K个信道即$A=\\left{ 3,5,6,7\\right}$发送信息比特；另外的信道集合${A^{c}}=\\left{ 0,1,2,4\\right}$作为固定比特传输。设信息比特集合为$\\left( {i_{0}},{i_{1}},{i_{2}},{i_{3}} \\right)=\\left( 1,1,1,1 \\right)$，固定比特设置为0，则最终得到待编码的信息比特：\n$$\nu_{0}^{7}=\\left[ 0,0,0,{i_{0}},0,{i_{1}},{i_{2}},{i_{3}} \\right]=\\left[ 0,0,0,1,0,1,1,1 \\right]\n$$\n经过上面的过程我们就完成了对信息位和冻结位的比特混合。\n构造生成矩阵 首先我们求出排序矩阵$B_{N}$，其有递归式：\n$$\n{B_{N}}={R_{N}}\\left( {I_{2}}\\otimes {B_{N/{2};}} \\right)\n$$\n$$\n{B_{2}}={I_{2}}\n$$\n我们得到排序矩阵$B_{N}$，对输入序列完成奇序元素和偶序元素的分离，即先排奇序元素，再排偶序元素，其作为效果如下:\n$$\n\\left( {u_{1}},{u_{2}},{u_{3}},{u_{4}},\u0026hellip;,u{}{N} \\right)\\times {R {N}}=\\left( {u_{1}},{u_{3}},{u_{5}},\u0026hellip;,{u_{N-1}},{u_{2}},{u_{4}},{u_{6}},\u0026hellip;,{u_{N}} \\right)\n$$\n$F$矩阵我们可以根据下面的递归式进行求解：\n$$\n{F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}\n$$\n$$\nF=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]\n$$\n最后，我们将求得的排序矩阵和$F$矩阵相乘，得到生成矩阵$G_{N}$：\n$$\n{G_{N}}={B_{N}}{F^{\\otimes n}}\n$$\n假设我们求得的生成矩阵是：\n生成极化码 将信息比特与生成矩阵$G_{N}$相乘得到最终编码后的极化码，例如：\n参考：\nPolar Code（2）编码原理 | Marshall - Comm. Tech. Blog ","description":"极化码的编码就是一些简单的线性运算，通过矩阵进行简化多维的运算，归根到底还是基于基本的异或操作。","id":29,"section":"posts","tags":["PolarCode","编码"],"title":"极化码-编码","uri":"https://hugo.jiahongw.com/posts/polarcode/polar-code-encode/"},{"content":"基本概念 信噪比 信噪比，英文名称叫做SNR（SIGNAL-NOISE RATIO )，是指一个电子设备或者电子系统中信号与噪声的比例。信噪比的计算可以为有用信号功率与噪声功率的比 ：\n$$\nSNR = \\frac {P_{signal}} {P_{noise}}\n$$\n它的单位一般使用分贝，其值为十倍对数信号与噪声功率比:\n$$\nSNR(dB) = 10\\log_{10}(\\frac {P_{sibnal}} {P_{noise}})\n$$\n其中，$P_{signal}$为信号功率，$P_{noise}$为噪声功率。\n转移概率 一个二进制输入离散无记忆信道（B-DMC）可表示为$W:X\\to Y$，$X$是输入符号集合，$Y$是输出符号集合，转移概率为$W\\left( y|x \\right),x\\in X,y\\in Y$。由于信道是二进制输入，集合$X=\\left{ 0,1 \\right}$；$Y$和$W\\left( y|x \\right)$是任意值。对信道$W$的$N$次使用后的信道可表示为${W^{N}}$，则信道${W^{N}}:{X^{N}}\\to {Y^{N}}$的转移概率为：\n$$\n{W^{N}}\\left( y_1^{N}|x_{1}^{N} \\right)=\\prod\\nolimits_{i=1}^{N}{W\\left( y|x \\right)}\n$$\n对称容量 对称容量是对信道速率的度量，记作$I(W)$，表示信道$W$在等概率输入下的可靠传输时的最大速率,计算公式如下：\n$$\nI\\left( W \\right)\\triangleq \\sum\\limits_{y\\in Y}{\\sum\\limits_{x\\in X}{\\frac{1}{2}}}W\\left( y|x \\right)\\log \\frac{W\\left( y|x \\right)}{\\frac{1}{2}W\\left( y|0 \\right)+\\frac{1}{2}W\\left( y|1 \\right)}\n$$\n当码长$N$趋近于无穷的时候，信道容量趋近于1的分裂信道比例约为$K=N×I(W)$，这部分是用来传输信息比特的信道数量，而信道容量趋近于0的比例约为$N×(1−I(W))$，这部分表示冻结比特的信道数量。对于信道容量为1的可靠信道，可以直接放置消息比特而不采用任何编码，即相当于编码速率为$R=1$；而对于信道容量为0的不可靠信道，可以放置发送端和接收端都事先已知的冻结比特，即相当于编码速率为$R=0$。那么当码长$N \\to\\infty$时，极化码的可达编码速率$R= \\frac {K}{N}= \\frac {N×I(W)}{N}=I(W)$，即在理论上，极化码可以被证明是可达信道容量的。\n信道极化 信道极化分为信道联合和信道分裂两个阶段。对于长度为$N={2^{n}}$（$n$为任意整数）的极化码，它利用信道$W$的$N$个独立副本，进行信道联合和信道分裂，得到新的$N$个子信道$\\left{ W_{N}^{\\left( 1 \\right)},W_{N}^{\\left( 2 \\right)},\u0026hellip;,W_{N}^{\\left( N \\right)} \\right}$。随着码长的增加，分裂之后的信道将向两个极端发展：其中一部分分裂信道会趋近于完美信道，即信道容量趋近于1的无噪声信道；而另一部分分裂信道会趋近于完全噪声信道，即信道容量趋近于0的信道。\n我们主要研究二进制离散无记忆信道，将上面的信道模型（包括BEC、BSC、AWGN）进行抽象，我们可以得出下面的信道传输模型：\n图中的W可以是BEC信道，也可以是BSC信道或者AWGN信道，其中I(W)为信道容量。\n信道联合 信道联合是将多个子信道进行蝶形的异或操作的过程。对于码长为N=2的极化码，我们可以通过下面的蝶形异或操作将两个信道进行混合：\n由上图可以发现，进行信道联合之后，坐标不同信道的信道容量发生了极化现象，有一个比特的信道信道容量$I(W)$增加了，另外一个比特的信道容量$I(W)$减少了。信道容量小的，我们称为差信道，信道容量大的，我们称为号好信道。因为进行了信道联合之后，因为要求得左边的信道$u1$，必须是在右边的信道$y1$和$y2$同时都收到的情况下才能够得出$u1$，所以$u1$的信道容量就是信道$y1$和$y2$的信道容量乘积；相应的，对于信道$u2$，只有$y1$和$y2$都收不到的情况下，才接收不到信道，所以它的信道容量$I(W)$为$2*0.5 - 0.5^{2}$。\n我们也可以使用一个二维表格来计算它们传输的概率：\ny1 y2 u1 u2 √ √ √ √ √ x x √ x √ x √ x x x x 由表格1可以发现，对于接收方收到的信号y1和y2，总共有4种情况，X表示该信道发生错误，未收到信道；√表示该信道收到了信道。对于子信道u1，在四种情况中，只有一种情况能够接受得到u1，也就是同时接收到y1和y2的情况,所以信道容量为1/4；而对于u2,只要能够收到y1或y2的任意一个它就能够解出来,根据信道极化理论，我们在进行极化的过程中，就已经知道信道u1的信道容量比较小，我们会把它作为冻结比特，填充为0，不传输信息比特，仅传输冻结比特，所以在没有接收到y2的情况下我们也能够得出u2。\n对于N=4的码长，我们可以递归的进行信道联合，如图，只不过相比于N=2的码长的极化码，我们需要增加一次的信道联合过程：\n按照这样不断的递归下去，到n级之后，可以得到递归的一般式：${W_{N/{2};}}$的2个独立副本联合产生信道${W_{N}}$，我们可以的到任意码长为$N=2^{n}$的极化码。\n信道分裂 信道分裂体现在信道联合之中 ，参考文献中对于信道分裂的解释，其大致过程是将两个信道$W_{N/2}$联合成一个信道$W_N$之后，再将联合的信道$W_N$分裂成两个子信道$W_{N/2}$，此时，这两个子信道的转移概率也改变了，这样极化码就完成了信道分裂。更具体的来说，它存在以下两个递推公式计算子信道的转移概率：\n$$\nW_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},u_{1}^{2i-2}|{u_{2i-1}} \\right)=\\sum\\limits_{u_{2i}}{\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)}\n$$\n$$\nW_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},u_{1}^{2i-1}|{u_{2i}} \\right)=\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)\n$$\n参考：\n《“太极混一”——极化码原理及5G应用》 ","description":"介绍关于极化码的一些基本的数学与计算原理，包括如何进行概率的转移的。","id":30,"section":"posts","tags":["PolarCode","基本原理"],"title":"极化码-基本原理","uri":"https://hugo.jiahongw.com/posts/polarcode/polar-code-fundamentals/"},{"content":"在通信过程中，物理层传输的就是电信号，假如我们只用0和1传输信号，并且这些信道互相都没有关系，我们称为二进制离散无记忆信道。信道模型是研究信道编码的基础，常见的几种信道模型分别有：二进制删除信道（BEC）、二进制对称信道（BSC）、高斯信道（AWGN）。设信道的输入和输出分别是长为N的序列，输入是x，输出是y，其信道的转移概率满足：\n$$\np\\left( {y|x} \\right) = \\sum_{i=1}^N p\\left( {y_{i} | x_{i}} \\right)\n$$\n无损信道 无论发送任何消息，接受方都能够准确无误的接收到，并且不会发生错误，那么这个信道就可以说是一个无损信道。最简单的的就是下面这个模型，不管发送者发送的是0还是1，接收者接受的都是一致的。\n假如我们随机进行传输0或者1的数据，其传输的数值图为下面：\n二进制删除信道 二进制删除信道，简记为BEC（Binary Erasure Channel ）。ϵ称为删除概率，表示有ϵ的概率这个信号会丢失。当接收方得到一个位，它是100%确定的位是正确的。只有当位被擦除时，才会出现唯一的混淆。对于二进制离散无记忆信道，我们有ϵ的概率丢失0或者1的比特位。\nBEC的信道容量为：\n$$\nC= 1 - \\epsilon\n$$\n二进制对称信道 二进制对称信道，简记为BSC（Binary Symmetric Channel ）。p称为交叉概率，表示有p的概率会导致传输过程中0信号和1信号的错乱。（错乱的意思是发送0，收到却是1；或者发送1，收到却是0）\nBSC的信道容量为：\n$$\nC = \\log n + q\\log q + (1-q) \\log \\frac {1-q}{n-1}\n$$\n加性高斯白噪声信道 高斯信道，常指加权高斯白噪声（AWGN）信道。这种噪声假设为在整个信道带宽下功率谱密度（PDF）为常数，并且振幅符合高斯概率分布。\n一般来说，高斯信道需要配合BPSK机制进行调制，在传输之前，我们对0和1比特进行变换，比特0会变成1，比特1变成-1，而这个将比特进行转换的过程就是BPSK调制，最后在BPSK调制后再加上高斯噪声，实际的模型如下：。\n通过BPSK调制之后0比特和1比特都会向1和-1这两个临界线靠经，在这个情况下传入高斯信道，即使存在高斯噪声进行影响，我们也能够减小它的影响，在解码端对码字进行BPSK解调，能够得到较高的准确率。\n由图可以发现，值靠近1的信号表示原来的信号是0，值靠近-1的信号表示原来的信号是1。这样的好处是在传输过程中减少高斯噪声的干扰，让传输的信号更加稳定。\n特别的，5G标准要求信道编码至少能够在加性高斯白噪声信道（AWGN）下进行传输。\n","description":"在信息论中，信道是指信息传输的通道。我们在实际通信中所利用的各种物理通道是信道的最典型的例子，如电缆、光纤、电波传布的空间、载波线路等等。但是极化码的信道模型将他们进行了抽象，将信道分成了几类：BEC、BSC、AWGN。","id":31,"section":"posts","tags":["PolarCode","信道模型"],"title":"极化码-信道模型","uri":"https://hugo.jiahongw.com/posts/polarcode/polar-code-channel-model/"},{"content":"Arıkan教授在文献[1]提出了串行抵消SC译码算法。SC译码算法类似一个深度优先搜索的算法，其根据两个判决函数进行迭代计算最大似然对数比LLR，两个判决函数分别叫做f函数和g函数。下面是这两个公式的计算方法：\n$$\n\\begin{align}\nf\\left( a,b \\right)=\\ln \\left( \\frac{1+{ {e}^{a+b}}}{ { {e}^{a}}+{ {e}^{b}}} \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\ng\\left( a,b,{ {u}{s}} \\right)={ {\\left( -1 \\right)}^{ { {u} {s}}}}a+b\n\\end{align}\n$$\n其中，$a,b\\in R,{ {u}_{s}}\\in \\left{ 0,1 \\right}$。LLR的递归运算借助函数f和g表示如下：\n$$\n\\begin{align}\nL_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},\\hat{u}{1}^{2i-2} \\right)=f\\left( L {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}{1,o}^{2i-2}\\oplus \\hat{u} {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}_{1,e}^{2i-2} \\right) \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\nL_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},\\hat{u}{1}^{2i-1} \\right)=g\\left( L {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}{1,o}^{2i-2}\\oplus \\hat{u} {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}{1,e}^{2i-2} \\right),{ { {\\hat{u}}} {2i-1}} \\right)\n\\end{align}\n$$\n递归的终止条件为当$N=1$时，即到达了信道$W$端，此时$L_{1}^{\\left( 1 \\right)}\\left( { {y}{j}} \\right)=\\ln \\frac{W\\left( { {y}{j}}|0 \\right)}{W\\left( { {y}_{j}}|1 \\right)}$。\nSC译码算法依靠一个蝶形单元，如图10，在计算的时候不断进行递归，但是必须是先计算出蝶形单元的上行比特，才能够调用g函数求出下行比特。即图10中必须使用f函数计算出u1，之后才能够通过g函数求出u2。在实际的计算过程中，从接收的比特进行递归执行f函数和g函数，其中假如编码每次进行一次极化，在译码阶段都会多一次递归的计算，中间的计算值就是进行极化的临时值，在一整个蝶形结构中体现，是一个深度优先的算法。\nSCL译码算法[3]类似树的广度优先遍历，它的好处就是能够进行剪枝操作，不用计算所有的节点。它从根节点开始往树底部进行广度遍历搜索，每一层会计算出一个估计比特，然后在这个估计比特的基础上往下进行估计下一个比特的值，另外，SCL译码算法还增加了惩罚因子，对于惩罚因子过高的节点，我们可以直接跳过它以及它子节点的计算，因为它是正确的码的可能性极低，这样排除了不可能的路径，同时，这也能达到对树进行剪枝的效果，提高译码的速度。图11展示了进行SCL译码的基本过程：\n","description":"译码和编码类似，基于递归的结构。","id":32,"section":"posts","tags":["PolarCode","极化码译码"],"title":"极化码-译码","uri":"https://hugo.jiahongw.com/posts/polarcode/polar-code-decode/"},{"content":"出发前的准备 冲锋衣（防风，防晒，防雨，防寒） 登山鞋或者越野鞋 登山杖 帽子 防晒霜 一次性内裤和一次性雨衣 相机 厚的衣服 口罩 学生证 身份证 驾驶证 基本路线 小环线+稻城亚丁\n川西美景 合照 some word 大学四年一下就过去了，很高兴遇见了一群很棒的朋友。希望未来的我们也更加优秀！旅游真是一件又累又让人重新认识世界事情啊！\n","description":"在大学的最后一次和朋友的旅行......","id":33,"section":"posts","tags":["life"],"title":"毕业旅行-川西","uri":"https://hugo.jiahongw.com/posts/life/biyeluxing/"},{"content":"川西毕业旅行的图片。\n","description":"川西毕业旅行","id":34,"section":"gallery","tags":null,"title":"川西","uri":"https://hugo.jiahongw.com/gallery/chuanxi/"},{"content":"5G下的极化码 这个专栏介绍极化码的相关原理，一方面是因为我目前的毕业设计是关于5G极化码方向的，另一方面我想将自己所学的一些知识记录或者分享起来。\n首先，我想要说的是，极化码是一种编码方式，它的目的是为了使得在传输过程中传输更多有效的消息，也可以理解为让传输更可靠的编码方式。当然，对于信道编码来讲，那最主要的就是编码和解码这两个板块。那什么是信道编码呢？可以这样理解：发送方先对发送的信息进行编码，通过信道进行传输，然后在接受方那边进行解码，得到消息，这就是信道编码的基本过程。我会在之后的文章中分析这些过程。\n专栏的目录分为如下几个板块：\n信道模型 极化码基本原理 极化码的编码 极化码的译码 极化码的构造（信道的选择） 极化码实现 ","description":"极化码已经入选5G的标准，是唯一一个被证明可以达到香农极限的一种编码方式。","id":35,"section":"posts","tags":["PolarCode"],"title":"5G下的极化码","uri":"https://hugo.jiahongw.com/posts/polarcode/polar-code-intro/"},{"content":"使用场景\n避免冗长的if-else或switch分支判断 提供框架的扩展点 策略模式：\n策略模式定义了算法族，分别封装起来，让他们之间可以互相替换。此模式让算法的变化独立于使用算法的客户。\n策略定义：\nclassDiagram Strategy \u0026lt;|-- StrategyA : implements Strategy \u0026lt;|-- StrategyB : implements Strategy : algorithmInterface() StrategyA : algorithmInterface() StrategyB : algorithmInterface() 策略创建：\nclassDiagram Strategy \u0026lt;|-- StrategyA : implements Strategy \u0026lt;|-- StrategyB : implements Strategy : algorithmInterface() StrategyA : algorithmInterface() StrategyB : algorithmInterface() StrategyFactory --\u0026gt; Strategy : 关联 StrategyFactory : getStrategy(type) 无状态策略：无状态的策略因为不会变，可以进行缓存，一开始就创建好所有的策略即可。（直接从map中拿取） 有状态策略：有状态的策略因为会改变，所以每次创建都需要是一个最新的策略对象。（在工厂类中存在if-else判断） 策略使用：\n​\ngraph TD; 拿取策略:getStrategy--\u0026gt;使用策略接口:algorithmInterface; 从工厂类中拿取策略。 调用策略对应的接口函数。 对于Java来说，可以使用反射来避免策略工厂类的修改。（配置文件或者annotation）\nSpring框架中有org.springframework.beans.factory.ListableBeanFactory#getBeansOfType(java.lang.Class)函数可以直接获取指定类型的Bean，通常这个类型可以设置成策略的接口。\n策略模式主要是解耦策略的定义、创建和使用，并且还能满足开闭原则，方便后面进行拓展。\n解决什么问题使用策略模式？\n告警 重试 规则配置（规则引擎） 什么情况下有必要去除if-else或者switch-case分支语句？\n业务逻辑过于复杂，后续需求不断来。（KISS原则） 个人沉淀和输出方面\n作为团队中最ES组件较为熟悉的人，需要对组件原理和最佳实践有一些自己的沉淀，并且能够针对组件的使用和实践在组内进行分享，增加团队的技术沉淀。此前有关于Thrift原理的分享，但是分享的时间周期太过于长，也应该制定一个规划时间，按照规划的时间进行总结和分享，做到更加有规划。在运维平台搭建完成之后，组内成员不知道如何进行接入，其实接入非常简单，但是缺少宣讲大家就不知道如何处理，都导致大家都以为接入过程很复杂。\n方案设计考虑\n目前在方案设计上能够考虑数据一致性、重试和监控等功能，对于大数据量操作，还需要考虑刷数据等方法的可回滚性，以及在方案设计中是否能想到更好的方法。目前可能是当前接住的项目还不够大，之后接触更多更大的项目也需要能够进行更多的一些思考，不断形成更加全面的思考方式和方案设计的思路，提前洞察到可能出现的问题。\nReference:\n极客时间《使用策略模式除去if-else分支逻辑》 ","description":"策略模式定义了算法族，分别封装起来，让他们之间可以互相替换","id":36,"section":"posts","tags":["行为模式","策略模式"],"title":"策略模式","uri":"https://hugo.jiahongw.com/posts/designpattern/strategypattern/"},{"content":" 在home目录下安装的nginx程序d\n申请证书 letsencrypt的证书 申请网站：https://letsencrypt.osfipin.com/\n腾讯云的证书 申请网站：https://cloud.tencent.com/product/ssl\n证书申请完成之后，记录证书的位置，在nginx.conf文件进行修改即可，修改方式可以参照下面的步骤。\n使用certbot自动化 参考地址：https://blog.csdn.net/xs18952904/article/details/79262646\n检查nginx 查看 nginx 是否安装 http_ssl_module 模块\n/usr/local/nginx/sbin/nginx -V 如果出现 configure arguments: –with-http_ssl_module, 则已安装，不然的话需要重新编译安装，参考下面：\nhttps://segmentfault.com/a/1190000022673232\n安装certbot 1 yum install certbot python2-certbot-nginx 配置 SSL 证书证书时,报错ImportError: cannot import name UnrewindableBodyError，可以参考：https://www.cnblogs.com/codecheng99/p/12620850.html\n部署步骤 申请证书\ncertbot certonly --standalone -d jiahongw.com -d www.jiahongw.com 证书路径：\n/etc/letsencrypt/live/jiahongw.com/fullchain.pem /etc/letsencrypt/live/jiahongw.com/privkey.pem 进入修改\nvim nginx.conf 设置HTTP强制跳转HTTPS\n1 2 3 4 5 server { listen 80; server_name example.com; #这里修改为网站域名 rewrite ^(.*)$ https://$host$1 permanent; } 设置HTTPS\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 server { listen 443 ssl; server_name jiahongw.com www.jiahongw.com; ssl_certificate /etc/letsencrypt/live/jiahongw.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jiahongw.com/privkey.pem; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #安全链接可选的加密协议 ssl_prefer_server_ciphers on; location / { root html/my_website; # my index index.html index.htm; } } 测试配置文件的正确性\nnginx -t 重启nginx\n/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 自动续费\necho \u0026#34;0 0,12 * * * root python -c \u0026#39;import random; import time; time.sleep(random.random() * 3600)\u0026#39; \u0026amp;\u0026amp; certbot renew\u0026#34; | sudo tee -a /etc/crontab \u0026gt; /dev/null 手动续期\ncertbot certonly --standalone -d example.com -d www.example.com 配置https代理\nserver { listen 443 ssl; server_name hostname.com; ssl_certificate cert/214547145790616.pem; ssl_certificate_key cert/214547145790616.key; location / { proxy_pass http://localhost:12345; } } 配置http2.0\nhttps://segmentfault.com/a/1190000017847301\n通过 Certbot 安装 Let\u0026rsquo;s Encrypt 证书，实现免费的全站 HTTPS 访问 | Laravel 学院\n配置Nginx 主要功能：\n静态资源 反向代理 API服务 Nginx配置反向代理：\nalias与root的区别 root 实际访问文件路径会拼接URL中的路径\nalias 实际访问文件路径不会拼接URL中的路径\n示例如下：\nlocation ^~ /sta/ { alias /usr/local/nginx/html/static/; } 请求：http://test.com/sta/sta1.html\n实际访问：/usr/local/nginx/html/static/sta1.html 文件\nlocation ^~ /tea/ { root /usr/local/nginx/html/; } 请求：http://test.com/tea/tea1.html\n实际访问：/usr/local/nginx/html/tea/tea1.html 文件\nRef：\nNginx location匹配规则 - Ryan.Miao - 博客园 Nginx配置文件详解 - 程序员自由之路 - 博客园 检测HTTP3（quic）：HTTP/3 Check\n","description":"使用Nginx + certbot快速的配置一个可以https访问的网站。","id":37,"section":"posts","tags":["nginx"],"title":"Nginx配置SSL证书","uri":"https://hugo.jiahongw.com/posts/nginx/nginx-ssl/"},{"content":" 《转载》 https://www.cnblogs.com/fanzhidongyzby/p/3250405.html\n按照冯·诺依曼存储程序原理，程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。\n上图是进程地址空间分布的简单表示。代码存储了用户程序的所有可执行代码，在程序正常执行的情况下，程序计数器（PC指针）只会在代码段和操作系统地址空间（内核态）内寻址。数据段内存储了用户程序的全局变量，文字池等。栈空间存储了用户程序的函数栈帧（包括参数、局部数据等），实现函数调用机制，它的数据增长方向是低地址方向。堆空间存储了程序运行时动态申请的内存数据等，数据增长方向是高地址方向。除了代码段和受操作系统保护的数据区域，其他的内存区域都可能作为缓冲区，因此缓冲区溢出的位置可能在数据段，也可能在堆、栈段。如果程序的代码有软件漏洞，恶意程序会“教唆”程序计数器从上述缓冲区内取指，执行恶意程序提供的数据代码！\n栈溢出 栈的主要功能是实现函数的调用。因此在介绍栈溢出原理之前，需要弄清函数调用时栈空间发生了怎样的变化。每次函数调用时，系统会把函数的返回地址（函数调用指令后紧跟指令的地址），一些关键的寄存器值保存在栈内，函数的实际参数和局部变量（包括数据、结构体、对象等）也会保存在栈内。这些数据统称为函数调用的栈帧，而且是每次函数调用都会有个独立的栈帧，这也为递归函数的实现提供了可能。\n如图所示，我们定义了一个简单的函数function，它接受一个整形参数，做一次乘法操作并返回。当调用function(0)时，arg参数记录了值0入栈，并将call function指令下一条指令的地址0x00bd16f0保存到栈内，然后跳转到function函数内部执行。每个函数定义都会有函数头和函数尾代码，如图绿框表示。因为函数内需要用ebp保存函数栈帧基址，因此先保存ebp原来的值到栈内，然后将栈指针esp内容保存到ebp。函数返回前需要做相反的操作——将esp指针恢复，并弹出ebp。这样，函数内正常情况下无论怎样使用栈，都不会使栈失去平衡。\nsub esp,44h指令为局部变量开辟了栈空间，比如ret变量的位置。理论上，function只需要再开辟4字节空间保存ret即可，但是编译器开辟了更多的空间（这个问题很诡异，你觉得呢？）。函数调用结束返回后，函数栈帧恢复到保存参数0时的状态，为了保持栈帧平衡，需要恢复esp的内容，使用add esp,4将压入的参数弹出。\n之所以会有缓冲区溢出的可能，主要是因为栈空间内保存了函数的返回地址。该地址保存了函数调用结束后后续执行的指令的位置，对于计算机安全来说，该信息是很敏感的。如果有人恶意修改了这个返回地址，并使该返回地址指向了一个新的代码位置，程序便能从其它位置继续执行。\n栈溢出基本原理 上边给出的代码是无法进行溢出操作的，因为用户没有“插足”的机会。但是实际上很多程序都会接受用户的外界输入，尤其是当函数内的一个数组缓冲区接受用户输入的时候，一旦程序代码未对输入的长度进行合法性检查的话，缓冲区溢出便有可能触发！比如下边的一个简单的函数。\n1 2 3 4 5 void fun(unsigned char *data) { unsigned char buffer[BUF_LEN]; strcpy((char*)buffer,(char*)data);//溢出点 } 这个函数没有做什么有“意义”的事情（这里主要是为了简化问题），但是它是一个典型的栈溢出代码。在使用不安全的strcpy库函数时，系统会盲目地将data的全部数据拷贝到buffer指向的内存区域。buffer的长度是有限的，一旦data的数据长度超过BUF_LEN，便会产生缓冲区溢出。\n由于栈是低地址方向增长的，因此局部数组buffer的指针在缓冲区的下方。当把data的数据拷贝到buffer内时，超过缓冲区区域的高地址部分数据会“淹没”原本的其他栈帧数据，根据淹没数据的内容不同，可能会有产生以下情况：\n1、淹没了其他的局部变量。如果被淹没的局部变量是条件变量，那么可能会改变函数原本的执行流程。这种方式可以用于破解简单的软件验证。\n2、淹没了ebp的值。修改了函数执行结束后要恢复的栈指针，将会导致栈帧失去平衡。\n3、淹没了返回地址。这是栈溢出原理的核心所在，通过淹没的方式修改函数的返回地址，使程序代码执行“意外”的流程！\n4、淹没参数变量。修改函数的参数变量也可能改变当前函数的执行结果和流程。\n5、淹没上级函数的栈帧，情况与上述4点类似，只不过影响的是上级函数的执行。当然这里的前提是保证函数能正常返回，即函数地址不能被随意修改（这可能很麻烦！）。\n如果在data本身的数据内就保存了一系列的指令的二进制代码，一旦栈溢出修改了函数的返回地址，并将该地址指向这段二进制代码的其实位置，那么就完成了基本的溢出攻击行为。\n通过计算返回地址内存区域相对于buffer的偏移，并在对应位置构造新的地址指向buffer内部二进制代码的其实位置，便能执行用户的自定义代码！这段既是代码又是数据的二进制数据被称为shellcode，因为攻击者希望通过这段代码打开系统的shell，以执行任意的操作系统命令——比如下载病毒，安装木马，开放端口，格式化磁盘等恶意操作。\nmore：\n参考链接：\nhttps://www.cnblogs.com/fanzhidongyzby/p/3250405.html 函数栈的实现原理 https://xz.aliyun.com/t/5964 ","description":"程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。","id":38,"section":"posts","tags":["Linux"],"title":"缓冲区溢出","uri":"https://hugo.jiahongw.com/posts/linux/buffer-overflow/"},{"content":"链接 链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。\n链接可以执行于编译时 (compile time) 也就是在源代码被翻译成机器代码时；也可以执行于加栽时（load time)，也就是在程序被加载器（loader)加载到内存并执行时；甚至执行于运行时（runtime)，也就是由应用程序来执行。\ngcc的编译过程：\n目标文件 编译器和汇编器生成可重定位目标文件(包括共享目标文件）。链接器生成可执行目标文件。\n可重定位目标文件 包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。\n下图是典型的ELF可重定位目标文件：\n这里需要注意的是，ELF 头（ELF header)以一个 16 字节的序列开始，这个序列描述了生成该文件的系统的字的大小和字节顺序。ELF 头剩下的部分包含帮助链接器语法分析和解释目标文件的信息。\n帮助链接器语法分析和解释目标文件的信息包括：\n括 ELF 头的大小 目标文件的类型 机器类型（如 X86-64) 节头部表的文件偏移 节头部表中条目的大小和数量 不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的条目（entry)\nELF 可重定位目标文件包含下面几个节：\n.text: 已编译程序的机器代码 .rodata: 只读数据，比如printf语句中的格式串和switch语句的跳转表。 .data: 已初始化的全局和静态 C 变量。(局部 C 变量在运行时被保存在栈中，既不出现在 .data 节中，也不出现在 .bss 节中) .-bss: 未初始化的全局和静态 C 变量，以及所有被初始化为 0 的全局或静态变量。 .symtab: —个符号表，它存放在程序中定义和引用的函数和全局变量的信息。 .rel.text: —个.text 节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置。 .rel.data: 被模块引用或定义的所有全局变量的重定位信息。 .debug: 一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的 C 源文件。 .line: 原始 C 源程序中的行号和.text 节中机器指令之间的映射。 .strtab: —个字符串表，其内容包括 .symtab 和 .debug 节中的符号表，以及节头部中的令名字。 可执行目标文件 包含二进制代码和数据，其形式可以被直接复制到内存并执行。\n加载可执行目标文件\n通过调用某个驻留在存储器中称为加载器（loader)的操作系统代码来运行它。任何Linux程序都可以通过execve 函数来调用加载器。\n加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。这个将程序复制到内存并运行的过程叫做加栽。\n在 Linux X86-64系统中，代码段总是从地址 0x400加0 处开始，后面是数据段。运行时堆在数据段之后，通过调用 malloc 库往上增长。\n用户栈总是从最大的合法用户地址（$2^{48}$ —1)开始，向较小内存地址增长。栈上的区域，从地址 $2^{48}$ 开始，是为内核（kernel)中的代码和数据保留的，所谓内核就是操作系统驻留在内存的部分。\nLinux X86-64 运行时内存映像。没有展示出由于段对齐要求和地址空间布局随机化（ASLR)造成的空隙。\n加载器运行时，创建上面所示的内存映像。在程序头部表的引导下,加载器将可执行文件的片(chunk)复制到代码段和数据段。接下来，加载器跳转到程序的人口点，也就是_start函数的地址。这个函数是在系统目标文件 ctrl.o 中定义的，对所有的 C 程序都是一样的。_start 函数调用系统启动函数__libc_start_main，该函数定义在 libc.so 中。它初始化执行环境，调用用户层的 main 函数，处理 main 函数的返回值，并且在需要的时候把控制返回给内核。\n共享目标文件 一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态地加载进内存并链接。\n静态链接 像 Linux LD 程序这样的静态链接器（static linker)以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的、可以加载和运行的可执行目标文件作为输出。\n为了构造可执行文件，链接器必须完成两个主要任务：\n符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量 重定位：编译器和汇编器生成从地址 0 开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置 为什么使用静态链接库 早期的问题：不使用静态链接库，如何像用户提供标准函数？\n一种方法是让编译器辨认出对标准函数的调用，并直接生成相应的代码。这种方法无疑会增加编译器的复杂性。(而且每次添\n加、删除或修改一个标准函数时，就需要一个新的编译器版本)\n另一种方法是将所有的标准 C 函数都放在一个单独的可重定位目标模块中。\n这种方法的优点是它将编译器的实现与标准函数的实现分离开来，并且仍然对程序员保持适度的便利。然而，一个很大的缺点是系统中每个可执行文件现在都包含着一份标准函数集合的完全副本，这对磁盘空间是很大的浪费。另一个大的缺点是，对任何标准函数的任何改变，无论多么小的改变，都要求库的开发人员重新编译整个源文件，这是一个非常耗时的操作，使得标准函数的开发和维护变得很复杂\n静态库概念被提出来，以解决这些不同方法的缺点。相关的函数可以被编译为独立的目标模块，然后封装成一个单独的静态库文件。\n在链接时，链接器将只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小。\n使用静态链接库 要创建一个静态库，我们将使用 AR 工具\n新建文件夹staticlib，在下面创建两个文件add.c和mul.c\n1 2 3 4 void add(int *x,int *y,int *z) { *z = (*x) + (*y); } 1 2 3 4 void mul(int *x,int *y,int *z) { *z = (*x) * (*y); } 并且新建一个文件mymath.h，里面包含了上面两个文件的函数申明：\n1 2 void add(int *x,int *y,int *z); void mul(int *x,int *y,int *z); 在文件夹staticlib下执行，编译成.o文件(就是一种可重定位文件)\ngcc -c *.c 使用 AR 工具生成静态链接库\nar rcs libmymath.a add.o mul.o 在 Linux 系统中，静态库以一种称为存档（archive)的特殊文件格式存放在磁盘中。存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置。存档文件名由后缀**.a** 标识。\n为了使用这个库，我们可以编写一个应用，与文件夹staticlib同级创建文件main.c\n1 2 3 4 5 6 7 8 9 10 11 12 #include \u0026lt;stdio.h\u0026gt; #include \u0026#34;staticlib/mymath.h\u0026#34; int main(int argc,const char *argv) { int x = 1,y = 2; int z; printf(\u0026#34;x = %d y = %d \\n\u0026#34;,x,y); add(\u0026amp;x,\u0026amp;y,\u0026amp;z); printf(\u0026#34;add: Z = %d\\n\u0026#34;,z); return 0; } gcc - c main.c libc.a没有安装会报错，此时可以执行下面的语句安装：\nyum install glibc-static 下面使用静态链接链接一个可执行文件\ngcc -static -o main main.o ./staticlib/libmymath.a 或者\ngcc -static -o main main.o -L staticlib/ -lmymath -static 参数告诉编译器驱动程序，链接器应该构建一个完全链接的可执行目标文件，它可以加载到内存并运行，在加载时无须更进一步的链接。-lmymath 参数是 libvector.a 的缩写，-L.参数告诉链接器在当前目录下査找 libvector.a\n大概的流程是下面这张图：\n当链接器运行时，它判定 main引用了add.o定义的 add 符号，所以复制add.o 到可执行文件。因为程序不引用任何由 mul.o 定义的符号，所以链接器就不会复制这个模块到可执行文件。链接器还会复制 libc.a 中的 printf.o 模块，以及许多 C 运行时系统中的其他模块。\nar 是 Linux 的一个备份压缩命令，它可以将多个文件打包成一个备份文件（也叫归档文件），也可以从备份文件中提取成员文件。ar 命令最常见的用法是将目标文件打包为静态链接库。\n对参数的说明：\n参数 r 用来替换库中已有的目标文件，或者加入新的目标文件。 参数 c 表示创建一个库。不管库否存在，都将创建。　参数 s 用来创建目标文件索引，这在创建较大的库时能提高速度。 使用静态链接库时，除了需要库文件本身，还需要对应的头文件：库文件包含了真正的函数代码，也即函数定义部分；头文件包含了函数的调用方法，也即函数声明部分。\n当链接器构造一个输出的可执行文件时，它只复制静态库里被应用程序引用的目标模块。\n符号解析 链接器如何解析静态链接库？\n在符号解析阶段，链接器从左到右按照它们在编译器驱动程序命令行上出现的顺序来扫描可重定位目标文件和存档文件。\n链接器维护的三个集合：\n可重定位目标文件集合E 未解析的符号集合U 已定义的符号集合D 初始时，三个集合都为空；最终的结果应该是集合U为空，才是链接成功，不然会报错。\n假如是目标文件\n假如是存档文件，那么链接器就尝试匹配 U 中未解析的符号和由存档文件成员定义的符号。如果某个存档文件成员 m定义了一个符号来解析 U 中的一个引用，那么就将 m 加到 E中，并且链接器修改U 和 D来反映 m 中的符号定义和引用。对存档文件中所有的成员目标文件都依次进行这个过程，直到 U 和 D都不再发生变化。此时，任何不包含在 E中的成员目标文件都简单地被丢弃，而链接器将继续处理下一个输入文件。\n最后，如果U是空集，它会合并和重定位 E中的目标文件，构建输出的可执行文件。\n在命令行中，如果定义一个符号的库出现在引用这个符号的目标文件之前，那么引用就不能被解析，链接会失败。(因为一开始集合U是空的，存档文件会假如E中，存档文件里面的定义永远不会被解析)\n关于库的一般准则是将它们放在命令行的结尾。\n重定位 此时，链接器就知道它的输人目标模块中的代码节和数据节的确切大小。现在就可以开始重定位步骤了，在这个步骤中，将合并输人模块，并为每个符号分配运行时地址。重定位由两步组成：\n注意下面一个是符号定义，一个是符号引用，两者不一样！\n重定位节和符号定义\n在这一步中，链接器将所有相同类型的节合并为同一类型的新的聚合节。例如，来自所有输人模块的.data 节被全部合并成一个节，这个节成为输出的可执行目标文件的.data 节。然后，链接器将运行时内存地址赋给新的聚合节，赋给输人模块定义的每个节，以及赋给输人模块定义的每个符号。当这一步完成时，程序中的每条指令和全局变量都有唯一的运行时内存地址了。也就是指令段与代码段中全局、静态变量、函数入口以及指令的运行时内存地址都已确定。\n注意：\n.bss段在目标文件和可执行文件中并不占用文件的空间，但是它在装载时占用地址空间（占用的是虚拟地址空间）\n重定位节中的符号引用\n这一步中，链接器修改代码节和数据节中对于每个符号的引用，使得他们指向正确的运行时地址。 这一步链接器依赖于可重定位目标模块中称为重定位条目的数据结构。\n参考地址：https://blog.csdn.net/weixin_44176696/article/details/106666236\n重定位条目\n无论何时汇编器遇到对最终位置未知的目标引用，它就会生成一个重定位条目 ，告诉链接器在将目标文件合并成可执行文件时如何修改这个引用。代码的重定位条目放在 .rel.text 中。已初始化数据的重定位条目放在 .rel.data 中。\n动态链接 对于静态链接来说，它还是太消耗内存了。\n共享库（shared library)是致力于解决静态库缺陷的一个现代创新产物。共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。这个过程称为动态链接(dynamic linking)� 是由一个叫做动态链接器（dynamic linker)\n的程序来执行的。\n共享库是以两种不同的方式来“共享”：\n在任何给定的文件系统，对于一个库只有一个.so 文件。\n所有引用该库的可执行目标文件共享这个.so文件中的代码和数据，而不是像静态库的内容那样被复制和嵌人到引用它们的可执行的文件中。\n其次，在内存中，一个共享库的 .text 节的一个副本可以被不同的正在运行的进程共享。\n基本的思路是当创建可执行文件时，静态执行一些链接，然后在程序加载时，动态完成链接过程。\n没有任何 libmymath.so 的代码和数据节真的被复制到可执行文件 main 中。反之，链接器复制了一些重定位和符号表信息，它们使得运行时可以解析对 libmymath.so 中代码和数据的引用。\n动态链接器通过执行下面的重定位完成链接任务：\n重定位 libc.so 的文本和数据到某个内存段 重定位 libmymath.so 的文本和数据到另一个内存段 重定位 main 中所有对由 libc.so 和 libmymath.so 定义的符号的引用 最后，动态链接器将控制传递给应用程序。从这个时刻开始，共享库的位置就固定了，并且在程序执行的过程中都不会改变。\n使用动态链接库 如果想创建一个动态链接库，可以使用 GCC 的-shared选项。输入文件可以是源文件、汇编文件或者目标文件。\n另外还得结合-fPIC选项。-fPIC 选项作用于编译阶段，告诉编译器产生与位置无关代码（Position-Independent Code）；这样一来，产生的代码中就没有绝对地址了，全部使用相对地址，所以代码可以被加载器加载到内存的任意位置，都可以正确的执行。这正是共享库所要求的，共享库被加载时，在内存的位置不是固定的。\n执行下面的命令，创建和使用动态链接库\ngcc -shared -fpic -o libmymath.so add.c mul.c gcc -o main main.c ./libmymath.so -fPIC 选项作用于编译阶段，在生成目标文件时就得使用该选项，以生成位置无关的代码。\n当然，必须要确保程序在运行时可以找到这个动态链接库。你可以将链接库放到标准目录下，例如 /usr/lib，或者设置一个合适的环境变量，例如 LIBRARY_PATH。不同系统，具有不同的加载链接库的方法。\n参考：\nGCC创建和使用静态链接库（.a文件） GCC生成动态链接库（.so文件） C语言和C++的混合编译 ","description":"链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。","id":39,"section":"posts","tags":["Linux"],"title":"linking","uri":"https://hugo.jiahongw.com/posts/linux/linking/"},{"content":"库打桩机制 LInux链接器有强大的库打桩机制，它允许你对共享库的代码进行截取，从而执行自己的代码。而为了调试，你通常可以在自己的代码中加入一些调试信息，例如，调用次数，打印信息，调用时间等等。\n基本原理 基本思想 给定需要打桩的目标函数，常见一个wrapper函数，其原型和目标函数一致。利用特殊的打桩机制，可以实现让系统调用你的wrapper函数而不是目标函数。wrapper函数中通常会执行自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者。\n打桩可以发生在编译时、链接时或者程序被加载执行的运行时。不同的阶段都有对应的打桩机制，也有其局限性。\n打桩时期 创建一个main.c文件，内容：\n1 2 3 4 5 6 7 8 9 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;malloc.h\u0026gt; int main() { char *p = malloc(64); printf(\u0026#34;Hello\\n\u0026#34;); free(p); return 0; } 编译时打桩 使用 C 预处理器在编译时打桩。\n定义插桩函数头文件 malloc.h\n1 2 3 4 5 #define malloc(size) mymalloc(size) #define freeCptr) myfree(ptr) 23 void *mymalloc(size_t size); void myfree(void *ptr); 定义插桩函数的文件 mymalloc.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 // mymalloc.c #ifdef COMPILETIME #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;malloc.h\u0026gt; // malloc wrapper function void * mymalloc(size_t size) { void * ptr = malloc(size); printf(\u0026#34;malloc %p size %u\\n\u0026#34;, ptr, size); return ptr; } // free wrapper function void myfree(void *ptr) { free(ptr); printf(\u0026#34;free %p\\n\u0026#34;, ptr); } #endif 这样编译和链接程序\n1 2 gcc -DCOMPILETIME -c mymalloc.c gcc -I. -o main main.c mymalloc.o 执行：\n1 ./main 链接时打桩 链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。\n这个不需要头文件，直接创建一个插桩函数文件 mymalloc.c:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 #ifdef LINKTIME #include \u0026lt;stdio.h\u0026gt; void *__real_malloc(size_t size); void __real_free(void *ptr); /* malloc wrapper function */ void *__wrap_malloc(size_t size) { void *p = __real_malloc(size); // 调用libc的malloc printf(\u0026#34;malloc(%d) = %p \\n\u0026#34;,size,p); return p; } /* free wrapper function */ void *__wrap_free(void *ptr) { __real_free(ptr); printf(\u0026#34;free(%p)\\n\u0026#34;,ptr); } #endif 这样编译和链接程序\n1 2 3 gcc -DLINKTIME -c mymalloc.c gcc -c main.c gcc -Wl,--wrap,malloc -Wl,--wrap,free -o main main.o mymalloc.o 执行\n1 ./main 运行时打桩 创建一个插桩函数文件 mymalloc.c:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 #ifdef RUNTIME #define _GNU_SOURCE #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;stdlib.h\u0026gt; #include \u0026lt;dlfcn.h\u0026gt; /* malloc wrapper function */ void *malloc(size_t size) { void *(*mallocp)(size_t size); char *error; mallocp = dlsym(RTLD_NEXT,\u0026#34;malloc\u0026#34;); // get the address of libc malloc if((error = dlerror()) != NULL) { fputs(error,stderr); exit(1); } char *ptr = mallocp(size); printf(\u0026#34;malloc(%d) = %p \\n\u0026#34;,(int)size,ptr); return ptr; } /* free wrapper function */ void free(void* ptr) { void (*freep)(void*) = NULL; char *error; if(!ptr) return; freep = dlsym(RTLD_NEXT,\u0026#34;free\u0026#34;); if((error = dlerror()) != NULL) { fputs(error,stderr); exit(1); } freep(ptr); printf(\u0026#34;free(%p)\\n\u0026#34;,ptr); } #endif 这样编译链接执行程序\n1 2 3 gcc -DRUNTIME -shared -fpic -o mymalloc.so mymalloc.c -ldl gcc -o main main.c LD_PRELOAD=\u0026#34;./mymalloc.so\u0026#34; ./main GCC相关参数 参数 功能 -c 只激活预处理,编译,和汇编,也就是他只把程序做成obj文件,将生成 .o 的 obj 文件\n例子：gcc -c hello.c -S 只激活预处理和编译，就是指把文件编译成为汇编代码,将生成 .s 的汇编代码。\n例子：gcc -S hello.c -E 只激活预处理,这个不生成文件, 你需要把它重定向到一个输出文件里面。\n例子：```gcc -E hello.c \u0026gt; pianoapan.txt gcc -E hello.c -o 指定目标名称 -g 只是编译器，在编译的时候，产生调试信息。 -static 此选项将禁止使用动态库，所以，编译出来的东西，一般都很大，也不需要什么动态连接库，就可以运行。 -share 此选项将尽量使用动态库，所以生成文件比较小，但是需要系统由动态库。 我们通过ldd命令查看程序链接的系统库：\n参考链接：\nhttps://zhuanlan.zhihu.com/p/76036630 https://www.cnblogs.com/tocy/p/Linux-library-Interposition.html GCC 参数详解 ","description":"LInux链接器有强大的库打桩机制，它允许你对共享库的代码进行截取，从而执行自己的代码。而为了调试，你通常可以在自己的代码中加入一些调试信息，例如，调用次数，打印信息，调用时间等等。","id":40,"section":"posts","tags":["MLK"],"title":"打桩机制","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/interposition/"},{"content":"DieHard 一个基于概率内存安全的运行时系统。\n基本介绍 源码：https://github.com/emeryberger/DieHard\n支持 Windows Linux Mac OS X 安装 需要C++14支持\n解压并且进入文件夹\n1 2 unzip DieHard.zip cd DieHard 编译\n1 2 3 cd src/ TARGET=libdiehard make linux-gcc-x86-64-replicated TARGET=libdieharder make linux-gcc-x86-64-replicated 编译完成在目录下会新增3个动态链接库：libdieharder.so和libdiehard.so、libdieharder_r.so\n1 2 3 cd src/util/ g++ -pipe -g -fPIC -I. -I.. -I../../src/archipelago/brokenmalloc -D_REENTRANT=1 -shared libbrokenmalloc.cpp -o libbrokenmalloc.so -ldl g++ -fPIC -pipe -g -I. -I.. -I../../src/archipelago/brokenmalloc/ -D_REENTRANT=1 -shared libtrackalloc.cpp -o libtrackalloc.so -ldl 编译完成会在目录下生成2个动态链接库libbrokenmalloc.so和libtrackalloc.so\n使用 基本使用方法 基本使用方法：\n在执行程序之前添加提前加载库选项LD_PRELOAD=libdiehard.so\n例如：\n1 LD_PRELOAD=/mnt/MLK/Tools/DieHard/src/libdiehard.so app app_args 原理 错误类型 涵盖的错误类型大概一下几类：\nDangling pointers\n迷途指针，或称悬空指针、野指针，指的是不指向任何合法的对象的指针。当所指向的对象被释放或者收回，但是对该指针没有作任何的修改，以至于该指针仍旧指向已经回收的内存地址，此情况下该指针便称迷途指针。\nBuffer overflflows\n堆缓冲溢出。越界写会损坏堆上活对象的内容。\nHeap metadata overwrites\n堆元数据被覆盖。如果堆元数据存储在堆对象附近，那么堆越界写可能会损坏它。\nUninitialized reads\n未初始化读。从新分配或未分配的内存中读取值会导致未定义的行为。\nInvalid frees\n非法释放内存。将非法地址传递给free可能会损坏堆或导致未定义的行为。\nDouble frees\n重复释放内存。\n上面的分类其实有点问题，既然未分配内存读取都能归为未初始化读的问题，那么重复释放内存为什么不能归为非法内存释放呢？\nDieHard以很高的概率消除或避免了上述所有内存错误\n概念 probabilistic memory safety(基于概率的内存安全) 将程序定义为完全内存安全，必须满足下面的条件：\n从不读取未初始化的内存。 在堆上不执行非法操作(非法释放内存/双释放内存)。 不访问已释放的内存(没有悬浮指针错误)。 注意：上面的条件中没有提及堆缓冲溢出。\n通过中止可能违反这些条件之一的计算，安全的C编译器提供了完整的内存安全。 然而，作者理想地希望有一个执行环境，允许这些程序在面对这些错误时继续正确地执行。(依靠复制版本实现)\n定义一个理想但无法实现的运行时系统。我们叫它无限堆内存管理器。它提供了无限堆语义。\ninfifinite-heap(无限堆) 在这样的系统中，堆的面积是无限大的，因此不存在堆耗尽的风险。 对象永远不会被去分配，所有对象都被分配到彼此无限远的地方(也就是说，它们可以被认为是无限的内存块。\n从正确的C执行的角度来看，一个不刻意寻求耗尽堆的程序不能判断它是用普通的堆实现运行还是用无限的堆运行。\n因为每个对象都离其他对象无限远，就算溢出写覆盖的也不是有用的对象数据，而是空数据，分配的对象从未被覆盖。所以不存在堆缓冲溢出问题。\n因为堆内存无限大，所以根本不需要释放内存，所以悬浮指针的问题也消失了。\n对堆的未初始化读取仍然未定义。与Java不同，新分配的C和C对象的内容不一定被定义。\n实际构建的系统 近似无限堆 虽然无限堆内存管理器是不可实现的，但我们可以概率地近似它的行为。\n我们将无限堆替换为一个所需的最大值的堆的M倍内存以获得无限堆语义。 通过在堆中均匀地随机放置对象，我们得到了最小的期望分离间隔。\n$$\nE[minimum separation] = (M - 1) objects\n$$\n使得溢出小于M-1倍对象大小时是无害的。\n最后，通过随机选择要回收的已释放对象，最近释放的对象极不可能被覆盖。\n为了检测对堆的未初始化读，我们要求无限堆和每个分配的对象都充满随机值。然后，我们可以通过同时执行至少两个具有不同随机分配器的副本来检测未初始化的读取并且比较他们的输出。未初始化的读取将在副本中返回不同的结果，如果此读取影响计算，则副本的输出将不同。这样DieHard就能够检测出来。\n随机内存管理器 randomized memory manager 随机内存管理器。允许计算检测或避免内存错误精确的概率。快速随机内存分配器，它构成了独立和复制版本的核心。\nDieHard的随机内存管理器将对象随机放置在一个堆中，堆的大小是所需最大值的几倍。例如下图：\n对象之间的间隔使得缓冲区溢出最终可能只覆盖空闲无用的空间\n随机分配也使得新释放的对象不太可能很快被随后的分配覆盖，从而避免了悬空指针错误。\n它还通过将所有堆元数据从堆中分离（避免大多数堆元数据覆盖）和忽略释放已经创建或无效对象的尝试来提高应用程序的健壮性。\n对于复制版本：\n模式 单独模式 + 复制模式\n而独立版本的Die Hard提供了防止内存错误的实质性保护。复制的版本既增加了保护，又检测了非法读取引起的错误。 在复制模式下，DieHard同时执行同一程序的多个副本，每个副本都有不同的种子给各自的随机分配器。\n复制模式\n对与缓冲区溢出。因为多个副本使用不一样的种子作为随机分配。因此，缓冲区溢出等错误很可能会覆盖不同副本中的不同内存区域。\nDieHard拦截来自所有不同副本的输出，并在发送任何输出之前比较每个副本的内容。 通过很高的概率，当任何两个程序在其输出上达成一致时，它们才安全地执行。\n对于悬浮指针。在任何一致的副本中，任何缓冲区溢出都只覆盖无用的数据。垂的指针从未被覆盖。\n对于未初始化的数据。如果应用程序的输出依赖于未初始化的数据，那么这些数据将在副本中不一致，DieHard将会检测到它们。\n使用额外的副本可以进一步提高可靠性。 虽然额外的复制自然会增加单处理器平台上的执行时间，但我们认为使用复制的自然设置是在具有多个处理器的系统上。Die Hard可以使用更新处理器上的多个核心来使遗留程序更可靠。\n优点和缺点 优点 性能好。(论文说) 由于用DieHard替换堆显著提高了可靠性，我们认为它适合于广泛的部署，特别是在提高可靠性值得空间成本的场景中。 缺点 安装复杂，并且需要C++14的支持。 可以报错但是不能提供错误的具体位置信息。 内存消耗大。 复制模式需要多处理器并行。 这种随机分配使得计算机无法根据空间局部性推断，系统中的TLB往往失效。为了保持性能，Die Hard堆的使用中部分应该适合物理RAM。 参考：\nhttps://securitygossip.com/blog/2018/09/29/guarder-a-tunable-secure-allocator/ https://firmianay.gitbooks.io/ctf-all-in-one/content/doc/8.46_freeguard.html ","description":"一个基于概率内存安全的运行时系统。","id":41,"section":"posts","tags":["MLK"],"title":"DieHard","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/diehard/"},{"content":"Valgrind Valgrind发行版目前包括七个生产质量工具：一个内存错误检测器，两个线程错误检测器，一个缓存和分支预测探查器，一个生成调用图的缓存和分支预测探查器以及两个不同的堆探查器。它还包括一个实验性的SimPoint基本块矢量生成器。\n在软件开发过程中我们有时需要追踪程序执行、诊断错误、衡量性能等需求。如果有源代码的话可以添加相应代码，没有源代码时这个方法就行不通了。前者可以对源代码分析，后者只能分析二进制了。我的理解是，dynamic Binary Instrumentation (DBI)强调对二进制执行文件的追踪与信息收集，dynamic Binary Analysis (DBA)强调对收集信息的分析，valgrind是一个DBI框架，使用它可以很方便构建一个DBA工具。\nValgrind作者认为当时的DBI框架都把注意力放在了性能检测上，对程序的质量(原文capabilities)并没有太注意。所以设计了一个新的DBI框架，目标是可以使用它开发重型DBA工具。\n基本介绍 官网： https://valgrind.org/\n文档： https://valgrind.org/docs/manual/index.html\n源码： https://github.com/groleo/mpatrolhttps://valgrind.org/downloads/repository.html\n支持 它可在以下平台上运行：\nX86 / Linux，AMD64 / Linux，ARM / Linux，ARM64 / Linux，PPC32 / Linux，PPC64 / Linux，PPC64LE / Linux，S390X / Linux，MIPS32 / Linux，MIPS64 / Linux，X86 / Solaris ，AMD64 / Solaris，ARM / Android（2.3.x和更高版本），ARM64 / Android，X86 / Android（4.0和更高版本），MIPS32 / Android，X86 / Darwin和AMD64 / Darwin（Mac OS X 10.12）。\n安装 解压安装包\n1 2 tar -jxvf valgrind-3.15.0.tar.bz2 cd valgrind-3.15.0/ 创建Makefile\n1 ./configure 安装\n1 2 3 make make install valgrind --version 使用 编译说明 最好使用debug版本（gcc -g），这样打印的信息中会将错误和分析的信息指定出相关的代码行； 如果是C++最好将内联函数以普通函数对待（gcc -fno-inline），这样更容易看到函数调用链，这有助于减少在大型C ++应用程序中导航时的混淆； 不要使用优化（gcc -O2或gcc-O1等），这会导致Memcheck错误地报告未初始化的值错误或丢失未初始化的值错误； 最好编译时能显示所有警告（gcc -Wall） 错误报告 当错误检查工具检测到程序中发生了错误时，就会向注释中写入一条错误消息。以下是来自Memcheck的一个例子：\n==25832== Invalid read of size 4 ==25832== at 0x8048724: BandMatrix::ReSize(int, int, int) (bogon.cpp:45) ==25832== by 0x80487AF: main (bogon.cpp:66) ==25832== Address 0xBFFFF74C is not stack\u0026#39;d, malloc\u0026#39;d or free\u0026#39;d 这个消息说，程序非法读取了地址0xBFFFF74C的4字节，据Memcheck所知，这不是一个有效的堆栈地址，也不对应于任何当前堆块或最近释放的堆块。发生在bogon.cpp的第45行。从同一文件的第66行调用，等等。对于与已识别的(当前或已释放的)堆块相关的错误，例如读取已释放的内存，Valgrind不仅会报告错误发生的位置，还会报告分配/释放关联堆块的位置。\n命令行选项 最简单的选项：\n--tool=\u0026lt;toolname\u0026gt; [default: memcheck] 运行名为toolname的Valgrind工具，如memcheck, cachegrind, callgrind, helgrind, drd, massif, dhat, lackey, none, expi -bbv等\n基本使用方法 假如你的程序原来是这样执行的：myprog arg1 arg2\n那么使用valgrind可以在前面添加 valgrind \u0026ndash;leak-check=yes 即可使用，例如：\nvalgrind --leak-check=yes myprog arg1 arg2 如果我们想用valgrind的内存检测工具，我们就要用如下方法调用：\n#valgrind --leak-check=full --show-reachable=yes --trace-children= yes ./a.out (2\u0026gt;logfile加上会好些，程序在执行期间stderr会有一些输出。提示比较多) 运行valgrind -h可以查看详细使用方法，命令格式如下：\nvalgrind [valgrind -h中的选项] 待测程序 [待测程序的命令行参数列表] 最重要的选项是–tool决定运行哪种Valgrind工具。\n--tool=\u0026lt;toolname\u0026gt; [default: memcheck]：最常用的选项。运行valgrind中名为toolname的工具。如果省略工具名，默认运行memcheck。 例如，使用内存检查工具Memcheck 运行“ls -l”命令 ，执行命令格式如下：\nvalgrind --tool = memcheck ls -l Memcheck是默认设置，因此如果要使用它，则可以省略该–tool选项，如：\nvalgrind ls -l https://blog.csdn.net/justheretobe/article/details/52986461\n原理 基本架构 Valgrind 的核心花费大部分的时间在制造、寻找、执行 machine code 和 VEX IR 的转换， 而 client program 原本的 machine code 都不会跑到。可以看到 Valgrind 的复杂來自要把 client 和 tool 放在同一個 process， 需要用分享的资源 (例如 registers 和 memory)， 而且 Valgrind 要小心地确保在 system call、signals、threads 参与的狀況下不會對 client 失去掌控。\n正常处理的程序有：\nnormal executable code dynamically linked libraries shared libraries dynamically generated code 只有 self-modifying code 會有問題， 而執行過程中只有 system calls 裡面的狀況是 Valgrind 不能掌控的， 但是 system call 的 side-effects 還是可以間接觀察到。\n+--------------------+ +-------------------------+ +--------------+ | libVEX | | IR instrumentation tool | | | | | | | +--------------+ | | | | | | | | | | +--------------+ | | | | | | | | | | x86/Linux +--------------+ | +--------+ | | | AMD64/Linux | machine code | ------------\u0026gt; | VEX IR | --------\u0026gt;| | ARM/Linux +--------------+ | +--------+ | | | x86/MacOSX | | | | | | AMD64/MacOSX +--------------+ | -----------------| | .... | | | | | | | +--------------+ | | | | | | | +---------|----------+ +-------------------------+ +--------------+ | v +--------------+ | machine code | +--------------+ Valgrind Core会反汇编应用程序代码，并将代码片段传递给工具插件以进行检测。工具插件会添加分析代码并将其重新组合。因此，Valgrind提供了在Valgrind框架之上编写我们自己的工具的灵活性。 Valgrind使用影子寄存器和影子存储器来检测读/写指令，读/写系统调用，堆栈和堆分配。\nvalgrind提供了围绕系统调用的包装，并为每个系统调用的前后回调注册，以跟踪作为系统调用一部分访问的内存。因此，Valgrind是Linux操作系统和客户端应用程序之间的OS抽象层。\n该图说明了Valgrind的8个阶段：\n阴影值 Valgrind 把重点放在 shadow values 这概念上， shadow values 是很强大但相关的研究较少、较难实作的 DBA 技术， 在这概念下需要对所有的 register 和 memory 做 shadow (自己维护一份)， 也因为这 feature 让 Valgrind 做出来的 lightweight 工具跑的相对慢，但是 Valgrind 可以做出更多更有趣、更重量级的工具， 这是其他 frameworks 很难做到的 (例如 Pin 或 DynamoRIO)。\nshadow value tools 会维护一份程式的状态， 把原本的程式状态称为 S， 那就会存一份 S’ 里面包含 S 的所有值 (例如 register 和 user-mode address)， 而 shadow values 有九种需求要满足， 九种需求可以依照特性分成四类 (Shadow State、读写操作、Allocation/Deallocation、增加辅助资讯)：\n阴影值简单来说就是：在软件中或者寄存器中用另外一个映射值来说明一些内容\n阴影值的各个工具的应用\nmemcheck使用阴影值跟踪哪个bit的值是未定义的。 TaintCheck跟踪哪些字节被污染(不受信任的源，或来自受污染的值). McCamant and Ernst’s secret-tracking tool跟踪每一个秘密bit的值，并且确定公共的输出中暴露了多少秘密的信息。 Hobbes跟踪每一个值得类型，因此可以检测后续操作不适合该类型的值。 DynCompB类似地，为程序理解和不变检测目的确定字节值的抽象类型。 Annelid跟踪是数组指针的word，可以检测越界错误。 Redux创建了一个动态数据流图，是程序的整个计算的可视化，从图中可以看到所有有助于每个值创建的先前操作。 可以是：\n每bit一个shadow bit 每byte一个shadow byte 每word一个shadow word 描述阴影值工具 如何在DBI框架中支持阴影值 DBI框架并不完全相同 为了实现shadow values需要框架实现以下4个部分：\nShadow State 读写操作 分配和释放操作 透明执行+额外的输出 9个功能\ninstrument read/write instructions instrument read/write system calls Allocation and deallocation operations instrument start-up allocations instrument system call (de)allocations instrument stack (de)allocations instrument heap (de)allocations Transparent execution, but with extra output extra output 具体来说就是：\nShadow State\nR1：提供阴影寄存器(例如 integer、FP、SIMD)。 R2：提供阴影内存(并且需要在 multithread 下可以安全地存取 shadow memory)。 读写操作\nR3：插桩读写指令。\n需要知道每個 instruction 存取了哪些 memory 和 registers 最好能做到跨平台 (跨 ISA) R4：插桩系统读写调用。\n所有的 system call 都会去存取 register 或 memory，还可能从 register 或 stack 读参数，最后写回 register 或 memory，而且还要注意许多 system call 会存取 user-mode 的 memory (pointer)\n分配和释放操作\nR5：插桩启动时的分配操作。 在程序开始执行时，所有 register 都會被 “allocated”，因為是 statically allocated memory locations，所以 shadow value tool 必須也這些做好 (create suitable 会hadow values) 对于此时还没 allocated 的也要处理，可能在 allocated 之前发生不当的存取 R6：插桩系统调用的分配和释放。 一些 system call 会 allocate memory (e.g. brk, mmap)，一些会 deallocate memory (e.g. munmap) mremap 會让memory 被 copy，shadow memory 也要 copy 好 R7：插桩栈的分配和释放。 更新 stack pointer 这部份会比较耗时，因为 stack pointer 时常变动，而且有些程式会在多个 stack 之间切换，shadow value tool 会需要把这些 stack allocations 或 deallocations 区分出来，这对于 binary level 来说不容易 R8：插桩堆的分配和释放. 大部分的程式会利用来自 library 的 heap allocator，heap allocator 会把用 system call (brk、mmap) 取得的 large chuncks 中的一块 heap blocks 传回去给 client，每段 heap block 都有 book-keeping data (例如 block size)，这些是 client program 不应该存取的 (读可能还安全，写的话可能会 crash allocator)，所以有 kernel-level addressability 之上盖了一层 library-level addressability 的概念 忽略 large chuncks 的 kernel-level allocations 直到 allocator 把 allocated 的 bytes 转交给 client 之前都不把 memory 当作 active realloc 也要像 mremap 一样被处理 透明执行+额外的输出\nR9：额外的输出。 不影响执行，产生有帮助的 output 另外开个地方來 output，例如沒在用的 stderr 或 file 核心思想就是要把寄存器和内存中的东西自己维护一份，并且在任何情况下都可以安全正确地使用，同时记录程序的所有操作，在不影响程序执行结果前提下，输出有用的信息。使用shadow values技术的DBI框架都使用不同方式实现了上述全部功能或部分功能。\n阴影状态：一个阴影状态S’包括每一个值对应的阴影值S。\n阴影值的支持\n阴影寄存器是一流的实体：\n在线程状态下为它们提供空间 它们可以像来宿主寄存器一样容易地访问 他们可以用同样的方式操纵和操作 其次，IR提供了不受限制的临时资源，可以在其中操纵来宾寄存器，影子寄存器和中间值。这对于易用性非常重要，因为\n影子操作会引入许多额外的中间值。\n第三，IR的RISC-ness公开了所有隐式中间值，例如由复杂寻址模式计算的中间值，这可以使测试变得更容易，特别是在像x86这样的CISC体系结构上\n第四，所有代码一视同仁。 阴影操作充分适合Valgrind的后仪器IR优化器和指令选择器。\nValgrind不提供阴影内存的公开支持，例如内置的数据结构，阴影内存从工具到工具的变化足够大。\n事件系统\nValgrind为每个系统调用提供一个包装器，它根据需要调用这些回调。 每个系统调用都有不同的参数，因此有不同的包装器。\n对于数据的处理 如何知道那些地址是合法的（内存已分配）？\n维护一张合法地址表（Valid-address (A) bits），当前所有可以合法读写（已分配）的地址在其中有对应的表项。该表通过以下措施维护\n全局数据(data, bss section)--在程序启动的时候标记为合法地址 局部变量--监控sp(stack pointer)的变化，动态维护 动态分配的内存--截获 分配/释放 内存的调用 ：malloc, calloc, realloc, valloc, memalign, free, new, new[], delete and delete[] 系统调用--截获mmap映射的地址 其他--可以显示知会memcheck某地字段是合法的 当要读写内存中的某个字节时，首先检查这个字节对应的A bit。如果该A bit显示该位置是无效位置，memcheck则会报告读写错误\n如何知道某内存是否已经被赋值(初始化)？\n维护一张合法值表（Valid-value (V) bits），指示对应的bit是否已经被赋值。因为虚拟CPU可以捕获所有对内存的写指令，所以这张表很容易维护。\n一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则memcheck会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。\n图解\n组件 valgrind结构上分为core和tool，不同的tool具有不同的功能。比较特别的是，valgrind tool都包含core的静态链接，虽然有点浪费空间，但可以简化某些事情。当我们在调用valgrind时，实际上启动的只是一个解析命令参数的启动器，由这个启动器启动具体的tool。\n为了实现上述功能，valgrind会利用dynamic binary re-compilation把测试程序（client程序）的机器码解析到VEX中间语言。VEX IR是valgrind开发者专门设计给DBI使用的中间语言，是一种RISC like的语言。目前VEX IR从valgrind分离出去成libVEX了。libVEX采用execution-driven的方式用just-in-time技术动态地把机器码转换为IR，如果发生了某些tool感兴趣的事件，就会hook tool的函数，tool会插入一些分析代码，再把这些代码转换为机器码，存储到code cache中，以便再需要的时候执行。\nMachine Code --\u0026gt; IR --\u0026gt; IR --\u0026gt; Machine Code ^ ^ ^ | | | translate | | | | instrument | | translate valgrind启动后，core、tool和client都在一个进程中，共用一个地址空间。core首先会初始化必要的组件，然后载入client，建立client的stack，完成后会要求tool初始化自己，tool完成剩余部分的初始化，这样tool就具有了控制权，开始转换client程式。从某种意义上说，valgrind执行的都是加工后的client程序的代码。\nDBI framework 有两种基本的方式可以表示code和进行 instrumentation：\ndisassemble-and-resynthesise (D\u0026amp;R)。 Valgrind 使用这种把machine code先转成IR，IR会通过加入更IR来instrument。IR最后转回machine code执行，原本的code对 guest state的所有影响都必须明确地转成IR，因为最后执行的是纯粹由IR转成的machine code。 copy-and-annotate (C\u0026amp;A)。instructions会被逐字地复制(除了一些 control flow 改变) 每个instruction都加上注解描述其影响(annotate)，利用这些描述来帮助做instrumentation 通过给每条指令添加一个额外的data structure (DynamoRIO) 通过提供相应的获取指令相关信息的API (Intel Pin) 这些添加的注解可以指导进行相应的instrument，并且不影响原来的native code的执行效果。 基本上 DBI framework 可以分成这两种， 但是混用是可以做到的， 早期的 Valgrind 对 interger instructions 使用 D\u0026amp;R， 而对 floating point insturctions 和 SIMD 使用 C\u0026amp;A (paper 上写说并非设计想往这边走，而是意外)。另外，做一些变化也是可以的，例如 DynamoRIO 允许 instructions 在复制前 in-place 地修改。\n各个设计都有优缺点，而 D\u0026amp;R 的方式需要更多的实作和设计， 而且最后从 IR 生出有效率地 machine code 也需要一些努力， Valgrind JIT 就用了很多编译器的技术。相对地，C\u0026amp;A 的作法就可以比 D\u0026amp;R 少费些心力。\n优点和缺点 优点 1.用valgrind监测内存泄漏，不用重新编译应用程序，不用重新链接应用程序，不用对应用进程做任何修改。如果想查看详细的出错信息，只需要在编译时加上-g选项。\n缺点 通常情况下，使用memcheck工具后应用程序的运行时间会比原生代码慢大约10-50倍。 -内存占用高，因为要维护两张表格，而这两张表的维度正比于程序的内存 -memcheck无法检测global和stack上的内存溢出，因为溢出的地方也在Valid-address (A) bits中。这是由memcheck 的工作原理决定的。 对于一些不停机运行的服务器程序的内存问题，valgrind无能为力。不仅仅是因为valgrind无法使之停止，还有可能是因为服务器进程本身就被设计为申请一些生命周期 与进程生命周期一样长的内存，永远不释放，这些内存会被valgrind报泄漏错误。 valgrind对多线程程序支持得不够好。在多线程程序执行时，valgrind在同一时刻只让其中一个线程执行，它不会充分利用多核的环境。在用valgrind运行您的多线程程序 时，您的宝贵程序的运行情况可能跟不使用valgrind的运行情况千差万别。 参考：\nhttps://blog.mengy.org/how-valgrind-work/ https://www.valgrind.org/docs/pubs.html https://blog.csdn.net/yinliyinli/article/details/51346431 https://blog.csdn.net/u014652595/article/details/23660347 valgrind如何工作？ http://awhite2008.blog.sohu.com/164824340.html https://wdv4758h-notes.readthedocs.io/zh_TW/latest/valgrind/dynamic-binary-instrumentation.html ","description":"官方首页上这个骑士与恶龙的绘画由伦敦画家 Rupert Lees 创作。灵感来自于神话传说 St George and the Dragon 。某日，圣乔治到利比亚去，当地沼泽中的一只恶龙（一说鳄鱼）在水泉旁边筑巢，这水泉是Silene城唯一的水源，市民为了取水，每天都要把两头绵羊献祭给恶龙。 到后来，绵羊都吃完了，只好用活人来替代，每天抽签决定何人应选派作牺牲。 有一天，国王的女儿被抽中，国王也没有办法，悲痛欲绝。当少女走近，正要被恶龙吞吃时，圣乔治在这时赶到，提起利矛对抗恶龙，并用腰带把它束缚住，牵到城里当众杀死，救出了公主。","id":42,"section":"posts","tags":["MLK"],"title":"Valgrind","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/valgrind/"},{"content":"duma DUMA是一个开源库(在GNU通用公共许可证下)，用于检测C和C++程序中的缓冲区溢出和运行错误，是一个Red-Zone memory allocator。这个库是 Electric Fence库的一个分支，并添加了一些新功能。\n该库是Buce Perens Electric Fence库的分支，并添加了一些其他功能，例如内存泄漏报告。\n基本介绍 官网： http://duma.sourceforge.net/\n源码： https://github.com/fortitudepub/duma\n文档： http://duma.sourceforge.net/README.txt\n支持 Linux / Unix MS Windows NT/2K/XP 安装 需要gmake工具\n1 2 3 4 unzip duma-master.zip cd duma-master gmake gmake install （不行的话编辑GNUmakefile，在开头添加OS=linux）\n问题\nCentos8或者高版本C++可能会导致与C++98的抛出异常不一\n解决办法：需要进入GNUmakefile中修改添加参数-std=c++98\n使用 基本功能 超出动态分配缓冲区的末尾（或开始）。 返回到堆后使用动态分配的缓冲区。 检测内存泄漏。 检测分配/取消分配功能的不匹配：例如，\n使用malloc（）进行分配，但使用运算符delete进行释放。 基本使用方法 使用限制：\n不能和lmalloc、lmallocdebug等malloc-debugger混用 duma会创建core文件，注意操作系统对core文件的限制 -lduma需要全局安装，否则就要指定路径，也可以环境变量的形式应用于所有动态可执行文件 方法：\n假如duma已经安装，可以使用-lduma去链接编译或者在命令行添加链接库的位置进行链接。(静态)\n没有显示安装duma也可以使用动态链接，如下(动态)\n1 (export LD_PRELOAD=/usr/lib/libduma.so; export DYLD_INSERT_LIBRARIES=libduma.dylib; export DYLD_FORCE_FLAT_NAMESPACE=1; exec APP args) 或者\n1 LD_PRELOAD=/usr/lib/libduma.so APP args 如果你的程序有一个被DUMA检测到的错误，它将得到一个错误指令的segmentation fault(SIGSEGV)。使用debugger 找到错误的声明，并修复它。\n下面是使用gdb找到错误位置的具体操作：\n静态(上面第一种方法编译的程序)：\n使用gdb启动程序，例如：\n1 gdb app 在gdb里面设置环境变量。\n1 set environment DUMA_PROTECT_BELOW 1 在gdb里面设置程序的参数。\n1 set args .. 运行程序等待字段错误。\n1 run 动态(上面第二种方法编译的程序)：\n设置“ulimit -c unlimited”获取内核文件。\n运行静态链接的程序或者动态链接的程序。\n等待字段错误，会在当前文件夹下生成一个内核文件core.pid。可以使用gdb打开：\n1 gdb \u0026lt;program\u0026gt; -c \u0026lt;core file\u0026gt; 环境变量 支持在gdb里面通过命令\u0026rsquo;set environment variable value\u0026rsquo; 设置环境变量\nDUMA_ALIGNMENT\n这是一个整数，它指定将由malloc()、calloc()和realloc()返回的任何内存分配的对齐大小。因此，值为4将导致内存对齐到32位，除非系统没有8位的char。\n默认情况下，DUMA_ALIGNMENT设置为特定于环境的最小所需对齐。 最小所需对齐由createconf检测并存储在文件duma_config.h中。\n因此，分配小于DUMA_ALIGNMENT的块可能会导致更小的对齐-例如，当分配3个字节时，它们将被对齐到2个字节边界。 这可以更好地检测溢出。\n出于这个原因，您有时希望将DUMA_ALIGNMENT设置为1（没有对齐），这样您就可以检测到超出CPU单词大小的情况\n如果您只需要对一些特殊缓冲区进行更大的对齐,您不需要更改此设置。 在这种情况下，您可以使用函数\n1 memalign(alignment, userSize). DUMA_PROTECT_BELOW\nDUMA通常会在每次内存分配后立即放置一个不可访问的页面，这样就会检测到在分配结束后运行的软件。\n将DUMA_PROTECT_BELOW设置为1将导致DUMA在分配之前将无法访问的页面放置在地址空间中，这样就会检测到运行不足而不是运行过度\nDUMA_SKIPCOUNT_INIT\n一般使用第一个分配器分配。在某些系统中，这可能会与pthreads或其他libaries的初始化发生冲突并产生挂起。 为了获得DUMA工作，即使在这些情况下，您也可以控制（使用此环境变量）在完成DUMA的全部内部初始化后的分配数量。 默认为0。\nDUMA_REPORT_ALL_LEAKS\nDUMA通常只报告内存泄漏，其中已知分配指令行号的源文件名。并不报错退出。\n默认值为0，以避免从系统/编译器环境报告无关内存泄漏。\nDUMA_FILL\n当设置为0到255之间的值时，分配内存的每个字节都被初始化为该值。\n这可以帮助检测未初始化内存的读取\n当设置为-1时，DUMA不会在分配时初始化内存。 但是一些内存中充满了零（大多数系统默认的操作系统），一些内存将保留在上次使用期间写入的值。每个默认的DUMA将初始化所有分配的字节到255(=0x FF)。\nDUMA_SLACKFILL\n当DUMA在整个页面中内部分配内存时，就会保留一个未使用和无法保护的内存块：可用但是还没使用的内存区域。 每个默认的DUMA将初始化这个区域到170(=0x AA)，这是10101010在二进制表示。\nDUMA_CHECK_FREQ\n将此变量设置为1，以便在每个分配和解除分配时允许DUMA检查无人区。每个默认值都使用0，这意味着只在取消分配时检查\nDUMA_ALLOW_MALLOC_0\n大小为零的内存分配符合ANSI。 但这往往是软件错误的结果。 因此，DUMA可能会将这样的调用捕获到大小为零的malloc()。 默认情况下，我将禁用此选项，但您可以自由地捕获这些调用，将shell环境中的DUMA_ALLOC_MALLOC_0设置为整数值。\nDUMA_MALLOC_0_STRATEGY\n此环境变量控制DUMA在malloc（0)上的行为）：\nALLOW_MALLOC_0的值\n0 - abort program with segfault\n1 - 返回空指针\n2 - 返回到某些受保护页面的指针总是相同的\n3 - 返回唯一受保护页的中间地址（=默认）\n注意：只有1和3是ANSI符合。 但是值1会破坏大多数程序，导致值3策略大多数系统库使用/实现。 所有返回的指针都可以传递给自由()。\nDUMA_NEW_0_STRATEGY\n此环境变量控制DUMA在大小为零的C操作符上的行为：\n2 - 返回到某些受保护页面的指针总是相同的\n3 - 返回唯一受保护页的中间地址（=默认）\n注意：只有3是标准符合。 价值2可能会打破一些，但将适用于大多数程序。 值2可以减少内存消耗。\n等等—\n原理 DUMA使用计算机的虚拟内存硬件，在每次内存分配之后（或之前，选择之前）立即放置一个不可访问的内存页面。读写这个不可访问的也页面会触发段错误，然后使用调试器分析并且解决问题\n“重载”所有标准内存分配函数及释放函数。\n利用CPU的MMU（内存管理单元）分配并保护一个额外的内存页，以检测超出缓冲区顶部（或底部，由用户选择）之外的任何非法访问。\n以free()方式释放的内存也被设置为不可访问，任何试图接触它的代码都会得到一个segmentation fault。\n初始化的内存可以自定义1-255的初始值，默认不设置\n使用0xAA填充申请页块中未使用但是可以使用的内存\n内存使用和执行速度 由于DUMA的每个分配至少使用两个虚拟内存页面，这是一个可怕的内存占用。 我有时发现有必要使用swapon（8）添加一个交换文件，这样系统就有足够的虚拟内存来调试我的程序。 此外，我们操作内存的方式导致各种缓存和转换缓冲区条目被刷新，每次调用malloc或免费。 最终的结果是，您的程序将慢得多，并且在使用DUMA调试时使用更多的资源。\n不要用于生产环境！\n优点和缺点 优点 安装方便 预加载库形式，无需修改代码重新编译 支持C++ 缺点 性能比较差 执行效率：我们操作内存的方式导致各种缓存和转换缓冲区条目被刷新，每次调用malloc或free。 最终的结果是，您的程序将慢得多 内存开销：每个分配使用至少两个虚拟内存页面 ","description":"DUMA是一个开源库(在GNU通用公共许可证下)，用于检测C和C++程序中的缓冲区溢出和运行错误，是一个Red-Zone memory allocator。","id":43,"section":"posts","tags":["MLK"],"title":"duma","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/duma/"},{"content":"Eletric-Fence Electric Fence是另一种malloc（）调试器。它使用系统的虚拟内存硬件来检测软件何时超出了malloc（）缓冲区的边界。它还将检测free（）释放的任何内存访问。因为它使用VM硬件进行检测，所以Electric Fence会在导致边界违反的第一条指令上停止您的程序。\n基本介绍 官网、参考文档：\n1.https://www.bbsmax.com/A/gVdnRMOadW/\n2.https://xsyr.github.io/%E7%BC%96%E7%A8%8B/c/c++/2013/10/13/use-electric-fence-to-detect-heap-overruns-and-underruns.html\n源码： https://github.com/kallisti5/ElectricFence\n支持 支持所有Linux、Unix平台。(Linux kernel version 1.1.83 and above)\n安装 efence库依赖于pthread(多线程)库\n安装依赖于scons工具：yum install scons -y\nSCons是一个基于python的软件构建工具，已经移植到大多数平台上，并且可以在大多数Linux发行库中使用。\nTo compile scons To clean scons -c 使用 基本使用方法 使用步骤：\n在编译的时候添加参数: -lefence -lpthread\n如果没有安装Efence，则需要指定libefence.a的位置：\ngcc –g –o ef ef.c –lefence –L /usr/lib\n或者\nLink the generated static libefence.a archive into your application at build.\nPreload the generated shared library\nlibefence.so at runtime via the following:\nLinux / Haiku / Solaris / HP-UX LD_PRELOAD=./path/to/library/libefence.so /bin/myapplication AIX 5.3+ (32-bit) LDR_PRELOAD=./path/to/library/libefence.so /bin/myapplication AIX 5.3+ (64-bit) LDR_PRELOAD64=./path/to/library/libefence.so /bin/myapplication 编译运行，查看运行产生的core文件，如果没有core文件，说明测试通过\n当发生segmentation fault时就会在当前目录下生产一个core文件，在linux下，我们可以使用GDB来调试core：\nGdb ef core.xxxx\n然后输入where就可以看到程序崩溃时的函数调用堆栈信息了。\n可以在执行的时候使用gdb调试，例如gdb -q ./test，然后执行run可以看到执行后的结果\n只需将应用程序与libefence.a连接起来，就可以检测到malloc缓冲区的大部分（但不是全部）溢出和免费内存的访问。\n可以通过配置以下几个全局变量和环境变量来控制Efence的行为：\nEF_ALIGNMENT：这是Efence malloc分配空间的内存对齐字节数。这个变量的默认值是sizeof(int)，32位字长的CPU对应的该值是4。这个值也是Efence能够检测的内存越界的最小值。 EF_PROTECT_BELOW： 默认情况下Efence是把inaccessible的页面置于分配的空间之后，所以检测到的是高地址方向的越界访问。把这个值设为1可以检测到低地址的越界访问。 EF_PROTECT_FREE： 通常free后的内存块会被放到内存池，等待重新被申请分配。把这个值设为1后，free后的内存块就不会被重新分配出去，而是也被设置为inaccessible，所以Efence能够发现程序再次访问这块已经free的内存。 EF_ALLOW_MALLOC_0： Efence默认会捕捉malloc(0)的情况。把该值设为1后则不会捕捉申请0字节内存的情况。 EF_FILL： 分配内存后Efence会将每一byte初始化成这个值(0-255)。当这个值被设成-1时，内存的值不固定。 调试程序方法 链接efence库并且执行自己的程序。 在debugger上运行程序并且修复溢出或者访问已释放内存的错误。 退出debugger工具。 在shell环境变量中Set EF_PROTECT_BELOW = 1 重复step 2 退出debugger工具。 看是否可以将EF_ALIGNMENT设置为0，重复步骤2。 有时这将是太多的工作，或者在库例程中会有问题，而您没有源，这将阻止您这样做。 原理、功能 字节对齐和溢出检测 在malloc()操作的对齐限制和Electric Fence使用的调试策略之间存在冲突。\nmalloc分配是按照字节对齐的，但是Electric Fence的分配至少是两个虚拟页或者更多，并且最后一页被设置为不可读写，即返回的地址为不可读写的的第一个byte地址减去申请的内存大小。因此，任何分配空间的溢出将导致 segmentation fault。\n如果Electric Fence malloc()要返回对齐地址，则必须将分配的大小增加到word大小的倍数。 此外，函数memalign()和valloc()必须遵守内存分配对齐的显式规范，这也只能通过增加分配的大小来实现。 因此，在某些情况下，内存分配的末尾包含一些填充空间，并且不会检测到该填充空间的访问，即使它们是超支的。(存在漏判？)\nElectric Fence提供了变量EF_ALIGNMENT，以便用户可以控制malloc()、calloc()和realloc()使用的默认对齐方式。\n若要调试小到单字节的溢出，可以将EF_ALIGNMENT设置为零\nEfence有2个主要的功能：\n内存越界读写时抛出segmentation fault。当程序用malloc申请内存时，Efence会使用虚拟内存技术将分配的内存空间之后的内存页面设置为inaccessible(不可读写和执行)，所以当程序发生越界读写时，OS会发出SIGSEGV信号，生成core文件(core dump)，进程退出。 当访问已经被释放的内存空间时抛出segmentation fault。当程序把一块空间free之后，Efence同样把这块内存的访问保护级别设置为inaccessible，所以当程序再次访问这块已经释放的内存时也会导致segmentation fault。 性能 内存消耗 由于Electric Fence在每个分配中至少使用两个虚拟内存页面，所以这是一个可怕的内存占用。 我有时发现有必要使用swapon（8）添加一个交换文件，这样系统就有足够的虚拟内存来调试我的程序。\n速度 在对各种缓存和转换缓冲区调用malloc和fredd的操作内存的方式。将导致慢并且用更多的资源。\n优点和缺点 优点 不需要您对程序的源代码进行任何更改。您只需要在编译期间将程序与工具的库链接即可。 调试工具的实现方式可确保在导致边界冲突的第一条指令上产生分段错误，这总是比在以后阶段发现问题要好。 缺点 仅支持Linux，非跨平台\n每一次分配都是利用一个 semaphore 同步，没有 thread local 的分配\nmalloc 和 free 在 slot 都是线性查找，这也造成了整体性能的落后\n内存消耗大，特别对于频繁的小内存分配\nreal_size = user_size + (alignment – (user_size % alignment )) + page_size 该工具无法检测到分配给栈的内存溢出\n不是线程安全的。\n另一个局限性是它不能明确地指出问题出在程序代码中的什么位置-它所做的只是在检测到与内存相关的错误时就产生分段错误。\n只能配合dbug工具进行分析具体位置。\n不能检测内存泄漏\n参考链接：\nhttps://www.cnblogs.com/jingzhishen/p/6025702.html?utm_source=itdadao\u0026amp;utm_medium=referral https://blog.csdn.net/chessinge/article/details/6743764 https://linux.die.net/man/3/efence http://www.bubuko.com/infodetail-2434473.html https://www.computerworld.com/article/3003957/review-5-memory-debuggers-for-linux-coding.htm ","description":"Electric Fence是另一种malloc（）调试器。它使用系统的虚拟内存硬件来检测软件何时超出了malloc（）缓冲区的边界。它还将检测free（）释放的任何内存访问。","id":44,"section":"posts","tags":["MLK"],"title":"Eletric-Fence","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/eletric-fence/"},{"content":"Dbgmem DBGMEM是用于C和C ++程序的功能丰富的内存调试器。目前仅适用于Linux。\n基本介绍 官网： http://dbgmem.sourceforge.net/\n源码： https://sourceforge.net/p/dbgmem/code/HEAD/tree/\nGithub: https://github.com/MoserMichael/cstuff\n文档： http://dbgmem.sourceforge.net/README.html\n支持 使用Perl编写，只支持Linux。\n安装 解压\n1 2 tar xvfz DBGMEM.tar.gz . cd dbgmem 构建测试集\n1 ./make 也可以构建cpp版本的测试集(尚有问题)\n1 ./make cpp 安装到 /usr/local/dbgmem\n1 ./make install 使用 基本功能 该工具将覆盖GLIBC内存分配功能，内存和字符串处理功能，以添加其功能。\n基本使用方法 仅内存泄漏检测使用参数：-d simple ；内存检测+内存检查使用参数：-d check 将内存错误附加到该程序的dbg上添加参数：-a gdb 对于内存分配，最多纪录n层栈帧可以使用参数：-s n (例如纪录7层栈帧:-s 7) 将分配和释放的内存初始化使用参数：-b 基础要求：\n不使用-O选项，或者同时使用-O和-fno-omit-frame-pointer 必须加上-g选项。 不能使用静态链接编译。例如-static-libgcc或-static 链接选项。 停止程序通过信号必须保证信号没有被注册。 基本使用方法：\n日志文件包括下面三个部分：\n返回信息 内存错误报告 内存泄漏报告 选项 所有工具共有的选项 报告 在程序退出时或应用程序请求时生成包含分配时所有内存块及栈的分配时间跟踪；同时检查所有内存块是否溢出。\n检查 应用程序可以调用服务函数来检查所有内存块是否溢出。或者打印出所有堆内存块；或者，该工具允许您为每个任务安装两个信号处理程序。\n错误处理 每当遇到内存错误时，事件都会被记录到日志文件和标准错误流中；您可以选择下面几种操作进行处理：\n继续执行 Dump core 将gdb调试器附加到当前正在运行的进程 钩子 该工具hooks以下GLIBC函数，并跟踪由它们返回的动态分配的内存\nmalloc calloc realloc memalign posix_memalign valign free strdup strndup getcwd new/new[]/delete/delete[] (for C++ version only) malloc_usable_size returns size of requested block. 填充模式值 (有一个选项-b填充)\n初始化所有分配的堆内存——用0xDD填充 所有释放的内存——用0xFF填充 这是一个强大的特性，使用已释放的内存或者或者未出世后的内存将导致程序错误，不开启将导致未被发现。 如果已释放/未初始化内存包含一个指针，则取消引用该指针将导致 core dump.。\n信号处理 有一个选项可以安装SIGSEGV/SIGBUS信号处理程序，该处理程序还可以检查所有堆块是否覆盖/越界写。\n并行调试 您可以运行一个选项-a dbg，该选项将程序与调试程序并行调用，以便它专门监视调试过程的内存消耗。\nsimple工具 使用-d simple 选项\n在最小开销的实时系统中精确定位和跟踪内存泄漏；？？为什么是最小开销，什么原理呢？ 在分配的块之前和分配的块之后，在头中保存额外的内务信息(housekeeping information)，因此堆错误检查并不总是完美的；检查工具更好地支持这些情况 检查双释放和释放未分配的内存。 check工具 使用-d check选项\n高效地检查堆损坏，精确定位和跟踪活系统中的内存泄漏，跟踪实时系统中的内存泄漏，在匿名共享内存段中，内务信息被保存在堆之外，因此堆检查在这里更好，尽管速度有点慢\n检查释放未分配的内存。\n对于一组标准库函数，还检查以下错误\n受保护的一组函数中的堆越界写\nReading past allocated heap memory range\n栈smash（有限的支持，只有当您粉碎函数返回地址时，检查才触发）被检查的函数集\n检查函数的集合： memcpy、memmove、memset、strncpy、strcat、strncat、strcmp、strncmp\n原理 术语 一个程序的不同阶段：\n[--- INITIALIZATION ---] [--- ACTIVE STAGE ---] [--- SHUTDOWN ---] [--- EXIT ---] INITIALIZATION 程序初始化。通常在这里读取配置，初始化缓存，并创建和初始化整个进一步阶段使用的对象和资源。\nACTIVE STAGE 这个过程是服务请求，并做一些有用的事情：\n在此阶段，进程完成一个或多个逻辑处理单元。 每个这样的单元可以是处理来自网络的请求或一系列请求、处理批处理数据作业或处理交互式用户请求。 通常，在处理某些资源和内存的每个逻辑单元期间都会分配然后释放或者直接泄漏。\nSHUTDOWN 进程已经收到一个信号，然后将退出。这个过程正在清理缓存，并且正在释放资源。\n这是一个常见但可选的阶段\nEXIT 程序退出。\n内存泄漏的原因(Nice) 泄漏是是指一种资源它在进程的实际状态中被分配并且没有释放。\n下面是几种内存泄漏：\n简单的内存泄漏：资源被分配然后忘记释放了。\n坏缓存泄漏：如果对象总是添加到缓存中，并且重用该缓存，则此模式可能导致泄漏。\n引用计数泄漏：\n参考计数是一种特殊的垃圾收集形式，通常在C/C++程序中实现；存在潜在的问题，如:\n计数泄漏：只有在释放所有未完成的引用时，才会释放引用计数对象。 当一个对象的至少一个引用仍然存在时，可能会发生泄漏，因为不知何故，我们忘记清除一个突出的对象引用。 如果根对象引用所有其他对象，但忘记清除其引用，则经常会出现这种情况。\n请注意，这类似于坏缓存泄漏。 请注意，这种情况经常发生在其他编程语言中，如Java。\n环形引用：对象A引用对象B，B也引用对象A；不管怎样，对象A总是有来自对象B的至少一个引用，所以它永远不会被删除。\n解决内存泄漏的方法 在不同时间点所作的两份报告：\n在完成SHUTDOWN时期 在进程正常退出之前，此报告总是由DBGMEM生成，除非进程被SIGKILL信号杀死\n本报告列出了大多数泄漏问题的起源；分配泄漏内存块的堆栈跟踪将给您一个强有力的提示，说明如何修复这些问题。\n对于与引用计数相关的某些类型的泄漏，您需要更多的信息\n在SHUTDOWN之前完成ACTIVE STAGE之后 如果您想跟踪引用计数泄漏，此阶段是有用的：\n通常，当这些引用的根对象被删除时，这些泄漏的引用在SHUTDOWN阶段被删除。\n当许多块发生在SHUTDOWN阶段之前的报告中，但在EXIT之前的报告中没有出现时，这可能表示泄漏。\n这一分析不是由工具完成的，而是由热心的读者完成的，当他比较这两份报告时；热心的读者也掌握了他的程序的工作原理，并将能够总结正在发生的事情。\n两种方法进入下面两个阶段：\nINITIALIZATION and ACTIVE STAGE ACTIVE STAGE and SHUTDOWN stage way1：允许dbgmem的命令行选项去设置两个信号处理，每个信号处理程序将执行请求的状态转换\nway2：修改已调试的程序，以便它调用调试库来指示这两个事件；如果您希望从单元测试/系统测试中运行DBGMEM，则这是首选的解决方案。\n组件 该工具由以下组件组成：\n/usr/mdbg/scripts/run脚本：该脚本运行调试程序。 库/usr/local/dbgmem/lib/libdmemc.so和/usr/mdbg/lib/libdmems.so：每个共享库都是内存调试工具中的一个陷入。 库/usr/local/dbgmem libdmems.so实现了在每个分配中添加arena header的简单工具 下一个/先前的块指针 何时分配块的堆栈 块大小 生成标签值类 + 一些分配函数(malloc/new/new[]) 在信息块之后，在用户分配块结束后，一个size of(void*)保护区域是keps，它由哨兵值初始化，以便我们可以检查内存覆盖/覆盖。 库 /usr/local/dbgmem/lib/libdmems.so：实现了更复杂的检查工具 在被调试的进程退出之后，noteate.pl脚本将由运行脚本启动。 脚本/usr/mdbg/scripts/annotate.pl读取原始报告并创建最终报告 优点和缺点 优点 使用简单，直接命令行使用。 可以在运行时进行检测。 缺点 存在误判，一些内存错误判断成内存泄漏。 仅支持Linux ","description":"DBGMEM是用于C和C ++程序的功能丰富的内存调试器。目前仅适用于Linux。","id":45,"section":"posts","tags":["MLK"],"title":"Dbgmem","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/dbgmem/"},{"content":"AddressSanitizer 基本介绍 官网：http://clang.llvm.org/docs/AddressSanitizer.html\n源码：https://github.com/google/sanitizers\n文档：https://github.com/google/sanitizers/wiki/AddressSanitizer\n支持 OS x86 x86_64 ARM ARM64 MIPS MIPS64 PowerPC PowerPC64 Linux yes yes yes yes yes yes OS X yes yes iOS Simulator yes yes FreeBSD yes yes Android yes yes yes yes 安装 llvm==3.4.2，yum -y install clang \u0026amp;\u0026amp; yum -y install gcc gcc-c++ GCC4.8之后直接提供了对这个工具的支持\n使用 基本要求 llvm\u0026gt;3.1，clang编译 编译时不允许使用-static参数（不支持静态链接） 尽量不加-O2和-O1（实测检测会失效，具体项待验证） Clang与gcc不能混用编译或链接 基本使用方法 选项 用-fsanitize=address选项编译和链接你的程序; 用-fno-omit-frame-pointer编译，以在错误消息中添加更好的堆栈跟踪。 增加-O1以获得更好的性能。 避免使用 -Wl,-z,defs，因为可能会造成链接错误 要获得完美的堆栈跟踪，您可能需要禁用内联(只使用-O1)和尾部调用消除(-fno-optimize-sibling-call) 使用 简单内存检查使用(不包括检查内存泄漏)：\n1 clang -O1 -g -fsanitize=address -fno-omit-frame-pointer {testfile.c} -o {testfile} 单独检查内存泄漏：\n1 clang -O1 -g -fsanitize=leak -fno-omit-frame-pointer {testfile.c} -o {testfile} 检查内存错误和内存泄漏：\n1 clang -fsanitize=address -g {testfile.c} - o {testfile} ; ASAN_OPTIONS=detect_leaks=1 ./testfile 最后执行程序\n1 ./testfile 检查的错误类型 原理 阴影内存 常见方法有两种：一种是直接将实际地址进行缩放+偏移映射到一个shadow地址，从而将整个的应用程序地址空间映射到一个shadow地址空间；一种是增加额外的地址转换表，通过查表完成实际地址到shadow地址的转换。比如Valgrind和Dr.Memory就是将shadow地址分成多个片段，然后通过查找表转换shadow地址。而AddressSanitizer则采用了直接缩放+偏移的方式。\n典型的直接映射的方法包括TraintTrace和LIFT\n使用多级翻译模式，例如Valgrind和DrMemory。将它们的影子内存分成几部分，并使用表查找来获得影子地址，需要额外的内存加载。\nUmbra结合了灵活的布局和高效性，避免了非均匀查表和动态缩放以及偏移模式\nBoundless将其某些元数据存储在64位指针的高16位中，但会在慢速路径上回退到更传统的影子内存。\nLBC使用存储在应用程序内存中的特殊值执行快速路径检查，并依赖慢速路径上的两级影子内存\n阴影内存映射\n假设应用程序内存地址为Addr，那么其对应的Shadow地址为(Addr\u0026raquo;3)+Offset。如果虚拟地址空间的最大合法地址为Max-1，那么Offset值的选择需要确保从Offset到Offset+Max/8在启动时不会被占用。对于常见的32位Linux和MacOS系统来说，其虚拟地址空间为0x00000000-0xffffffff，我们令Offset = 0x20000000 (2^29)。对于具有47个地址位的64位系统来说，我们令Offset =0x0000100000000000 (2^44)。\nSanitizer维护程序的所有地址访问权限，用于判断内存访问是否合法。需要开辟一定的空间存储阴影内存。\n注意到malloc函数的返回地址都是8字节对齐的, 所以对于heap上的8字节内存空间, 只有9种状态, 分别表示first k (0 \u0026lt;= k \u0026lt;= 8)是否可以访问, 而9种状态只需要1个字节就可以表示, 严格说1字节都用不着, 也就是说只使用1/8的虚拟地址空间的shadow memory就可以描述所有的地址。\n阴影内存的地址的映射计算方法如下：\nShadowAddr = (Addr \u0026gt;\u0026gt; 3) + Offset 图示如下所示：\n因为shadow memory放在了中间, 所以用户的内存空间分成了上下2个部分 shadow memory本身也使用同样的映射算法, 但是shadow memory会映射到bad区域, 因为这是ASAN添加的内存区域, 程序是不能访问的 bad区域在页表中是禁止访问的 上面简单提过对齐的8字节有9种状态, 在ASAN的实现中采用如下编码:\n0 - 该8字节均可访问 k (1 \u0026lt;= k \u0026lt;= 7) - 前k个字节可访问 negative - 该8字节均不可访问 负值表示所有8个字节都是不可访问的。同时我们采用不同的负值来标示不同类型的不可访问地址：\nHeap left redzone: fa Heap righ redzone: fb Freed Heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack partial redzone: f4 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 组成 AddressSanitizer consists of two parts: an instrumentation module and a run-time library.\nAddressSanitizer 包括两部分：指令模块和运行时库。\n代码插桩模块(instrumentation) 作用：代码插桩模块会对code进行修改以在每次内存访问时检查shadow state，同时负责在栈和全局对象周围创建用于检测overflow和underflow的poisoned redzones。\n基于LLVM编译器指令集。\n其他工具都不能发现栈溢出的错误。\n友商比较\nMudflap使用编译时检测因此能够检查对象的越界访问，但是因为对象之间没有插入红色区域，所以不能检查出所有的栈溢出bug\nCCured编译指令使用静态分析(仅C程序)消除多余的检查；它们的指令与非指令库不兼容。\nLBC使用源到源的转换和基于CCured去消除多余的检查。(仅限C语言和不能处理use-after-free)\nInsure++主要依靠编译时工具，但也使用二进制工具。实施细节尚未公开。\nMudflap就是采用的编译时代码插入技术，因此它可以检测到栈对象的越界访问。但是，由于它并没有在栈帧上的每个对象之间插入redzone，因此无法发现所有的栈缓冲区溢出bug，同时对于复杂C++代码还存在误报的问题。AddressSanitizer采用了compile-time instrumentation，因此可以发现栈及global对象的相关越界访问。\n有了shadow memory之后, 还需要在访问内存的时候进行检查, 如果是已经编译好的二进制问题, 它是不知道shadow memory的, 所以这就需要在编译的时候插入相应的指令, 也就是说必须带上ASAN编译才能使用到这个功能.\nASAN的检查比较简单(意味着高效), 对于8字节内存访问只需要额外的一次内存访问:\n访问8字节内存：\n1 2 3 4 5 6 7 byte *shadow_address = MemToShadow(address); byte shadow_value = *shadow_address; if (shadow_value) { if (SlowPathCheck(shadow_value, address, kAccessSize)) { ReportError(address, kAccessSize, kIsWrite); } } 访问非8字节内存(1-, 2-, 4-byte的内存访问)：\n1 2 3 4 5 6 // Check the cases where we access first k bytes of the qword // and these k bytes are unpoisoned. bool SlowPathCheck(shadow_value, address, kAccessSize) { last_accessed_byte = (address \u0026amp; 7) + kAccessSize - 1; return (last_accessed_byte \u0026gt;= shadow_value); } 这两种情况都是为原始代码中的每一次内存访问(读\u0026amp;写)增加了一次内存读。\n这里需要注意的是, 对于unaligned access(不对齐的内存访问), ASAN有可能检查不出来.\n错误报告代码(ReportAndCrash(Addr))最多只会被执行一次{!AddressSanitizer的机制是一旦检测到一个错误，就直接报告错误退出，这样做的理由是实现简单，也减少了记录所有错误的开销}，但是会被插入到代码的很多地方，因此需要确保它的紧凑性。\n如何检测栈区和全局对象？\n对于globals，在编译时创建redzones，在应用程序启动时将redzones的地址传递给运行时库。运行时库设置红区不可访问并且记录地址以进行进一步的错误报告。 对于栈对象，红区被创建和设置为不可访问在运行时。 例如给一个程序：\n1 2 3 4 void foo() { char a[10]; \u0026lt;function body\u0026gt; } 将被转换为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 void foo() { char rz1[32] char arr[10]; char rz2[32-10+32]; unsigned *shadow = (unsigned*)(((long)rz1\u0026gt;\u0026gt;8)+Offset); // poison the redzones around arr. shadow[0] = 0xffffffff; // rz1 shadow[1] = 0xffff0200; // arr and rz2 shadow[2] = 0xffffffff; // rz2 \u0026lt;function body\u0026gt; // un-poison all. shadow[0] = shadow[1] = shadow[2] = 0; } 运行时库(Run-time Libaray) 作用：替换malloc、free等相关的函数，并且在堆区周围创建用于检测的poisoned redzones，延迟已被free的堆空间的重用(正常情况下为提高内存使用率，已经被free的内存是可以被重用的，但是对于AddressSanitizer来说，因为要检查use-after-free错误，因此被free的空间会被放到一个队列中，这些来确保已被free的内存如果还会被使用的话能够被发现，当然该队列还是有一定的大小限制，按照FIFO的原则进行退出)，同时还会负责报告错误。\n主要工作包括:\n在程序启动的时候, 申请shadow memory的空间. 注意这里是虚拟地址空间, 并不是实际的物理内存, 设置bad区域为不可访问 malloc/free的重新实现 其实通过shadow memory和instrumentation了, 我们已经可以检查出那些内存是可以访问的, 那么重新实现malloc/free的目的是什么?\n首先, 合法访问不代表是正确的访问, 比如2次malloc返回连续的地址, 那么out-of-bounds就可能访问到另外一个合法的内存. 如果2次malloc的内存中间加上redzone, 那么就可以尽量抓住这种情况. redzone本身是不会被程序写坏的, 因为在写之前就已经发现这是一次非法访问了 redzone可以用来记录一些额外的信息, 比如malloc的调用栈 (free的调用栈直接记录在内存区域) 另外, 如果free的内存重新被别人malloc了, 那么use-after-free, double free可能不能及时检查出来, 所以在free的时候尽量避免该内存重新被malloc出来.\n从整体上看，AddressSanitizer采用的方法类似于基于Valgrind的工具AddrCheck：采用Shadow Memory来记录应用程序的每一字节是否可以安全地访问，同时采用代码插桩技术来针对应用的每次load和store对Shadow Memory进行检查。但是AddressSanitizer采用了一种更高效的Shadow映射方式，一种更紧致的Shadow编码技术，除了可以对堆进行检查外还可以检查栈和global对象，另外它要比AddrCheck快一个数量级。\n精度与资源使用tunning 如下三个因素会影响AddressSanitizer的精度及资源使用，这三个值都是由环境变量控制，可以在程序启动时设置：\n1)Depth of stack unwinding (default: 30)。对于每个malloc和free调用，该工具都会对调用栈进行unwind以为错误报告提供更多信息。该选项会影响工具的执行速度，尤其是对于那些属于malloc调用密集型的调用来说。它不会影响内存占用及查找bug的能力，但是调用栈太短的话不利于定位问题。\n2)Quarantine size (default: 256MB)。即保存到前面提到的FIFO队列中的已free的内存空间大小之和，这个值会影响发现use-after-free类型bug的能力。但是它不影响性能。\n3)Size of the heap redzone (default: 128 bytes)。该选项会影响发现堆异常类型bug的能力。该值越大，会导致性能变低并且占用更多内存，尤其是对那些进行了很多小块内存分配的程序来说。由于redzone会被用来保存malloc的调用栈，因此减少这个值，会导致最大unwinding深度变小。\n优点和缺点 可以从多个方面看：\n运行速度 内存消耗 支持的内存错误类型 发现错误的可能性(会不会误报) 支持的平台 其他的特性 优点 支持跨平台。\n支持的错误报告类型多达21种。\n平均速度为越来的73%,内存消耗大约3.4倍。速度和消耗都不错。\n支持C与C++。\n线程安全。\n因为它只会在应用程序内存数据不可访问时(在malloc和free内部，在栈帧被创建和销毁时，在模块初始化时)才会对它进行修改\n缺点 漏报\n那些产生局部越界的未对齐的内存访问。\n1 2 3 int *a = new int[2]; // 8-aligned int *u = (int*)((char*)a + 6); *u = 1; // Access to range [6-9] 根据前述的shadow计算方法，u这个地址会被左移3位，实际上得到的ShadowAddr与a没啥区别，这样k = *ShadowAddr;直接就是0，而不会报错。目前AddressSanitizer没有解决这个问题，因为目前能够想到的解决方案都会造成性能损失。\n跳过redzone的越界访问。\n1 2 3 char *a = new char[100]; char *b = new char[1000]; a[500] = 0; // may end up somewhere in b 陷入到redzone的越界访问，100%会被检测到，但是如上的越界访问，可能刚好已经落到b分配的合法空间内了。如果内存充足，推荐采用128字节的redzone。\n如果在free和下次use之间，又发生了大量内存的分配和释放，use-after-free错误可能无法被检测到。\n1 2 3 4 5 6 char *a = new char[1 \u0026lt;\u0026lt; 20]; // 1MB delete [] a; // \u0026lt;\u0026lt;\u0026lt; \u0026#34;free\u0026#34; char *b = new char[1 \u0026lt;\u0026lt; 28]; // 256MB delete [] b; // drains the quarantine queue. char *c = new char[1 \u0026lt;\u0026lt; 20]; // 1MB a[0] = 0; // \u0026#34;use\u0026#34;. May land in ’c’ 非期望的bug报告\n与编译器的Load Widening发生冲突。\n1 2 3 4 struct X { char a, b, c; }; void foo() { X x; ... ... = x.a + x.c; } 在该代码中，对象x是3字节大小，4字节对齐的。Load Widening会将x.a+x.c转换成一个4字节的load。按照之前的栈代码插入方式，第4个字节应该是被染毒的，这样在load这4个字节时，就会报错。通过在LLVM中临时关闭load widening解决。\n与Clone冲突。\n首先进程，采用CLONE VM|CLONE FILES调用了clone，该操作会创建一个与父进程共享内存的子进程。特别是，子进程的栈使用的内存也是属于父进程的。然后子进程调用了一个包含栈上对象的函数，此时AddressSanitizer会将栈对象的redzone区域染毒。最后，子进程调用了一个不会return的函数(比如_exit或exec)，这样该函数对redzone进行消毒(un-poisoning)的那部分代码就不会被执行。这样父进程地址空间仍处于染毒状态，当该内存被再次使用时就会报错。我们通过找到所有的never-return函数(像_exit或exec这样具有该属性的那些函数)，然后在调用它们之前将整个栈内存消毒。与之类似，AddressSanitizer还必须要对longjmp和C++异常进行拦截。\n不能执行过程添加，需要编译时期进行指定\n更多工具 ThreadSanitizer\nThreadSanitizer是一个用于C/C++和Go的快速数据竞争检测器。\nMemorySanitizer\n一个快速的基于llvm的工具，用于检测未初始化内存的使用情况。\n参考链接：\n.AddressSanitizer使用介绍 https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions 论文《AddressSanitizer: A Fast Address Sanity Checker》 https://zhuanlan.zhihu.com/p/95977383 https://zhuanlan.zhihu.com/p/338158556 ","description":"A Fast Address Sanity Checker","id":46,"section":"posts","tags":["MLK"],"title":"AddressSanitizer Tool","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/mlk/addresssanitizer/"},{"content":"什么是汉明码？ 看下面这张图，蓝色的表示需要发送的数据，我们就假设发送的数据为0101吧，外面橙色的码就是汉明码，汉明码是一种纠错码，但是只能纠正一个错误的比特。汉明码是添加到到发送数据后面的冗余码。每一个汉明码与同一个圆中的所有数据进行异或都是0.\n汉明码怎么进行纠错的？ 假设原来的数据中一个比特错误了，如下面红色的字，原来的1变成了0\n此时对于每一个园，它们进行异或的值都不是0，说明错误的地方是三个圆公共的部分，这个时候我们就可以知道错误的是中间的位置：\n假如是汉明码中的一个比特错误了，如下面红色的字，原来的0变成了1\n此时只有右上角那个圆的所有比特异或不为0，而右上角的圆与其他圆没有关系的部分就是它的汉明码部分，所以可以推断是右上角的圆的汉明码错误了\n汉明码放置的位置在哪里呢？ 首先需要计算汉明码的校验位数。\n汉明码的校验位数 设数据有$n$位，校验码有$x$位。则校验码一共有$2^x$种取值方式。其中需要一种取值方式表示数据正确，剩下$2^x - 1$种取值方式表示有一位数据出错。因为编码后的二进制串有$n+x$位，因此x应该满足：$2^x -1 \u0026gt;= n + x$　使不等式成立的x的最小值就是校验码的位数。\n假设以1010110为例进行海明码编码。\n使不等式成立的x的最小值就是校验码的位数。在本例中，n=7，解得x=4。\n信息码和校验码的对应关系如下表：\n信息码位数 1 2~4 5~11 12~26 27~57 58~120 校验码位数 2 3 4 5 6 7 规定在采用汉明码的一串数据中，2的i次方的位置上，我们放校验码。\n更加详细的校验码位置可看下面绿色的比特，下图为分组及校验码位置图：\n汉明码如何分组，为什么？ 按位置分组\n凡是位置符合这种形式的，XXX1，归到P1； 凡是位置符合这种形式的，XX1X，归到P2； 凡是位置符合这种形式的，X1XX，归到P3； 凡是位置符合这种形式的，1XXX，归到P4； ……..\n其中的规律就是使用每个比特判断数据序列的子集，然后逐步缩小范围，从时间复杂度$O(n)$降到$O(log(n))$\n计算校验码？ 每一行都是从对应的校验位开始校验，即从第$2^n / 2$位开始校验，校验$2^n / 2$个，然后跳过$2^n / 2$个。\n下面计算本例子(以1010110为例进行海明码编码)，将表格中的位置用二进制表示：\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 计算x1:\nx1是第一个校验码，位置对应栏所有最后一位为1（xxx1格式）的相异或为0，即:\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 $$\nx1 \\oplus 1 \\oplus 0 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x1 = 0。\n计算x2:\nx2是第二个校验码，位置对应栏所有倒数第二位为1（xx1x格式）的相异或为0，即\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 $$\nx2 \\oplus 1 \\oplus 1 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x2 = 1。\n计算x3:\nx3是第三个校验码，位置对应栏所有倒数第三位为1（x1xx格式）的相异或为0，即\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 $$\nx3 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x3 = 1。\n计算x4:\nx4是第四个校验码，位置对应栏所有倒数第四位为1（1xxx格式）的相异或为0，即\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 x1 x2 1 x3 0 1 0 x4 1 1 0 $$\nx4 \\oplus 1 \\oplus 1 \\oplus 0 = 0\n$$\n则x4 = 0。\n所以最终的汉明码为: 01100100110,即\n位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011 内容 0 1 1 1 0 1 0 0 1 1 0 如何进行校验？ 假设位置为1011的数据传输错误，由0变成了1，则校验纠错的过程为：\n将所有位置形如xxx1, xx1x, x1xx, 1xxx的数据分别异或。\nxxx1: 0^1^0^0^1^1 = 1\nxx1x: 1^1^1^0^1^1 = 1\nx1x: 1^0^1^0 = 0\n1xxx: 0^1^1^1 = 1\n那么出错数据的位置为1011，这样便可得到出错的位置。\n假设同时有两个位置出错，本例中假设位置为1010对应数据由1变成0,，位置为1011对应数据由0变成1，则推出校验纠错过程：\nxxx1: 0^1^0^0^1^1 = 1\nxx1x: 1^1^1^0^0^1 = 0\nx1x: 1^0^1^0 = 0\n1xxx: 0^1^0^1 = 0\n那么校算出的错误位是0001，即第一位；但实际上是倒数第二位和最后一位都有错误，说明海明码不能校验两位以上出错的数据，即海明码只能检测并纠正一位错误。\nmore 如果一条信息中包含更多用于纠错的位，且通过妥善安排这些纠错位使得不同的出错位产生不同的错误结果，那么我们就可以找出出错位了。在一个7位的信息中，单个位出错有7种可能，因此3个错误控制位就足以确定是否出错及哪一位出错了。\n汉明研究了包括五取二码在内的编码方案，并归纳了他们的想法。\nReference：\n汉明码（海明码、hamming code）通俗易懂的解释 海明码之编码原理和校验方法 三蓝一褐 汉明码 维基百科 https://zh.wikipedia.org/wiki/%E6%B1%89%E6%98%8E%E7%A0%81 ","description":"在一个7位的信息中，单个位出错有7种可能，因此3个错误控制位就足以确定是否出错及哪一位出错了。","id":47,"section":"posts","tags":["汉明码"],"title":"汉明码","uri":"https://hugo.jiahongw.com/posts/network/hamming-code/"},{"content":"求职原理三要素 1. 价值 绝⼤部分公司购买⼈才都是为了使⽤，所以他们看中的是其使⽤价值！这个使⽤价值说得更直⽩⼀点，就是⼈才如何直接或者间接的为公司挣钱。\n2. 供需 一个段子：\n读⼩学时，⼤学不要钱；读⼤学时，⼩学不要钱；还没⼯作时，⼯作是分配的；可以⼯作时，得⾃谋职业；没挣钱时，房⼦是分配的；能挣钱时，发现⼀辈⼦的薪⽔也买不起房⼦。\n简单的说，当企业的职位空缺远少于找⼯作的⼈数时，⼈才的价格就会下降；⽽当企业的职位空缺⽐找⼯作的⼈数更多时，⼈才的价格就会上升。\n举个例⼦，同样是管服务器，普通运维⼯程师和云计算运维⼯程师的薪资差异是⾮常⼤的。⼀个普通运维要变成云计算运维，需要补充的知识并不是特别多。所以你只要合理安排好⾃⼰的职业规划，⽐如以相对较低的薪资到类似新浪云这样的地⽅⼯作⼀到两年，你的能⼒和交换价值都会⼤幅度提升。\n3. 信息透明度 当⼈才市场很⼩的时候，信息是很透明的。因为很容易了解到各⾃的情况。\n但当信息量变⼤后，你就会发现虽然整个市场很⼤，但只有你接触到的才对你有意义。\n⽐如北京现在有100家公司都在招聘PHP，但你只知道其中3家，这个时候，其他97家公\n司的存在对你⽽⾔是没有意义的，即使这3家给你的薪资⽐其他公司低，你也只能被迫接\n受。这就是信息透明度对我们求职的影响。\n所以要想拿到⾜够好的薪资和获得⾜够多的机会，我们要学会和信息不对称进⾏抗争。⼀\n定要在短时间内获取到⼤量的机会，这样才能「 做选择题 」⽽不是「 做判断题 」。\n程序员职业路线图 构建个人品牌 对于技术⼈员，下边这个列表我是建议你要有的：\nGithub账号，不解释。 技术博客，可以直接放到Github上，Big更⾼。 微博，最好能加V，⽤于业内交流。 技术社区账号，⽐如stackoverflow。 本文取自《程序员跳槽攻略》\n","description":"永远不要因为「现在很差」而跳槽，要因为「未来更好」而跳槽。只有这样才能保证你一直往上走。","id":48,"section":"posts","tags":["跳槽"],"title":"程序员职业路线","uri":"https://hugo.jiahongw.com/posts/ideas/programer-go-go/"},{"content":"最近在知乎专栏《高效学习法》中看到一篇比较有用的文章，主要就是讲高效人士的六个好习惯。我觉得这些习惯倒是可以好好学习，因为其实有很多时候我们不能够判断自己当前最应该做什么事情。假如我们这个时候有了一个好的习惯作为准则，一般来说我们都会做出一个比较正确的选择。至少，我们会变得更优秀！\n下面是麦肯锡思维高效工作的六个习惯：\n做正确的事和正确的做事。 这个习惯一方面强调选择比努力更重要，另一方面又强调了选对方法解决问题很重要。\n提高效率的起点——管理时间 对事情的重要程度和紧急程度进行排序\n找到关键的驱动点，才能更好的解决问题。 使用逻辑树分析法解决有难度的问题 将复杂的问题分解为小而简单的问题，先从小事做起，找到成就感。\n如何把工作简单化？ 找到重点 提高技术水平 授权或外包 取消 提高效率的绝招——穿透力 集中全部力量在你要做的重要事情上。\n摆脱事物 抗干扰 明确目标 ","description":"一个好的习惯能够让你做事情更加的轻松，也能够展示你这个人的风格；好的习惯是后天养成的，不是一蹴而就的。","id":49,"section":"posts","tags":["习惯"],"title":"高效人士的几个习惯","uri":"https://hugo.jiahongw.com/posts/ideas/seven-habits/"},{"content":"如何让网络数据传输地更快？(合并一些层)\n为什么需要QUIC？ 中间设备的僵化\n可能是 TCP 协议使用得太久，也非常可靠。所以我们很多中间设备，包括防火墙、NAT 网关，整流器等出现了一些约定俗成的动作。\n依赖于操作系统的实现导致协议僵化\nTCP 是由操作系统在内核西方栈层面实现的，应用程序只能使用，不能直接修改。虽然应用程序的更新迭代非常快速和简单。但是 TCP 的迭代却非常缓慢，原因就是操作系统升级很麻烦。\n建立连接的握手延迟大\n不管是 HTTP1.0/1.1 还是 HTTPS，HTTP2，都使用了 TCP 进行传输。HTTPS 和 HTTP2 还需要使用 TLS 协议来进行安全传输。这就出现了两个握手延迟：\nTCP 三次握手导致的 TCP 连接建立的延迟。\nTLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟。\n对于很多短连接场景，这样的握手延迟影响很大，且无法消除。\n队头阻塞\n队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。\n另外 TLS 协议层面也有一个队头阻塞，因为 TLS 协议都是按照 record 来处理数据的，如果一个 record 中丢失了数据，也会导致整个 record 无法正确处理。\nQUIC 协议选择了 UDP，因为 UDP 本身没有连接的概念，不需要三次握手，优化了连接建立的握手延迟，同时在应用程序层面实现了 TCP 的可靠性，TLS 的安全性和 HTTP2 的并发性，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制。\nQUIC概述 QUIC 是 Quick UDP Internet Connections 的缩写，谷歌发明的新传输协议。\n与 TCP 相比，QUIC 可以减少延迟。\nQUIC 协议可以在 1 到 2 个数据包（取决于连接的服务器是新的还是已知的）内，完成连接的创建（包括 TLS）。\nQUIC 与现有 TCP + TLS + HTTP/2 方案相比，有以下几点主要特征：\n利用缓存，显著减少连接建立时间；(减少了 TCP 三次握手及 TLS 握手时间) 改善拥塞控制，拥塞控制从内核空间到用户空间； 没有 head of line 阻塞的多路复用； 前向纠错，减少重传； 连接平滑迁移，网络状态的变更不会影响连接断线。 拥塞控制、加密和一些HTTP/2的特性都移动到QUIC层去了\n从图上可以看出，QUIC 底层通过 UDP 协议替代了 TCP，上层只需要一层用于和远程服务器交互的 HTTP/2 API。这是因为 QUIC 协议已经包含了多路复用和连接管理，HTTP API 只需要完成 HTTP 协议的解析即可。\nQUIC也合并了TLS握手过程到它的连接过程之中\n目标 QUIC 协议的主要目的，是为了整合 TCP 协议的可靠性和 UDP 协议的速度和效率。\nQUIC连接过程 如何做到0RTT？ 首先解释一下什么是0RTT。\n所谓的0RTT就是，通信双方发起通信连接时，第一个数据包便可以携带有效的业务数据。而我们知道，这个使用传统的TCP是完全不可能的，除非你使能了TCP Fast Open特性，而这个很难，因为几乎没人愿意为了这个收益去对操作系统的网络协议栈大动手脚。未使能Fast Open的TCP传输第一笔数据前，至少要等1个RTT：\n此外，对于HTTPS这种应用而言，由于还需要额外的TLS握手，0RTT就更不可能了。\n首先声明一点，如果一对使用QUIC进行加密通信的双方此前从来没有通信过，那么0RTT是不可能的，即便是QUIC也是不可能的，所谓的0RTT是值之前连接过服务器，后面再次连接的时候就是0RTT。\n连接过程 Step1：首次连接时，客户端发送 Inchoate Client Hello 给服务端，用于请求连接；\nStep2：服务端生成 g、p、a，根据 g、p 和 a 算出 A，然后将 g、p、A 放到 Server Config 中再发送 Rejection 消息给客户端；\nStep3：客户端接收到 g、p、A 后，自己再生成 b，根据 g、p、b 算出 B，根据 A、p、b 算出初始密钥 K。B 和 K 算好后，客户端会用 K 加密 HTTP 数据，连同 B 一起发送给服务端；\nStep4：服务端接收到 B 后，根据 a、p、B 生成与客户端同样的密钥，再用这密钥解密收到的 HTTP 数据。为了进一步的安全（前向安全性），服务端会更新自己的随机数 a 和公钥，再生成新的密钥 S，然后把公钥通过 Server Hello 发送给客户端。连同 Server Hello 消息，还有 HTTP 返回数据；\nStep5：客户端收到 Server Hello 后，生成与服务端一致的新密钥 S，后面的传输都使用 S 加密。\n这样，QUIC 从请求连接到正式接发 HTTP 数据一共花了 1 RTT，这 1 个 RTT 主要是为了获取 Server Config，后面的连接如果客户端缓存了 Server Config，那么就可以直接发送 HTTP 数据，实现 0 RTT 建立连接。\n这里使用的是 DH 密钥交换算法，DH 算法的核心就是服务端生成 a、g、p 3 个随机数，a 自己持有，g 和 p 要传输给客户端，而客户端会生成 b 这 1 个随机数，通过 DH 算法客户端和服务端可以算出同样的密钥。在这过程中 a 和 b 并不参与网络传输，安全性大大提高。因为 p 和 g 是大数，所以即使在网络中传输的 p、g、A、B 都被劫持，那么靠现在的计算机算力也没法破解密钥。\n如下图：\nQUIC连接迁移 当手机从数据信号切换到WIFI信号时需要可以灵活的进行连接的切换。\nTCP 连接基于四元组（源 IP、源端口、目的 IP、目的端口），切换网络时至少会有一个因素发生变化，导致连接发生变化。当连接发生变化时，如果还使用原来的 TCP 连接，则会导致连接失败，就得等原来的连接超时后重新建立连接，所以我们有时候发现切换到一个新网络时，即使新网络状况良好，但内容还是需要加载很久。如果实现得好，当检测到网络变化时立刻建立新的 TCP 连接，即使这样，建立新的连接还是需要几百毫秒的时间。\nQUIC 的连接不受四元组的影响，当这四个元素发生变化时，原连接依然维持。那这是怎么做到的呢？道理很简单，QUIC 连接不以四元组作为标识，而是使用一个 64 位的随机数，这个随机数被称为 Connection ID，即使 IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。\n是不是很强~\nQUIC解决队头阻塞问题 HTTP 一般又允许每个主机建立 6 个 TCP 连接，这样可以更加充分地利用带宽资源，但每个连接中队头阻塞的问题还是存在。\nHTTP/2 的多路复用解决了上述的队头阻塞问题。不像 HTTP/1.1 中只有上一个请求的所有数据包被传输完毕下一个请求的数据包才可以被传输，HTTP/2 中每个请求都被拆分成多个 Frame 通过一条 TCP 连接同时被传输，这样即使一个请求被阻塞，也不会影响其他的请求。如下图所示，不同颜色代表不同的请求，相同颜色的色块代表请求被切分的 Frame。\n事情还没完，HTTP/2 虽然可以解决“请求”这个粒度的阻塞，但 HTTP/2 的基础 TCP 协议本身却也存在着队头阻塞的问题。HTTP/2 的每个请求都会被拆分成多个 Frame，不同请求的 Frame 组合成 Stream，Stream 是 TCP 上的逻辑传输单元，这样 HTTP/2 就达到了一条连接同时发送多条请求的目标，这就是多路复用的原理。我们看一个例子，在一条 TCP 连接上同时发送 4 个 Stream，其中 Stream1 已正确送达，Stream2 中的第 3 个 Frame 丢失，TCP 处理数据时有严格的前后顺序，先发送的 Frame 要先被处理，这样就会要求发送方重新发送第 3 个 Frame，Stream3 和 Stream4 虽然已到达但却不能被处理，那么这时整条连接都被阻塞。\n不仅如此，由于 HTTP/2 必须使用 HTTPS，而 HTTPS 使用的 TLS 协议也存在队头阻塞问题。TLS 基于 Record 组织数据，将一堆数据放在一起（即一个 Record）加密，加密完后又拆分成多个 TCP 包传输。一般每个 Record 16K，包含 12 个 TCP 包，这样如果 12 个 TCP 包中有任何一个包丢失，那么整个 Record 都无法解密。\n那 QUIC 是如何解决队头阻塞问题的呢？主要有两点。\nQUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、传输、解密都基于 Packet，不会跨越多个 Packet，这样就能避免 TLS 的队头阻塞问题； QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理。(Stream 之间相互独立) 当然，并不是所有的 QUIC 数据都不会受到队头阻塞的影响，比如 QUIC 当前也是使用 Hpack 压缩算法 [10]，由于算法的限制，丢失一个头部数据时，可能遇到队头阻塞。\n总体来说，QUIC 在传输大量数据时，比如视频，受到队头阻塞的影响很小。\nQUIC的拥塞控制(可插拔) 拥塞控制的目的是避免过多的数据一下子涌入网络，导致网络超出最大负荷。QUIC 的拥塞控制与 TCP 类似，并在此基础上做了改进。\nAIMD:线性增加，乘性减少反馈控制算法。\n热拔插 TCP 中如果要修改拥塞控制策略，需要在系统层面进行操作。QUIC 修改拥塞控制策略只需要在应用层操作，并且 QUIC 会根据不同的网络环境、用户来动态选择拥塞控制算法。\nQUIC前向纠错FEC QUIC 使用前向纠错(FEC，Forward Error Correction)技术增加协议的容错性。一段数据被切分为 10 个包后，依次对每个包进行异或运算，运算结果会作为 FEC 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 9 个包以及 FEC 包推算出丢失的那个包的数据，这样就大大增加了协议的容错性。\n这是符合现阶段网络技术的一种方案，现阶段带宽已经不是网络传输的瓶颈，往返时间才是，所以新的网络传输协议可以适当增加数据冗余，减少重传操作。\nQUIC重传序列号单调递增 TCP 为了保证可靠性，使用 Sequence Number 和 ACK 来确认消息是否有序到达，但这样的设计存在缺陷。\n超时发生后客户端发起重传，后来接收到了 ACK 确认消息，但因为原始请求和重传请求接收到的 ACK 消息一样，所以客户端就郁闷了，不知道这个 ACK 对应的是原始请求还是重传请求。如果客户端认为是原始请求的 ACK，但实际上是左图的情形，则计算的采样 RTT 偏大；如果客户端认为是重传请求的 ACK，但实际上是右图的情形，又会导致采样 RTT 偏小。\n图中有几个术语，RTO 是指超时重传时间（Retransmission TimeOut），跟我们熟悉的 RTT（Round Trip Time，往返时间）很长得很像。采样 RTT 会影响 RTO 计算，超时时间的准确把握很重要，长了短了都不合适。\nQUIC 解决了上面的歧义问题。与 Sequence Number 不同的是，Packet Number 严格单调递增，如果 Packet N 丢失了，那么重传时 Packet 的标识不会是 N，而是比 N 大的数字，比如 N + M，这样发送方接收到确认消息时就能方便地知道 ACK 对应的是原始请求还是重传请求。\n如上图所示，RTO 发生后，根据重传的 Packet Number 就能确定精确的 RTT 计算。如果 Ack 的 Packet Number 是 N+M，就根据重传请求计算采样 RTT。如果 Ack 的 Pakcet Number 是 N，就根据原始请求的时间计算采样 RTT，没有歧义性。\n保证包的顺序 单纯依靠严格递增的 Packet Number 肯定是无法保证数据的顺序性和可靠性。QUIC 又引入了一个 Stream Offset 的概念。\n即一个 Stream 可以经过多个 Packet 传输，Packet Number 严格递增，没有依赖。但是 Packet 里的 Payload 如果是 Stream 的话，就需要依靠 Stream 的 Offset 来保证应用数据的顺序。如下图所示，发送端先后发送了 Pakcet N 和 Pakcet N+1，Stream 的 Offset 分别是 x 和 x+y。\n假设 Packet N 丢失了，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可以将 Stream x 和 Stream x+y 按照顺序组织起来。\n不允许 Reneging 什么叫 Reneging 呢？就是接收方丢弃已经接收并且上报给 SACK 选项的内容。TCP 协议不鼓励这种行为，但是协议层面允许这样的行为。主要是考虑到服务器资源有限，比如 Buffer 溢出，内存不够等情况。\nReneging 对数据重传会产生很大的干扰。因为 Sack 都已经表明接收到了，但是接收端事实上丢弃了该数据。QUIC 中的 ACK 包含了与 TCP 中 SACK 等价的信息，但 QUIC 不允许任何（包括被确认接受的）数据包被丢弃。这样不仅可以简化发送端与接收端的实现难度，还可以减少发送端的内存压力。\nQUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰。\n更多的 ACK 块 一般来说，接收方收到发送方的消息后都应该发送一个 ACK 回复，表示收到了数据。但每收到一个数据就返回一个 ACK 回复太麻烦，所以一般不会立即回复，而是接收到多个数据后再回复，TCP SACK 最多提供 3 个 ACK block。但有些场景下，比如下载，只需要服务器返回数据就好，但按照 TCP 的设计，每收到 3 个数据包就要“礼貌性”地返回一个 ACK。而 QUIC 最多可以捎带 256 个 ACK block。在丢包率比较严重的网络下，更多的 ACK block 可以减少重传量，提升网络效率。\nACK Delay TCP 计算 RTT 时没有考虑接收方接收到数据到发送确认消息之间的延迟，如下图所示，这段延迟即 ACK Delay。QUIC 考虑了这段延迟，使得 RTT 的计算更加准确。\n这段时间可能是解析包的时间。\nQUIC流量控制(基于 stream 和 connecton 级别) QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。\n但 QUIC 不同，就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数。\n针对 Stream：\n$$\n可用窗口 = 最大窗口 - 接受到的最大偏移数\n$$\n针对 Connection：\n$$\n可用窗口= stream1可用窗口 + stream2可用窗口 + streamN可用窗口\n$$\n最重要的是，我们可以在内存不足或者上游处理性能出现问题时，通过流量控制来限制传输速率，保障服务可用性。\n加密认证的报文 TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。\n但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。\n这样只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险。\n如下图所示，红色部分是 Stream Frame 的报文头部，有认证。绿色部分是报文内容，全部经过加密。\nReference：\nThe Road to QUIC 科普：QUIC协议原理分析 Quic协议介绍和浅析 QUIC协议是如何做到0RTT加密传输的 Quic协议介绍和浅析 ","description":"新一代HTTP协议，成为HTTP/3，基于UDP，非常强大.有更快速、更灵活、更安全的特点。","id":50,"section":"posts","tags":["quic"],"title":"Quic协议为什么这么好","uri":"https://hugo.jiahongw.com/posts/network/quic-protocol/"},{"content":"TCP拥塞控制算法的目的可以简单概括为：公平竞争、充分利用网络带宽、降低网络延时、优化用户体验，然而就目前而言要实现这些目标就难免有权衡和取舍。\n算法分类 基于丢包策略的传统拥塞控制算法的几个迭代版本，如图所示：\n与此同时还有一类算法是基于RTT延时策略来进行控制的，但是这类算法在发包速率上可能不够激进，竞争性能不如其他算法，因此在共享网络带宽时有失公平性，但是算法速率曲线却是很平滑\n基于链路容量的拥塞控制：实时测量网络带宽和时延，认为网络上报文总量大于带宽时延乘积时出现了拥塞，如 BBR。\n基于学习的拥塞控制：没有特定的拥塞信号，而是借助评价函数，基于训练数据，使用机器学习的方法形成一个控制策略，如 Remy。\n如何感知拥塞 基于各种拥塞策略的拥塞控制算法有不一样的拥塞判断标准：\n基于丢包\n丢包可以由重传超时RTO和重复确认来做判断。\n基于时延\n基于链路容量\n基于机器学习\n根据参数得出一个拥塞窗口值\n拥塞控制基本策略 拥塞控制是一个动态的过程，它既要提高带宽利用率发送尽量多的数据又要避免网络拥堵丢包RTT增大等问题，基于这种高要求并不是单一策略可以搞定的，因此TCP的 拥塞控制策略实际上是分阶段分策略的综合过程：\n基于丢包的拥塞控制 Tahoe算法 如果收到三次重复确认即第四次收到相同确认号的分段确认，并且分段对应包无负载分段和无改变接收窗口的话，Tahoe算法则进入快速重传，将慢启动阈值改为当前拥塞窗口的一半，将拥塞窗口降为1个MSS，并重新进入慢启动阶段。\n拥塞控制过程大致如下：\nReno算法(我们当前理解的算法) 如果收到三次重复确认，Reno算法则进入快速重传只将拥塞窗口减半来跳过慢启动阶段，将慢启动阈值设为当前新的拥塞窗口值，进入一个称为快速恢复的新设计阶段。\n拥塞控制流程如下：\nReno 算法将收到 ACK 这一信号作为拥塞窗口增长的依据，在早期低带宽、低时延的网络中能够很好的发挥作用，但是随着网络带宽和延时的增加，Reno 的缺点就渐渐体现出来了，发送端从发送报文到收到 ACK 经历一个 RTT，在高带宽延时（High Bandwidth-Delay Product，BDP）网络中，RTT 很大，导致拥塞窗口增长很慢，传输速度需要经过很长时间才能达到最大带宽，导致带宽利用率将低。\n适用场景：\n适用于低延时、低带宽的网络。\nTCP New Reno是对TCP Reno中快速恢复阶段的重传进行改善的一种改进算法，New Reno在低错误率时运行效率和选择确认SACK相当，在高错误率仍优于Reno。\nCUBIC算法 Cubic是 Linux 内核 2.6 之后的默认 TCP 拥塞控制算法， 使用一个立方函数（cubic function）:\n$$\nW_{cubic} = C(t-K)^3 + W_{max}\n$$\n作为拥塞窗口的增长函数，其中，C 是调节因子，t 是从上一次缩小拥塞窗口经过的时间，$W_{max}$是上一次发生拥塞时的窗口大小，\n$$\nK = \\sqrt[3]{W_{max}\\beta /C}\n$$\nβ是乘法减小因子。从函数中可以看出拥塞窗口的增长不再与 RTT 有关，而仅仅取决上次发生拥塞时的最大窗口和距离上次发生拥塞的时间间隔值。\nCubic 拥塞窗口增长曲线如下，凸曲线部分为稳定增长阶段，凹曲线部分为最大带宽探测阶段。如图下图 所示，在刚开始时，拥塞窗口增长很快，在接近 $W_{max}$ 口时，增长速度变的平缓，避免流量突增而导致丢包；在 $W_{max}$ 附近，拥塞窗口不再增加；之后开始缓慢地探测网络最大吞吐量，保证稳定性（在 $W_{max}$ 附近容易出现拥塞），在远离 $W_{max}$ 后，增大窗口增长的速度，保证了带宽的利用率。\n当出现丢包时，将拥塞窗口进行乘法减小(拥塞窗口减小到当前的一半)，再继续开始上述增长过程。此方式可以使得拥塞窗口一直维持在 $W_{max}$ 附近，从而保证了带宽的利用率。Cubic 的拥塞控制过程：\nCubic 算法的优点在于只要没有出现丢包，就不会主动降低自己的发送速度，可以最大程度的利用网络剩余带宽，提高吞吐量，在高带宽、低丢包率的网络中可以发挥较好的性能。\n但是，Cubic 同之前的拥塞控制算法一样，无法区分拥塞丢包和传输错误丢包，只要发现丢包，就会减小拥塞窗口，降低发送速率，而事实上传输错误丢包时网络不一定发生了拥塞，但是传输错误丢包的概率很低，所以对 Cubic 算法的性能影响不是很大。\nCubic 算法的另一个不足之处是过于激进，在没有出现丢包时会不停地增加拥塞窗口的大小，向网络注入流量，将网络设备的缓冲区填满，出现 Bufferbloat（缓冲区膨胀）。由于缓冲区长期趋于饱和状态，新进入网络的的数据包会在缓冲区里排队，增加无谓的排队时延，缓冲区越大，时延就越高。另外 Cubic 算法在高带宽利用率的同时依然在增加拥塞窗口，间接增加了丢包率，造成网络抖动加剧。\n适用场景：\n适用于高带宽、低丢包率网络，能够有效利用带宽。\n基于链路容量的算法 BRR算法 BBR[4] 是谷歌在 2016 年提出的一种新的拥塞控制算法，已经在 Youtube 服务器和谷歌跨数据中心广域网上部署，据 Youtube 官方数据称，部署 BBR 后，在全球范围内访问 Youtube 的延迟降低了 53%，在时延较高的发展中国家，延迟降低了 80%。目前 BBR 已经集成到 Linux 4.9 以上版本的内核中。\nBBR 算法不将出现丢包或时延增加作为拥塞的信号，而是认为当网络上的数据包总量大于瓶颈链路带宽和时延的乘积时才出现了拥塞。\nBBR 算法周期性地探测网络的容量，交替测量一段时间内的带宽极大值和时延极小值，将其乘积作为作为拥塞窗口大小（交替测量的原因是极大带宽和极小时延不可能同时得到，带宽极大时网络被填满造成排队，时延必然极大，时延极小时需要数据包不被排队直接转发，带宽必然极小），使得拥塞窗口始的值始终与网络的容量保持一致。\n什么叫做BDP呢？它叫做带宽时延积，例如一条链路的带宽是100Mbps，而RTT是40ms，那么\nBDP=100Mbps*0.04s=4Mb=0.5MB 即平均每秒飞行中的报文应当是0.5MB。因此Linux的接收窗口缓存常参考此设置：\n事实上，我们的传输速度在3个阶段被不同的因素限制：\n应用程序限制阶段，此时RTT不变，随着应用程序开始发送大文件，速率直线上升； BDP限制阶段，此时RTT开始不断上升，但吞吐量不变，因为此时瓶颈路由器已经达到上限，缓冲队列正在不断增加； 瓶颈路由器缓冲队列限制阶段，此时开始大量丢包。 如下所示：\n如CUBIC这样基于丢包的拥塞控制算法在第2条灰色竖线发生作用，这已经太晚了，更好的作用点是BDP上限开始发挥作用时，也就是第1条灰色竖线。\n而BBR通过检测RTprop和~BtlBw~来实现拥塞控制。什么是RTprop呢？这是链路的物理时延，因为RTT里含有报文在路由器队列里的排队时间、ACK的延迟确认时间等。什么叫延迟确认呢？TCP每个报文必须被确认，确认动作是通过接收端发送ACK报文实现的，但由于TCP和IP头部有40个字节，如果不携带数据只为发送ACK网络效率过低，所以会让独立的ACK报文等一等，看看有没有数据发的时候顺便带给对方，或者等等看多个ACK一起发。所以，可以用下列公式表示RTT与RTprop的差别：\n$$\nRTT_t = RT_{prop_t} + n_t\n$$\nRTT我们可以测量得出，RTprop呢，我们只需要找到瓶颈路由器队列为空时多次RTT测量的最小值即可\n而BtlBw全称是bottleneck bandwith，即瓶颈带宽，我们可以通过测量已发送但未ACK确认的飞行中字节除以飞行时间deliveryRate来测量\n早在1979年Leonard Kleinrock就提出了第1条竖线是最好的拥塞控制点，但被Jeffrey M. Jaffe证明不可能实现，因为没有办法判断RTT变化到底是不是因为链路变化了，从而不同的设备瓶颈导致的，还是瓶颈路由器上的其他TCP连接的流量发生了大的变化。但我们有了RTprop和BtlBw后，当RTprop升高时我们便得到了BtlBw，这便找到第1条灰色竖线最好的拥塞控制点，也有了后续发送速率的依据。\n由于 BBR 的拥塞窗口是精确测量出来的，不会无限的增加拥塞窗口，也就不会将网络设备的缓冲区填满，避免了出现 Bufferbloat (缓冲区膨胀)问题，使得时延大大降低。\n如下图所示，网络缓冲区被填满时时延为 250ms，Cubic 算法会继续增加拥塞窗口，使得时延持续增加到 500ms 并出现丢包，整个过程 Cubic 一直处于高时延状态，而 BBR 由于不会填满网络缓冲区，时延一直处于较低状态。\n由于 BBR 算法不将丢包作为拥塞信号，所以在丢包率较高的网络中，BBR 依然有极高的吞吐量，如图 5下图所示，在 1% 丢包率的网络环境下，Cubic 的吞吐量已经降低 90% 以上，而 BBR 的吞吐量几乎没有受到影响，当丢包率大于 15% 时，BBR 的吞吐量才大幅下降。\nBBR 算法是反馈驱动的，有自主调节机制，不受 TCP 拥塞控制状态机的控制，通过测量网络容量来调整拥塞窗口，发送速率由自己掌控，而传统的拥塞控制算法只负责计算拥塞窗口，而不管发送速率（pacing rate），怎么发由 TCP 自己决定，这样会在瓶颈带宽附近因发送速率的激增导致数据包排队或出现丢包。\n经过测试，在高延时、高丢包率的环境下，BBR 相对于 Cubic 算法在传输速度上有较大的提升，具体的测试结果如下表所示：\n200ms 延时下 Cubic 与 BBR 传输速度对比 BBR 算法的不足之处在于设备队列缓存较大时，BBR 可能会竞争不过 Cubic 等比较激进算法，原因是 BBR 不主动去占据队列缓存，如果 Cubic 的流量长期占据队列缓存，会使得 BBR 在多个周期内测量的极小 RTT 增大，进而使 BBR 的带宽减小。\n适用场景：\n适用于高带宽、高时延、有一定丢包率的长肥网络，可以有效降低传输时延，并保证较高的吞吐量。\n基于学习的算法 Remy Remy 也称为计算机生成的拥塞控制算法（computer-generated congestion-control algorithm），采用机器学习的方式生成拥塞控制算法模型。\n略了吧\u0026hellip;\u0026hellip;🙃\n基于时延的算法 Vegas算法 Vegas将时延 RTT 的增加作为网络出现拥塞的信号，RTT 增加，拥塞窗口减小，RTT 减小，拥塞窗口增加。具体来说，Vegas 通过比较实际吞吐量和期望吞吐量来调节拥塞窗口的大小.\n期望吞吐量为：\n$$\nExpected = cwnd / BaseRTT\n$$\n实际吞吐量为：\n$$\nActual = cwnd / RTT\n$$\n定义一个它们之间的差距diff:\n$$\ndiff = (Expected-Actual) * BaseRTT\n$$\nBaseRTT 是所有观测来回响应时间的最小值，一般是建立连接后所发的第一个数据包的 RTT，cwnd 是目前的拥塞窗口的大小。Vegas 定义了两个阈值 a，b，当 diff \u0026gt; b 时，拥塞窗口减小，当 a \u0026lt;= diff \u0026lt;=b 时，拥塞窗口不变，当 diff \u0026lt; a 时，拥塞窗口增加。\nVegas 算法采用 RTT 的改变来判断网络的可用带宽，能精确地测量网络的可用带宽，效率比较好。但是，网络中 Vegas 与其它算法共存的情况下，基于丢包的拥塞控制算法会尝试填满网络中的缓冲区，导致 Vegas 计算的 RTT 增大，进而降低拥塞窗口，使得传输速度越来越慢，因此 Vegas 未能在 Internet 上普遍采用。\n适用场景：\n适用于网络中只存在 Vegas 一种拥塞控制算法，竞争公平的情况。\nReference：\n万字长文|全网最强 TCP/IP 拥塞控制总结\u0026hellip; 万字详文：TCP 拥塞控制详解 浅谈 TCP 拥塞控制算法 一文解释清楚google-bbr拥塞控制算法原理 ","description":"以往的拥塞控制算法是基于TCP丢包的，随着技术的发展，也出现了基于链路容量的一些拥塞控制算法，例如BBR，使得拥塞控制也可以基于UDP，更进一步的推动了HTTP/3的发展。","id":51,"section":"posts","tags":["拥塞控制"],"title":"拥塞控制算法","uri":"https://hugo.jiahongw.com/posts/network/congestion-control/"},{"content":"哈夫曼编码算法用字符在文件中出现的频率表来建立一个用0，1串表示各字符的最优表示方式。给出现频率高的字符较短的编码，出现频率较低的字符以较长的编码，可以大大缩短总码长。\nHuffman Coding两个步骤 编码(从输入的字符数据构建一颗哈夫曼树，并将字符串转化位01编码) 解码(遍历哈夫曼树将01编码转化为字符) 构建哈夫曼树的过程 计算输入数据的每一个字符的出现频率。 从最小堆中提取两个频率最小的字符。 创建一个频率等于两个节点频率之和的新内部节点。使第一个提取的节点为其左子节点，另一个提取的节点为其右子节点。将此节点添加到最小堆中。 重复step2和step3直到最小堆为空。 假如有如下几个字母及它们出现的次数(频率):\n字符 字数 a 5 b 4 c 3 d 2 e 1 在线演示霍夫曼树的构建：https://people.ok.ubc.ca/ylucet/DS/Huffman.html\nC++使用STL实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 // C++ program for Huffman Coding #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; // A Huffman tree node struct MinHeapNode { // One of the input characters char data; // Frequency of the character unsigned freq; // Left and right child MinHeapNode *left, *right; MinHeapNode(char data, unsigned freq) { left = right = NULL; this-\u0026gt;data = data; this-\u0026gt;freq = freq; } }; // For comparison of // two heap nodes (needed in min heap) struct compare { bool operator()(MinHeapNode* l, MinHeapNode* r) { return (l-\u0026gt;freq \u0026gt; r-\u0026gt;freq); } }; // Prints huffman codes from // the root of Huffman Tree. void printCodes(struct MinHeapNode* root, string str) { if (!root) return; if (root-\u0026gt;data != \u0026#39;$\u0026#39;) cout \u0026lt;\u0026lt; root-\u0026gt;data \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; printCodes(root-\u0026gt;left, str + \u0026#34;0\u0026#34;); printCodes(root-\u0026gt;right, str + \u0026#34;1\u0026#34;); } // The main function that builds a Huffman Tree and // print codes by traversing the built Huffman Tree void HuffmanCodes(char data[], int freq[], int size) { struct MinHeapNode *left, *right, *top; // Create a min heap \u0026amp; inserts all characters of data[] priority_queue\u0026lt;MinHeapNode*, vector\u0026lt;MinHeapNode*\u0026gt;, compare\u0026gt; minHeap; for (int i = 0; i \u0026lt; size; ++i) minHeap.push(new MinHeapNode(data[i], freq[i])); // Iterate while size of heap doesn\u0026#39;t become 1 while (minHeap.size() != 1) { // Extract the two minimum // freq items from min heap left = minHeap.top(); minHeap.pop(); right = minHeap.top(); minHeap.pop(); // Create a new internal node with // frequency equal to the sum of the // two nodes frequencies. Make the // two extracted node as left and right children // of this new node. Add this node // to the min heap \u0026#39;$\u0026#39; is a special value // for internal nodes, not used top = new MinHeapNode(\u0026#39;$\u0026#39;, left-\u0026gt;freq + right-\u0026gt;freq); top-\u0026gt;left = left; top-\u0026gt;right = right; minHeap.push(top); } // Print Huffman codes using // the Huffman tree built above printCodes(minHeap.top(), \u0026#34;\u0026#34;); } // Driver program to test above functions int main() { char arr[] = { \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39; }; int freq[] = { 5, 9, 12, 13, 16, 45 }; int size = sizeof(arr) / sizeof(arr[0]); HuffmanCodes(arr, freq, size); return 0; } // This code is contributed by Aditya Goel Reference:\n哈夫曼编码的理解(Huffman Coding) 哈夫曼编码 Huffman Coding | Greedy Algo-3 ","description":"哈夫曼编码算法用字符在文件中出现的频率表来建立一个用0，1串表示各字符的最优表示方式。","id":52,"section":"posts","tags":["huffman"],"title":"Huffman Tree是如何编码的？","uri":"https://hugo.jiahongw.com/posts/algorithmstructure/huffman-coding/"},{"content":"参考地址：\ncloudflare.com 使用Cloudflare和Nginx来托管网站 管理 Cloudflare Origin CA 证书 已安装nginx支持https配置 nginx启动、重启、关闭 nginx配置ssl实现https访问 点击SSL/TLS，并且点击源服务器\n进入下面的页面，点击下面的创建证书，接下来按照下面链接的指导进行操作：\n使用Cloudflare和Nginx来托管网站\n同时在Nginx服务器的配置文件nginx.conf中设置相关的配置\nnginx配置ssl实现https访问\n假如Nginx提示the \u0026quot;ssl\u0026quot; parameter requires ngx_http_ssl_module,表示Nginx没有安装SSL模块，按照下面的链接指导进行操作\n已安装nginx支持https配置\n接下来在CloudFlare中设置完全严格\n最后就可以看到小锁头啦\n","description":"使用Nginx配合CloudFlare设置服务器使用Https证书。","id":53,"section":"posts","tags":["Nginx","https"],"title":"CloudFlare+Nginx配置HTTPS连接","uri":"https://hugo.jiahongw.com/posts/%E5%87%86%E5%A4%87%E4%B8%A2%E5%BC%83/https-set/"},{"content":"🍂 HTTP报文 请求报文 HTTP 请求报文由3部分组成(请求行+请求头+请求体)\n请求行包括：请求方法、请求URL、HTTP协议及版本：\nGET和POST是最常见的HTTP方法,初次以外还包括 DELETE、HEAD、OPTIONS、PUT、TRACE，不过现在大部分的浏览器只支持GET和POST\n请求对应的URL地址,他和报文头的Host属性,组合起来是一个完整的请求URL\n报文头是一些参数信息：\n有若干个属性,形式为key:val,服务端据此获取客户端信息\n报文体是具体传输的内容。\n响应报文 响应报文与请求报文一样,由三个部分组成(响应行,响应头,响应体)\n参考：HTTP请求头和响应头详解\n🚉 HTTP状态码： 1xx：表示通知信息，如请求收到了或正在进行处理 100 Continue：继续，客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议 2xx：表示成功，如接收或知道了 200 OK: 请求成功 3xx：表示重定向，如要完成请求还必须采取进一步的行动 301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替 4xx：表示客户的差错，如请求中有错误的语法或不能完成 400 Bad Request: 客户端请求的语法错误，服务器无法理解 401 Unauthorized: 请求要求用户的身份认证 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够） 404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面 408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时 5xx：表示服务器的差错，如服务器失效无法完成请求 500 Internal Server Error: 服务器内部错误，无法完成请求 503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中 504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求 ✋ HTTP的主要方法 下面这个例子是查询HTTP服务器端支持的HTTP方法种类。\n参考：HTTP请求头和响应头详解\n","description":"Http是定义在TCP上的一种传输协议，要传输消息就必须遵守规定，本文是使用Http的发送消息与接受消息的报文规定及方法。","id":54,"section":"posts","tags":["http"],"title":"Http报文格式及Http方法","uri":"https://hugo.jiahongw.com/posts/network/http-message/"},{"content":"同步异步与阻塞非阻塞 用户空间和内核空间 操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立（一个进程的崩溃不会影响其他的进程 ， 恶意进程不能直接读取和修改其他进程运行时的代码和数据）。 因此操作系统内核需要拥有高于普通进程的权限， 以此来调度和管理用户的应用程序。\n于是内存空间被划分为两部分，一部分为内核空间，一部分为用户空间，内核空间存储的代码和数据具有更高级别的权限。内存访问的相关硬件在程序执行期间会进行访问控制（ Access Control），使得用户空间的程序不能直接读写内核空间的内存。\n进程切换 上图展示了进程切换中几个最重要的步骤：\n当一个程序正在执行的过程中， 中断（interrupt） 或 系统调用（system call） 发生可以使得 CPU 的控制权会从当前进程转移到操作系统内核。 操作系统内核负责保存进程 i 在 CPU 中的上下文（程序计数器， 寄存器）到 PCBi （操作系统分配给进程的一个内存块）中。 从 PCBj 取出进程 j 的CPU 上下文， 将 CPU 控制权转移给进程 j ， 开始执行进程 j 的指令。 可以看出来， 操作系统在进行进切换时，需要进行一系列的内存读写操作， 这带来了一定的开销\n进程阻塞 上图展示了一个进程的不同状态：\nNew. 进程正在被创建. Running. 进程的指令正在被执行 Waiting. 进程正在等待一些事件的发生（例如 I/O 的完成或者收到某个信号） Ready. 进程在等待被操作系统调度 Terminated. 进程执行完毕（可能是被强行终止的） 我们所说的 “阻塞”是指进程在发起了一个系统调用（System Call） 后， 由于该系统调用的操作不能立即完成，需要等待一段时间，于是内核将进程挂起为**等待 （waiting）**状态， 以确保它不会被调度执行， 占用 CPU 资源。\n阻塞的原理\n阻塞的原理？\n对于Socket来说：\n当发生阻塞时候，调用阻塞程序，而阻塞程序最重要的一个操作就是将进程从工作队列移除，并且将其加到等待队列。\n当发生中断时候，调用中断程序，而中断程序最重要的一个操作就是将等待队列中的进程重新移回工作队列，继续分配系统的CPU资源。\n文件描述符 我们最熟悉的句柄是0、1、2三个，0是标准输入，1是标准输出，2是标准错误输出。0、1、2是整数表示的，对应的FILE *结构的表示就是stdin、stdout、stderr，0就是stdin，1就是stdout，2就是stderr。\n1 2 3 4 5 6 7 8 9 10 11 #include \u0026lt;stdio.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;string.h\u0026gt; int main(int argc, char **argv) { char buf[10] = \u0026#34;\u0026#34;; read(0, buf, 9);\t/* 从标准输入 0 读入字符 */ // fprintf(stdout, \u0026#34;%s\\n\u0026#34;, buf); /* 向标准输出 stdout 写字符 */ write(1, buf, strlen(buf)); return 0; } 同步 同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。也就是说，调用会等待返回结果计算完成才能继续执行。\n异步 异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。也就是说，其实异步调用会直接返回，但是这个结果不是计算的结果，当结果计算出来之后，才通知被调用的程序。\n举个通俗的例子：\n你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下\u0026quot;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。\n而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。\n阻塞 阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。\n非阻塞 不管可不可以读写，它都会立即返回，返回成功说明读写操作完成了，返回失败会设置相应errno状态码，根据这个errno可以进一步执行其他处理。它不会像阻塞IO那样，卡在那里不动。\n阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.\n可以这么理解么？阻塞和非阻塞，应该描述的是一种状态，同步与非同步描述的是行为方式.\n多路复用 ==IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程==。\n在处理 IO 的时候，阻塞和非阻塞都是同步 IO。\n只有使用了特殊的 API 才是异步 IO。\nselect、poll、epoll之间的区别：\n\\ select poll epoll 操作方式 遍历 遍历 回调 底层实现 数组 链表 哈希表 IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1) 最大连接数 1024（x86）或 2048（x64） 无上限 无上限 fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝 Select 基于select调用的I/O复用模型如下：\n流程 传统select/poll的另一个致命弱点就是当你拥有一个很大的socket集合，由于网络得延时，使得任一时间只有部分的socket是\u0026quot;活跃\u0026quot; 的，而select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。\n但是epoll不存在这个问题，它只会对\u0026quot;活跃\u0026quot;的socket进 行操作\u0026mdash;这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。于是，只有\u0026quot;活跃\u0026quot;的socket才会主动去调用 callback函数，其他idle状态的socket则不会，在这点上，epoll实现了一个 \u0026ldquo;伪\u0026quot;AIO，因为这时候推动力在os内核。\n过程\n当进程A调用select语句的时候，会将进程A添加到多个监听socket的等待队列中\n当网卡接收到数据，然后网卡通过中断信号通知cpu有数据到达，执行中断程序，中断程序主要做了两件事：\n将网络数据写入到对应socket的接收缓冲区里面 唤醒队列中的等待进程(A),重新将进程A放入工作队列中. 如下图，将所有等待队列的进程移除，并且添加到工作队列中。\n上面只是一种情况，当程序调用 Select 时，内核会先遍历一遍 Socket，如果有一个以上的 Socket 接收缓冲区有数据，那么 Select 直接返回，不会阻塞。\n问题：\n每次调用 Select 都需要将进程加入到所有监视 Socket 的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个 FDS 列表传递给内核，有一定的开销。 进程被唤醒后，程序并不知道哪些 Socket 收到数据，还需要遍历一次 select和poll在内部机制方面并没有太大的差异。相比于select机制，poll只是取消了最大监控文件描述符数限制，并没有从根本上解决select存在的问题。\nSlect API 轮询所有的句柄，找到有处理状态的句柄并且进行操作。\n主要函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 /* According to POSIX.1-2001 */ #include \u0026lt;sys/select.h\u0026gt; /* According to earlier standards */ #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;sys/types.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); /** nfds: 监控的文件描述符集里最大文件描述符加1，因为此参数会告诉内核检测前多少个文件描述符的状态 readfds： 监控有读数据到达文件描述符集合，传入传出参数 writefds： 监控写数据到达文件描述符集合，传入传出参数 exceptfds： 监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数 timeout： 定时阻塞监控时间，3种情况 1.NULL，永远等下去 2.设置timeval，等待固定时间 3.设置timeval里时间均为0，检查描述字后立即返回，轮询 struct timeval { long tv_sec; // seconds long tv_usec; // microseconds }; */ void FD_CLR(int fd, fd_set *set);\t// 把文件描述符集合里fd清0 int FD_ISSET(int fd, fd_set *set); // 测试文件描述符集合里fd是否置1 void FD_SET(int fd, fd_set *set); // 把文件描述符集合里fd位置1 void FD_ZERO(fd_set *set);\t//把文件描述符集合里所有位清0 Select例子 服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 /************************************************************************* \u0026gt; File Name: server.cpp \u0026gt; Author: SongLee \u0026gt; E-mail: lisong.shine@qq.com \u0026gt; Created Time: 2016年04月28日 星期四 22时02分43秒 \u0026gt; Personal Blog: http://songlee24.github.io/ ************************************************************************/ #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in #include \u0026lt;sys/types.h\u0026gt; // socket #include \u0026lt;sys/socket.h\u0026gt; // socket #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/select.h\u0026gt; // select #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; #define BUFFER_SIZE 1024 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd int max_fd; // 最大的fd fd_set master_set; // 所有fd集合，包括监听fd和客户端fd fd_set working_set; // 工作集合 struct timeval timeout; public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(int nums); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; // 允许重用本地地址和端口 setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { for (int fd = 0; fd \u0026lt;= max_fd; ++fd) { if (FD_ISSET(fd, \u0026amp;master_set)) { close(fd); } } } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 将新建立的连接的fd加入master_set FD_SET(new_fd, \u0026amp;master_set); if (new_fd \u0026gt; max_fd) { max_fd = new_fd; } } void Server::Run() { max_fd = listen_fd; // 初始化max_fd FD_ZERO(\u0026amp;master_set); FD_SET(listen_fd, \u0026amp;master_set); // 添加监听fd while (1) { FD_ZERO(\u0026amp;working_set); memcpy(\u0026amp;working_set, \u0026amp;master_set, sizeof(master_set)); timeout.tv_sec = 30; timeout.tv_usec = 0; int nums = select(max_fd + 1, \u0026amp;working_set, NULL, NULL, \u0026amp;timeout); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;select() error!\u0026#34;; exit(1); } if (nums == 0) { //cout \u0026lt;\u0026lt; \u0026#34;select() is timeout!\u0026#34;; continue; } if (FD_ISSET(listen_fd, \u0026amp;working_set)) Accept(); // 有新的客户端请求 else Recv(nums); // 接收客户端的消息 } } void Server::Recv(int nums) { for (int fd = 0; fd \u0026lt;= max_fd; ++fd) { if (FD_ISSET(fd, \u0026amp;working_set)) { bool close_conn = false; // 标记当前连接是否断开了 PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度 // std::cout \u0026lt;\u0026lt; head.length \u0026lt;\u0026lt; std::endl; char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端 { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它 { close(fd); FD_CLR(fd, \u0026amp;master_set); if (fd == max_fd) // 需要更新max_fd; { while (FD_ISSET(max_fd, \u0026amp;master_set) == false) --max_fd; } } } } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; } 客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 /************************************************************************* \u0026gt; File Name: client.cpp \u0026gt; Author: SongLee \u0026gt; E-mail: lisong.shine@qq.com \u0026gt; Created Time: 2016年04月28日 星期四 23时10分15秒 \u0026gt; Personal Blog: http://songlee24.github.io/ ************************************************************************/ #include\u0026lt;netinet/in.h\u0026gt; // sockaddr_in #include\u0026lt;sys/types.h\u0026gt; // socket #include\u0026lt;sys/socket.h\u0026gt; // socket #include\u0026lt;arpa/inet.h\u0026gt; #include\u0026lt;sys/ioctl.h\u0026gt; #include\u0026lt;unistd.h\u0026gt; #include\u0026lt;iostream\u0026gt; #include\u0026lt;string\u0026gt; #include\u0026lt;cstdlib\u0026gt; #include\u0026lt;cstdio\u0026gt; #include\u0026lt;cstring\u0026gt; using namespace std; #define BUFFER_SIZE 1024 struct PACKET_HEAD { int length; }; class Client { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int fd; public: Client(string ip, int port); ~Client(); void Connect(); void Send(string str); string Recv(); }; Client::Client(string ip, int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; if(inet_pton(AF_INET, ip.c_str(), \u0026amp;server_addr.sin_addr) == 0) { cout \u0026lt;\u0026lt; \u0026#34;Server IP Address Error!\u0026#34;; exit(1); } server_addr.sin_port = htons(port); server_addr_len = sizeof(server_addr); // create socket fd = socket(AF_INET, SOCK_STREAM, 0); if(fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } } Client::~Client() { close(fd); } void Client::Connect() { cout \u0026lt;\u0026lt; \u0026#34;Connecting......\u0026#34; \u0026lt;\u0026lt; endl; if(connect(fd, (struct sockaddr*)\u0026amp;server_addr, server_addr_len) \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Can not Connect to Server IP!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Connect to Server successfully.\u0026#34; \u0026lt;\u0026lt; endl; } void Client::Send(string str) { PACKET_HEAD head; head.length = str.size()+1; // 注意这里需要+1 int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, str.c_str(), head.length, 0); if(ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Send Message Failed!\u0026#34;; exit(1); } } string Client::Recv() { PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); char* buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while(total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if(len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; break; } total = total + len; } string result(buffer); delete buffer; return result; } int main() { Client client(\u0026#34;127.0.0.1\u0026#34;, 15000); client.Connect(); while(1) { string msg; getline(cin, msg); if(msg == \u0026#34;exit\u0026#34;) break; client.Send(msg); cout \u0026lt;\u0026lt; client.Recv() \u0026lt;\u0026lt; endl; } return 0; } 说明：\n监听socket也由select来轮询，不需要单独的线程； working_set每次都要重新设置，因为select调用后它所检测的集合working_set会被修改； 接收很长一段数据时，需要循环多次recv。但是recv函数会阻塞，可以通过自定义包头（保存数据长度） Poll poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n相关的函数：\n1 2 #include \u0026lt;poll.h\u0026gt; int poll(struct pollfd fds[], nfds_t nfds, int timeout)； 参数描述：\n该poll()函数返回fds集合中就绪的读、写，或出错的描述符数量，返回0表示超时，返回-1表示出错； fds是一个struct pollfd类型的数组，用于存放需要检测其状态的socket描述符，并且调用poll函数之后fds数组不会被清空； nfds：记录数组fds中描述符的总数量； timeout：调用poll函数阻塞的超时时间，单位毫秒； 其中pollfd结构体定义如下：\n1 2 3 4 5 typedef struct pollfd { int fd; /* 需要被检测或选择的文件描述符*/ short events; /* 对文件描述符fd上感兴趣的事件 */ short revents; /* 文件描述符fd上当前实际发生的事件*/ } pollfd_t; 一个pollfd结构体表示一个被监视的文件描述符，通过传递fds[]指示 poll() 监视多个文件描述符，其中：\n结构体的events域是监视该文件描述符的事件掩码，由用户来设置这个域。 结构体的revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。 events域中请求的任何事件都可能在revents域中返回。合法的事件如下：\n常量 说明 POLLIN 普通或优先级带数据可读 POLLRDNORM 普通数据可读 POLLRDBAND 优先级带数据可读 POLLPRI 高优先级数据可读 POLLOUT 普通数据可写 POLLWRNORM 普通数据可写 POLLWRBAND 优先级带数据可写 POLLERR 发生错误 POLLHUP 发生挂起 POLLNVAL 描述字不是一个打开的文件 当需要监听多个事件时，使用POLLIN | POLLRDNORM设置 events 域；当poll调用之后检测某事件是否就绪时，fds[i].revents \u0026amp; POLLIN进行判断。\nPoll例子 服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in #include \u0026lt;sys/types.h\u0026gt; // socket #include \u0026lt;sys/socket.h\u0026gt; // socket #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;poll.h\u0026gt; // poll #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; #define BUFFER_SIZE 1024 #define MAX_FD 1000 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd struct pollfd fds[MAX_FD]; // fd数组，大小为1000 int nfds; public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { for (int i = 0; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026gt;= 0) { close(fds[i].fd); } } } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 将新建立的连接的fd加入fds[] int i; for (i = 1; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026lt; 0) { fds[i].fd = new_fd; break; } } // 超过最大连接数 if (i == MAX_FD) { cout \u0026lt;\u0026lt; \u0026#34;Too many clients.\\n\u0026#34;; exit(1); } fds[i].events = POLLIN; // 设置新描述符的读事件 nfds = i \u0026gt; nfds ? i : nfds; // 更新连接数 } void Server::Run() { fds[0].fd = listen_fd; // 添加监听描述符 fds[0].events = POLLIN; nfds = 0; for (int i = 1; i \u0026lt; MAX_FD; ++i) fds[i].fd = -1; while (1) { int nums = poll(fds, nfds + 1, -1); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;poll() error!\u0026#34;; exit(1); } if (nums == 0) { continue; } if (fds[0].revents \u0026amp; POLLIN) Accept(); // 有新的客户端请求 else Recv(); } } void Server::Recv() { for (int i = 1; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026lt; 0) continue; if (fds[i].revents \u0026amp; POLLIN) // 读就绪 { int fd = fds[i].fd; bool close_conn = false; // 标记当前连接是否断开了 PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度 char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端 { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它 { close(fd); fds[i].fd = -1; } } } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; } 客户端\n核Select客户端一样\nEpoll epoll可以理解为event poll(基于事件的轮询)。\n使用场合： 当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。\n当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。\n如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。\n如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。\n如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。\nI/O多路复用有很多种实现。在linux上，2.4内核前主要是select和poll，自Linux 2.6内核正式引入epoll以来，epoll已经成为了目前实现高性能网络服务器的必备技术。尽管他们的使用方法不尽相同，但是本质上却没有什么区别。\nEpoll原理 不同于select/poll，Epoll正是保存了那些收到数据的Socket到一个双向链表中，这样一来，就少了一次遍历。epoll = 减少遍历 + 保存就绪Socket\n减少遍历 将控制与阻塞分离。\n保存就绪Socket 维护一个rdlist以及rb_tree，类似于双向链表操作。\n通过 epoll_ctl 添加 Sock1、Sock2 和 Sock3 的监视，内核会将 eventpoll的引用 添加到这三个 Socket 的等待队列中。\nepoll 在 Linux 内核中申请了一个简易的文件系统，用于存储相关的对象，每一个 epoll 对象都有一个独立的 eventpoll 结构体，这个结构体会在内核空间中创造独立的内存，用于存储使用epoll_ctl 方法向 epoll 对象中添加进来的事件。这些事件都会挂到 rbr 红黑树中，这样，重复添加的事件就可以通过红黑树而高效地识别出来。\nepoll底层实现最重要的两个数据结构:epitem和eventpoll。可以简单的认为epitem是和每个用户态监控IO的fd对应的,eventpoll是用户态创建的管理所有被监控fd的结构，详细的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 struct epitem { struct rb_node rbn; struct list_head rdllink; struct epitem *next; struct epoll_filefd ffd; int nwait; struct list_head pwqlist; struct eventpoll *ep; struct list_head fllink; struct epoll_event event; }; struct eventpoll { spin_lock_t lock; struct mutex mtx; wait_queue_head_t wq; wait_queue_head_t poll_wait; struct list_head rdllist; //就绪链表 struct rb_root rbr; //红黑树根节点 struct epitem *ovflist; }; epoll过程\n调用epoll_create，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll对象也是文件系统中的一员，和socket一样，它也会有等待队列。\n通过 epoll_ctl 添加 Sock1、Sock2 和 Sock3 的监视，内核会将 eventpoll的引用 添加到这三个 Socket 的等待队列中。\n当Socket收到数据之后，中断程序会执行将Socket的引用添加到eventpoll对象的rdlist就绪列表中。\n假设计算机中正在运行进程 A 和进程 B、C，在某时刻进程 A 运行到了 epoll_wait 语句，会将进程A添加到eventpoll的等待队列中。\n当 Socket 接收到数据，中断程序一方面修改 Rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态。因为Soket包含eventpoll对象的引用，因此可以直接操作eventpoll对象.\nepoll API\nepoll的api定义:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 //用户数据载体 typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; //fd装载入内核的载体 struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //三板斧api int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout); poll_create是在内核区创建一个epoll相关的一些列结构，并且将一个句柄fd返回给用户态，后续的操作都是基于此fd的，参数size是告诉内核这个结构的元素的大小，类似于stl的vector动态数组，如果size不合适会涉及复制扩容，不过貌似4.1.2内核之后size已经没有太大用途了； epoll_ctl是将fd添加/删除于epoll_create返回的epfd中，其中epoll_event是用户态和内核态交互的结构，定义了用户态关心的事件类型和触发时数据的载体epoll_data； epoll_wait*是阻塞等待内核返回的可读写事件，epfd还是epoll_create的返回值，events是个结构体数组指针存储epoll_event，也就是将内核返回的待处理epoll_event结构都存储下来，maxevents告诉内核本次返回的最大fd数量，这个和events指向的数组是相关的； epoll_wait是用户态需监控fd的代言人，后续用户程序对fd的操作都是基于此结构的； epoll例子 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in #include \u0026lt;sys/types.h\u0026gt; // socket #include \u0026lt;sys/socket.h\u0026gt; // socket #include \u0026lt;arpa/inet.h\u0026gt; #include \u0026lt;unistd.h\u0026gt; #include \u0026lt;sys/epoll.h\u0026gt; // epoll #include \u0026lt;sys/ioctl.h\u0026gt; #include \u0026lt;sys/time.h\u0026gt; #include \u0026lt;iostream\u0026gt; #include \u0026lt;vector\u0026gt; #include \u0026lt;string\u0026gt; #include \u0026lt;cstdlib\u0026gt; #include \u0026lt;cstdio\u0026gt; #include \u0026lt;cstring\u0026gt; using namespace std; #define BUFFER_SIZE 1024 #define EPOLLSIZE 100 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd int epfd; // epoll fd struct epoll_event events[EPOLLSIZE]; // epoll_wait返回的就绪事件 public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(int fd); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { close(epfd); } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 在epfd中注册新建立的连接 struct epoll_event event; event.data.fd = new_fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_ADD, new_fd, \u0026amp;event); } void Server::Run() { epfd = epoll_create(1); // 创建epoll句柄 struct epoll_event event; event.data.fd = listen_fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd, \u0026amp;event); // 注册listen_fd while (1) { int nums = epoll_wait(epfd, events, EPOLLSIZE, -1); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;poll() error!\u0026#34;; exit(1); } if (nums == 0) { continue; } for (int i = 0; i \u0026lt; nums; ++i) // 遍历所有就绪事件 { int fd = events[i].data.fd; if ((fd == listen_fd) \u0026amp;\u0026amp; (events[i].events \u0026amp; EPOLLIN)) Accept(); // 有新的客户端请求 else if (events[i].events \u0026amp; EPOLLIN) Recv(fd); // 读数据 else ; } } } void Server::Recv(int fd) { bool close_conn = false; // 标记当前连接是否断开了 PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度 char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端 { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它 { close(fd); struct epoll_event event; event.data.fd = fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_DEL, fd, \u0026amp;event); // Delete一个fd } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; } 总结：\n每次调用poll/select系统调用，操作系统都要把current（当前进程）挂到fd对应的所有设备的等待队列上，可以想象，fd多到上千的时候，这样“挂”法很费事；而每次调用epoll_wait则没有这么罗嗦，epoll只在epoll_ctl时把current挂一遍（这第一遍是免不了的）并给每个fd一个命令“好了就调回调函数”，如果设备有事件了，通过回调函数，会把fd放入rdllist，而每次调用epoll_wait就只是收集rdllist里的fd就可以了——epoll巧妙的利用回调函数，实现了更高效的事件驱动模型。\nepoll工作模式 LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。\nET模式 ET (edge-triggered) 是高速工作方式，只支持no-block socket(非阻塞)。 在这种模式下，当描述符从未就绪变为就绪时，内核就通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的 就绪通知，直到你做了某些操作而导致那个文件描述符不再是就绪状态(比如 你在发送，接收或是接受请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误)。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核就不会发送更多的通知(only once)。不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。\n参考：\nIO多路复用之select总结 IO多路复用之poll总结 IO多路复用之epoll总结 Linux IO模式及 select、poll、epoll详解 select详解 Linux下的I/O复用与epoll详解 聊聊同步、异步、阻塞与非阻塞 聊聊Linux 五种IO模型 聊聊IO多路复用之select、poll、epoll详解 Linux IO模式及 select、poll、epoll详解 彻底学会使用epoll(一)——ET模式实现分析 epoll 或者 kqueue 的原理是什么？ epoll事件处理机制详解 如果这篇文章说不清epoll的本质，那就过来掐死我吧 select、poll、epoll整理总结 ","description":"本文详细介绍了多路复用中的三种模型，它们是迭代更新的结果。现在常用的会是Epoll。","id":55,"section":"posts","tags":["Epoll","Select","Poll"],"title":"Select Poll Epoll 详解","uri":"https://hugo.jiahongw.com/posts/linux/select-poll-epoll/"},{"content":"虚拟存储器作为现代操作系统中存储器管理的一项重要技术，实现了内存扩充功能。**但该功能并非是从物理上实际地扩大内存的容量，而是从逻辑上实现对内存容量的扩充，让用户所感觉到的内存容量比实际内存容量大得多。**于是便可以让比内存空间更大的程序运行，或者让更多的用户程序并发运行。这样既满足了用户的需要，又改善了系统的性能。\n虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。\n我们可以将虚拟内存看作是在磁盘上一片空间，当这片空间中的一部分访问比较频繁时，该部分数据会以页为单位被缓存到主存中以加速 CPU 访问数据的性\n能，虚拟内存利用空间较大的磁盘存储作为『内存』并使用主存储缓存进行加速，让上层认为操作系统的内存很大而且很快，然而区域很大的磁盘并不快，而很快的内存也并不大。\nLinux为什么需要虚拟内存:\n为应用程序提供看起来容量足够大且访问足够快的存储。 通过共享代码库以减少物理内存的开销。让改动尽可能的少。 通过分配连续的虚拟内存（物理内存上不一定连续） 简化内存的连接、分配过程。 通过给各个进程分配不同的虚拟内存空间实现内存访问上的隔离，提供了一定的安全性。 拓展：\n​\t当我们在 Linux 中调用 fork 创建子进程时，实际上只复制了父进程的页表。\n问题❓ 当有一个作业很大，超过了内存的总容量，作业不能全部装入内存怎么办？ 有大量作业需要运行，但是由于内存容量不足以容纳这些所有的作业怎么办？(先执行一部分) 解决办法：\n增加物理内存容量 逻辑上扩充内存容量(虚拟内存方法) 局部性原理🥇 程序在执行时将呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分，相应地，它所访问的存储空间也局限于某个区域。\n时间局部性：访问最近访问过的空间的可能性较大。 空间局部性：访问当前空间周围的空间的可能较大。 局部性原理使得虚拟存储技术的实现成为可能。\n基于局部性原理可知，应用程序在运行之前没有必要将之全部装入内存，而仅须将那些当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它所要访问的页(段)已调入内存，便可继续执行下去；但如果程序所要访问的页(段)尚未调入内存(称为缺页或缺段)，便发出缺页(段)中断请求，此时 OS 将利用请求调页(段)功能将它们调入内存，以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)，OS 还须再利用页(段)的置换功能，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的页(段)调入内存，使程序继续执行下去。这样，便可使一个大的用户程序在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。\n虚拟存储器📝 定义 **所谓虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。**其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。\n当用户看到自己的程序能在系统中正常运行时，他会认为，该系统所具有的内存容量一定比自己的程序大，或者说，用户所感觉到的内存容量会比实际内存容量大得多。但用户所看到的大容量只是一种错觉，是虚的，故人们把这样的存储器称为虚拟存储器。\n虚拟存储器并非可以无限大，其容量受外存大小和指令中地址长度两方面的限制。\n特征 多次性 对换性 虚拟性 实现方法 所有的虚拟存储器都是采用下述方式之一实现的：\n请求分页系统 请求分段系统 请求分页存储管理方式 请求分页系统是建立在基本分页基础上的，为了能支持虚拟存储器功能，而增加了请求调页功能和页面置换功能。相应地，每次调入和换出的基本单位都是长度固定的页面，这使得请求分页系统在实现上要比请求分段系统简单(后者在换进和换出时是可变长度的段)。因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式。\n请求页表机制(基本原理) 在请求分页系统中需要的主要数据结构是请求页表，其基本作用仍然是将用户地址空间中的逻辑地址映射为内存空间中的物理地址。为了满足页面换进换出的需要，在请求页表中又增加了四个字段。这样，在请求分页系统中的每个页表应含以下诸项(配合clock置换算法)：\n字段说明：\n状态位(P)：用于指示该页是否已调入内存，供程序访问时参考。 访问字段(A)：记录本页在一段时间内被访问的次数，或者记录本页最近已有多久时间未被访问，供置换算法在选择换出页面时参考。 修改位(M)：表示该页在调入内存之后有没有被修改。供置换页面时参考。未修改则无需写入外存。 外存地址：用于指出该页在外存上的地址，通常是物理块号地址，供调入该页时参考。 缺页中断机构 在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求 OS将缺的页调入内存。\n**缺页中断作为中断，它们同样需要经历诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序进行处理，以及在中断处理完成后再恢复 CPU 环境等几个步骤。**但缺页中断又是一种特殊的中断，它与一般的中断相比有着明显的区别，主要表现在下面两个方面：\n在指令执行期间产生和处理中断信号。 一条指令在执行期间可能产生多次缺页中断。 地址变换机构 请求分页系统中的地址变换机构是在分页系统地址变换机构的基础上，为实现虚拟存储器，再增加了某些功能所形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等等。下图示出了请求分页系统中的地址变换过程：\n在进行地址变换时，首先检索快表，试图从中找出所要访问的页。若找到，便修改页表项中的访问位，供置换算法选换出页面时参考。对于写指令，还须将修改位置成“1”,表示该页在调入内存后已被修改。然后利用页表项中给出的物理块号和页内地址形成物理地址。地址变换过程到此结束。\n如果在快表中未找到该页的页表项，则应到内存中去查找页表，再从找到的页表项中的状态位 P 来了解该页是否已调入内存。若该页已调入内存，这时应将该页的页表项写入快表。当快表已满时，则应先调出按某种算法所确定的页的页表项，然后再写入该页的页表项；若该页尚未调入内存，这时应产生缺页中断，请求 OS 从外存把该页调入内存。\n请求分页的内存分配 三个问题：\n最小物理块数的确定。先分配给进程多少物理空间它才能先正常运行。\n内存分配策略。\n固定分配局部置换\n所谓固定分配，是指为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。所谓局部置换，是指如果进程在运行中发现缺页，则只能从分配给该进程的 n 个页而中选出一页换出，然后再调入一页，以保证分配给该进程的内存空间不变。\n可变分配全局置换\n所谓可变分配，是指先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。所谓全局置换，是指如果进程在运行中发现缺页，则将 OS 所保留的空闲物理块(一般组织为一个空闲物理块队列)取出一块分配给该进程，或者以所有进程的全部物理块为标的，选择一块换出，然后将所缺之页调入。这样，分配给该进程的内存空间就随之增加。\n可变分配局部置换\n该策略同样是基于进程的类型或根据程序员的要求，为每个进程分配一定数目的物理块，但当某进程发现缺页时，只允许从该进程在内存的页面中选择一页换出，这样就不会影响其它进程的运行。如果进程在运行中频繁地发生缺页中断，则系统须再为该进程分配若干附加的物理块，直至该进程的缺页率减少到适当程度为止。反之，若一个进程在运行过程中的缺页率特别低，则此时可适当减少分配给该进程的物理块数，但不应引起其缺页率的明显增加。\n物理块分配算法\n平均分配算法 比例分配算法 考虑优先权的分配算法 页面调入策略 问题：\n何时调入页面\n预调页策略，一次调入若干个相邻的页面。 请求调页机制，当请求的页面不存在内存，由OS将所需页面调入内存。 何处调入页面\n将请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页而的对换区。通常，由于对换区是采用连续分配方式，而文件区是采用离散分配方式，所以对换区的数据存取(磁盘 I/O)速度比文件区的高。\n系统拥有足够的对换区空间，这时可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，便须将与该进程有关的文件从文件区拷贝到对换区。 系统缺少足够的对换区空间，这时凡是不会被修改的文件，都直接从文件区调入；而当换出这些页面时，由于它们未被修改，则不必再将它们重写到磁盘(换出)，以后再调入时，仍从文件区直接调入。但对于那些可能被修改的部分，在将它们换出时便须调到对换区，以后需要时再从对换区调入。 UNIX 方式。由于与进程有关的文件都放在文件区，故凡是未运行过的页面，都应从文件区调入。而对于曾经运行过但又被换出的页面，由于是被放在对换区，因此在下次调入时应从对换区调入。由于 UNIX 系统允许页面共享，因此，某进程所请求的页面有可能已被其它进程调入内存，此时也就无需再从对换区调入。 页面调入过程\n每当程序所要访问的页面未在内存时(存在位为“0”)，便向 CPU 发出一缺页中断，中断处理程序首先保留 CPU 环境，分析中断原因后转入缺页中断处理程序。该程序通过杳找页表得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘 I/O，将所缺之页调入内存，然后修改页表。如果内存已满，则须先按照某种置换算法，从内存中选出一页准备换出；如果该页未被修改过(修改位为“0”)，可不必将该页写回磁盘；但如果此页已被修改(修改位为“1”)，则必须将它写回磁盘，然后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项写入快表中。在缺页调入内存后，利用修改后的页表形成所要访问数据的物理地址，再去访问内存数据。整个页面的调入过程对用户是透明的。\n页面置换算法 不适当的算法可能会导致进程发生“抖动”(Thrashing)，即刚被换出的页很快又要被访问，需要将它重新调入，此时又需要再选一页调出；而此刚被调出的页很快又被访问,又需将它调入，如此频繁地更换页面，以致一个进程在运行中把大部分时间都花费在页面置换工作上，我们称该进程发生了“抖动”。\n假定系统为某进程分配了三个物理块，并考虑有以下的页面号引用串：\n7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1 最佳置换算法 是一种理想化的算法，具有最好的性能，但是实际上是实现不了的，但是可以作为评估其他算法的优劣。采用这种算法可以获取最低的缺页率。\n先进先出置换算法 该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。用链表就能够很容易的实现。\n最近最久未使用置换算法(LRU) FIFO 置换算法的性能之所以较差，是因为它所依据的条件是各个页面调入内存的时间，而页面调入的先后并不能反映页面的使用情况。最近最久未使用(LRU)的页面置换算法是根据页面调入内存后的使用情况做出决策的。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU 置换算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页而自上次被访问以来所经历的时间 t。当需淘汰一个页面时，选择现有页面中其 t 值最大的，即最近最久未使用的页面予以淘汰。\n算法实现(硬件支持)：\n寄存器\n为了记录某进程在内存中各页的使用情况，须为每个在内存中的页面配置一个移位寄存器，可表示为：\n$$\nR = R_{n-1}R_{n-2}R_{n-3} … R_2R_1R_0\n$$\n当进程访问某物理块时，要将相应寄存器的 $R_{n-1}$位置成 1。此时，定时信号将每隔一定时间(例如 100 ms)将寄存器右移一位。如果我们把 n 位寄存器的数看作是一个整数，那么，具有最小数值的寄存器所对应的页面，就是最近最久未使用的页面。下图中第三个内存页面的R值最小，缺页时因该被换出：\n特殊的栈\n可利用一个特殊的栈保存当前使用的各个页面的页面号。每当进程访问某页而时，便将该页面的页面号从栈中移出，将它压入栈顶。因此，栈顶始终是最新被访问页面的编号,而栈底则是最近最久未使用页面的页面号。\nmap + 双向链表实现LRU算法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 struct MyNode { int k, v; MyNode(int tk = 0, int tv = 0) { k = tk; v = tv; } }; // @lc code=start class LRUCache { private: map\u0026lt;int, int\u0026gt; hashtable; list\u0026lt;MyNode *\u0026gt; cache; unsigned int capacity; public: LRUCache(int capacity) { this-\u0026gt;capacity = capacity; } int get(int key) { if (hashtable.find(key) != hashtable.end()) { MyNode *node = new MyNode(key, hashtable[key]); for (list\u0026lt;MyNode *\u0026gt;::iterator it = cache.begin(); it != cache.end(); it++) { if ((*it)-\u0026gt;k == key) { cache.erase(it); break; } } cache.push_front(node); return hashtable[key]; } return -1; } void put(int key, int value) { MyNode *node = new MyNode(key, value); if (hashtable.find(key) == hashtable.end()) { // 不存在这个Key if (hashtable.size() \u0026gt;= capacity) { // 超过容量，移除队尾元素 MyNode *rnode = cache.back(); cache.pop_back(); hashtable.erase(rnode-\u0026gt;k); } hashtable[key] = value; cache.push_front(node); } else { // 存在这个key // 移除 for (list\u0026lt;MyNode *\u0026gt;::iterator it = cache.begin(); it != cache.end(); it++) { if ((*it)-\u0026gt;k == key) { cache.erase(it); break; } } cache.push_front(node); hashtable[key] = value; } } }; 最少使用置换算法(LFU) LFU（Least Frequently Used）最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。\n注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。举个简单的例子：\n为了能够淘汰最少使用的数据，因此LFU算法最简单的一种设计思路就是 利用一个数组存储 数据项，用hashmap存储每个数据项在数组中对应的位置，然后为每个数据项设计一个访问频次，当数据项被命中时，访问频次自增，在淘汰的时候淘汰访问频次最少的数据。这样一来的话，在插入数据和访问数据的时候都能达到O(1)的时间复杂度，在淘汰数据的时候，通过选择算法得到应该淘汰的数据项在数组中的索引，并将该索引位置的内容替换为新来的数据内容即可，这样的话，淘汰数据的操作时间复杂度为O(n)。\nClock置换算法 简单Clock置换算法 每页设置一个访问位，取值为0和1，当该页被访问时，访问位置为1。\n当利用简单 Clock 算法时，只需为每页设置一位访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位被置 1。置换算法在选择一页淘汰时，只需检查页的访问位。如果是 O，就选择该页换出；若为 1，则重新将它置 O，暂不换出，给予该页第二次驻留内存的机会，再按照 FIFO 算法检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为 1，则再返回到队首去检查第一个页面。\n改进Clock置换算法 设置两个关键位，一个为访问位，一个为修改位。\n页面。由访问位 A 和修改位 M 可以组合成下面四种类型的页面：\n1 类(A=0，M=0)：表示该页最近既未被访问，又未被修改，是最佳淘汰页。\n2 类(A=0，M=1）：表示该页最近未被访问，但已被修改，并不是很好的淘汰页。\n3 类(A=1，M=O)：表示最近已被访问，但未被修改，该页有可能再被访问。\n4 类(A=1，M=1)：表示最近已被访问且被修改，该页可能再被访问。\n面中的哪一种。其执行过程可分成以下三步:\n从指针所指示的当前位置开始，扫描循环队列，寻找 A=0 且 M=0 的第一类页面，将所遇到的第一个页面作为所选中的淘汰页。在第一次扫描期间不改变访问位 A。 如果第一步失败，即查找一轮后未遇到第一类页面，则开始第二轮扫描，寻找且 M=1 的第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0。 如果第二步也失败，亦即未找到第二类页面，则将指针返回到开始的位置，并将所有的访问位复 0。然后重复第一步，即寻找 A=O 且 M=O 的第一类页面，如果仍失败，必要时再重复第二步，寻找 A=0 且 M=1 的第二类页面，此时就一定能找到被淘汰的页。 该算法与简单 Clock 算法比较，可减少磁盘的 I/O 操作次数。但为了找到一个可置换的页，可能须经过几轮扫描。换言之，实现该算法本身的开销将有所增加。\n参考链接：\n为什么 Linux 需要虚拟内存 《操作系统》- 第四版 ","description":"虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。","id":56,"section":"posts","tags":["虚拟内存"],"title":"Linux虚拟内存与分页存储管理","uri":"https://hugo.jiahongw.com/posts/linux/virtual-memory/"},{"content":"从今天开始，准备记录以下自己平时的想法。因为有趣的想法可能一瞬间就消失了。如果没有将这些想法及过程记录下来，后面可能被什么事情给耽搁了，很快就会忘记。这样前面的想法就只能进行到一半，没有后续了。我希望以后能够经常记录自己的想法，因为自己的记忆力其实不太好，这也许是一种方法能够让我坚持下去做某一件事情吧\n并且我还想到的一件事情就是，其实多写关于自己的想法还有一个好处，就是能够拓宽自己的思维。因为我在写东西的时候也喜欢和自己进行对话，这样能够得出很多不一样的idea. 🤠\n","description":"把有趣的东西记录下来，才能记住当下自己在做什么！","id":57,"section":"posts","tags":["life"],"title":"博客小记","uri":"https://hugo.jiahongw.com/posts/ideas/first-thoughts/"},{"content":"哈希表 什么是哈希表？\n哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。\n哈希表hashtable(key，value) 就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。（或者：把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。）\n其中，记录的位置 = H(关键字)，H称为哈希函数。\n哈希构造方法 直接定址法\n例如如果我们现在要对0-100岁的人口数字统计表，那么我们对年龄这个关键字就可以直接用年龄的数字作为地址。此时f(key) = key。\n这个时候，我们可以得出这么个哈希函数：f(0) = 0，f(1) = 1，……，f(20) = 20。这个是根据我们自己设定的直接定址来的。人数我们可以不管，我们关心的是如何通过关键字找到地址。\n除留余数法\n除留余数法此方法为最常用的构造散列函数方法。对于散列表长为m的散列函数公式为：\n$$\nf( key ) = key \\mod p ( p ≤ m )\n$$\nmod是取模（求余数）的意思。事实上，这方法不仅可以对关键字直接取模，也可在折叠、平方取中后再取模。\n数字分析法\n如下图所示，有80个记录，每一行为一个记录中的键，假设表长为100，则可取两位十进制数组成哈希地址。\n折叠法\n将关键字分成位数相同的几部分（最后一位可以不同），然后取叠加和作为哈希地址，这一方法被称为折叠法。当表的键位数很多，而且每一位上数字分布比较均匀的时候， 可以考虑采用这一方法。 折叠法有移位叠加和间位叠加两种方法例如国际标准图书编号0-442-20586-4的哈希地址可以用这两种方法表示为\n平方取中法\n取关键字平方后的中间几位为哈希地址，这种方法叫做平方取中法。它弥补了数字分析法的一些缺陷，因为我们有时并不能知道键的全部情况，取其中几位也不一定合适，而一个数平方后的中间几个数和原数的每一位都相关，由此我们就能得到随机性更强的哈希地址取的位数由表长决定。\n哈希表处理冲突的方法 链地址法\n冲突的关键字存储在一个链表中，查找的时候可能需要遍历链表。例如下面：\n开放地址法\n开放定址法是指可存放新表项的空闲地址，既向它的同义词表项开放，又向它的非同义词表项开放。\n一般有一个递推公式:l\n$$H_i = (H(key) + d_i) % m$$\n式中，i = 1，2，…，k，m为散列表表长，$d_i$为增量序列。$d_i$通常有以下几种取法：\n当$d_i = 1，2，…，m - 1$时，称为**线性探测法。**其特点是，冲突发生时顺序查看表中下一个单元，直到找出一个空单元或查遍全表。 当$d_i = 1^2，-1^2，2^2，-2^2，…，k^2，-k2$时，又称为二次探测法。 当$d_i$ = 伪随机数序列时，称为伪随机探测法。 再散列法\n当发生冲突时，再利用一个新的哈希函数计算得到一个新的地址，直到不发生冲突时进行存放。\n公共溢出区\n所有发生冲突的关键字都存储在这个公共溢出区，当查找不到的时候来这里查找。\n哈希表的优缺点 优点：不论哈希表中有多少数据，查找、插入、删除（有时包括删除）只需要接近常量的时间即0(1）的时间级。实际上，这只需要几条机器指令。\n哈希表运算得非常快，在计算机程序中，如果需要在一秒种内查找上千条记录通常使用哈希表（例如拼写检查器)哈希表的速度明显比树快，树的操作通常需要O(N)的时间级。哈希表不仅速度快，编程实现也相对容易。\n如果不需要有序遍历数据，并且可以提前预测数据量的大小。那么哈希表在速度和易用性方面是无与伦比的。\n缺点：它是基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程）。\n数据结构及图示 线性探测的哈希表数据结构和图片\n1 2 3 4 5 6 7 8 9 10 11 12 typedef char KeyType; typedef struct { KeyType key; }RcdType; typedef struct { RcdType *rcd; int size; int count; bool *tag; }HashTable; 哈希表实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 #include\u0026lt;stdio.h\u0026gt; #include\u0026lt;stdlib.h\u0026gt; #define SUCCESS 1 #define UNSUCCESS 0 #define OVERFLOW -1 #define OK 1 #define ERROR -1 #define MAXNUM 9999\t// 用于初始化哈希表的记录 key typedef int Status; typedef int KeyType; // 哈希表中的记录类型 typedef struct { KeyType key; }RcdType; // 哈希表类型 typedef struct { RcdType *rcd; int size; int count; int *tag; }HashTable; // 哈希表每次重建增长后的大小 int hashsize[] = { 11, 31, 61, 127, 251, 503 }; int index = 0; // 初始哈希表 Status InitHashTable(HashTable \u0026amp;H, int size) { int i; H.rcd = (RcdType *)malloc(sizeof(RcdType)*size); H.tag = (int *)malloc(sizeof(int)*size); if (NULL == H.rcd || NULL == H.tag) return OVERFLOW; KeyType maxNum = MAXNUM; for (i = 0; i \u0026lt; size; i++) { H.tag[i] = 0; H.rcd[i].key = maxNum; } H.size = size; H.count = 0; return OK; } // 哈希函数：除留余数法 int Hash(KeyType key, int m) { return (3 * key) % m; } // 处理哈希冲突：线性探测 void collision(int \u0026amp;p, int m) { p = (p + 1) % m; } // 在哈希表中查询 Status SearchHash(HashTable H, KeyType key, int \u0026amp;p, int \u0026amp;c) { p = Hash(key, H.size); int h = p; c = 0; while ((1 == H.tag[p] \u0026amp;\u0026amp; H.rcd[p].key != key) || -1 == H.tag[p]) { collision(p, H.size); c++; } if (1 == H.tag[p] \u0026amp;\u0026amp; key == H.rcd[p].key) return SUCCESS; else return UNSUCCESS; } //打印哈希表 void printHash(HashTable H) { int i; printf(\u0026#34;key : \u0026#34;); for (i = 0; i \u0026lt; H.size; i++) printf(\u0026#34;%3d \u0026#34;, H.rcd[i].key); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;tag : \u0026#34;); for (i = 0; i \u0026lt; H.size; i++) printf(\u0026#34;%3d \u0026#34;, H.tag[i]); printf(\u0026#34;\\n\\n\u0026#34;); } // 函数声明：插入哈希表 Status InsertHash(HashTable \u0026amp;H, KeyType key); // 重建哈希表 Status recreateHash(HashTable \u0026amp;H) { RcdType *orcd; int *otag, osize, i; orcd = H.rcd; otag = H.tag; osize = H.size; InitHashTable(H, hashsize[index++]); //把所有元素，按照新哈希函数放到新表中 for (i = 0; i \u0026lt; osize; i++) { if (1 == otag[i]) { InsertHash(H, orcd[i].key); } } return OK; } // 插入哈希表 Status InsertHash(HashTable \u0026amp;H, KeyType key) { int p, c; if (UNSUCCESS == SearchHash(H, key, p, c)) { //没有相同key if (c*1.0 / H.size \u0026lt; 0.5) { //冲突次数未达到上线 //插入代码 H.rcd[p].key = key; H.tag[p] = 1; H.count++; return SUCCESS; } else recreateHash(H); //重构哈希表 } return UNSUCCESS; } // 删除哈希表 Status DeleteHash(HashTable \u0026amp;H, KeyType key) { int p, c; if (SUCCESS == SearchHash(H, key, p, c)) { //删除代码 H.tag[p] = -1; H.count--; return SUCCESS; } else return UNSUCCESS; } int main() { printf(\u0026#34;-----哈希表-----\\n\u0026#34;); HashTable H; int i; int size = 11; KeyType array[8] = { 22, 41, 53, 46, 30, 13, 12, 67 }; KeyType key; //初始化哈希表 printf(\u0026#34;初始化哈希表\\n\u0026#34;); if (SUCCESS == InitHashTable(H, hashsize[index++])) printf(\u0026#34;初始化成功\\n\u0026#34;); //插入哈希表 printf(\u0026#34;插入哈希表\\n\u0026#34;); for (i = 0; i \u0026lt;= 7; i++) { key = array[i]; InsertHash(H, key); printHash(H); } //删除哈希表 printf(\u0026#34;删除哈希表中key为12的元素\\n\u0026#34;); int p, c; if (SUCCESS == DeleteHash(H, 12)) { printf(\u0026#34;删除成功，此时哈希表为：\\n\u0026#34;); printHash(H); } //查询哈希表 printf(\u0026#34;查询哈希表中key为67的元素\\n\u0026#34;); if (SUCCESS == SearchHash(H, 67, p, c)) printf(\u0026#34;查询成功\\n\u0026#34;); //再次插入，测试哈希表的重建 printf(\u0026#34;再次插入，测试哈希表的重建：\\n\u0026#34;); KeyType array1[8] = { 27, 47, 57, 47, 37, 17, 93, 67 }; for (i = 0; i \u0026lt;= 7; i++) { key = array1[i]; InsertHash(H, key); printHash(H); } getchar(); return 0; } 参考链接：\n哈希表（散列表）原理详解 【算法】哈希表的诞生 ","description":"哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。。","id":58,"section":"posts","tags":["数据结构","哈希表"],"title":"哈希表","uri":"https://hugo.jiahongw.com/posts/algorithmstructure/hash/"},{"content":"关于程序的装入 绝对装入：绝对映射，程序中逻辑地址与内存物理地址完全相同 （单片机)\n可重定位装入：静态映射，在装入时对逻辑地址进行修改\n动态运行时装入：逻辑地址到物理地址的映射在程序运行时才执行 (现代PC机)\n而动态重定位如下：\n静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。\n关于程序的链接 静态链接方式(Static Linking)\n在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。\n装入时动态链接(Load time Dynamic Linking)\n将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。\n运行时动态链接(Run-time Dynamic Linking）\n对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。\n连续分配方式 单一连续分配 只能用于单用户、单任务的操作系统中。采用这种存储管理方式时，可把内存分为系统区和用户区两部分，系统区仅提供给 OS 使用，通常是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用。\n固定分区连续分配 将内存用户空间划分为若干个固定大小的区域，在每个分区中只装入一道作业，这样，把用户空间划分为几个分区，便允许有几道作业并发运行。当有一空闲分区时，便可以再从外存的后备作业队列中选择一个适当大小的作业装入该分区，当该作业结束时，又可再从后备作业队列中找出另一作业调入该分区。\n划分分区的方法：\n分区大小相等 分区大小不相等 另外可以设置分区大小不等的一些分区，如下：\n固定分区分配的缺点：\n造成存储空间的浪费 拓展性差 动态分区分配 动态分区分配数据结构：\n空闲分区表\n在系统中设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括分区序号、分区始址及分区的大小等数据项。\n空闲分区链\n为了实现对空闲分区的分配和链接，在每个分区的起始部分，设置一些用于控制分区分配的信息，以及用于链接各分区所用的前向指针；在分区尾部则设置一后向指针，通过前、后向链接指针，可将所有的空闲分区链接成一个双向链，如下图所示：\n内存分配分配算法 基于顺序搜索：(适合不太大的系统) 首次适应算法(FF)\n在分配内存时，从链首开始顺序查找，直到找到一个大小能满足的空闲分区即可。然后再再按照作业的大小，从空间分区中划分出与作业大小相同的空间给作业使用，余下的空间留在空闲分区链中。\n首次适应算法要求空闲分区链以地址递增的次序链接。\n缺点：空闲分区链的低地址部分不断被划分，会有许多细小的碎片空间难以利用。每次都是从低地址开始找空闲分区，查找的效率低。\n循环首次适应算法(NF)\n循环首次适应算法在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直到找到一个能够满足进程的空闲分区为止，最后从空闲分区划分出与请求大小相等的空间给作业。\n循环到链表末尾又从新从链首开始查找。\n缺点：缺少可用的大空间空闲分区。\n最佳适应算法(BF)\n最佳适应算法在分配内存的时候，把满足要求并且又是最小的空闲分区给作业。为了加速寻找，该算法需要对空闲分区链按照空闲分区大小进行从小到大排序。\n缺点：会产生许多细小的碎片\n最差适应算法(WF)\n最差适应算法每次分配内存的时候，把满足要求的最大的空闲分区给作业，将与作业申请大小的空间划分出来，剩余的空间留在空闲分区中，并且更新空闲分区链。该算法需要对空闲分区链按照空闲分区大小进行从大到小排序。\n优点：查找效率块，产生碎片少。\n缺点：缺少大的空闲分区\n例子：\n假设有新程序F装入，大小为32K，当前已有程序B和D，最近一次空间分配是D：\n基于索引搜索：(适合比较大的系统) 快速适应算法(QF)\n该算法又叫做分类搜索法，是将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设置一个空闲分区链，这样系统存在多个空闲分区链。同时，还需要在内存中设立一张管理索引表，其中的每一个索引表项对应了一种空闲分区类型，并记录了该类型空闲分区链表表头指针。\n空闲分区的分类是根据进程常用的空闲大小进行划分的，如2KB、4KB、8KB等，对于其他大小的空闲分区像7KB的空闲分区，既可以放在8KB的链表中，也可以放在一个特殊的空闲链表中。\n伙伴系统\n该算法规定，无论是分配分区还是空闲分区，其大小均为2的k次幂(k为整数且1\u0026lt;=k\u0026lt;=m)。通常$2^m$是整个可分配内存的大小。\n哈希算法\n哈希算法是利用哈希快速查找的优点，以及空闲分区在可利用空闲分区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。\n动态重定位分区分配 紧凑\n对内存中正在使用的分区进行搬迁，使多个小的空闲分区（碎片）合并为一个大的空闲分区\n动态重定位\n算法：\n什么是内存碎片？\n内部碎片是指已经分配给作业但不能被利用的内存空间，外部碎片是指系统中还没有分配给作业，但由于碎片太小而无法分配给申请内存空间的新进程的存储块。通俗点的理解就是，某个作业所占用的内存区域如果没有装满，就是内部碎片，而作业与作业之间，如果有内存区域没有分配给某个作业，但又不能分配给任何作业，就是外部碎片。\n连续分配: 为用户进程分配的必须是一个连续的内存空间。\n非连续分配: 为用户进程分配的可以是一些分散的内存空间。\n非连续分配方式(离散分配方式) 思想\n假设进程A大小为23MB,但是每个分区大小只有10MB,如果进程只能占用一个分区,那显然放不下。\n解决思路:\n如果允许进程占用多个分区,那么可以把进程拆分成10MB+10MB+3MB三个部外,再把这三个部分分别放到三个分区中(这些分区不要求连续)\u0026hellip;\n进程A的最后一个部分是3MB,放入分区后会产生7MB的内部碎片，如果每个分区大小为2MB,那么进程A可以拆分成11*2MB +1MB共12个部分,只有最后一部分1MB占不满分区,共产生1MB的内部碎片.\n显然,如果把外区大小设置的更小一些,内部碎片会更小,内学利用率会更高.\n具有快表的地址变换机构：（时间局部性与空间局部性原理）\n快表,又称联想寄存器(TLB) ,是一种访问速度比内存快很多的高速缓冲存储器,用来存放当\u0026quot;前访间的若干页表项,以加速地址变换的过程。与此对应,内存中的页表常称为慢表。\n多级页表\n问题\n加载一个大的页表需要占用很大的内存\n解决\n将大表分为几个小表。类似CIDR。\n可将长长的页表进行分组,使每个内存块刚好可以放入一个分组(比如上个侧子中,页面大小4KB,每个页表项48,每个页面可存放1K个页表项,因此每1K个连续的页表项为一组,每组刚好占一个内存块,再讲各组离散地放到各个内存块中)另外,要为离散分配的页表再建立一张页表,称为页目录表,或称外层页表,或称顶层页表\n存储管理方式 本质上是一种内存的划分方法\n分页存储管理 这种方式中，将用户程序的地址空间，注意，是用户程序的地址空间分为若干个固定大小的区域，成为“页”或“页面”。我们可以知道，这也页其实是不存在的，只是一种划分内存空间的方法。也就是说，这种方式将用户的程序**“肢解”**了，分成很多个小的部分，每个部分称为一个“页”。\n逻辑地址 将逻辑地址的前n位作为页号，后面32-n位作为页内偏移量。\n页内碎片 由于进程的最后一页经常装不满一个块，从而形成了不可利用的碎片，称之为**“页内碎片”**。\n页表 作用：实现页号到物理号的地址映射。\n页表是记录逻辑空间（虚拟内存）中每一页在内存中对应的物理块号。但并非每一页逻辑空间都会实际对应着一个物理块，只有实际驻留在物理内存空间中的页才会对应着物理块。\n系统会为每一个进程建立一张页表，页表是需要一直驻留在物理内存中的（多级页表除外），另外页表的起址和长度存放在 PCB（Process Control Block）进程控制结构体中。\n可以在页表的表项中设置相关的权限控制字段，例如设置存取控制字段，用于保护该存储块的读写；若存取控制字段为2位，则可以设置读/写、只读和只执行等存取方式。\n物理块 物理块是实实在在存在于内存中的：\n地址变换机构 由于执行频率高，要求效率比较高，需要使用硬件实现。\n在系统中设置一个页表寄存器(PTR),其中存放页表在内存的起始地址和页表的长度。平时进程未执行的时候，页表的起始地址和页表长度放在本进程的PCB中。当调度程序调度到某个进程的时候，才将这两个数据装入页表寄存器。\n注意，当创建一个进程的时候，它的页表也同时创建了，只不过只在PCB存储了页表的起始地址和长度。\n变换过程：\n进程访问某个逻辑地址时，分页地址机构自动将逻辑地址分为页号和页内地址 页号大于页表长度，越界错误;否则继续下面的步骤 页表项的地址 p = 页表起始地址 F + 页号 P * 表项大小 S，从而得到对应的物理块号 B 页和物理块的大小是一致的，所以 页内地址=块内地址 然后 物理地址 = 物理块号 B * 页大小 L + 页内地址 根据物理地址读取数据 快表的变换机构\n基础的地址变换机构的缺点：\n由于页表是存放在内存中的，这使得CPU在每存取一个数据时，都需要两次访问内存。第一次时访问内存中的页表，获取物理块号，于偏移值拼接得到物理地址，第二次是从第一次所得物理地址获取所需数据(或者向该地址写入数据)。这样计算机的处理速度几乎降低了1/2；\n为了提高地址变换速度，可在地址变换机构中增设一个具有并行查询能力的特殊高速缓冲寄存器，又称为\u0026quot;联想寄存器\u0026quot;或者“快表”。俗称TLB。\n快表与页表的功能类似，其实就是将一部分页表存到 CPU 内部的高速缓冲存储器 Cache。CPU 寻址时先到快表查询相应的页表项形成物理地址，如果查询不到，则到内存中查询，并将对应页表项调入到快表中。但，如果快表的存储空间已满，则需要通过算法找到一个暂时不再需要的页表项，将它换出内存。\n由于成本的关系，快表不可能做得很大，通常只存放 16~512 个页表项，这对中、小型作业来说，已有可能把全部页表项放在快表中；但对于大型作业而言，则只能将其一部分页表项放入其中。由于对程序和数据的访问往往带有局限性，因此，据统计，从快表中能找到所需页表项的概率可达 90% 以上。这样，由于增加了地址变换机构而造成的速度损失可减少到 10% 以下，达到了可接受的程度。\n两级页表 一级页表的缺陷：由于页表必须连续存放，并且需要常驻物理内存，当逻辑地址空间很大时，导致页表占用内存空间很大。\n我们可以采用这样两个方法来解决这一问题：\n① 对于页表所需的内存空间，可采用离散分配方式，以解决难以找到一块连续的大内存空间的问题；\n② 只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。\n二级页表的页表项：\n过程：\n外层页表寄存器中保存了外层页表的始址，根据外层页号查找到内层页号。 找到指定页表分页的始址，根据内层页号找到物理块号。 物理块号P和页内地址d组装成一个实际的物理地址。 在采用两级页表结构的情况下，对于正在运行的进程，必须将其外层页表调入内存，而对于内页表则只需调入一页或几页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位 S，其值若为 0，表示该页表分页不在内存中，否则说明其分页已调入内存。进程运行时，地址变换机构根据逻辑地址中的 P1去查找外层页表；若所找到的页表项中的状态位为 0，则产生一个中断信号，请求 OS 将该页表分页调入内存。\n多级页表 多级页表和二级页表类似。多级页表和二级页表是为了节省物理内存空间。使得页表可以在内存中离散存储。（单级页表为了随机访问必须连续存储，如果虚拟内存空间很大，就需要很多页表项，就需要很大的连续内存空间，但是多级页表不需要。）\n分页式管理很好的避免了外部碎片，但是还是存在内部碎片，因为程序大小不可能总是2的n次幂。多级页表使得页表数据可以不需要连续存储，即实现了页表的离散式存储。并且在当对应程序运行才将内页表数据调入内存也减少了页表所占用的内存空间。本质上是提高内存利用率。\n分段存储管理 为了满足用户要求的一种存储管理的方式\n为什么引入分段存储管理？\n通常的程序都可以分为若干个段，如主程序段、子程序段A、子程序段B、\u0026hellip;、数据段和栈段等等。 实现和满足信息共享、信息保护、动态链接以及信息的动态增长 引入效果：\n方便编程\n使用符号作为段地址进行使用。(每个段都是从 0 开始的独立逻辑地址空间；)\n信息共享\n在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，为了共享某个过程、函数或文件。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的逻辑意义，这样，一个可被共享的过程往往可能需要占用数十个页面，这为实现共享增加了困难。段可以是信息的逻辑单位，因此，我们可以为该被共享过程建立一个独立的段，这就极大地简化了共享的实现。\n信息保护\n信息保护同样是以信息的逻辑单位为基础的，而且经常是以一个过程、函数或文件为基本单位进行保护的。例如，我们希望函数 A 仅允许进程执行，而不允许读，更不允许写，那么，我们只须在包含了函数 A 的这个段上标上只执行标志即可。但是在分页系统中，函数 A 可能要占用若干个页面，而且其中的第一个和最后一个页面还会装有其它程序段的数据，它们可能有着不同的保护属性，如可以允许进程读写，这样就很难对这些页面实施统一的保护，因此，分段管理方式能更有效和方便地实现对信息的保护功能。\n动态增长\n在实际应用中，往往存在着一些段，尤其是数据段，在它们的使用过程中，由于数据量的不断增加，而使数据段动态增长，相应地它所需要的存储空间也会动态增加。然而，对于数据段究竟会增长到多大，事先又很难确切地知道。对此，很难采取预先多分配的方法进行解决。前述的其它几种存储管理方式都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。\n动态链接\n动态链接在作业运行之前，并不是把所有的目标程序段都链接起来。当程序要运行时，首先将主程序和它立即需要用到的目标程序装入内存，即启动运行。而在程序运行过程中，当需要调用某个目标程序时，才将该段(目标程序)调入内存并进行链接。可见，动态链接要求的是以目标程序(即段)作为链接的基本单位,因此，分段存储管理方式非常适合于动态链接。\n它将用户程序的地址空间分为若干个大小不同的的段，每个段可以定义一组完整的信息。\n分段地址 段号表示段名，每个段都从0开始编址，并且采用一段连续的地址空间。\n在该地址结构中，允许一个作业最长有64K个段，每个段的最大长度为64KB。\n在分段式存储管理系统中，为每一个分段分配一个连续的分区。进程的各个段，可以离散地装入内存中不同的分区中。\n段表 作用：实现从逻辑地址到物理内存区的映射。\n为了保证程序能够正常运行，就必须能够从物理内存中找出每个逻辑段所对应的位置。为此在系统中会为每一个进程建立一张段表。每个段在表中有一个表项，其中记录了该段在内存中的起始地址和段的长度。一般将段表保存在内存中。\n在配置了段表之后，执行的过程可以通过查找段表，找到每一个段所对应的内存区。\n地址变换机构 为了实现进程从逻辑地址到物理地址的变换功能，在系统设置了段表寄存器，用于存放段表的起始地址和段表长度TL。\n在进行地址变换时，系统将逻辑地址中的段号与段表长度TL 进行比较。若 S \u0026gt; TL，表示段号太大，是访问越界，于是产生越界中断信号。若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址。然后，再检查段内地址 d 是否超过该段的段长 SL。若超过，即 d\u0026gt;SL，同样发出越界中断信号。若未越界，则将该段的基址 d 与段内地址相加，即可得到要访问的内存。\n像分页系统一样，当段表放在内存中时，每要访问一个数据，都须访问两次内存，从而成倍地降低了计算机的速率。解决的方法和分页系统类似，也增设一个联相存储器，用于保存最近常用的段表项。一般情况下，由于是段比页大，因而段表项的数目比页表项的数目少，其所需的联想存储器也相对较小，所以可以显著地减少存取数据的时间，与没有地址变换的常规存储器相比而言，其存取速度约慢 10%~15%。\n段页式存储管理 分页和分段的区别 分页和分段系统相似之处：两者都采用离散分配方式，且都是通过地址映射机构实现地址变换。\n但在概念上两者完全不同，主要表现在下述三个方面：\n页是信息的物理单位，段是信息的逻辑单位。 页的大小确定且又系统决定；段的长度不固定，决定于用户所编写的程序。 分页的用户程序地址空间是一维的，只需要一个记忆符就能够表示一个地址；分段的用户程序地址空间是二维的，既需要段名，又需要段内地址。 段页式 分页系统以页面作为内存分配的基本单位，能有效地提高内存利用率，而分段系统以段作为内存分配的基本单位，它能够更好地满足用户多方面的需要。\n段页式地址结构 段页式地址结构由段号、段内页号及页内地址三部分所组成\n段页式系统的基本原理是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。如下图展示了一个作业地址空间的结构。该作业有三个段：主程序段、子程序段和数据段；页面大小为 4 KB：\n在段页式系统中，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表和页表。段表的内容与分段系统略有不同，它不再是内存始址和段长，而是页表始址和页表长度。下图展示出了利用段表和页表进行从用户地址空间到物理(内存)空间的映射。\n地址变换过程 在段页式系统中，为了便于实现地址变换，须配置一个段表寄存器，其中存放段表始址和段长 TL。进行地址变换时，首先利用段号 S，将它与段长 TL 进行比较。若 S \u0026lt; TL，表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址，并利用逻辑地址中的段内页号 P 来获得对应页的页表项位置，从中读出该贝所在的物理块号 b，再利用块号 b 和页内地址来构成物理地址。\n在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中取出指令或数据。\n显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址：若未找到匹配表项，则仍需第三次访问内存。\n参考链接：\n【操作系统 - 4】动态分区分配算法 程序的链接的三种方式 连续分配管理方式 深入理解操作系统之——分页式存储管理 《计算机操作系统》(第四版) ","description":"","id":60,"section":"posts","tags":["Linux"],"title":"Linux内存管理","uri":"https://hugo.jiahongw.com/posts/linux/memory-control/"},{"content":"网络层 网际协议IP是TCP/IP体系中两个最主要的协议之一[STEV94][COME06][FORO10]，也是最重要的因特网标准协议之一。\n与IP协议配套使用的还有三个协议：\n地址解析协议ARP (Address Resolution Protocol) 网际控制报文协议ICMP (Internet Control Message Protocol) 网际组管理协议IGMP (Internet Group Management Protocol) 在这一层中，ARP画在最下面，因为IP经常要使用这个协议。ICMP和IGMP画在这一层的上部，因为它们要使用IP协议。由于网际协议IP是用来使互连起来的许多计算机网络能够进行通信，因此TCP/IP体系中的网络层常常称为网际层(internet layer)，或IP层。\n虚拟互连网络 从一般的概念来讲，将网络互相连接起来要使用一些中间设备。根据中间设备所在的层次，可以有以下四种不同的中间设备：\n(1) 物理层使用的中间设备叫做转发器(repeater)。\n(2) 数据链路层使用的中间设备叫做网桥或桥接器(bridge)。\n(3) 网络层使用的中间设备叫做路由器(router)[插图]。\n(4) 在网络层以上使用的中间设备叫做网关(gateway)。\n用网关连接两个不兼容的系统需要在高层进行协议的转换。\nIP网：\n异构的互联网链路\nH1→R1→R2→R3→R4→R5→H2\nARP协议 已经知道了一个机器（主机或路由器）的IP地址，需要找出其相应的硬件地址\nARP协议工作原理：\n当主机A要向本局域网上的某个主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址。如有，就在ARP高速缓存中查出其对应的硬件地址，再把这个硬件地址写入MAC帧，然后通过局域网把该MAC帧发往此硬件地址。\n当找不到时，执行下面的操作：\nARP进程在本局域网上广播发送一个ARP请求分组 在本局域网上的所有主机上运行的ARP进程都收到此ARP请求分组 主机B的IP地址与ARP请求分组中要查询的IP地址一致，就收下这个ARP请求分组，并向主机A发送ARP响应分组，并在这个ARP响应分组中写入自己的硬件地址。 在网络链路上传送的帧最终是按照硬件地址找到目的主机的，那么为什么我们不直接使用硬件地址进行通信，而是要使用抽象的IP地址并调用ARP来寻找出相应的硬件地址呢？\n由于全世界存在着各式各样的网络，它们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，因此由用户或用户主机来完成这项工作几乎是不可能的事。但统一的IP地址把这个复杂问题解决了。连接到因特网的主机只需拥有统一的IP地址，它们之间的通信就像连接在同一个网络上那样简单方便，因为上述的调用ARP的复杂过程都是由计算机软件自动进行的，对用户来说是看不见这种调用过程的。\nIP数据报 IP报文格式：\n片偏移的列子：\n一数据报的总长度为3 820字节，其数据部分为3 800字节长（使用固定首部），需要分片为长度不超过1 420字节的数据报片。因固定首部长度为20字节，因此每个数据报片的数据部分长度不能超过1 400字节。于是分为3个数据报片，其数据部分的长度分别为1 400，1 400和1000字节。原始数据报首部被复制为各数据报片的首部，但必须修改有关字段的值。下如给出分片后得出的结果（请注意片偏移的数值）\n下面是数据报首部与分片有关的字段中的数值，其中标识字段的值是任意给定的（12345）。具有相同标识的数据报片在目的站就可无误地重装成原来的数据报。\n首部检验和 占16位。这个字段只检验数据报的首部，但不包括数据部分\n这是因为数据报每经过一个路由器，路由器都要重新计算一下首部检验和（一些字段，如生存时间、标志、片偏移等都可能发生变化）。不检验数据部分可减少计算的工作量。为了进一步减小计算检验和的工作量，IP首部的检验和不采用复杂的CRC检验码而采用下面的简单计算方法：在发送方，先把IP数据报首部划分为许多16位字的序列，并把检验和字段置零。用反码算术运算[插图]把所有16位字相加后，将得到的和的反码写入检验和字段。接收方收到数据报后，将首部的所有16位字再使用反码算术运算相加一次。将得到的和取反码，即得出接收方检验和的计算结果。若首部未发生任何变化，则此结果必为0，于是就保留这个数据报。否则即认为出差错，并将此数据报丢弃。\nIP层转发分组 网络拓扑图：\n在简化图中，网络变成了一条链路，但每一个路由器旁边都注明其IP地址。使用这样的简化图，可以使我们不用关心某个网络内部的具体拓扑以及连接在该网络上有多少台计算机，因为这些对于研究分组转发问题并没有什么关系。这样的简化图强调了在互联网上转发分组时，是从一个路由器转发到下一个路由器。\n总之，在路由表中，对每一条路由最主要的是以下两个信息：\n（目的网络地址，下一跳地址）\n于是，我们就根据目的网络地址来确定下一跳路由器，这样做得出以下的结果。\n(1) IP数据报最终一定可以找到目的主机所在目的网络上的路由器（可能要通过多次的间接交付）。\n(2) 只有到达最后一个路由器时，才试图向目的主机进行直接交付。\n网际控制报文协议ICMP 为了更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP。\nICMP允许主机或路由器报告差错情况和提供有关异常情况的报告.一个新搭建好的网络，往往需要先进行一个简单的测试，来验证网络是否畅通；但是IP协议并不提供可靠传输。如果丢包了，IP协议并不能通知传输层是否丢包以及丢包的原因。所以我们就需要一种协议来完成这样的功能–ICMP协议。\nICMP报文格式\nICMP报文的种类有两种，即ICMP差错报告报文和ICMP询问报文。\n几种常用的ICMP报文类型\nICMP报文的代码字段是为了进一步区分某种类型中的几种不同的情况。检验和字段用来检验整个ICMP报文。我们应当还记得，IP数据报首部的检验和并不检验IP数据报的内容，因此不能保证经过传输的ICMP报文不产生差错。\nICMP差错报告 ICMP差错报文共有五种，即：\n终点不可达 当路由器或主机不能交付数据报时就向源点发送终点不可达报文。\n源点抑制 当路由器或主机由于拥塞而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢。\n时间超过 当路由器收到生存时间为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，并向源点发送时间超过报文。\n参数问题 当路由器或目的主机收到的数据报的首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文。\n改变路由（重定向） 路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）。\n如果默认路由器发现主机发往某个目的地址的数据报的最佳路由不应当经过默认路由器而是应当经过网络上的另一个路由器R时，就用改变路由报文把这情况告诉主机。于是，该主机就在其路由表中增加一个项目：到某某目的地址应经过路由器R （而不是默认路由器）。\n所有的ICMP差错报告报文中的数据字段都具有同样的格式：\n下面是不应发送ICMP差错报告报文的几种情况。\n● 对ICMP差错报告报文不再发送ICMP差错报告报文。\n● 对第一个分片的数据报片的所有后续数据报片都不发送ICMP差错报告报文。\n● 对具有多播地址的数据报都不发送ICMP差错报告报文。\n● 对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报不发送ICMP差错报告报文。\nICMP询问报文 常用的ICMP询问报文有两种，即:\n回送请求和回答 ICMP回送请求报文是由主机或路由器向一个特定的目的主机发出的询问。收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文。这种询问报文用来测试目的站是否可达以及了解其有关状态。 时间戳请求和回答 ICMP时间戳请求报文是请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，其中写入的整数代表从1900年1月1日起到当前时刻一共有多少秒。时间戳请求与回答可用来进行时钟同步和测量时间。 应用 ping ICMP报文的一个最大用途就是ping命令，用来测试两个主机之间的连通性：\ntracert Traceroute从源主机向目的主机发送一连串的IP数据报，数据报中封装的是无法交付的UDP用户数据报[插图]。第一个数据报P1的生存时间TTL设置为1。当P1到达路径上的第一个路由器R1时，路由器R1先收下它，接着把TTL的值减1。由于TTL等于零了，R1就把P1丢弃了，并向源主机发送一个ICMP时间超过差错报告报文。源主机接着发送第二个数据报P2，并把TTL设置为2。P2先到达路由器R1，R1收下后把TTL减1再转发给路由器R2。R2收到P2时TTL为1，但减1后TTL变为零了。R2就丢弃P2，并向源主机发送一个ICMP时间超过差错报告报文。这样一直继续下去。当最后一个数据报刚刚到达目的主机时，数据报的TTL是1。主机不转发数据报，也不把TTL值减1。但因IP数据报中封装的是无法交付的运输层的UDP用户数据报，因此目的主机要向源主机发送ICMP终点不可达差错报告报文。\n这样，源主机达到了自己的目的，因为这些路由器和最后目的主机发来的ICMP报文正好给出了源主机想知道的路由信息——到达目的主机所经过的路由器的IP地址，以及到达其中的每一个路由器的往返时间\n","description":"网络层浅析","id":61,"section":"posts","tags":["计算机网络","网络层"],"title":"网络层","uri":"https://hugo.jiahongw.com/posts/network/net-level/"},{"content":"描述符的就绪状态有两种判断方法: 边沿触发和水平触发。\n水平触发\n我认为这是“拉”模式或“民意调查”模式。为了确定描述符是否就绪，进程尝试执行非阻塞 I/O 操作。一个进程可以多次执行这样的操作。这允许在处理任何后续 I/O 操作方面有更大的灵活性ー例如，如果描述符已经准备好，进程可以选择读取所有可用的数据或者根本不执行任何 I/O 操作，或者选择不读取缓冲区中所有可用的输入数据。让我们通过一个例子来看看它是如何工作的。\n在 t0时，进程可以在非阻塞描述符上尝试 I/O 操作。如果 I/O 操作阻塞，系统调用将返回一个错误。\n然后在 t1时，进程可以再次尝试在描述符上进行 I/O。假设调用再次阻塞，并返回一个错误。\n然后在时间 t2，进程再次尝试描述符上的 I/O。假设调用再次阻塞，并返回一个错误。\n假设在 t3时，进程轮询描述符的状态，描述符就绪。然后进程可以选择实际执行整个 I/O 操作(例如，读取套接字上的所有可用数据)。\n让我们假设在 t4时进程轮询描述符的状态，而描述符没有准备好。调用再次阻塞，并且 I/O 操作返回一个错误。\n假设在 t5时，进程轮询描述符的状态，描述符就绪。进程随后可以选择只执行部分 I/O 操作(例如，只读取所有可用数据的一半)。\n​\t假设在 t6时，进程轮询描述符的状态，描述符就绪。这一次，进程可以选择根本不执行后续的 I/O。\n边缘触发 流程只有在文件描述符“就绪”时才会收到通知(通常是在文件描述符上有任何新活动时，因为它是上次被监视的)。我认为这就是“推送”模型，因为通知被推送到进程中，说明文件描述符的准备就绪情况。此外，对于 push 模型，只通知进程说描述符已经为 I/O 准备好了，而不提供其他信息，例如到达 socket 缓冲区的字节数。\n因此，当一个进程试图执行任何后续 I/O 操作时，它只配备了不完整的数据。为了解决这个问题，进程可以在每次获得描述符准备就绪通知时，尝试执行尽可能大的 I/O，因为如果不这样做，就意味着进程必须等待下一个通知到来，即使在下一个通知到来之前，在描述符上可以进行 I/O。\n开始：\n在 t2时，进程得到一个关于描述符已经准备好的通知。\n可用于 I/O 的字节流存储在缓冲区中。假设当进程在时间 t2获得通知时，有1024个字节可供读取。\n假设该进程只读取1024个字节中的500个字节。\n这意味着在 t3、 t4和 t5时，缓冲区中仍然有524个字节可供进程读取而不会阻塞。但是，由于进程只能在获得下一个通知后执行 I/O，因此在这段时间内，这524个字节将保留在缓冲区中。\n假设进程在时间 t6获得下一个通知，当额外的1024个字节到达缓冲区时。缓冲区上可用的数据总量现在是1548字节ー524字节，以前没有读过，1024字节是新到的。\n假设进程现在读取1024个字节。\n这意味着在第二次 I/O 操作结束时，524个字节仍然保留在缓冲区中，在下一个通知到达之前，进程将无法读取这个缓冲区。\n虽然在通知到达后立即执行所有 I/O 可能是临时的，但这样做会产生一些后果。单个描述符上的大型 I/O 操作可能会饿死其他描述符。此外，即使在级别触发通知的情况下，一个非常大的写或发送调用也有可能阻塞。\nMultiplexing I/O on descriptors 有几种在描述符上多路 I/O 的方法:\n— non-blocking I/O (the descriptor itself is marked as non-blocking, operations may finish partially)\n— signal driven I/O (the process owning the descriptor is notified when the I/O state of the descriptor changes)\n— polling I/O (with *select* or *poll* system calls, both of which provide level triggered notifications about the readiness of descriptors)\n— BSD specific kernel event polling (with the *kevent* system call).\n参考：\nhttps://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642 ","description":"","id":62,"section":"posts","tags":["Linux","epoll"],"title":"epoll的水平触发与边缘触发","uri":"https://hugo.jiahongw.com/posts/linux/epoll-lt-et/"},{"content":"HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。\nHTTP/0.9 HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。\n协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。\nHTTP/1.x 在早期，HTTP 使用一个简单的模型来处理这样的连接。这些连接的生命周期是短暂的：每发起一个请求时都会创建一个新的连接，并在收到应答时立即关闭。连接的成本较高。\n当请求发起时，网络延迟和带宽都会对性能造成影响。现代浏览器往往要发起很多次请求(十几个或者更多)才能拿到所需的完整信息，证明了这个早期模型的效率低下。\n在 HTTP/1.x 里有多种模型：短连接, 长连接, 和 HTTP 流水线。\n短链接模型 HTTP/1.0 的默认模型。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。\n在 HTTP/1.1 中，只有当 Connection 被设置为 close 时才会用到这个模型\n长连接模型 保持连接去完成多次连续的请求，减少了不断重新打开连接的时间。在 HTTP/1.1 里，默认就是长连接的。\n短连接有两个比较大的问题：创建新连接耗费的时间尤为明显，另外 TCP 连接的性能只有在该连接被使用一段时间后(热连接)才能得到改善。另外我们知道，TCP协议有个滑动窗口，有慢启动这回事，就是说每次建立新连接后，数据先是慢慢地传，然后滑动窗口慢慢变大，才能较高速度地传。\n具体流程：\n一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：连接在空闲一段时间后会被关闭(服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间)。\n缺点：\n就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS attacks 攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。\n长连接一个优化的方法就是设置一个超时时间，但是具体这个时间是多少，应该通过测试之后得出一个较为均衡的时间。\n流水线模型(管线化) 多个连续的请求甚至都不用等待立即返回就可以被发送。HTTP 流水线在现代浏览器中并不是默认被启用的。\n默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n**流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟。理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。**就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的 MSS(Maximum Segment Size) 选项，仍然足够包含一系列简单的请求。\n比如，当请求一个包含10张图片的HTML Web页面，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n队头阻塞 在一般情况下，HTTP遵守“请求-响应”的模式，也就是客户端每次发送一个请求到服务端，服务端返回响应，这种模式很简单，但是有一个致命缺陷那就是页面中有多个请求，每个请求必须等到前一个请求响应之后才能发送，并且当前请求的响应返回之后，当前请求的下一个请求才能发送，流程如下图\n在TCP链接中，http请求必须等待前一个请求响应之后，才能发送，后面的依次类推，由此可以看出，如果在一个tcp通道中如果某个http请求的响应因为某个原因没有及时返回，后面的响应会被阻塞，这就是队头阻塞。\n注意这里说的是响应之后，并不是请之后!\n为了提高速度和效率，在持久连接的基础上，HTTP1.1进一步地支持在持久连接上使用管道化（pipelining）特性。管道化允许客户端在已发送的请求收到服务端的响应之前发送下一个请求，借此来减少等待时间提高吞吐，如果多个请求能在同一个TCP分节发送的话，还能提高网络利用率，流程如图：\n同一个tcp连接中可以同时发送多个http请求，也就是并发，但是在响应的时候，必须排队响应，谁先到达的谁先响应，相比不支持管道化的http请求确实提高了效率，但是还是有局限性，假如其中某个响应因为某种原因延迟了几秒，后面的响应都会被阻塞。上面箭头所指的响应如果阻塞了，那么这个也是队头阻塞。\n并且使用HTTP管道化还有一些限制:\n1、管道化要求服务端按照请求发送的顺序返回响应（FIFO），原因很简单，HTTP请求和响应并没有序号标识，无法将乱序的响应与请求关联起来。\n2、当客户端在支持管道化时需要保持未收到响应的请求，当连接意外中断时，需要重新发送这部分请求。如果这个请求只是从服务器获取数据，那么并不会对资源造成任何影响，而如果是一个提交信息的请求如post请求，那么可能会造成资源多次提交从而改变资源，这是不允许的。而不会对服务器资源产生影响的请求有个专业名词叫做幂等请求。客户端在使用管道化的时候请求方式必须是幂等请求。\n比较：\n上面的管线化的模型就是加速了请求的过程，但是响应的过程还是存在队头阻塞。\n因为HTTP管道化本身可能会导致队头阻塞的问题，以及上面提到的一些限制，现代浏览器默认都关闭了管道化，并且大部分服务器也是默认不支持管道化的。\n如何解决队头阻塞？\n客户端使用并发长连接，注意这个并发指的是tcp并发连接。\n并发长连接虽然在一定程度上解决了http的队头阻塞，但是会对服务器的性能有较高的要求\nHTTP/2 HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为\u0026quot;帧\u0026quot;（frame）：头信息帧和数据帧。\n😆 HTTP/2 没有改动 HTTP 的应用语义。 HTTP 方法、状态代码、URI 和标头字段等核心概念一如往常。 不过，HTTP/2 修改了数据格式化（分帧）以及在客户端与服务器间传输的方式。这两点统帅全局，通过新的分帧层向我们的应用隐藏了所有复杂性。 因此，所有现有的应用都可以不必修改而在新协议下运行。\n为什么不是 HTTP/1.2？\n为了实现 HTTP 工作组设定的性能目标，HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端向后兼容，因此协议的主版本提升到 HTTP/2。\n二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。\n这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。\n数据流、消息和帧 数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。 关系：\n所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。(多工) 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。 简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。\nHTTP/2 帧结构如下：\n实际的传输过程可能是下面这样(吞吐量增大)：\n请求与响应复用 HTTP/2 中新的二进制分帧层实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。\n数据流优先级 我们来看一下上图中的几个操作示例。 从左到右依次为：\n数据流 A 和数据流 B 都没有指定父依赖项，依赖于隐式“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 依赖于根数据流；C 依赖于 D。 因此，D 应先于 C 获得完整资源分配。 权重不重要，因为 C 的依赖关系拥有更高的优先级。 数据流 D 应先于 C 获得完整资源分配；C 应先于 A 和 B 获得完整资源分配；数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 应先于 E 和 C 获得完整资源分配；E 和 C 应先于 A 和 B 获得相同的资源分配；A 和 B 应基于其权重获得比例分配。 流控制 流控制是一种阻止发送方向接收方发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常繁忙、处于较高的负载之下，也可能仅仅希望为特定数据流分配固定量的资源。 例如，客户端可能请求了一个具有较高优先级的大型视频流，但是用户已经暂停视频，客户端现在希望暂停或限制从服务器的传输，以免提取和缓冲不必要的数据。 再比如，一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接的速度来控制其资源利用率；等等。类似TCP流量控制。\n服务器推送 HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源（图 12-5），而无需客户端明确地请求。\n标头压缩 每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。为了减少此开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：\n这种格式支持通过静态霍夫曼代码对传输的标头字段进行编码，从而减小了各个传输的大小。 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输的值进行有效编码。 利用霍夫曼编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。\n哈夫曼树如何压缩 文件压缩的主要思想是利用哈夫曼编码来实现的，但是得到编码之前我们需要构建这棵树。那么利用什么来构建树呢？！这里，我们需要统计每个字符出现的次数，用次数来构建HuffmanTree。假设我们现在有一个.txt的小文件，内容是\u0026quot;aaaabbbccd\u0026quot;。字符存在计算机中时以字节为单位的，因此我们需要将这些字符压缩成0、1表示的编码，0和1表示字节中的“位”，这样能大大降低文件的大小。\n体验HTTP2 https://http2.akamai.com/demo\n参考链接：\nHTTP 连接管理进化论 https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn 白话http队头阻塞 ","description":"http协议迭代了好几个版本，从一开始的短链接模型到长连接模型，最后还衍生出二进制帧层......","id":63,"section":"posts","tags":["network","http","https"],"title":"Http协议浅析","uri":"https://hugo.jiahongw.com/posts/network/http/"},{"content":"树是一种非常实用的结构！🌴\n以下的二叉树采用的结构都为链式结构\n1 2 3 4 5 typedef struct BiTNode /* 结点结构 */ { int data; /* 结点数据 */ struct BiTNode *lchild, *rchild; /* 左右孩子指针 */ } BiTNode, *BiTree; 1. 二叉排序树 二叉排序树又称“二叉查找树”、“二叉搜索树”。\n定义 或者是一棵空树，或者是具有下列性质的二叉树：\n若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n它的左、右子树也分别为二叉排序树。\n中序遍历二叉排序树可得到一个依据关键字的有序序列，一个无序序列可以通过构造一棵二叉排序树变成一个有序序列，构造树的过程即是对无序序列进行排序的过程。每次插入的新的结点都是二叉排序树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的时间复杂度等于树高，期望O(logn)，最坏O(n)（数列有序，树退化成线性表，如右斜树）。\n查找算法 查找过程：\n1.若b是空树，则搜索失败，否则：\n2.若x等于b的根节点的数据域之值，则查找成功；否则：\n3.若x小于b的根节点的数据域之值，则搜索左子树；否则：\n4.查找右子树。\n5.若查找不成功， 则指针 p 指向查找路径上访问的最后一个结点并返回FALSE\n插入算法 插入过程：\n先调用查找操作将要插入的关键字进行比较\n如果在原有的二叉排序树中没有要插入的关键字，则将关键字与查找的结点p（在查找操作中返回的结点）的值进行比较\n若p为空，则插入关键字赋值给该节点；\n若小于结点p的值，则插入关键字作为结点p的左子树；\n若大于结点p的值，则插入关键字作为结点p的右子树；\n每次需要插入的节点都为叶子节点。\n删除算法 删去一个结点，分三种情况讨论：\n若*p结点为叶子结点，即PL(左子树)和PR(右子树)均为空树。由于删去叶子结点不破坏整棵树的结构，则只需修改其双亲结点的指针即可。\n若p结点只有左子树PL或右子树PR，此时只要令PL或PR直接成为其双亲结点f的左子树（当p是左子树）或右子树（当p是右子树）即可，作此修改也不破坏二叉排序树的特性。\n若p结点的左子树和右 子树均不空。在删去p之后，为保持其它元素之间的相对位置不变，可按中序遍历保持有序进行调整。比较好的做法是，找到*p的**直接前驱（或直接后继）s，用s来替换结点p，然后再删除结点s。(依靠中序遍历在p节点下进行遍历得到的最后一个数即为替换的节点)\n性能分析 最好的情况是二叉排序树的形态和折半查找的判定树相同，其平均查找长度和logn成正比（O(log2(n))）。 最坏情况下，当先后插入的关键字有序时，构成的二叉排序树为一棵斜树，树的深度为n，其平均查找长度为(n + 1) / 2。也就是时间复杂度为O(n)，等同于顺序查找。 虽然二叉排序树的最坏效率是O(n)，但它支持动态查找。最好是把它构建成一棵平衡的二叉排序树（平衡二叉树），这些平衡二叉树可以使树高为O(logn)，如AVL、红黑树等。\n2. 平衡二叉树（AVL） 定义 它或者是一颗空树，或者具有以下性质的二叉树：它的左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一颗平衡二叉树。\n平衡因子(bf)：结点的左子树的深度减去右子树的深度，那么显然-1\u0026lt;=bf\u0026lt;=1;\n在AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。\n查找、插入和删除在平均和最坏情况下的时间复杂度都是$O(log(n))$。增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。\n查找操作 平衡二叉树的查找基本与二叉查找树相同。\n插入操作 在平衡二叉树中插入结点与二叉查找树最大的不同在于要随时保证插入后整棵二叉树是平衡的。那么调整不平衡树的基本方法就是： 旋转 。\n首先，还需要明白的一个概念就是：\n最小不平衡子树的根结点：也就是当你进行插入操作时，找到该需要插入结点的位置并插入后，从该结点起向上寻找（回溯），第一个不平衡的结点即平衡因子bf变为-2或2的节点。\n那究竟是如何“转”的呢？\n其实，可以换一种思路思考，不让它叫“旋转”！而叫——\u0026gt;“两个结点的变换”\n下面分情况分析四种旋转方式\n左左 即在x的左孩子a的左孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的左孩子（如图②），也可以是c的右孩子（不在画出）\n这种左左插入方式有一个规律：不平衡子树的左子树深度比右子树深度大2.\n图①②插入的节点都为y，此时向上回溯第一个不平衡的子树根节点为x，那么将x节点及其右子树(图①为NULL，图②为b)一起绕着x的左子树根节点(即a)右旋(即顺时针旋转),然后将a的右子树作为x的左子树，假如a的右子树为空则不必插入。那么这样旋转最后将不平衡子树变为平衡。\n右右 即在x的右孩子a的右孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n这种右右插入方式有一个规律：不平衡子树的左子树深度比右子树深度小2.\n图①②插入的节点都为y，此时向上回溯找到第一个不平衡子树的节点为x，需要将节点x及其左子树(图①为NULL，图二为b)绕着x右子树(两图都为a为根节点的子树)进行左旋(逆时针旋转),然后将其右子树(a)的左节点作为x的右节点，这样使得不平衡子树又再度平衡。\n左右 即在x的左孩子a的右孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n这种左右插入的规律就是：不平衡子树的左子树高度比右子树大2且左子树的右子树比左子树的左子树深度深。\n向上回溯的第一个不平衡子树为x，先对x的左子树左旋(旋转中心为c)，再对x的左子树进行右旋(旋转中心为c)。(旋转中心为左子树的右节点)\n如果是图①，旋转中心为y\n右左 即在x的右孩子a的左孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n这种右左插入的规律就是：不平衡子树的右子树高度比左子树大2且右子树的左子树比右子树的右子树深度深。\n向上回溯的第一个不平衡子树为x，先对x的右子树右旋(旋转中心为c)，再对x的右子树进行左旋(旋转中心为c)。(旋转中心为左子树的右节点)\n如果是图①，旋转中心为y\nAVL树的操作汇总：\n删除操作 删除类似插入的操作。删除时少一个结点，也就是该结点所在的子树深度可能会减小，而插入时多一个结点，该结点所在的子树深度可能会增加，所以递归删除一个结点时，回溯时找到最小不平衡子树的根结点时，要向相反的方向去找属于哪种情况；\n如图y为要删除的节点\n图①：y结点删除后，回溯到x结点从bf=-1变为bf=-2；则需从相反方向即从x的右孩子的方向向下检查属于哪种情况，显然第一个方向为1：右；第二个方向看a的bf的值——若为1时，那就相当于插入时‘右左’的情况；若为-1时，那就相当于插入时‘右右’的情况；可现在a的bf既不是1也不是-1而是0，这就是删除的特殊情况了！我们不妨试试对他进行类似于插入时的‘右右’操作，看怎么样~ 如上图，经过变换后该子树平衡了！但是因子的修改就跟插入时的‘右右’不一样了！此时变为：x的bf=-1,a的bf=1；所以我们不妨就把a的bf=0也归纳为删除的‘右右’或‘左左’（如图②，不再敖述）操作；\n那么删除时因子的改变需在插入时因子的改变中添加上：\n左左：前a:bf=0 后x:bf=1,a:bf=-1； 右右：前a:bf=0 后x:bf=-1,a:bf=1；其他不变！\n可以想象，其实是很简单的道理：除了特殊情况其他都与插入的情况一模一样，说白了就是把深度大的子树（根结点的其中一个）向深度小子树贡献一个深度，那么这样一来，该子树（对于根结点所领导的树）的深度是不是比原来的小1了？！所以要继续向上一个一个进行检索，直到根结点为止！\n代码实现 https://blog.csdn.net/nightwizard2030/article/details/72874715\n性能分析 优势 平衡二叉树的优势在于不会出现普通二叉查找树的最差情况。其查找的时间复杂度为$O(logN)$。\n缺陷 为了保证高度平衡，动态插入和删除的代价也随之增加. 所有二叉查找树结构的查找代价都与树高是紧密相关的，能否通过减少树高来进一步降低查找代价呢。 应用场景 应用：windows对进程地址空间的管理用到了AVL树。\n3. 红黑树 也被称为\u0026quot;对称二叉B树\u0026quot;。\n定义 红黑树(red-black tree) 是一棵满足下述性质的二叉查找树：\n每一个结点要么是红色，要么是黑色。\n根结点是黑色的。\n所有叶子结点都是黑色的（实际上都是Null指针，下图用NIL表示）。叶子结点不包含任何关键字信息，所有查询关键字都在非终结点上。\n每个红色结点的两个子节点必须是黑色的。换句话说：从每个叶子到根的所有路径上不能有两个连续的红色结点\n从任一结点到其每个叶子的所有路径都包含相同数目的黑色结点\n几个概念：\n黑深度 ——从某个结点x出发(不包括结点x本身)到叶结点(包括叶子结点)的路径上的黑结点个数,称为该结点x的黑深度,记为$bd(x)$,根结点的黑深度就是该红黑树的黑深度。叶子结点的黑深度为0。比如：上图$bd(13)=2， bd(8)=2， bd(1)=1$\n内部结点 —— 红黑树的非终结点\n外部节点 —— 红黑树的叶子结点\n相关原理 从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。 红黑树的树高$(h)$不大于两倍的红黑树的黑深度$(bd)$，即$h\u0026lt;=2bd$ 一棵拥有n个内部结点(不包括叶子结点)的红黑树的树高$h\u0026lt;=2log(n+1)$ 查找操作 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的查找操作与普通二叉查找树上的查找操作相同.\n插入操作 我们首先以二叉查找树的方法增加节点并标记它为红色。下面要进行什么操作取决于其他临近节点的颜色。同人类的家族树中一样，我们将使用术语叔父节点来指一个节点的父节点的兄弟节点。\n假设新加入的结点为N，父亲结点为P，叔父结点为Ui(叔父结点就是一些列P的兄弟结点)，祖父结点G(父亲结点P的父亲)。\n情况1. 当前红黑树为空，新结点N位于树的根上，没有父结点。\n此时很简单，我们将直接插入一个黑结点N（满足性质2），因为是特殊大的情况，不插入红色而插入黑色节点。\n情况2. 新结点N的父结点P是黑色。\n在这种情况下，我们插入一个红色结点N(满足性质5)\n注意：在情况3，4，5下，我们假定新节点有祖父节点，因为父节点是红色；并且如果它是根，它就应当是黑色。所以新节点总有一个叔父节点，尽管在情形4和5下它可能是叶子。\n情况3.如果父节点P和叔父节点U二者都是红色。\n如下图，因为新加入的N结点必须为红色，那么我们可以将父结点P(保证性质4)，以及N的叔父结点U(保证性质5)重新绘制成黑色。如果此时祖父结点G是根，则结束变化。如果不是根，则祖父结点重绘为红色(保证性质5)。但是，G的父亲也可能是红色的，为了保证性质4。我们把G递归当做新加入的结点N在进行各种情况的重新检查。\n注意：在情形4和5下，我们假定父节点P 是祖父结点G 的左子节点。如果它是右子节点，情形4和情形5中的左和右应当对调。\n情况4. 父节点P是红色而叔父节点U是黑色或缺少; 另外，新节点N是其父节点P的右子节点，而父节点P又是祖父结点G的左子节点。\n如下图, 在这种情形下，我们进行一次左旋转调换新节点和其父节点的角色（与AVL树的左旋转相同）; 这导致某些路径通过它们以前不通过的新节点N或父节点P中的一个，但是这两个节点都是红色的，所以性质5没有失效。但目前情况将违反性质4，所以接着，我们按下面的情况5继续处理以前的父节点P。\n情况5. 父节点P是红色而叔父节点U 是黑色或缺少，新节点N 是其父节点的左子节点，而父节点P又是祖父结点的G的左子节点。\n如下图： 在这种情形下，我们进行针对祖父节点P 的一次右旋转; 在旋转产生的树中，以前的父节点P现在是新节点N和以前的祖父节点G 的父节点。我们知道以前的祖父节点G是黑色，否则父节点P就不可能是红色。我们切换以前的父节点P和祖父节点G的颜色，结果的树满足性质4[3]。性质 5[4]也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过祖父节点G ，现在它们都通过以前的父节点P。在各自的情形下，这都是三个节点中唯一的黑色节点。\n删除操作 相较于插入操作，红黑树的删除操作则要更为复杂一些。删除操作首先要确定待删除节点有几个孩子，如果有两个孩子，不能直接删除该节点。而是要先找到该节点的前驱（该节点左子树中最大的节点）或者后继（该节点右子树中最小的节点），然后将前驱或者后继的值复制到要删除的节点中，最后再将前驱或后继删除。由于前驱和后继至多只有一个孩子节点，这样我们就把原来要删除的节点有两个孩子的问题转化为只有一个孩子节点的问题，问题被简化了一些。我们并不关心最终被删除的节点是否是我们开始想要删除的那个节点，只要节点里的值最终被删除就行了，至于树结构如何变化，这个并不重要。\n应用场景 工业界最主要使用的二叉搜索平衡树，广泛用在C++的STL中。如map和set都是用红黑树实现的。Java用它来实现TreeMap。著名的linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块。\nepoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等 Code 实现：https://www.cnblogs.com/skywang12345/p/3624291.html\n红黑树节点定义 1 2 3 4 5 6 7 8 9 10 11 12 template \u0026lt;class T\u0026gt; class RBTNode { public: RBTColor color; // 颜色 T key; // 关键字(键值) RBTNode *left; // 左孩子 RBTNode *right; // 右孩子 RBTNode *parent; // 父结点 RBTNode(T value, RBTColor c, RBTNode *p, RBTNode *l, RBTNode *r) : key(value), color(c), parent(), left(l), right(r) {} }; 颜色定义 1 2 3 4 5 enum RBTColor { RED, BLACK }; 4.B树 背景\n一个比较实际的问题：就是大量数据存储中，实现查询这样一个实际背景下，平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。那么如何减少树的深度（当然不能减少查询数据量），一个基本的想法就是：\n每个节点存储多个元素 （但元素数量不能无限多，否则查找就退化成了节点内部的线性查找了）。\n摒弃二叉树结构，采用多叉树 （由于节点内元素数量不能无限多，自然子树的数量也就不会无限多了）。\n这样我们就提出来了一个新的查找树结构 ——多路查找树。 根据AVL给我们的启发，一颗平衡多路查找树(B~树) 自然可以使得数据的查找效率保证在O(logN)这样的对数级别上。\n目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构\nB-树 B-树是一种多路搜索树。\nB-Tree 是满足下列条件的数据结构：\nd 为大于 1 的一个正整数，称为 B-Tree 的度。 h 为一个正整数，称为 B-Tree 的高度。 每个非叶子节点由 n-1 个 key 和 n 个指针组成，其中 d\u0026lt;=n\u0026lt;=2d。 每个叶子节点最少包含一个 key 和两个指针，最多包含 2d-1 个 key 和 2d 个指针，叶节点的指针均为 null 。 所有叶节点具有相同的深度，等于树高 h。 key 和指针互相间隔，节点两端是指针。 一个节点中的 key 从左到右非递减排列。 所有节点组成树结构。 每个指针要么为 null，要么指向另外一个节点。 如果某个指针在节点 node 最左边且不为 null，则其指向节点的所有 key 小于 v(key1)，其中 v(key1) 为 node 的第一个 key 的值。 如果某个指针在节点 node 最右边且不为 null，则其指向节点的所有 key 大于 v(keym)，其中 v(keym) 为 node 的最后一个 key 的值。 如果某个指针在节点 node 的左右相邻 key 分别是 keyi 和 keyi+1 且不为 null，则其指向节点的所有 key 小于 v(keyi+1) 且大于 v(keyi)。 性质：\n根结点至少有两个子女；\n每个非根节点所包含的关键字个数 j 满足：┌m/2┐ - 1 \u0026lt;= j \u0026lt;= m - 1；\n除根结点以外的所有结点（不包括叶子结点）的度数正好是关键字总数加1，故内部子树个数 k 满足：┌m/2┐ \u0026lt;= k \u0026lt;= m ；\n所有的叶子结点都位于同一层。\n用在磁盘文件组织 数据索引和数据库索引。\nB-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，例：\n每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。\n两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。\n以根节点为例，关键字为 17 和 35，P1 指针指向的子树的数据范围为小于 17，P2 指针指向的子树的数据范围为 17~35，P3 指针指向的子树的数据范围为大于 35。\n模拟查找关键字 29 的过程：\n根据根节点找到磁盘块 1，读入内存。【磁盘 I/O 操作第 1 次】 比较关键字 29 在区间（17,35），找到磁盘块 1 的指针 P2。 根据 P2 指针找到磁盘块 3，读入内存。【磁盘 I/O 操作第 2 次】 比较关键字 29 在区间（26,30），找到磁盘块 3 的指针 P2。 根据 P2 指针找到磁盘块 8，读入内存。【磁盘 I/O 操作第 3 次】 在磁盘块 8 中的关键字列表中找到关键字 29。 B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。\nB+树 B+树是B-树的变体，也是一种多路搜索树：\n1.其定义基本与B-树同，除了：\n2.非叶子结点的子树指针与关键字个数相同；\n3.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树\n（B-树是开区间）；\n5.为所有叶子结点增加一个链指针；\n6.所有关键字都在叶子结点出现；\n用在磁盘文件组织 数据索引和数据库索引。MySQL常用的引擎InnoDB 和 Myisam 都是用 B+Tree 来存储数据的。\nB和B+主要用在文件系统以及数据库中做索引等，比如Mysql：B-Tree Index in MySql\n在 B-Tree 中，每个节点中有 key，也有 data，而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小。当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。\nB+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。\nB+Tree 在 B-Tree 的基础上有两点变化：\n数据是存在叶子节点中的； 数据节点之间是有指针指向的。 由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：\nMySQL应用 我们通常所说的在某个字段上建索引，意思就是让 MySQL 对该字段以索引这种数据结构来存储，然后查找的时候就有对应的查找算法。\n建索引的根本目的是为了查找的优化，特别是当数据很庞大的时候，一般的查找算法有顺序查找、折半查找、快速查找等。\nInnoDB\nInnoDB 的存储文件有两个，后缀名分别是 .frm 和 .idb，其中 .frm 是表的定义文件，而 idb 是数据文件。 InnoDB 中存在表锁和行锁，不过行锁是在命中索引的情况下才会起作用。\nInnoDB 支持事务，且支持四种隔离级别（读未提交、读已提交、可重复读、串行化），默认的为可重复读；而在 Oracle 数据库中，只支持串行化级别和读已提交这两种级别，其中默认的为读已提交级别。\nInnoDB 通过 B+Tree 结构对 ID 建索引，然后在叶子节点中存储记录。\nMyisam\nMyisam 的存储文件有三个，后缀名分别是 .frm、.MYD、MYI，其中 .frm 是表的定义文件，.MYD 是数据文件，.MYI 是索引文件。 Myisam 只支持表锁，且不支持事务。Myisam 由于有单独的索引文件，在读取数据方面的性能很高 。\n由于 Myisam 中的索引和数据分别存放在不同的文件，所以在索引树中的叶子节点中存的数据是该索引对应的数据记录的地址，由于数据与索引不在一起，所以 Myisam 是非聚簇索引。\n红黑树和多路查找树都是属于深度有界查找树（depth-bounded tree —DBT）\n2-3-4树 2-3-4 树在计算机科学中是阶为 4 的B树。\n2-3-4 树把数据存储在叫做元素的单独单元中。它们组合成节点，每个节点都是下列之一\n2-节点，就是说，它包含 1 个元素和 2 个儿子， 3-节点，就是说，它包含 2 个元素和 3 个儿子， 4-节点，就是说，它包含 3 个元素和 4 个儿子 。 每个儿子都是（可能为空）一个子 2-3-4 树。根节点是其中没有父亲的那个节点；它在遍历树的时候充当起点，因为从它可以到达所有的其他节点。叶子节点是有至少一个空儿子的节点。\n同B树一样，2-3-4 树是有序的：每个元素必须大于或等于它左边的和它的左子树中的任何其他元素。每个儿子因此成为了由它的左和右元素界定的一个区间。\n2-3-4 树是红黑树的一种等同，这意味着它们是等价的数据结构。换句话说，对于每个 2-3-4 树，都存在着至少一个数据元素是相同次序的红黑树。在 2-3-4 树上的插入和删除操作也等价于在红黑树中的颜色翻转和旋转。这使得它成为理解红黑树背后的逻辑的重要工具。\n字典树 (又称trie 树，单词查找树)\n1.又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。\n典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。\n2.它的优点是：利用字符串的公共前缀来节约存储空间，最大限度地减少无谓的字符串比较，查询效率比哈希表高。\n3.字典树与字典很相似,当你要查一个单词是不是在字典树中,首先看单词的第一个字母是不是在字典的第一层,如果不在,说明字典树里没有该单词,如果在就在该字母的孩子节点里找是不是有单词的第二个字母,没有说明没有该单词,有的话用同样的方法继续查找.字典树不仅可以用来储存字母,也可以储存数字等其它数据。\n用在统计和排序大量字符串，如自动机。\ntrie 树的一个典型应用是前缀匹配，比如下面这个很常见的场景，在我们输入时，搜索引擎会给予提示\n还有比如IP选路，也是前缀匹配，一定程度会用到trie\n后缀树\n广义后缀树\n参考：\nhttps://www.cnblogs.com/zhuyf87/archive/2012/11/09/2763113.html 二叉排序树 https://www.cnblogs.com/fornever/archive/2011/11/15/2249492.html 平衡二叉树（解惑） https://www.iteye.com/blog/hxraid-609949 平衡二叉查找树 https://www.iteye.com/blog/hxraid-611816 红黑树(RBT) https://www.zhihu.com/question/30527705 树的应用场景 说一下聚簇索引 \u0026amp; 非聚簇索引 MySQL索引背后的数据结构及算法原理 ","description":"","id":64,"section":"posts","tags":["二叉树"],"title":"高级的二叉树","uri":"https://hugo.jiahongw.com/posts/algorithmstructure/bst/"},{"content":"需要从 UGameViewportClient 类继承 修改返回值为true,路径：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n1 virtual bool RequiresHitProxyStorage() override { return true; } 在FViewportClient类中新建DrawHitProxy函数 文件UnrealClient.h\n在GameViewportClient类中声明并且实现 声明：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n将GameViewportClient类中的函数Draw()内容复制到该函数DrawHitProxy，修改下面的的地方：\n修改FViewport类中的GetRawHitProxyData函数 在GetRawHitProxyData函数中进行以下的修改：Engine\\Source\\Runtime\\Engine\\Private\\UnrealClient.cpp\n调用\u0026ndash;获取屏幕坐标Hitproxy 相关类型 HHitProxy：用于检测用户界面命中的基类\nFHitProxyMap：从2D坐标到缓存命中代理的地图。\n参考：\nHow to select an actor in-game using GetHitProxy? UE4 编辑器的光标拾取 编辑器Viewport窗口中的鼠标拾取原理 场景基本对象 渲染总流程 https://docs.unrealengine.com/zh-CN/Programming/Rendering/MeshDrawingPipeline/index.html Unreal Mesh Drawing源码分析 白袍笑道 ","description":"","id":65,"section":"posts","tags":["C++","UE4","Game"],"title":"UE编辑器下模拟使用HitProxy","uri":"https://hugo.jiahongw.com/posts/ue/ue-hitproxy/"},{"content":"在UE4中获取深度缓存，调用渲染命令读取。\n获取深度缓存 深度像素格式 键入命令vis scenedepthz uv0以查看实际使用的深度缓冲区。UE4对场景使用“反向”深度缓冲区。\nWay1：直接使用ENQUEUE_RENDER_COMMAND命令获取(效率较低) 在任意tick函数或者其他函数添加以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 struct DepthPixel\t//定义深度像素结构体 { float depth; char stencil; char unused1; char unused2; char unused3; }; float* cpuDataPtr;\t// Texture深度值数组首地址 TArray\u0026lt;DepthPixel\u0026gt; mydata;\t//最终获取色深度值数据 FIntPoint buffsize;\t//深度长宽大小X和Y ENQUEUE_RENDER_COMMAND(ReadSurfaceFloatCommand)(\t// 将读取深度数据的命令推给渲染线程进行执行 [\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize](FRHICommandListImmediate\u0026amp; RHICmdList) //\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize为传入的外部参数 { FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, 1); FTexture2DRHIRef uTex2DRes = FSceneRenderTargets::Get(RHICmdList).GetSceneDepthSurface();\tbuffsize = uTex2DRes-\u0026gt;GetSizeXY(); uint32 sx = buffsize.X; uint32 sy = buffsize.Y; mydata.AddUninitialized(sx * sy); uint32 Lolstrid = 0; cpuDataPtr = (float*)RHILockTexture2D(uTex2DRes,0,RLM_ReadOnly,Lolstrid,true);\t// 加锁 获取可读depth Texture深度值数组首地址 memcpy(mydata.GetData(), cpuDataPtr, sx * sy * sizeof(DepthPixel));\t//复制深度数据 RHIUnlockTexture2D(uTex2DRes, 0, true);\t//解锁 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, -1);\t}); FlushRenderingCommands();\t//等待渲染线程执行 mydata; //最终获取深度数据 最终返回的mydata数据就是最终的深度值数组，其中每个深度值的结构是DepthPixel，其中一个成员为depth，另外四个不不使用。其中使用上面的几个命令需要添加\u0026quot;RHI.h\u0026ldquo;头文件\nWay2：写个请求类读取 UML图：\n流程图：\n1. 首先在项目的build.cs文件添加： 添加引擎源码地址\n1 2 3 4 5 6 7 8 9 // 添加引擎源码地址 string EnginePath = \u0026#34;C:/Program Files (x86)/UE4+VS2017/UnrealEngine/\u0026#34;; PrivateIncludePaths.AddRange( new string[] { EnginePath + \u0026#34;Source/Runtime/Renderer/Private\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/CompositionLighting\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/PostProcess\u0026#34; } ); 添加引依赖项\n2. 类实现 将下面类代码复制到PostProcessing.h文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /*****************************************Get Depth Class*******************************************************/ /*\t存储一个像素的缓存 depth 深度缓存 stencil （抠图缓存）*/ struct DepthPixel { float depth; char stencil; char unused1; char unused2; char unused3; }; /*\t存储整个视窗的缓存 data\t像素缓存数组 bufferSizeX\t缓存大小X bufferSizeY\t缓存大小Y pixelSizeBytes\t像素缓存字节数*/ struct DepthResult { TArray\u0026lt;DepthPixel\u0026gt; data; int bufferSizeX; int bufferSizeY; int pixelSizeBytes; }; /*\t获取深度缓存的类\t*/ class RENDERER_API DepthCapture { public: /*\t静态成员，当用户发出一个获取深度缓存的请求后，waitForCapture长度加1，新增DepthResult内容为空 当系统完成一个深度缓存的请求后，waitForCapture长度减一 */ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; waitForCapture; /*\t静态成员，当系统完成一个深度缓存的请求后，finishedCapture长度加1， 新增DepthResult含有深度缓存信息\t*/ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; finishedCapture; public: /*用户发出一个获取深度缓存的请求时调用*/ static void AddCapture() { waitForCapture.Enqueue(new DepthResult()); } /*系统完成一个深度缓存请求后调用*/ static void FinishedCapture(DepthResult *result) { finishedCapture.Enqueue(result); } /*返回是否存在已经完成的请求*/ static bool HasFinishedCapture() { return !finishedCapture.IsEmpty(); } /*如果存在已完成的请求，返回一个深度结果*/ static DepthResult* GetIfExistFinished() { DepthResult* result = NULL; if (!finishedCapture.IsEmpty()) { finishedCapture.Dequeue(result); } return result; } /*返回是否存在等待系统执行的请求*/ static bool HasCaptureRequest() { return !waitForCapture.IsEmpty(); } /*如果存在待完成的请求，返回一个深度结果（为空）*/ static DepthResult* GetIfExistRequest() { DepthResult* result = NULL; if (!waitForCapture.IsEmpty()) { waitForCapture.Dequeue(result); } return result; } //friend void AddPostProcessingPasses(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, const FPostProcessingInputs\u0026amp; Inputs); }; /*****************************************end******************************************************/ 将下面类中静态成员初始化和添加执行获取代码代码复制到PostProcessing.cpp文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /*类静态成员的定义*/ TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::waitForCapture; TQueue\u0026lt; DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::finishedCapture; /*获取深度缓存*/ void AddDepthInspectorPass(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, DepthResult* result) { RDG_EVENT_SCOPE(GraphBuilder, \u0026#34;DepthInspector\u0026#34;); { // 获取渲染对象 FSceneRenderTargets\u0026amp; renderTargets = FSceneRenderTargets::Get(GRHICommandList.GetImmediateCommandList()); // 定义拷贝参数 uint32 striped = 0; FIntPoint size = renderTargets.GetBufferSizeXY(); result-\u0026gt;bufferSizeX = size.X; result-\u0026gt;bufferSizeY = size.Y; result-\u0026gt;data.AddUninitialized(size.X * size.Y); // 获取视窗某一帧的深度缓存对象 FRHITexture2D* depthTexture = (FRHITexture2D *)renderTargets.SceneDepthZ-\u0026gt;GetRenderTargetItem().TargetableTexture.GetReference(); // 执行拷贝深度缓存操作，将GPU显存中的缓存信息拷贝到CPU内存中，返回指向这块CPU内存的首地址 void* buffer = RHILockTexture2D(depthTexture, 0, EResourceLockMode::RLM_ReadOnly, striped, true); // 将缓存结果拷贝到result，用于输出 memcpy(result-\u0026gt;data.GetData(), buffer, size.X * size.Y * 8); // 必须执行解锁语句，否则被锁住的GPU缓存信息将不能释放 RHIUnlockTexture2D(depthTexture, 0, true); // 拷贝结果入队 DepthCapture::FinishedCapture(result); } } //////////////////////////////////////// PostProcessing.cpp中该位置添加以下代码：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 // Capture depth buffer，otherwise the buffer will be changed if (DepthCapture::HasCaptureRequest()) { DepthResult *reuslt; reuslt = DepthCapture::GetIfExistRequest(); if (reuslt) { AddDepthInspectorPass(GraphBuilder, View, reuslt); } } 3. 调用 使用以下的代码可以获取深度值，获取的结果为result：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int tickcount = 0; // Called every frame void ATestPawn::Tick(float DeltaTime) { tickcount++; if (tickcount % 2 == 0)\t// 设计几帧调用 DepthCapture::AddCapture(); // 定时发出获取深度缓存的请求 // 如果存在已完成的深度缓存请求 if (DepthCapture::HasFinishedCapture()) { DepthResult *result; // 获取已完成的深度缓存结果 result = DepthCapture::GetIfExistFinished(); if (result) { int n = result-\u0026gt;data.Num(); //this is test GEngine-\u0026gt;AddOnScreenDebugMessage(-1, -1, FColor::Blue, FString::Printf(TEXT(\u0026#34;Get Depth Size: %d \u0026#34;), n)); } } } ","description":"","id":66,"section":"posts","tags":["C++","UE4","Game"],"title":"UE4获取深度值","uri":"https://hugo.jiahongw.com/posts/ue/ue-depth/"},{"content":"探索UE4游戏线程的进入\n游戏线程 \u0026amp; 渲染线程 UE4游戏线程启动 游戏线程每一帧更新所有内容。\n这个tick是哪里打开的？\n头文件：Engine\\Source\\Runtime\\Launch\\Private\\Launch.cpp\nLauch.cpp定义了一个全局的变量FEngineLoop GEngineLoop;\n该类路径：Engine\\Source\\Runtime\\Launch\\Public\\LaunchEngineLoop.h，继承一个接口类IEngineLoop，定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 /** * Implements the main engine loop.\t*/ class FEngineLoop #if WITH_ENGINE : public IEngineLoop #endif { public: /** Default constructor. */ FEngineLoop(); virtual ~FEngineLoop() { } public: /** * Pre-Initialize the main loop, and generates the commandline from standard ArgC/ArgV from main(). * * @param ArgC The number of strings in ArgV. * @param ArgV The command line parameters (ArgV[0] is expected to be the executable name). * @param AdditionalCommandLine Optional string to append to the command line (after ArgV is put together). * @return Returns the error level, 0 if successful and \u0026gt; 0 if there were errors. */ int32 PreInit(int32 ArgC, TCHAR* ArgV[], const TCHAR* AdditionalCommandline = nullptr); /** * Pre-Initialize the main loop - parse command line, sets up GIsEditor, etc. * * @param CmdLine The command line. * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ int32 PreInit(const TCHAR* CmdLine); /** First part of PreInit. */ int32 PreInitPreStartupScreen(const TCHAR* CmdLine); /** Second part of PreInit. */ int32 PreInitPostStartupScreen(const TCHAR* CmdLine); /** Load all modules needed before Init. */ void LoadPreInitModules(); /** Load core modules. */ bool LoadCoreModules(); /** Clean up PreInit context. */ void CleanupPreInitContext(); #if WITH_ENGINE /** Load all core modules needed at startup time. */ bool LoadStartupCoreModules(); /** Load all modules needed at startup time. */ bool LoadStartupModules(); /** * Initialize the main loop (the rest of the initialization). * * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ virtual int32 Init() override; /** Initialize the timing options from the command line. */ void InitTime(); /** Performs shut down. */ void Exit(); /** Whether the engine should operate in an idle mode that uses no CPU or GPU time. */ bool ShouldUseIdleMode() const; // Advances the main loop.推进主循环 virtual void Tick() override; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() override; #endif // WITH_ENGINE /** RHI post-init initialization */ static void PostInitRHI(); /** Pre-init HMD device (if necessary). */ static void PreInitHMDDevice(); public: /** Initializes the application. */ static bool AppInit(); /** * Prepares the application for shutdown. * * This function is called from within guarded exit code, only during non-error exits. */ static void AppPreExit(); /** * Shuts down the application. * * This function called outside guarded exit code, during all exits (including error exits). */ static void AppExit(); private: /** Utility function that processes Slate operations. */ void ProcessLocalPlayerSlateOperations() const; protected: /** Holds a dynamically expanding array of frame times in milliseconds (if FApp::IsBenchmarking() is set). */ TArray\u0026lt;float\u0026gt; FrameTimes; /** Holds the total time spent ticking engine. */ double TotalTickTime; /** Holds the maximum number of seconds engine should be ticked. */ double MaxTickTime; /** Holds the maximum number of frames to render in benchmarking mode. */ uint64 MaxFrameCounter; /** Holds the number of cycles in the last frame. */ uint32 LastFrameCycles; #if WITH_ENGINE /** Holds the objects which need to be cleaned up when the rendering thread finishes the previous frame. */ FPendingCleanupObjects* PendingCleanupObjects; #endif //WITH_ENGINE private: #if WITH_ENGINE /** Holds the engine service. */ FEngineService* EngineService; /** Holds the application session service. */ TSharedPtr\u0026lt;ISessionService\u0026gt; SessionService; #endif // WITH_ENGINE FPreInitContext PreInitContext; }; 该文件只需#include \u0026quot;CoreMinimal.h\u0026quot;，最多加上#include \u0026quot;UnrealEngine.h\u0026quot;\n接口类，位于路径Engine\\Source\\Runtime\\Engine\\Public\\UnrealEngine.h：\n1 2 3 4 5 6 7 8 9 /** Public interface to FEngineLoop so we can call it from editor or editor code */ class IEngineLoop { public: virtual int32 Init() = 0; virtual void Tick() = 0; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() = 0; }; 开启Tick函数之前需要初始化，初始化函数在Launch.cpp这个文件中：\n1 2 3 4 5 6 /* Inits the engine loop */ int32 EngineInit() { int32 ErrorLevel = GEngineLoop.Init(); return( ErrorLevel ); } GEngineLoop.Init()函数：\n其中会判断是进入那种引擎模式，分为Game模式与Editor模式。\n结束引擎的函数为：\n1 2 3 4 5 6 7 8 9 10 /** * Shuts down the engine */ void EngineExit( void ) { // Make sure this is set RequestEngineExit(TEXT(\u0026#34;EngineExit() was called\u0026#34;)); GEngineLoop.Exit(); } 也在Launch.cpp\nLaunch.cpp中的函数多次使用GEngine这个外部变量，这个变量在上面的初始化函数会自定设置为相应的引擎，即Game引擎或者Editor引擎：\n所在文件Engine.h\n在FEngineLoop::Tick()函数会调用GEngine的Tick函数：\n也就是本文开始的那个Tick函数。\n","description":"","id":67,"section":"posts","tags":["C++","UE4","Game"],"title":"UE游戏、渲染线程","uri":"https://hugo.jiahongw.com/posts/ue/ue-game-render/"},{"content":"UE4问题汇总 UE4光照构建失败⚠️\nhttps://blog.csdn.net/earlyAutumnOfRain/article/details/80863561\nUE4导入灰度图\nhttps://www.cnblogs.com/gucheng/p/10116857.html\n详解UE4静态库与动态库的导入与使用\nhttps://gameinstitute.qq.com/community/detail/121551\nUe4_序列化浅析_\nhttps://blog.csdn.net/mohuak/article/details/83027211\nUE快捷键\nhttps://www.unrealengine.com/zh-CN/tech-blog/designer-s-guide-to-unreal-engine-keyboard-shortcuts\nUE4资源加载（一）从StaticLoadObject开始\nhttp://suo.im/6v7hUc\nUnreal Cookbook：创建对象的的几种姿势（C++）\nhttps://blog.csdn.net/Neil3D/article/details/51488401\nAery的UE4 C++游戏开发之旅（1）基础对象模型\nhttps://www.cnblogs.com/KillerAery/p/11986316.html\n目录结构\nhttps://docs.unrealengine.com/zh-CN/Engine/Basics/DirectoryStructure/index.html\n引擎世界\nhttps://www.engineworld.cn/\n《InsideUE4》GamePlay架构（一）Actor和Component\nhttps://zhuanlan.zhihu.com/p/22833151\n实时渲染中的坐标系变换（5）：投影变换-3\nhttps://zhuanlan.zhihu.com/p/115395322\nUE4 屏幕坐标转换到世界坐标\nhttps://blog.csdn.net/weixin_36412907/article/details/77306212\nUE4必读文章列表_个人整理\nhttps://zhuanlan.zhihu.com/p/126611976\nOpenGL 学习系列\u0026mdash;投影矩阵\nhttps://juejin.im/post/5b0ec5fef265da092a2b79b1\nAlpha Test\nhttp://geekfaner.com/shineengine/blog13_OpenGLESv2_12.html\nRendoc使用\nhttps://www.cnblogs.com/kekec/p/11760288.html\n[多视图几何] - 逆透视变换\nhttps://blog.csdn.net/chishuideyu/article/details/79136903\nUE4必读文章列表_个人整理\nhttps://zhuanlan.zhihu.com/p/126611976\nUE4中的Tone Mapping\nhttps://www.dingshukai.com/blog/ue4-tone-mapping.html\nUE4 渲染流程\nhttps://blog.csdn.net/or_7r_ccl/article/details/81102771\n[UE4]尝试使用自定义深度 fq\nhttp://monsho.blog63.fc2.com/blog-entry-138.html#comment469\n[UE4]扩展GBuffer\nhttp://monsho.blog63.fc2.com/blog-entry-191.html\nhttps://ue4study-osaka.connpass.com/event/120568/\nUE4文件系统 模块是UE4的构建块。引擎是以大量模块的集合形式实现的，游戏提供自己的模块来扩充自己。每个模块都封装了一组功能，并且可以提供公共接口和编译环境（包括宏、路径等）供其他模块使用。\n.build.cs文件的典型结构如下。\n1 2 3 4 5 6 7 8 9 using UnrealBuildTool; using System.Collections.Generic; public class MyModule : ModuleRules { public MyModule(ReadOnlyTargetRules Target) : base(Target) { // Settings go here } } \\Engine\\Source\\ThirdParty目录\n存放第三方的库\nF:\\UnrealEngine4.14\\Engine\\Plugins目录(或者F:\\UE4Project\\项目名称\\Plugins目录)\n保存插件的目录\nUE创世，万物皆UObject，接着有Actor。\nComponent和Actor UE4让Actor们轻装上阵，只提供一些通用的基本生存能力，而把众多的“技能”抽象成了一个个“Component”并提供组装的接口，让Actor随用随组装，把自己武装成一个个专业能手。\n相关组件 RootComponent 定义这个演员在世界上的变换(位置、旋转、缩放)的组件，所有其他组件必须以某种方式附加到这个组件\n弹簧臂组件 弹簧臂组件用于自动控制摄像机受阻时的应对方式。\nUE文件存储的方式 UE 中使用统一的格式存储资源 (uasset， umap)，每个 uasset 对应一个包 (package)，存储一个 UPackage 对象时，会将该包下的所有对象都存到 uasset 中。\n一个资源在文件中对应uasset，在内存中对应为UPackage。\nuasset文件格式 File Summary 文件头信息 Name Table 包中对象的名字表 Import Table 存放被该包中对象引用的其它包中的对象信息(路径名和类型) Export Table 该包中的对象信息(路径名和类型) Export Objects 所有Export Table中对象的实际数据。 FlinkerLoad FLinkerLoad是作为uasset和内存UPackage的中间桥梁。在加载内容生成UPackage的时候，UPackage会根据名字找到uasset文件，由FLinkerLoad来负责加载。\nFLinkerLoad主要内容如下：\nFArchive* Loader;\t//Loader负责读取具体文件 TArray ImportMap; //将uasset的ImportTable加载到ImportMap中，FObjectImport是需要依赖（导入）的UObject TArray ExportMap; //FObjectExport是这个UPackage所拥有的UObject（这些UObject都能提供给其他UPackage作为Import） StaticLoadObject加载 步骤：\n根据文件名字创建一个空的包（没有任何文件相关的数据） 建立一个LinkerLoad去加载对应的uasset文件 序列化。 优先加载ImportMap 加载ExportMap（本身的数据） 1、建立一个UPackage\n2、序列化uasset\n3、加载ImportMap\nPawn默认组件 UE相机 http://www.geodesic.games/2019/03/27/projection-matrices-in-unreal-engine/\nFirstly, Unreal inverses the perspective divide, applying 1 instead of -1 for the “W” value.（虚幻处理投影与 Unity 中使用的标准 OpenGL 透视矩阵不同。） Secondly, Unreal applies a matrix transposition to all their perspective matrices.（其次，Unreal 对所有的透视矩阵进行了矩阵移位。 缺省情况下，Unreal 提供了各种方便的透视矩阵构造函数。 有两种变体，一种是普通透视矩阵，另一种是逆向透视矩阵。 右手坐标系： https://zhuanlan.zhihu.com/p/114729671\n透视投影：\n归一化齐次坐标以后的结果是：\ncamera space 3D空间中，相同的x，z越大，投影变换以后的x分量越靠近0。\u0026ldquo;近大远小\u0026quot;的透视效果，就是这么算出来的。\nUnity的投影矩阵，是把视锥内的所有3D坐标，转换到 [-1,1] 范围之内。最后转化为Screen Space，范围为[0,1]\n深度值是到近平面的距离：\n正交投影：\n透视投影变换，有\u0026quot;近大远小\u0026quot;的透视效果。3D空间中的两条平行线，在投影变换以后会相交于某个\u0026quot;灭点\u0026rdquo;。\n正交投影变换，没有\u0026quot;近大远小\u0026quot;的透视效果。3D空间中的两条平行线，在投影变换以后，仍旧是平行的。\nUnreal 正交矩阵：\nUE4里的透视投影矩阵的计算方式，参见引擎源代码的OrthoMatrix.h文件。\n代码1：\n1 UGameplayStatics::DeprojectScreenToWorld(UGameplayStatics::GetPlayerController(GetWorld(), 0), forwardCursorPos, forwardWorldPos, forwardMoveDirection); 代码2：\n1 2 3 FVector forwardMoveDirection; GetWorld()-\u0026gt;GetFirstPlayerController()-\u0026gt;GetMousePosition(forwardCursorPos.X, forwardCursorPos.Y); UGameplayStatics::DeprojectScreenToWorld(UGameplayStatics::GetPlayerController(GetWorld(), 0), forwardCursorPos, forwardWorldPos, forwardMoveDirection); APlayerController 玩家控制器被人类玩家用来控制棋子。地址 ULocalPlayer 当前客户端上的每个玩家都有一个LocalPlayer。地址 FViewportClient 视窗客户端的抽象接口。地址 ViewportClient 在玩家中包含此玩家视图的主视窗.。 地址 ULocalPlayer::GetProjectionData 用于导出投影所需的各种数据位的辅助函数。 地址 bianxngjing:\nhttps://v.qq.com/x/page/t0770a2b6f6.html\nAPI UGameplayStatics::DeprojectScreenToWorld Unity 与 NGUI 坐标转换原理 将给定的2D屏幕空间坐标转换为3D世界空间点和方向。\nAPI地址： https://docs.unrealengine.com/en-US/API/Runtime/Engine/Kismet/UGameplayStatics/DeprojectScreenToWorld/index.html\n语法：\n1 2 3 4 5 6 7 static bool DeprojectScreenToWorld ( APlayerController const * Player,\t// 玩家视角 const FVector2D \u0026amp; ScreenPosition,\t// 2D点 FVector \u0026amp; WorldPosition,\t// 世界空间三维坐标 输出 FVector \u0026amp; WorldDirection\t// 在给定的2d点上远离相机的世界空间方向矢量。\t输出 ) 源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 bool UGameplayStatics::DeprojectScreenToWorld(APlayerController const* Player, const FVector2D\u0026amp; ScreenPosition, FVector\u0026amp; WorldPosition, FVector\u0026amp; WorldDirection) { // 获取LocalPlayer ULocalPlayer* const LP = Player ? Player-\u0026gt;GetLocalPlayer() : nullptr; if (LP \u0026amp;\u0026amp; LP-\u0026gt;ViewportClient) {//ViewpoetClient 包含此玩家视图的主视窗。 // get the projection data FSceneViewProjectionData ProjectionData; //立体渲染通过。FULL表示此过程中未启用立体渲染，eSSP_FULL if (LP-\u0026gt;GetProjectionData(LP-\u0026gt;ViewportClient-\u0026gt;Viewport, eSSP_FULL, /*out*/ ProjectionData)) {// 获取投影数据 FMatrix const InvViewProjMatrix = ProjectionData.ComputeViewProjectionMatrix().InverseFast(); FSceneView::DeprojectScreenToWorld(ScreenPosition, ProjectionData.GetConstrainedViewRect(), InvViewProjMatrix, /*out*/ WorldPosition, /*out*/ WorldDirection); return true; } } // something went wrong, zero things and return false，错误不管 WorldPosition = FVector::ZeroVector; WorldDirection = FVector::ZeroVector; return false; } 逆透视变换 投影矩阵：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 // Projection data for a FSceneView struct FSceneViewProjectionData { FVector ViewOrigin;\t//源视图向量 /** Rotation matrix transforming from world space to view space. */ FMatrix ViewRotationMatrix;\t// 从世界空间到视图空间的旋转矩阵转换。 /** UE4 projection matrix projects such that clip space Z=1 is the near plane, and Z=0 is the infinite far plane. */ FMatrix ProjectionMatrix;\t// UE4投影矩阵投影使得剪辑空间Z=1是近平面，Z=0是无限远平面。 protected: //The unconstrained (no aspect ratio bars applied) view rectangle (also unscaled) FIntRect ViewRect;\t// 无约束(未应用宽高比条)视图矩形(也未缩放) // The constrained view rectangle (identical to UnconstrainedUnscaledViewRect if aspect ratio is not constrained) FIntRect ConstrainedViewRect;\t// 受约束的视图矩形(如果长宽比不受约束，则与UnconstrainedUnscaledViewRect相同) public: void SetViewRectangle(const FIntRect\u0026amp; InViewRect) { ViewRect = InViewRect; ConstrainedViewRect = InViewRect; } void SetConstrainedViewRectangle(const FIntRect\u0026amp; InViewRect) { ConstrainedViewRect = InViewRect; } // 上面两个函数设置Rect窗口 bool IsValidViewRectangle() const {//判断窗口是否有效 return (ConstrainedViewRect.Min.X \u0026gt;= 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Min.Y \u0026gt;= 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Width() \u0026gt; 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Height() \u0026gt; 0); } bool IsPerspectiveProjection() const {// 判断是不是透视投影矩阵 return ProjectionMatrix.M[3][3] \u0026lt; 1.0f; } const FIntRect\u0026amp; GetViewRect() const { return ViewRect; } const FIntRect\u0026amp; GetConstrainedViewRect() const { return ConstrainedViewRect; } FMatrix ComputeViewProjectionMatrix() const {// 计算视图投影矩阵 return FTranslationMatrix(-ViewOrigin) * ViewRotationMatrix * ProjectionMatrix; } }; 上面平移矩阵：\n1 2 3 4 5 6 7 8 FORCEINLINE FTranslationMatrix::FTranslationMatrix(const FVector\u0026amp; Delta)\t//基于给定向量的构造函数转换矩阵，//转置矩阵 : FMatrix( FPlane(1.0f,\t0.0f,\t0.0f,\t0.0f), FPlane(0.0f,\t1.0f,\t0.0f,\t0.0f), FPlane(0.0f,\t0.0f,\t1.0f,\t0.0f), FPlane(Delta.X,\tDelta.Y,Delta.Z,1.0f) ) { } 难点一：GetProjectionData函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 bool ULocalPlayer::GetProjectionData(FViewport* Viewport, EStereoscopicPass StereoPass, FSceneViewProjectionData\u0026amp; ProjectionData) const { // If the actor //Size为分配给此玩家的主视口子区域的大小。0-1 // Viewport-\u0026gt;GetSizeXY()获取视端的X与Y if ((Viewport == NULL) || (PlayerController == NULL) || (Viewport-\u0026gt;GetSizeXY().X == 0) || (Viewport-\u0026gt;GetSizeXY().Y == 0) || (Size.X == 0) || (Size.Y == 0)) { return false; } // 将浮点数转换为截断值接近零的整数。即向下取整 // Origin为分配给该玩家的主视口子区域左上角的坐标。0-1 int32 X = FMath::TruncToInt(Origin.X * Viewport-\u0026gt;GetSizeXY().X); int32 Y = FMath::TruncToInt(Origin.Y * Viewport-\u0026gt;GetSizeXY().Y); // 加上视端初始的坐标值 X += Viewport-\u0026gt;GetInitialPositionXY().X; Y += Viewport-\u0026gt;GetInitialPositionXY().Y; //新的窗口大小 uint32 SizeX = FMath::TruncToInt(Size.X * Viewport-\u0026gt;GetSizeXY().X); uint32 SizeY = FMath::TruncToInt(Size.Y * Viewport-\u0026gt;GetSizeXY().Y); //X=0,Y = 0 #if !(UE_BUILD_SHIPPING || UE_BUILD_TEST) // We expect some size to avoid problems with the view rect manipulation // 我们希望有一定的大小来避免view rect操作的问题 if(SizeX \u0026gt; 50 \u0026amp;\u0026amp; SizeY \u0026gt; 50) { int32 Value = CVarViewportTest.GetValueOnGameThread();\t//根据value的值分类各种视端 if(Value) { int InsetX = SizeX / 4; int InsetY = SizeY / 4; // this allows to test various typical view port situations (todo: split screen) // 这允许测试各种典型的视图端口情况(todo:分割屏幕) switch(Value) { case 1: X += InsetX; Y += InsetY; SizeX -= InsetX * 2; SizeY -= InsetY * 2;break; case 2: Y += InsetY; SizeY -= InsetY * 2; break; case 3: X += InsetX; SizeX -= InsetX * 2; break; case 4: SizeX /= 2; SizeY /= 2; break; case 5: SizeX /= 2; SizeY /= 2; X += SizeX;\tbreak; case 6: SizeX /= 2; SizeY /= 2; Y += SizeY; break; case 7: SizeX /= 2; SizeY /= 2; X += SizeX; Y += SizeY; break; } } } #endif // FIntRect为二维空间中整数矩形的结构。新的视端矩阵 FIntRect UnconstrainedRectangle = FIntRect(X, Y, X+SizeX, Y+SizeY);//InMin(X,Y),InMax(X+SizeX,Y+SizeY) // 设置投影数据的窗口 ProjectionData.SetViewRectangle(UnconstrainedRectangle); // Get the viewpoint. // 获得视点 FMinimalViewInfo ViewInfo; //结构 /** enum EStereoscopicPass { eSSP_FULL, eSSP_LEFT_EYE, eSSP_RIGHT_EYE, eSSP_LEFT_EYE_SIDE, eSSP_RIGHT_EYE_SIDE, } **/ GetViewPoint(/*out*/ ViewInfo, StereoPass);\t//检索该玩家的视点。 // If stereo rendering is enabled, update the size and offset appropriately for this pass // 如果启用了立体渲染，请为此过程适当更新大小和偏移 const bool bNeedStereo = IStereoRendering::IsStereoEyePass(StereoPass) \u0026amp;\u0026amp; GEngine-\u0026gt;IsStereoscopic3D(); const bool bIsHeadTrackingAllowed = GEngine-\u0026gt;XRSystem.IsValid() \u0026amp;\u0026amp; GEngine-\u0026gt;XRSystem-\u0026gt;IsHeadTrackingAllowed(); if (bNeedStereo) { GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;AdjustViewRect(StereoPass, X, Y, SizeX, SizeY); } // scale distances for cull distance purposes by the ratio of our current FOV to the default FOV // 根据我们当前的FOV与默认FOV的比率，为选择距离的目的缩放距离 PlayerController-\u0026gt;LocalPlayerCachedLODDistanceFactor = ViewInfo.FOV / FMath::Max\u0026lt;float\u0026gt;(0.01f, (PlayerController-\u0026gt;PlayerCameraManager != NULL) ? PlayerController-\u0026gt;PlayerCameraManager-\u0026gt;DefaultFOV : 90.f); FVector StereoViewLocation = ViewInfo.Location; // 加入立体渲染或者 if (bNeedStereo || bIsHeadTrackingAllowed) {// 假如启用了立体渲染和头部追踪 auto XRCamera = GEngine-\u0026gt;XRSystem.IsValid() ? GEngine-\u0026gt;XRSystem-\u0026gt;GetXRCamera() : nullptr;\t//虚拟现实相机 if (XRCamera.IsValid()) { AActor* ViewTarget = PlayerController-\u0026gt;GetViewTarget(); const bool bHasActiveCamera = ViewTarget \u0026amp;\u0026amp; ViewTarget-\u0026gt;HasActiveCameraComponent(); XRCamera-\u0026gt;UseImplicitHMDPosition(bHasActiveCamera); } if (GEngine-\u0026gt;StereoRenderingDevice.IsValid()) { GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;CalculateStereoViewOffset(StereoPass, ViewInfo.Rotation, GetWorld()-\u0026gt;GetWorldSettings()-\u0026gt;WorldToMeters, StereoViewLocation); } } // Create the view matrix // 创建视图矩阵 // FPlane 三维平面的结构。(X,Y,Z,W) // FMatrix 浮点值的4x4矩阵。 ProjectionData.ViewOrigin = StereoViewLocation; ProjectionData.ViewRotationMatrix = FInverseRotationMatrix(ViewInfo.Rotation) * FMatrix( FPlane(0,\t0,\t1,\t0), FPlane(1,\t0,\t0,\t0), FPlane(0,\t1,\t0,\t0), FPlane(0,\t0,\t0,\t1)); // @todo viewext this use case needs to be revisited // 重新考虑viewext if (!bNeedStereo)\t//假如没有立体渲染 { // Create the projection matrix (and possibly constrain the view rectangle) // 创建投影矩阵(并可能约束视图矩形) // ViewInfo视点 FMinimalViewInfo::CalculateProjectionMatrixGivenView(ViewInfo, AspectRatioAxisConstraint, Viewport, /*inout*/ ProjectionData);//计算给定视图投影矩阵 // 视图扩展对象可以在没有运动控制器组件的情况下保留在渲染线程上，大概是设置相关试图拓展的投影矩阵 for (auto\u0026amp; ViewExt : GEngine-\u0026gt;ViewExtensions-\u0026gt;GatherActiveExtensions()) { ViewExt-\u0026gt;SetupViewProjectionMatrix(ProjectionData); }; } else {\t// 有三维渲染 // Let the stereoscopic rendering device handle creating its own projection matrix, as needed // 让立体渲染设备根据需要处理创建自己的投影矩阵，调用一系列函数GetProjectMatrix ProjectionData.ProjectionMatrix = GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;GetStereoProjectionMatrix(StereoPass); // calculate the out rect ProjectionData.SetViewRectangle(FIntRect(X, Y, X + SizeX, Y + SizeY)); } return true; } 难点：计算给定视图投影矩阵\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 void FMinimalViewInfo::CalculateProjectionMatrixGivenView(const FMinimalViewInfo\u0026amp; ViewInfo, TEnumAsByte\u0026lt;enum EAspectRatioAxisConstraint\u0026gt; AspectRatioAxisConstraint, FViewport* Viewport, FSceneViewProjectionData\u0026amp; InOutProjectionData) { // Create the projection matrix (and possibly constrain the view rectangle) // 创建投影矩阵(并可能约束视图矩形) if (ViewInfo.bConstrainAspectRatio) { // Enforce a particular aspect ratio for the render of the scene. // Results in black bars at top/bottom etc. InOutProjectionData.SetConstrainedViewRectangle(Viewport-\u0026gt;CalculateViewExtents(ViewInfo.AspectRatio, InOutProjectionData.GetViewRect())); InOutProjectionData.ProjectionMatrix = ViewInfo.CalculateProjectionMatrix(); } else { // Avoid divide by zero in the projection matrix calculation by clamping FOV float MatrixFOV = FMath::Max(0.001f, ViewInfo.FOV) * (float)PI / 360.0f; float XAxisMultiplier; float YAxisMultiplier; const FIntRect\u0026amp; ViewRect = InOutProjectionData.GetViewRect(); const int32 SizeX = ViewRect.Width(); const int32 SizeY = ViewRect.Height(); // if x is bigger, and we\u0026#39;re respecting x or major axis, AND mobile isn\u0026#39;t forcing us to be Y axis aligned if (((SizeX \u0026gt; SizeY) \u0026amp;\u0026amp; (AspectRatioAxisConstraint == AspectRatio_MajorAxisFOV)) || (AspectRatioAxisConstraint == AspectRatio_MaintainXFOV) || (ViewInfo.ProjectionMode == ECameraProjectionMode::Orthographic)) { //if the viewport is wider than it is tall XAxisMultiplier = 1.0f; YAxisMultiplier = SizeX / (float)SizeY; } else { //if the viewport is taller than it is wide XAxisMultiplier = SizeY / (float)SizeX; YAxisMultiplier = 1.0f; } if (ViewInfo.ProjectionMode == ECameraProjectionMode::Orthographic) {\t//判断投影模式 const float OrthoWidth = ViewInfo.OrthoWidth / 2.0f * XAxisMultiplier; const float OrthoHeight = (ViewInfo.OrthoWidth / 2.0f) / YAxisMultiplier; const float NearPlane = ViewInfo.OrthoNearClipPlane; const float FarPlane = ViewInfo.OrthoFarClipPlane; const float ZScale = 1.0f / (FarPlane - NearPlane); const float ZOffset = -NearPlane; InOutProjectionData.ProjectionMatrix = FReversedZOrthoMatrix( // 计算反向Z正交矩阵 OrthoWidth, OrthoHeight, ZScale, ZOffset );\t} else { InOutProjectionData.ProjectionMatrix = FReversedZPerspectiveMatrix(\t// 反转Z透视矩阵 MatrixFOV, MatrixFOV, XAxisMultiplier, YAxisMultiplier, GNearClippingPlane, GNearClippingPlane ); } } if (!ViewInfo.OffCenterProjectionOffset.IsZero()) { const float Left = -1.0f + ViewInfo.OffCenterProjectionOffset.X; const float Right = Left + 2.0f; const float Bottom = -1.0f + ViewInfo.OffCenterProjectionOffset.Y; const float Top = Bottom + 2.0f; InOutProjectionData.ProjectionMatrix.M[2][0] = (Left + Right) / (Left - Right); InOutProjectionData.ProjectionMatrix.M[2][1] = (Bottom + Top) / (Bottom - Top); } } 反向Z正交：\n1 2 3 4 5 6 7 8 FORCEINLINE FReversedZOrthoMatrix::FReversedZOrthoMatrix(float Width,float Height,float ZScale,float ZOffset) : FMatrix( FPlane((Width != 0.0f) ? (1.0f / Width) : 1.0f, 0.0f, 0.0f, 0.0f), FPlane(0.0f, (Height != 0.0f) ? (1.0f / Height) : 1.f, 0.0f, 0.0f), FPlane(0.0f, 0.0f, -ZScale, 0.0f), FPlane(0.0f, 0.0f, 1.0f - ZOffset * ZScale, 1.0f) ) { } 难点2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 void FSceneView::DeprojectScreenToWorld(const FVector2D\u0026amp; ScreenPos, const FIntRect\u0026amp; ViewRect, const FMatrix\u0026amp; InvViewProjMatrix, FVector\u0026amp; out_WorldOrigin, FVector\u0026amp; out_WorldDirection) { float PixelX = FMath::TruncToFloat(ScreenPos.X); float PixelY = FMath::TruncToFloat(ScreenPos.Y); // Get the eye position and direction of the mouse cursor in two stages (inverse transform projection, then inverse transform view). // //分两个阶段获取鼠标光标的眼睛位置和方向(逆变换投影，然后逆变换视图)。 // This avoids the numerical instability that occurs when a view matrix with large translation is composed with a projection matrix // //这避免了当具有大平移的视图矩阵由投影矩阵组成时出现的数值不稳定性 // Get the pixel coordinates into 0..1 normalized coordinates within the constrained view rectangle // 将像素坐标转换为0..1约束视图矩形内的标准化坐标 const float NormalizedX = (PixelX - ViewRect.Min.X) / ((float)ViewRect.Width()); const float NormalizedY = (PixelY - ViewRect.Min.Y) / ((float)ViewRect.Height()); // Get the pixel coordinates into -1..1 projection space // 将像素坐标转换为-1..1投影空间 const float ScreenSpaceX = (NormalizedX - 0.5f) * 2.0f; const float ScreenSpaceY = ((1.0f - NormalizedY) - 0.5f) * 2.0f; // The start of the ray trace is defined to be at mousex,mousey,1 in projection space (z=1 is near, z=0 is far - this gives us better precision) // //光线跟踪的开始被定义为在投影空间中mousex，mousey，1处(z = 1是近的，z=0是远的-这给了我们更好的精度) // To get the direction of the ray trace we need to use any z between the near and the far plane, so let\u0026#39;s use (mousex, mousey, 0.5) // //为了得到光线轨迹的方向，我们需要使用近平面和远平面之间的任何z，所以让我们使用(mousex，mousey，0.5) const FVector4 RayStartProjectionSpace = FVector4(ScreenSpaceX, ScreenSpaceY, 1.0f, 1.0f); const FVector4 RayEndProjectionSpace = FVector4(ScreenSpaceX, ScreenSpaceY, 0.5f, 1.0f); // Projection (changing the W coordinate) is not handled by the FMatrix transforms that work with vectors, so multiplications // //投影(改变w坐标)不是由处理向量的矩阵变换来处理的，所以乘法 // by the projection matrix should use homogeneous coordinates (i.e. FPlane). // 由投影矩阵应使用齐次坐标(即平面)。 const FVector4 HGRayStartWorldSpace = InvViewProjMatrix.TransformFVector4(RayStartProjectionSpace); const FVector4 HGRayEndWorldSpace = InvViewProjMatrix.TransformFVector4(RayEndProjectionSpace); FVector RayStartWorldSpace(HGRayStartWorldSpace.X, HGRayStartWorldSpace.Y, HGRayStartWorldSpace.Z); FVector RayEndWorldSpace(HGRayEndWorldSpace.X, HGRayEndWorldSpace.Y, HGRayEndWorldSpace.Z); // divide vectors by W to undo any projection and get the 3-space coordinate // //将向量除以w以撤销任何投影并获得3-空间坐标 if (HGRayStartWorldSpace.W != 0.0f) { RayStartWorldSpace /= HGRayStartWorldSpace.W; } if (HGRayEndWorldSpace.W != 0.0f) { RayEndWorldSpace /= HGRayEndWorldSpace.W; } const FVector RayDirWorldSpace = (RayEndWorldSpace - RayStartWorldSpace).GetSafeNormal(); // Finally, store the results in the outputs out_WorldOrigin = RayStartWorldSpace; out_WorldDirection = RayDirWorldSpace; } FPlane:\nFMatrix:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 FORCEINLINE FMatrix::FMatrix(const FPlane\u0026amp; InX,const FPlane\u0026amp; InY,const FPlane\u0026amp; InZ,const FPlane\u0026amp; InW) { M[0][0] = InX.X; M[0][1] = InX.Y; M[0][2] = InX.Z; M[0][3] = InX.W; M[1][0] = InY.X; M[1][1] = InY.Y; M[1][2] = InY.Z; M[1][3] = InY.W; M[2][0] = InZ.X; M[2][1] = InZ.Y; M[2][2] = InZ.Z; M[2][3] = InZ.W; M[3][0] = InW.X; M[3][1] = InW.Y; M[3][2] = InW.Z; M[3][3] = InW.W; } FORCEINLINE FMatrix::FMatrix(const FVector\u0026amp; InX,const FVector\u0026amp; InY,const FVector\u0026amp; InZ,const FVector\u0026amp; InW) { M[0][0] = InX.X; M[0][1] = InX.Y; M[0][2] = InX.Z; M[0][3] = 0.0f; M[1][0] = InY.X; M[1][1] = InY.Y; M[1][2] = InY.Z; M[1][3] = 0.0f; M[2][0] = InZ.X; M[2][1] = InZ.Y; M[2][2] = InZ.Z; M[2][3] = 0.0f; M[3][0] = InW.X; M[3][1] = InW.Y; M[3][2] = InW.Z; M[3][3] = 1.0f; } step1:\nAPI UGameplayStatics::ProjectWorldToScreen 将给定的3D世界空间点转换为其2D屏幕空间坐标。\nAPI地址： https://docs.unrealengine.com/en-US/API/Runtime/Engine/Kismet/UGameplayStatics/ProjectWorldToScreen/index.html\n语法：\n1 2 3 4 5 6 7 static bool ProjectWorldToScreen ( APlayerController const * Player, const FVector \u0026amp; WorldPosition, FVector2D \u0026amp; ScreenPosition, bool bPlayerViewportRelative\t//这是否应该与玩家视窗子区域相关(在分割屏幕中使用玩家附加的小部件时很有用) ) Z-Buffer 用Renderdoc对UE4(PC，DX11）截帧，UE4的版本为4.18. 可以看到UE4一帧画面的渲染过程如下\n获取GBuffer的一种方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 ENQUEUE_UNIQUE_RENDER_COMMAND_ONEPARAMETER( DZRenderSutioBP_InterceptSceneBaseColor, UTexture2D*, vTextureAsset, TextureAsset, { /*if (!IsInRenderingThread()) return;*/ FRHICommandListImmediate\u0026amp; RHICmdList = GRHICommandList.GetImmediateCommandList(); //计数加一避免Render完成后直接清空了GBuffer,但会慢一帧，你猜 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, 1); static const FString ScrollingMessage(TEXT(\u0026#34;Hello World: \u0026#34;)); GEngine-\u0026gt;AddOnScreenDebugMessage(-1, 0.2f, FColor::Red, ScrollingMessage); FSceneRenderTargets\u0026amp; SceneContext = FSceneRenderTargets::Get(RHICmdList); if (SceneContext.GBufferA) { FTexture2DRHIRef vTextTarget = SceneContext.GetGBufferATexture(); FString vSiceStr = FString::Printf(TEXT(\u0026#34;FSceneRenderTargets GBufferA Size = %d*%d\u0026#34;), vTextTarget-\u0026gt;GetSizeX(), vTextTarget-\u0026gt;GetSizeY()); GEngine-\u0026gt;AddOnScreenDebugMessage(-1, 0.2f, FColor::Red, vSiceStr); } //移除 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, -1); } ); How to export FTexture2DRHIRef to png?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class SceneDepthCapture { public: TArray\u0026lt;FLinearColor\u0026gt; sceneDepthData; FIntPoint bufferSize; void SceneDepthCaptureSync() { ENQUEUE_RENDER_COMMAND(ReadSurfaceFloatCommand)( [this](FRHICommandListImmediate\u0026amp; RHICmdList) { FSceneRenderTargets\u0026amp; context = FSceneRenderTargets::Get(RHICmdList); bufferSize = context.GetBufferSizeXY(); FIntRect Rect(0, 0, bufferSize.X, bufferSize.Y); RHICmdList.ReadSurfaceData( context.GetSceneDepthTexture(), Rect, sceneDepthData, FReadSurfaceDataFlags()); }); FlushRenderingCommands(); } }; 使用模块的方式 使用模块\n添加自定义Pass的方法 添加Shader 了解了一个Pass要完成的工作，我们就可以动手实现一个自己的 Pass 了。首先要确定的问题是 Shader。既然要把同一个模型画两次，那必然要用到不同的Shader。关于如何在UE4中添加 Shader，可以参考 DepthPass 的 VS/PS(在DepthRendering.h中) 和 UE4 的官方文档：https://docs.unrealengine.com/en-US/Programming/Rendering/ShaderDevelopment/index.html。MobileBasePass的Shader因为涉及环境光，点光源数等可开关的Defination，所以对应的 C++ 类是以 template 的形式实现的。一般来说自定义 Pass 的 Shader 会继承 FMaterialShader 并用 IMPLEMENT_MATERIAL_SHADER_TYPE 宏来绑定对应的 usf 文件。 可以完全自己写新的 usf 文件，也可以在 FMaterialShader::ModifyCompilationEnvironment() 中应用不同的 SetDefine() 来实现不同的 Shader。需要注意的是 UE4 的 Shader 编译是一个比较漫长的过程，所以最好在 FMaterialShader::ShouldCompilePremutation() 中对材质进行筛选，只编译必要的Shader。否则所有的 Material 都会编译对应的 Shader，效率很低。还有注意 Shader 要在构造函数中绑定需要的 Uniform Buffer，在 GetShaderBinding 中绑定对应的UniformBuffer，否则会出现 ResourceMiss。\n2. 添加 MeshProcessor\n根据对UE4的渲染流程分析我们可以看出，Pass 生成 DrawCall 的主要逻辑是在 MeshProcessor 中完成的。MeshProcessor 是 4.22 中新加入的类名，之前对应的是 DrawingPolicy。添加 MeshProcessor 很简单，只需要继承 FMeshPassProcessor 并复写其 AddMeshBatch() 方法即可。一般我们会在 AddMeshBatch 方法中获取 Material Resource 的信息并对 MeshBatch 做进一步筛选，最后调用 Process 方法绑定 Shader，Mesh 和 Material，计算 Mesh 的 CullMode，ZTest，Zwrite，BlendOP 和 SortKey等等并用 BuildMeshCommands 生成 DrawCall。\n3. 添加 Pass\n所有的 Pass 都可以在 Enum EMeshPass中找到，所以第一步就是在 MeshProcessor.h 的 EMeshPass 中添加对应的 Enum。然后我们要为 Pass 创建对应的 MeshProcessor，我们可以在对应 .cpp 文件中实现对应 MeshProcessor 的 Creator 方法，并定义对应的 FRegisterPassProcessorCreatFunction 在其构造函数中传入对应的 Creator 方法指针和 Pass Enum。这一部分可以参考 MobileBasePass.cpp 最后的 CreateMobileBasePassProcessor 和 RegisterMobileBasePass 部分。之后我们就要在 MobileSceneRenderer 的 Render 方法中插入自定义 Pass 的渲染流程，这一部分主要是一些 Profile 标签和 RHICmdList 的Setup 和 Flush，还有生成 Pass 的多线程 DrawTask。这一部分逻辑可以参考 MobileBasePassRendering.cpp 中的 RenderMobileBasePass 方法。\n","description":"虚幻引擎相关问题","id":68,"section":"talks","tags":[null],"title":"UE4 Problems","uri":"https://hugo.jiahongw.com/talks/ue4-talks/"},{"content":"大概介绍以下UE4的主要渲染过程。\nUE4渲染过程 延迟渲染 所谓延迟渲染，是指将一个场景的几何体（3D模型、多边形）的光照、阴影、质感搁置到一旁，先着手于绘画，然后在后半段再对光照、阴影、质感进行处理的处理方式。即给人一种把原本的多边形先绘制出来的印象，实际上不仅要绘制多边形，前者的参数还需要配合后面光照和阴影的处理。其输出目标，在成为复数缓冲时具有普遍性，但是这里的缓冲我们称之为\u0026quot;物理缓冲\u0026quot;。物体缓冲是指使用后照明和后处理特效的中间过渡环节\n相关术语 RHI\n渲染硬件接口，是为不同平台抽象出不同图形API的一层。所有渲染命令均通过RHI层传递，以转换为适用的渲染器。\n延迟渲染\n虚幻引擎4中的默认渲染器。它因将照明/阴影计算推迟到全屏过程而不是绘制每个网格时而得名。\n顶点工厂\n顶点工厂是封装顶点数据源并链接到顶点着色器上的输入的类。静态网格物体，骨架网格物体和过程网格组件均使用不同的顶点工厂。\n着色器\n在虚幻引擎中，着色器是HLSL代码（以.ush / .usf文件的形式）和材质图的内容的组合。在Unreal中创建材质时，它会根据设置（如着色模式）和用法来编译多个着色器排列。\n渲染数据 相关的渲染的数据包括深度值及一些Gbuffer，如下图：\n几个Pass Z Pre Pass UE4的渲染管道，是在Bass Pass的物体缓冲写出来之前，在仅预处理深度值（Z值）之后，运行Z预阶段。\n事先预处理深度值的目的，是将最终影像和同一深度缓冲的内容结果，在透视前获得。Z预阶段之后的Base Pass则是，参考预先得出的深度值缓冲进行Z预测试，因此通过在最终的画面里不留下像素痕迹（即编写后又被消去的像素），以回避像素着色器的运行。\nBase Pass\n使用Base Pass输出物体缓冲需要注意的两点：\n不绘制没进入视线的对象\n这种\u0026quot;投影剔除\u0026quot;（Frustum Culling），一般是通过CPU端来处理；为了整体覆盖被称为\u0026quot;包围球\u0026quot;（Bounding sphere）的各个3D对象，对象是否在视野内的判定标准，是通过预先设定的包围球来实行的。\n什么程度的剔除会成功，可以通过Stat初始视图（Stat InitViews）指令的\u0026quot;视锥体裁剪基元（Frustum Culled Primitives）\u0026ldquo;进行确认。\n不计算多余的像素\n在图像处理的流程中，使用像素着色器实际处理前，会有运行深度测试（Z 测试）的\u0026quot;Pre Z 测试\u0026quot;这一步骤。从这里着手处理的像素，会因为被某个东西所遮挡而无法绘制出来，这时可以进行撤销处理。\n但是，像半透明对象这种会伴随α测试的绘制、视差遮蔽映射这种像素着色器处理后会重新编写深度值的情况，就不进行Pre Z测试，而通过处理实行分路迂回。\nUE4 绘制策略DrawingPolicy\n绘制策略在UE4渲染中使用很多， 中文也不好翻译。 其实就是根据策略 使用了哪些 着色器 。\n\u0026hellip;\u0026hellip;\u0026hellip;.\nUE4渲染一帧 渲染管道 首先，虚幻的渲染由三个线程共同完成。分别是CPU线程，DRAW线程，和GPU线程。\n知乎：https://zhuanlan.zhihu.com/p/57158725\nRender模块 调用Render()函数在Render模块RendererModule.h中，以下函数：\n1 2 3 4 5 class FRendererModule : public IRendererModule { // 开始渲染视图族 virtual void BeginRenderingViewFamily(FCanvas* Canvas,FSceneViewFamily* ViewFamily) override; } ==谁最终调用了Render？==\n实时渲染流程图： part1:https://i.loli.net/2020/05/30/qU8vN2WZVbt9hkF.jpg\npart2:https://i.loli.net/2020/05/30/3trKVpOMU5sTQfB.jpg\n渲染函数Render 路径：Engine \\ Source \\ Runtime \\ Renderer \\ Private \\ DeferredShadingRenderer.cpp（660）\n函数：FDeferredShadingSceneRenderer :: Render（）渲染路径\n全局系统纹理初始化 DeferredShadingRenderer.cpp（677） GSystemTextures.InitializeTextures（） 保护 必要的渲染目标您是否已确保可以保护的最大目标数目？ DeferredShadingRenderer.cpp（680） GSceneRenderTargets.Allocate（） 初始化每个视口 设置视口显示的对象，选择使用动态阴影时显示的对象，对半透明对象进行排序 DeferredShadingRenderer.cpp（683） InitViews()（） FXSystem预处理 GPU粒子正在被仿真 DeferredShadingRenderer.cpp（758） FXSystem-\u0026gt; PreRender（） 启用Z Pre-Pass时执行的早期Z绘制 不绘制Tile渲染的硬件（移动设备，Android或iOS）对于 PC或PS4，将生成深度缓冲区和HiZ，因此后续绘制速度很快成为？ DeferredShadingRenderer.cpp（768） RenderPrePass（） 安全GBuffer DeferredShadingRenderer.cpp（774） GSceneRenderTargets.AllocGBufferTargets（） 透明光传播量 DeferredShadingRenderer.cpp（779） ClearLPVs（） 使用DBuffer时绘制延期贴图单击此处获取 DBuffer和延期贴图 DeferredShadingRenderer.cpp（796） GCompositionLighting.ProcessBeforeBasePass（） 如有必要，请 在绘制线框图时清除GBuffer透明颜色缓冲区， 有些游戏在发行游戏时无法清除GBuffer或屏幕。 DeferredShadingRenderer.cpp（805） SetAndClearViewGBuffer（） DeferredShadingRenderer.cpp（816） RHICmdList.Clear（） 渲染不透明的对象渲染 项目，这些项目根据它们是Masked还是Default，是否有LightMap等按每种排序顺序进行了精细分类 DeferredShadingRenderer.cpp（828） RenderBasePass（） 清除 GBuffer 的未绘制部分如果事先清除GBuffer，则不必要。 DeferredShadingRenderer.cpp（851） ClearGBufferAtMaxZ（） 绘制 自定义深度请参见此处以获取自定义深度 DeferredShadingRenderer.cpp（860） RenderCustomDepthPass（） 在这里再次模拟GPU粒子除了在这里 处理使用深度缓冲区执行碰撞检测的 粒子外，还对GPU粒子进行排序 DeferredShadingRenderer.cpp（865） 场景-\u0026gt; FXSystem-\u0026gt; PostRenderOpaque（） 为SceneDepthTexture创建一个半分辨率（每个方面为1/4分辨率）的缓冲区 DeferredShadingRenderer.cpp（875） UpdateDownsampledDepthSurface（） 执行阻塞测试 HZB的构建，执行提交 的HZB Attotempkinder的这篇文章指 DeferredShadingRenderer.cpp（881） BeginOcclusionTests（） 开始写 因为有点复杂，所以要写一些细节 DeferredShadingRenderer.cpp（890） 不使用DBuffer绘制延迟的贴图 CompositionLighting.cpp（293） AddDeferredDecalsBeforeLighting（） 在屏幕空间中绘制环境光遮挡 CompositionLighting.cpp（300） AddPostProcessingAmbientOcclusion（） 后期处理环境立方体贴图 CompositionLighting.cpp（305） AddPostProcessingAmbientCubemap（） 到这里为止的一系列处理 DeferredShadingRenderer.cpp（904） GCompositionLighting.ProcessAfterBasePass（） 透明的体积光缓冲液可提高透明度 DeferredShadingRenderer.cpp（908） ClearTranslucentVolumeLighting（） 从此处开始的主要照明设备 收集要绘制的灯光并将其排序 不要投影，不使用灯光功能的灯光将使用“ 基于图块” 绘制（如果可能）如果不能使用“ 基于图块”关于延迟渲染，这是味o，但请参见此处 LightRendering.cpp（312-348） LightRendering.cpp（423） RenderTiledDeferredLighting（） LightRendering.cpp（429） RenderSimpleLightsStandardDeferred（） 它不会阴影，也不会使用灯光功能，但是似乎无法使用TBDR绘制的灯光 被称为标准延迟灯光。 LightRendering.cpp（445） RenderLight（） 如果用于半透明的体积光是有效的，则将每个光注入到体积光中 ，从而在3D纹理上绘制光效果。 LightRendering.cpp（455） InjectTranslucentVolumeLightingArray（） LightRendering.cpp（461） InjectSimpleTranslucentVolumeLightingArray（） 使用灯光功能投射阴影的灯光将单独处理 LightRendering.cpp（468-552） 首先，我在投射阴影时 绘制了一个阴影贴图；在这里我还绘制了一个 半透明的阴影贴图；我记得半透明的当然是傅立叶不透明度贴图。 LightRendering.cpp（495） RenderTranslucentProjectedShadows（） LightRendering.cpp（497） RenderProjectedShadows（） 使用LPV时绘制反射阴影贴图 LightRendering.cpp（508） RenderReflectiveShadowMaps（） 灯光功能图 阴影指示器图 LightRendering.cpp（515） RenderLightFunction（） LightRendering.cpp（522） RenderPreviewShadowsIndicator（） 衰减缓冲器中的分辨 光的衰减信息是否曾经被吸入另一个缓冲器中？ LightRendering.cpp（534） GSceneRenderTargets.FinishRenderingLightAttenuation（） 注入体积光以获得半透明 LightRendering.cpp（541） InjectTranslucentVolumeLighting（） 这 是使用光功能投射阴影的光处理的结束。 LightRendering.cpp（550） RenderLight（） 这 是每个光的LPV 的主要注入照明过程的结尾 LightRendering.cpp（561-593） Lpv-\u0026gt; InjectLightDirect（） 注入体积光以实现环境立方体贴图的半透明 DeferredShadingRenderer.cpp（916） InjectAmbientCubemapTranslucentVolumeLighting（） 过滤体积光以获得半透明 DeferredShadingRenderer.cpp（919） FilterTranslucentVolumeLighting（） LPV传输过程 此外，第921行的注释上写有“ copypimis”，例如“ Clear LPV buffer”。 DeferredShadingRenderer.cpp（924） PropagateLPVs（） 动态天光绘图 DeferredShadingRenderer.cpp（928） RenderDynamicSkyLighting（） 延迟的反射图形 捕获的反射图形而不是屏幕空间 DeferredShadingRenderer.cpp（931） RenderDeferredReflections（） LPV的GI绘图 CompositionLighting.cpp（344） AddPostProcessingLpvIndirect（） 屏幕空间次表面散射（SSSSS）的后处理 CompositionLighting.cpp（347-376） 如果启用了“光轴”，则绘制“光轴遮挡” DeferredShadingRenderer.cpp（953） RenderLightShaftOcclusion（） 大气雾图 DeferredShadingRenderer.cpp（977） RenderAtmosphere（） 绘图雾 这是高度雾吗？ DeferredShadingRenderer.cpp（986） RenderFog（） 画一个半透明的物体 在这里也画一个单独的半透明的东西 DeferredShadingRenderer.cpp（1000） RenderTranslucency（） 折射变形处理 DeferredShadingRenderer.cpp（1008） RenderDistortion（） 光轴的起霜处理 DeferredShadingRenderer.cpp（1013） RenderLightShaftBloom（） 距离场AO处理不能在 当前不支持多个视口 的分屏游戏中使用吗？ DeferredShadingRenderer.cpp（1019） RenderDistanceFieldAOSurfaceCache（） 它只是在查看网格的“距离场”的可视化处理结果吗？ DeferredShadingRenderer.cpp（1024） RenderMeshDistanceFieldVisualization（） 由于速度模糊而绘制运动对象的速度 DeferredShadingRenderer.cpp（1034） RenderVelocities（） 从这里到最后的发布过程， 这也很复杂而且很长 DeferredShadingRenderer.cpp（1047） GPostProcessing.Process（） 使用BeforeTranslucency设置绘制后处理材料 PostProcessing.cpp（878） AddPostProcessMaterial（） 景深处理 通过高斯模糊进行DOF 处理之后，正在执行散焦处理（使用指定的光圈形状的纹理进行绘制）， 在此阶段似乎合并了单独的半透明缓冲区 PostProcessing.cpp（888） AddPostProcessDepthOfFieldGaussian（） PostProcessing.cpp（898） AddPostProcessDepthOfFieldBokeh（） PostProcessing.cpp（905） FRCPassPostProcessBokehDOFRecombine （如果未启用模糊） 使用BeforeTonemapping设置绘制后处理材料 PostProcessing.cpp（913） AddPostProcessMaterial（） 如果要使用TemporalAA ，请在此处绘制，如果使用FXAA，请稍后再绘制 PostProcessing.cpp（921） AddTemporalAA（） PostProcessing.cpp（928） AddTemporalAA（） （如果不使用速度缓冲区，请单击此处） 运动模糊处理 设置，分辨率下采样，高斯模糊，运动模糊绘制，组合处理 PostProcessing.cpp（932-994） FRCPassPostProcessMotionBlurSetup FRCPassPostProcessDownsample RenderGaussianBlur（） FRCPassPostProcessMotionBlur FRCPassPostProcessMotionBlurRecombine SceneColor下采样 PostProcessing.cpp（1000） FRCPassPostProcessDownsample 直方图 PostProcessing.cpp（1006-1040） FRCPassPostProcessHistogram FRCPassPostProcessHistogramReduce 此处需要眼睛适应图直方图 PostProcessing.cpp（1046） AddPostProcessEyeAdaptation（） 布卢姆绘图 PostProcessing.cpp（1057） AddBloom（） PostProcessing.cpp（1060-1148） （对于移动设备，请单击此处） 色调映射 仅替换ReplacecingTonemapper设置工程图的一种后处理材料，但是 如果存在该材料，则执行默认色调映射 PostProcessing.cpp（1155） AddSinglePostProcessMaterial（） PostProcessing.cpp（1171） AddTonemapper（） （默认色调映射） 如果启用了FXAA，请在此处处理 PostProcessing.cpp（1177） AddPostProcessAA（） 绘制一些编辑器（如选定的轮廓）， 然后使用AfterTonemapping设置绘制后期处理材料 PostProcessing.cpp（1244） AddPostProcessMaterial（） 用于地下和GBuffer的可视化 调试 PostProcessing.cpp（1246-1254） 用于HMD的后处理 Oculus或Morpheus PostProcessing.cpp（1256-1277） FRCPassPostProcessHMD FRCPassPostProcessMorpheus 之后，调试和高分辨率屏幕截图功能等。 之后，进行后处理并结束！ 谢谢！ PostProcessing.cpp（1279-） 哦，很长。\n参考链接：\n如何在C ++中从UTexture2D读取数据\nhttps://forums.unrealengine.com/development-discussion/c-gameplay-programming/1422920-casting-converting-frhitexture-to-utexture\nUnreal渲染相关的缓冲区\nhttps://qiita.com/mechamogera/items/a0c369a3b853a3042cae\nhttps://answers.unrealengine.com/questions/17862/access-color-and-depth-buffer-of-each-frame.html\nhttps://segmentfault.com/a/1190000012737548\nGbuff数据\n渲染系统概述 图片\n","description":"","id":69,"section":"posts","tags":["C++","UE4","Game"],"title":"UE4渲染过程","uri":"https://hugo.jiahongw.com/posts/ue/ue4-render/"},{"content":"RSA算法 RSA加密算法是一种非对称加密算法，在公开密钥加密和电子商业中被广泛使用。\n对极大整数做因数分解的难度决定了 RSA 算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用 RSA 加密的信息的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的 RSA 钥匙才可能被强力方式破解。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被破解的。\n公钥/双密钥/非对称 加密 涉及到两个密钥的使用:\n一个公钥, 可以被任何人知道，用于加密消息和验证签名 一个私钥, 只有接收方才知道，用于解密消息和创造签名 RSA实现过程 1. 公钥与私钥的产生 生成公钥e和私钥d的步骤如下：\n随意选择两个大的质数$p$和$q$，$p$不等于$q$，计算$n=pq$。 根据欧拉函数，求$r = \\varphi (N) = \\varphi (p)\\varphi (q) = (p - 1)(q - 1)$ 选择一个小于$r$的整数$e$，使$e$与$r$互质。并求得$e$关于$r$的模反元素，命名为$d$(求$d$令$ed \\equiv 1(\\bmod ;r)$)。(模反元素存在，当且仅当$e$与$r$互质) 将$p$和$q$的记录销毁 经过上面四个步骤最终可以得到公钥$(n,e)$和私钥$(n,d)$。\n接收消息的人将自己的公钥$(n,e)$发送给发送消息的人,发送的人使用这个公钥加密信息发送给接收方，而接收方将私钥$(n,d)$保存起来用于解密。\n下面实现RSA类\n参考资料：\n米勒-拉宾素性检验 RSA加密算法 C++实现 实验步骤与结果 1.实现大整数类 因为该加密算法涉及的数可能很大，而C++中并没有像Java一样，内置大整数类BigInteger，故需自己实现，这里我参考了网上的一些资料设计了BigInteger类，实现了加减乘除以及模幂等运算，也实现了运算符重载，具体参考实现的方法如下：\n2. 设计RSA类 编写rsa.h头文件，定义RSA类，其中包含的成员以及成员函数如下：\n下面分别实现上述的各个方法\n首先要生成密钥对，即生成公钥和私钥，那么，我们首先需要生成两个大素数p和q,显然，素数是不可能是偶数的，故定义一个生成随机奇数的函数BigInteger createOddNum(unsigned len)参数为奇数的长度。\n使用16进制的随机字母，然后随机选取其中的len/4个得到一个随机的大奇数，只需要末尾那个数为奇数即可，最后返回BigInteger类型的奇数大整数，关键代码如下：\n然后定义一个生成素数的函数，其中用到米勒-拉宾素性检验算法判断生成的素数是否为素数素数：\n米勒-拉宾素性检测算法 基于以下定理：\n费马小定理 要测试$N$是否为素数，首先将$N−1$分解为$2^{s}d$。在每次测试开始时，先随机选一个介于$[1,N−1]$的整数$a$，之后如果对所有的$r∈[0,s−1]$，若${a^d}\\bmod N \\ne 1$且${a^{{2^r}d}}\\bmod N \\ne - 1$，则$N$是合数。否则，$N$有$3/4$的概率为素数。\n关键代码如下：\n生成素数的逻辑就是首先使用函数createOddNum生成一个大奇数，然后调用isPrime判断是否为一个素数，是的话就可以return，不然继续寻找，知道生成一个素数。\n接下来计算n值，n值的计算很简单，直接使用$n = p * q$ 这个式子就能够计算出来；计算欧拉值也一样，可以使用$\\varphi(n) = (p-1) * (q-1)$得出。其中比较难的是生成的私钥d。\n下面定义一个RSA类的初始化函数init()​，生成p、q以及密钥对，如下：\n在创建公钥e和私钥d的函数createExponent(eul)中，首先创建一个比欧拉值小的公钥e，其中e为一个素数，直接调用函数createPrime()生成，然后使用大整数类中的求模逆元，即求出私钥d。\n扩展欧几里得算法 逆元\n逆元是模运算中的一个概念，我们通常说 A 是 B 模 C 的逆元，实际上是指 A * B = 1 mod C，也就是说 A 与 B 的乘积模 C 的余数为 1。可表示为 A = B^(-1) mod C。\n打个比方，7 模 11 的逆元，即：7^(-1) mod 11 = 8，这是因为 7 × 8 = 5 × 11 + 1，所以说 7 模 11 的逆元是 8。\n扩展欧几里得算法是欧几里得算法（又叫辗转相除法）的扩展。已知整数a、b，扩展欧几里得算法可以在求得a、b的最大公约数的同时，能找到整数x、y（其中一个很可能是负数），使它们满足贝祖等式\n$$\nax{\\rm{ }} + {\\rm{ }}by{\\rm{ }} = {\\rm{ }}gcd\\left( {a,b} \\right).\n$$\n在RSA算法中求私钥中的整数d时，需要使得 (e * d ) % n = 1，该方程等价于 e * d = 1 + y * n （y为整数），也等价于 e * d - y * n = 1。\n因此求解d的过程就是求解该二元一次方程组（e和n已知，求解d），即求e模n的逆元。\n关键代码如下：\n我们知道，RSA的加密与解密其实就是一个模幂的运算，而这个模幂的运算已经在大整数类中实现了，如下：\n使用RSA类进行加密解密的函数只需要调用这个模幂运算即可，例如私钥加密可以这样调用：\n以上就设计完了RSA类的相关操作，主要是包括密钥的生成。下面将RSA加密解密的操作封装在一个类中。\n3. 设计加密解密类EncryptDecrypt 主要的方法及成员如下：\n实现RSA加密解密字符串 加密字符串的逻辑是，先将字符串以每两个字符 一组，转化为一个16进制数据序列，使用vector容器保存，之后调用rsa的公钥加密函数进行加密，如下是关键代码：\n解密函数其实是接受一个加密后的16进制序列，然后对这个序列调用RSA的私钥解密函数进行解密，然后得到解密后的16进制数据序列，最后还有一步就是需要将这个16进制序列最终转化为原来的字符串，只需要根据ascii码的数值即可得到，这里编写了一个hex2string函数，关键代码如下：\n实现效果\n首先显示密钥：\n加密字符串\n解密字符串\n实现RSA加密解密文件 实现RSA加密解密文件时基于RSA加密解密字符串实现的，其中主要的加密逻辑就是将一个文件看作是一行一行的字符串文本，没每读取一行，就调用加密字符串的函数进行加密，然后将加密得到的16进制序列写入到另外一个文件中，而这个文件也就是加密后的文件，主要关键代码如下：\n解密文件的函数稍微有点不一样，是从打开的待解密文件中循环读取每一个16进制数据，然后对每一个16进制数据调用解密函数得到解密后的16进制数据，将16进制数据转为字符串后再相继的写到另外一个文件中，即解密后的文件，关键代码如下：\n实现效果\n加密文件\n解密文件\n加密文件解密文件对比\n实现RSA数字签名及验证 实现数字签名方案，按照以下的流程图进行操作。\n首先需要对文件进行信息的摘要，得到Hash值，这里选择的Hash算法是SHA512算法，可以直接对文件进行信息摘要。\n可以直接include C++ 实现的\u0026quot;sha512.h\u0026quot;文件头，然后使用以下的语句就能够生成一个长度为512的Hash值，如下：\n可以在命令行输出文件的Hash摘要值如下:\n数字签名的实现类似字符串加密，对文件的hash值进行加密得到后面的16进制序列，然后将16进制序列伴随文件发送出去，签名的关键代码就是对hash值进行加密，如下：\n验证函数直接将16进制序列进行解密，然后还原成字符串再与收到的文件的hash值进行比较，如果相等，那么验证成功；否则验证失败，关键代码如下：\n实现效果\n数字签名\n验证数字签名\n","description":"","id":70,"section":"posts","tags":["rsa"],"title":"RSA加密算法","uri":"https://hugo.jiahongw.com/posts/cryptography/rsa/"},{"content":"C++学习路线🌱 hode on!💠\n","description":"","id":71,"section":"talks","tags":["C++"],"title":"C++学习路线","uri":"https://hugo.jiahongw.com/talks/cpp_router/"},{"content":"| 管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理。\ngrep Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。\n语法 grep [选项] 查找内容 源文件 选项参数 -a --text #不要忽略二进制的数据。\n-A\u0026lt;显示行数\u0026gt; --after-context=\u0026lt;显示行数\u0026gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。\n-b --byte-offset #在显示符合样式的那一行之前，标示出该行第一个字符的编号。⭐\n-B\u0026lt;显示行数\u0026gt; --before-context=\u0026lt;显示行数\u0026gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。\n-c --count #计算符合样式的列数。⭐\n-C\u0026lt;显示行数\u0026gt; --context=\u0026lt;显示行数\u0026gt;或-\u0026lt;显示行数\u0026gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。\n-d \u0026lt;动作\u0026gt; --directories=\u0026lt;动作\u0026gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。⭐\n-e\u0026lt;范本样式\u0026gt; --regexp=\u0026lt;范本样式\u0026gt; #指定字符串做为查找文件内容的样式。\n-E --extended-regexp #将样式为延伸的普通表示法来使用。\n-f\u0026lt;规则文件\u0026gt; --file=\u0026lt;规则文件\u0026gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。\n-F --fixed-regexp #将样式视为固定字符串的列表。\n-G --basic-regexp #将样式视为普通的表示法来使用。\n-h --no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。\n-H --with-filename #在显示符合样式的那一行之前，表示该行所属的文件名称。\n-i --ignore-case #忽略字符大小写的差别。⭐\n-l --file-with-matches #列出文件内容符合指定的样式的文件名称。\n-L --files-without-match #列出文件内容不符合指定的样式的文件名称。\n-n --line-number #在显示符合样式的那一行之前，标示出该行的列数编号。\n-q --quiet或--silent #不显示任何信息。\n-r --recursive #此参数的效果和指定“-d recurse”参数相同。\n-s --no-messages #不显示错误信息。\n-v --revert-match #显示不包含匹配文本的所有行。\n-V --version #显示版本信息。\n-w --word-regexp #只显示全字符合的列。\n-x --line-regexp #只显示全列符合的列。\n-y #此参数的效果和指定“-i”参数相同。\n其中标⭐号的为比较常实用的\n查找内容规则 查找内容的规则与正则表达式大同小异。\n^ #锚定行的开始 如：\u0026rsquo;^grep\u0026rsquo;匹配所有以grep开头的行。\n$ #锚定行的结束 如：\u0026lsquo;grep$\u0026lsquo;匹配所有以grep结尾的行。\n. #匹配一个非换行符的字符 如：\u0026lsquo;gr.p\u0026rsquo;匹配gr后接一个任意字符，然后是p。\n*#匹配零个或多个先前字符 如：\u0026rsquo;*grep\u0026rsquo;匹配所有一个或多个空格后紧跟grep的行。\n.* #一起用代表任意字符。\n[] #匹配一个指定范围内的字符，如\u0026rsquo;[Gg]rep\u0026rsquo;匹配Grep和grep。\n[^] #匹配一个不在指定范围内的字符，如：\u0026rsquo;[^A-FH-Z]rep\u0026rsquo;匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。\n\\(..\\) #标记匹配字符，如\u0026rsquo;(love)\u0026rsquo;，love被标记为1。\n\\\u0026lt; #锚定单词的开始，如:\u0026rsquo;\u0026lt;grep\u0026rsquo;匹配包含以grep开头的单词的行。\n\\\u0026gt; #锚定单词的结束，如\u0026rsquo;grep\u0026gt;\u0026lsquo;匹配包含以grep结尾的单词的行。\nx\\{m\\} #重复字符x，m次，如：\u0026lsquo;0{5}\u0026lsquo;匹配包含5个o的行。\nx\\{m,\\} #重复字符x,至少m次，如：\u0026lsquo;o{5,}\u0026lsquo;匹配至少有5个o的行。\nx\\{m,n\\} #重复字符x，至少m次，不多于n次，如：\u0026lsquo;o{5,10}\u0026lsquo;匹配5\u0026ndash;10个o的行。\n\\w #匹配文字和数字字符，也就是[A-Za-z0-9]，如：\u0026lsquo;G\\w*p\u0026rsquo;匹配以G后跟零个或多个文字或数字字符，然后是p。\n\\W #\\w的反置形式，匹配一个或多个非单词字符，如点号句号等。\n\\b #单词锁定符，如: \u0026lsquo;\\bgrep\\b\u0026rsquo;只匹配grep。\n在/etc/profile文件中查找关键字CLASS_PATH所在位置\n查询ssh相关进程\n压缩解压类命令 gzip/gunzip gzip用于压缩文件，gunzip用于解压\n语法：\ngzip文件名（功能描述：压缩文件，只能将文件压缩为*.gz文件）\ngunzip 文件名(.gz结尾)：(功能描述：解压缩文件命令）\n压缩b.txt文件\n解压b.txt.gz压缩文件\nzip/unzip zip用于压缩文件，unzip用于解压的，这个在项目打包发布中很有用的.\n语法：\nzip [选项] XXX.zip 将要压缩的内容（功能描述：压缩文件和目录的命令）\nunzip [选项] XXX.zip (功能描述：解压缩文件）\n加密a.txt文件\n解密a.zip文件\ntar tar指令是打包指令，最后打包后的文件可以是.tar.gz的文件。\n语法：\ntar [选项] XXX.tar.gz 打包的内容（功能描述：打包目录，压缩后的文件格式tar.gz)\n选项参数：\n-A 新增压缩文件到已存在的压缩\n-B 设置区块大小\n-c 建立新的压缩文件\n-d 记录文件的差别\n-r 添加文件到已经压缩的文件\n-u 添加改变了和现有的文件到已经存在的压缩文件\n-x 从压缩的文件中提取文件\n-t 显示压缩文件的内容\n-z 支持gzip解压文件\n-j 支持bzip2解压文件\n-Z 支持compress解压文件\n-v 显示操作过程\n-l 文件系统边界设置\n-k 保留原有文件不覆盖\n-m 保留文件不被覆盖\n-W 确认压缩文件的正确性\n可选参数如下：\n-b 设置区块数目\n-C 切换到指定目录\n-f 指定压缩文件\n--help 显示帮助信息\n--version 显示版本信息\n实例：\n打包/victor文件夹下所有内容，打包后的文件名为victor.tar\n解压victor.tar文件\n打包文件夹/victor并且压缩成data.tar.gz\n将多个文件压缩成a.tar.gz\n将a.tar.gz解压到当前目录\n解压到文件夹/a(文件夹必须存在，不然报错)\n![](https://i.loli.net/2020/04/16/xALa9JldzXuBjRi.png\nhttps://www.cnblogs.com/peida/archive/2012/12/17/2821195.html https://www.cnblogs.com/peida/archive/2012/12/19/2824418.html https://www.cnblogs.com/peida/archive/2012/12/06/2804323.html ","description":"","id":72,"section":"posts","tags":["Linux","grep","tar","gzip"],"title":"Linux实用指令","uri":"https://hugo.jiahongw.com/posts/linux/linux-grep/"},{"content":"每一个用户都是一个个体，每一个个体都属于一个群组，而每一个群组又有区别!\n——Users\nLinux系统是一个多用户多任务的操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。\n添加用户 基本语法 useradd [选项] 用户名 实操 输入以下命令之后创建一个用户victor\n这里我们选项参数什么也没有写，此时会默认在/home目录下创建一个/victor的文件夹用于保存用户victor用户的数据信息。\n当然我们可以指定参数：\n用参数 -d 目录指定用户信息存储的目录，使用命令useradd -d /home/test tom创建用户tom。\n使用-g 用户组指定将当前创建的用户添加到指定的用户组，使用命令useradd -g root wjh将新建用户wjh添加到root用户组。\n给用户设置密码 基本语法 passwd 用户名 实操 给用户victor设置密码(默认密码是不会显示出来的)\n下面可以使用victor这个用户登陆\n默认是不能访问root用户的文件的，因为不在同一个组\n切换用户 基本语法 su - 切换用户名 实操 切换到root。其中低权限用户切换到高权限用户需要输入密码。\n退出切换使用exit\n删除用户 基本语法 userdel [选项] 用户名 其中选项参数可以添加-r，表示删除用户时同时删除保存用户的文件夹。\n实操 删除用户tom\n可以看到之前tom致电给创建的文件夹test并没有删除。\n注意，删除用户必须要root权限，不然删除不了。\n删除用户victor，同时删除其文件夹，victor文件夹消失了\n其他操作 查询用户信息 语法\nid 用户名 如下查询用户root的信息\nroot用户的用户id为0，组id为0，组为0\n查询当前用户 语法\nwhoami 用户组 类似于角色，系统可以对有共性的多个用户进行统一的管理。\n用户组关系图：\n增加组 语法\ngroupadd 组名 增加用户组test\n删除组 语法\ngroupdel 组名 删除用户组test\n修改用户的组 语法\nusermod -g 用户组 用户名 相关配置文件 用户信息文件：/etc/passwd 密码文件： /etc/shadow 用户组文件：/etc/group 用户组密码文件： /etc/gshadow 用户配置文件：\n/etc/login.defs\n/etc/default/useradd 新用户信息文件：/etc/skel 登录信息：/etc/motd /etc/passwd 每一行内容存放一个用户的信息，每个用户信息有7部分组成\nroot​：x:0:0:root:/root:/bin/bash\nroot 用户名 用户登录系统时使用的用户名\nx 密码 密码位\n2 UID 用户标识号\n2 GID 缺省组标识\nroot 注释性描述 例如存放用户全名等信息\n/root 宿主目录 用户登录系统后的缺省目录\n/bin/bash 命令解释器 用户使用的Shell ,默认为bash\nUID分类\n超级用户：（root UID=0）\n普通用户： （UID 500~60000）\n伪用户： （UID 1~499）\n什么是伪用户?\n伪用户与系统和程序服务相关 bin、daemon、shutdown、halt等，任何Linux系统默认都有这些伪用户。\nmail、news、games、apache、ftp、mysql及sshd等，与linux系统的进程相关。\n伪用户通常不需要或无法登录系统\n可以没有宿主目录\n/etc/shadow 每行的含义： 登录名: 加密口令: 最后一次修改时间: 最小时间间隔: 最大时间间隔:警告时间: 不活动时间: 失效时间:标志\n/etc/group 每行含义： 组名: 口令: 组标识号: 组内用户列表\nhttps://www.cnblogs.com/qmfsun/p/3674024.html linux用户管理命令 ","description":"","id":73,"section":"posts","tags":["Linux","用户管理"],"title":"Linux用户管理","uri":"https://hugo.jiahongw.com/posts/linux/linux-users/"},{"content":"在大学时代，Vim 的大名就已如雷贯耳，但由于它陡峭的学习曲线，一直望而却步。等真正开始学习之后，发现并没有想象中的复杂，也没有所谓的瓶颈，只要在实际写代码中强迫自己使用就可以了，无形中就会形成习惯。\n​\t——GeekPlux\n三种模式 正常模式 以 vim 打开一个档案就直接进入一般模式了(这是默认的模式)。正常模式可以使用快捷键。\n编辑模式 按下i, I, o, O, a, A, r, R等任何一个字母之后才会进入编辑模式, 一般来说按i即可.\n命令行模式 在这个模式当中， 可以提供你相关指令，完成读取、存盘、替换、离开 vim 、显示行号等的动作则是在此模式中达成的。\nvi 和vim模式的相互切换\n常用快捷键 使用快捷键在正常模式下输入！\n复制粘贴 拷贝当前行输入yy，然后再按下p键的时候就可以粘贴了。\n复制多行可以输入nyy，其中n为一个数字，例如5yy，即复制当前行向下的5行，同样粘贴也是按p键。\n删除 删除当前行输入dd\n删除多行输入ndd，表示删除当前行向下的n行。\n查找单词 再正常模式下输入/关键字即可查找关键字所在的位置，例如/hello为查找hello这个单词所有的所在位置，输入 n 就是查找下一个。\n设置文件行号 有时候为了看文档更清楚，想要知道每一行的行数，可以先进入命令模式，在输入set nu，即再正常模式下输入:set nu,然后回车。\n取消行号可以输入:set nonu\n移动到底部到首部 有时候需要直接看文档的末尾，可以输入G移动到文件末行。\n而移动到首行则是输入gg，然后回车即可。\n撤销 取消上一次做的操作，输入u。表示undo。\n移动到某行 假如我们要移动到第20行，我们可以这样输入：20 + shift + g\n更多快捷键可以参考：https://zhuanlan.zhihu.com/p/77283813\nVim键盘图\n思维导图：\n","description":"","id":74,"section":"posts","tags":["Linux","Vim"],"title":"Linux编辑利器-Vim","uri":"https://hugo.jiahongw.com/posts/linux/vim-use/"},{"content":"Linux基本操作。🤠\nLinux 目录结构及解释 查看命令行执行完位置：\n1 echo $BASH 命令记录 mkdir mkdir命令 用来创建目录。\n语法：mkdir (选项)(参数)\n主要选项：\n-m\u0026lt;目标属性\u0026gt;或\u0026ndash;mode\u0026lt;目标属性\u0026gt;建立目录的同时设置目录的权限；\n-p或\u0026ndash;parents 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录；\n参数：\n指定要创建的目录列表，多个目录之间用空格隔开。\n创建多层目录：\n1 mkdir a/b/c/d chmod chmod命令用来变更文件或目录的权限。\n语法：chmod(选项)(参数)\n权限范围的表示法如下：\nu User，即文件或目录的拥有者；\ng Group，即文件或目录的所属群组；\no Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；\na All，即全部的用户，包含拥有者，所属群组以及其他用户；\nr 读取权限，数字代号为“4”;\nw 写入权限，数字代号为“2”；\nx 执行或切换权限，数字代号为“1”；\n- 不具任何权限，数字代号为“0”；\ns 特殊功能说明：变更文件或目录的权限。\n例子：\n1 2 3 4 chmod u+x,g+w f01　//为文件f01设置自己可以执行，组员可以写入的权限 chmod u=rwx,g=rw,o=r f01 chmod 764 f01 chmod a+x f01　//对文件f01的u,g,o都设置可执行属性 可以输入命令ll -d 文件名查看文件的权限：\nlinux文件的用户权限的分析图\n例：rwx　rw-　r\u0026ndash;\nr=读取属性　//值＝4\nw=写入属性　//值＝2\nx=执行属性　//值＝1\n对demo.sh执行chmod a+x demo.sh之后，查看其权限，三个组都含x，表示所有用户都能执行：\nShell脚本 shell脚本一般以.sh结尾。如demo.sh：\n1 2 3 #!/bin/bash #This is my First shell echo \u0026#34;Hello World!\u0026#34; 第一行表示脚本的位置\n第二行为注释\n第三行为脚本的命令\n如何执行？在Linux下需要先赋予权限\n1 chmod o+x demo.sh 执行\n1 ./demo.sh 常见的变量\n$0当前程序的名称\n$n当前程序的第 n 个参数,n=1,2,…9\n$* 当前程序的所有参数(不包括程序本身)\n$# 当前程序的参数个数(不包括程序本身)\n$? 命令或程序执行完后的状态，一般返回 0 表示执行成功。\n$UID 当前用户的 ID\n$PWD 当前所在的目录\nIf 条件判断语句 格式：\n1 2 3 4 5 if (表达式) #if ( Variable in Array ) 语句 1 else 语句 2 fi 例：\n1 2 3 4 5 #!/bin/sh NUM=100 if (( $NUM \u0026gt; 4 )) ;then echo “this num is $NUM greater 4 !” fi 参考：\nhttps://wangchujiang.com/linux-command/ ","description":"","id":75,"section":"posts","tags":["Linux","Shell","bash"],"title":"Linux命令与Shell","uri":"https://hugo.jiahongw.com/posts/linux/linux-shell/"},{"content":"C++特性之多态🍄\n静态类型 是指不需要考虑表达式的执行期语义，仅分析程序文本而决定的表达式类型。\n动态类型 是指由一个左值表达式表示的左值所引用的最终派生对象的类型。\n动态绑定与静态绑定 **静态绑定：**编译时绑定，通过对象调用\n**动态绑定：**运行时绑定，通过地址实现\n何时使用动态绑定?\n只有采用“指针-\u0026gt;函数()”或“引用变量.函数()”的方式调用C++类中的虚函数才会执行动态绑定。 对于C++中的非虚函数，因为其不具备动态绑定的特征，所以不管采用什么样的方式调用，都不会执行动态绑定。 总的来所,动态绑定执行的函数只针对虚函数,执行虚函数会动态执行,而非虚函数就直接执行基类类型的函数,也就是说指针类型是什么，就会调用该类型相应的函数。\n例如下面的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 #include \u0026lt;iostream\u0026gt; using namespace std; class Base { public: void func() { cout \u0026lt;\u0026lt; \u0026#34;func() in Base.\u0026#34; \u0026lt;\u0026lt; endl; } virtual void test() { cout \u0026lt;\u0026lt; \u0026#34;test() in Base.\u0026#34; \u0026lt;\u0026lt; endl; } }; class Derived : public Base { void func() { cout \u0026lt;\u0026lt; \u0026#34;func() in Derived.\u0026#34; \u0026lt;\u0026lt; endl; } virtual void test() { cout \u0026lt;\u0026lt; \u0026#34;test() in Derived.\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { Base *b; b = new Derived(); b-\u0026gt;func(); b-\u0026gt;test(); } 输出为:\nfunc() in Base. test() in Derived. 再例如下面的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 class A { public: virtual void func(int val = 1) { std::cout\u0026lt;\u0026lt;\u0026#34;A-\u0026gt;\u0026#34;\u0026lt;\u0026lt;val \u0026lt;\u0026lt;std::endl;} virtual void test() { func();} }; class B : public A { public: void func(int val=0) {std::cout\u0026lt;\u0026lt;\u0026#34;B-\u0026gt;\u0026#34;\u0026lt;\u0026lt;val \u0026lt;\u0026lt;std::endl;} }; int main(int argc ,char* argv[]) { B*p = new B; p-\u0026gt;test(); return 0; } 输出为: B-\u0026gt;1\ntest()是虚函数,p-\u0026gt;test()会动态调用B类中的test()函数,并且,还需要记住一个结论:virtual 函数是动态绑定，而缺省参数值却是静态绑定,绝不重新定义继承而来的缺省参数值！\n虚函数、动态绑定、运行时多态之间的关系 要触发动态绑定，需满足两个条件：\n只有虚函数才能进行动态绑定，非虚函数不进行动态绑定。\n必须通过基类类型的引用或指针进行函数调用。\n简单地说，虚函数是动态绑定的基础；动态绑定是实现运行时多态的基础。\nhttps://blog.csdn.net/iicy266/article/details/11906509 C++中的动态类型与动态绑定、虚函数、运行时多态的实现 ","description":"","id":76,"section":"posts","tags":["C++","多态"],"title":"C++动态与静态","uri":"https://hugo.jiahongw.com/posts/candcplusplus/cpp-duotai/"},{"content":"c文件读写🗃️\nFILE对象结构体 1 2 3 4 5 6 7 8 typedef struct { int _fd; // 文件号 int _cleft; // 缓冲区中剩下的字节数 int _mode; // 文件操作模式 char * _nextc; // 下一个字节的位置 char * _buff; // 文件缓冲区位置 }FILE; 打开文件 可以使用 fopen( ) 函数来创建一个新的文件或者打开一个已有的文件，这个调用会初始化类型 FILE 的一个对象，类型 FILE 包含了所有用来控制流的必要的信息。下面是这个函数调用的原型：\n1 FILE *fopen( const char * filename, const char * mode ); mode 的值可以是r,w,a,,r+,w+,a+:\nr 打开一个已有的文本文件，允许读取文件。 w 打开一个文本文件，允许写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会从文件的开头写入内容。如果文件存在，则该会被截断为零长度，重新写入。 a 打开一个文本文件，以追加模式写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会在已有的文件内容中追加内容。 r+ 打开一个文本文件，允许读写文件。 w+ 打开一个文本文件，允许读写文件。如果文件已存在，则文件会被截断为零长度，如果文件不存在，则会创建一个新文件。 a+ 打开一个文本文件，允许读写文件。如果文件不存在，则会创建一个新文件。读取会从文件的开头开始，写入则只能是追加模式。 如果处理的是二进制文件，则需使用下面的访问模式来取代上面的访问模式：\n1 \u0026#34;rb\u0026#34;, \u0026#34;wb\u0026#34;, \u0026#34;ab\u0026#34;, \u0026#34;rb+\u0026#34;, \u0026#34;r+b\u0026#34;, \u0026#34;wb+\u0026#34;, \u0026#34;w+b\u0026#34;, \u0026#34;ab+\u0026#34;, \u0026#34;a+b\u0026#34; 关闭文件 关闭文件非常简单,只需要调用**fclose()**函数即可,其中参数就是指向文件对象的指针.\n1 int fclose( FILE *fp ); 如果成功关闭文件，fclose( ) 函数返回零，如果关闭文件时发生错误，函数返回 EOF。这个函数实际上，会清空缓冲区中的数据，关闭文件，并释放用于该文件的所有内存。EOF 是一个定义在头文件 stdio.h 中的常量。 demo 1 2 3 4 5 6 7 8 9 10 11 12 13 void open_close_file(){ char fname[10]; printf(\u0026#34;pease input file name: \u0026#34;); scanf(\u0026#34;%s\u0026#34;,fname); FILE *p = fopen(fname,\u0026#34;r+\u0026#34;); if(p == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return ; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;,fname); fclose(p); printf(\u0026#34;file %s had be closed!\\n\u0026#34;,fname); } 读取文件 读取单个字符的最简单的函数:\n1 int fgetc( FILE * fp ); 读取多个字符的函数(也可以读取单个字符):\n1 char *fgets( char *buf, int n, FILE *fp ); fgetc() 函数从 fp 所指向的输入文件中读取一个字符。返回值是读取的字符，如果发生错误则返回 EOF。\n函数 fgets() 从 fp 所指向的输入流中读取 n - 1 个字符。它会把读取的字符串复制到缓冲区 buf，并在最后追加一个 null 字符来终止字符串。\n例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 void read_file_demo() { char fname[10] = \u0026#34;basic.sql\u0026#34;; FILE *fp = fopen(fname, \u0026#34;r+\u0026#34;); if (fp == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;, fname); char ch; int n = 5; printf(\u0026#34;\\nusing fgetc()......\\n\u0026#34;); while (n--) { ch = fgetc(fp); if(ch != EOF) printf(\u0026#34;char = %c\\n\u0026#34;, ch); } char str[20]; printf(\u0026#34;\\nusing fgets()......\\n\u0026#34;); fgets(str,20,fp); printf(\u0026#34;str[20] = %s\\n\u0026#34;,str); fclose(fp); printf(\u0026#34;file %s had be closed!\\n\u0026#34;, fname); } 读取二进制输入:\n1 size_t fread(void *buffer, size_t size, size_t count, FILE * stream); buffer为接收数据的地址，size为一个单元的大小，count为单元个数，stream为文件流。\n返回实际读取的单元个数。如果小于count，则可能文件结束或读取出错；可以用ferror()检测是否读取出错，用feof()函数检测是否到达文件结尾。如果size或count为0，则返回0。\n写入文件 写入单个字符的最简单的函数:\n1 int fputc( int c, FILE *fp ); 写入多个字符的函数(也可以写入单个字符):\n1 int fputs( const char *s, FILE *fp ); 函数 fputc() 把参数 c 的字符值写入到 fp 所指向的输出流中。如果写入成功，它会返回写入的字符，如果发生错误，则会返回 EOF。\n函数 fputs() 把字符串 s 写入到 fp 所指向的输出流中。如果写入成功，它会返回一个非负值，如果发生错误，则会返回 EOF。\n例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 void write_file_demo() { char fname[10] = \u0026#34;test.txt\u0026#34;; FILE *fp = fopen(fname, \u0026#34;w+\u0026#34;); if (fp == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;, fname); char ch; int n = 5; printf(\u0026#34;\\nusing fputc()......\\n\u0026#34;); while (n--) { ch = (char)(100+n); if((ch = fputc(ch,fp)) != EOF) printf(\u0026#34;char %c write successful!\\n\u0026#34;,ch); } char str[30] = \u0026#34;\\nIt`s a test for write!\u0026#34;; printf(\u0026#34;\\nusing fputs()......\\n\u0026#34;); int r = fputs(str,fp); if(r \u0026gt;= 0) printf(\u0026#34;str[30] = %s write successful!\\n\u0026#34;,str); fclose(fp); printf(\u0026#34;file %s had be closed!\\n\u0026#34;, fname); } 二进制输出:\n1 size_t fwrite(void * buffer, size_t size, size_t count, FILE * stream); buffer为数据源地址，size为每个单元的字节数，count为单元个数，stream为文件流指针。\n返回成功写入的单元个数。如果小于count，则说明发生了错误，文件流错误标志位将被设置，随后可以通过ferror()函数判断。\n参考:\nhttps://www.runoob.com/cprogramming/c-file-io.html ","description":"","id":77,"section":"posts","tags":["C","文件读写"],"title":"C文件读写","uri":"https://hugo.jiahongw.com/posts/candcplusplus/c-read-write/"},{"content":"TCP/IP编程\n目标: 能进行网络编程\n1.如果你说你会select,epoll,iocp模型,那会让对方觉得更靠谱\n2.如果你说出你做过im,下载之类那会让对方来兴趣.\n3.如果你说设计了通讯协议,会让对方觉得更贴切\n4.如果你说做过,熟悉, ftp http snmp smtp 这些简单的老古董协议,会加分,但不大.\n5.如果你说熟悉bt,emule,udt等协议,那会对你很有好感.\n6.如果你说你破解过某大牌 qq,360内某通讯协议,那会对你加分很大.\n阶段:\n1)熟悉TCP/IP协议族的基本原理\nIP地址的分类，定义，获得，大概的管理方法\nTCP、UDP等主要协议的特点，主要格式，以及重要字段在协议交互中起到的作用。\n2）对于简单的TCP/IP协议导致的问题，有基本的判断\n熟悉网络问题的解决方法，一个问题，应该是由上而下（top-button），还是由下而上（button-top）来分析？\n3）基本的编程知识。\n在系统内，构建简单通信。\n在系统间，构建简单的通信。\n熟悉系统内的API，知道在什么时候，改使用哪些API协调工作。\n能够熟练使用这些API，在系统间传递信息，文件。\n能够熟练使用这些API，实现自己的简单的私有协议。\n4）进阶编程知识\n知道一两个已经封装好的框架（framwork），它们之间的差别。\n使用一个框架，写过能正常工作的程序。\n知道网络协议处理也是要讲究性能的，知道性能的瓶颈会在什么地方产生。\n能有较好的设计技巧，将私有协议设计得更加具有弹性，优雅。\n熟悉系统间协议处理的细微的差异，以及将会对业务造成的影响，时延、状态不一致、自定义字段、、、、、\n5）熟练阶段的知识\n针对业务的需求，快速选型，定框架。\n不再认为多线程是万能的。\n知道稳定性比性能更加重要。\n数据包去了哪儿，不用看代码，也能预估出来。\n6）源代码是最好的老师，永远都是。\n以上，差不多或者已经达到4）的时候，就是“熟悉”了。\n网络模型 OSI模型 TCP/IP模型 示例 协议对应 数据封装 C++UDP/TCP实例 套接字 为了区分不同应用程序进程和连接，许多计算机操作系统为应用程序与TCP/IP交互提供了称为**嵌套字(Socket)**的接口。\n常用的TCP/IP有以下三种类型的嵌套字：\n流式嵌套字（SOCK_STREAM）\n用于提供面向连接的、可靠的数据传输服务，即使用TCP进行传输。\n数据报嵌套字（SOCK_DGRAM）\n用于提供无连接的服务，即使用UDP进行传输。\n原始嵌套字（SOCK_RAW\n可以读写内核没有处理的IP数据报，而流式嵌套字只能读取TCP的数据，数据报嵌套字只能读取UDP的数据.\n如果要访问其它协议发送的数据必须使用原始嵌套字，它允许对底层协议(如IP或ICMP)直接访问\n端口对应进程 单单之后ip地址还不足以辨识通信的两个进程,因为操作系统是并发的,使用端口来辨认某个进程.所以套接字必须的两个信息为: ip地址 + 端口,例如: 192.168.1.4 1500\n参考:\nhttps://www.jianshu.com/p/c1015f5ffa74 进程间通信 https://segmentfault.com/a/1190000003063859 Linux IO模式及 select、poll、epoll详解 https://cloud.tencent.com/developer/article/1373483 各种IO复用模式之select，poll，epoll，kqueue，iocp分析 ","description":"","id":78,"section":"posts","tags":["tcp","udp","网络"],"title":"Udp-Tcp编程","uri":"https://hugo.jiahongw.com/posts/network/udp-tcp/"},{"content":"每次push都需要输入用户名和密码,其实可以免去这些操作.🚛\n1. 使用.git-credentials文件 在git项目目录下新建.git-credentials这个文件,然后在里面填写下面内容(大括号不用填写):\nhttps://{username}:{password}@github.com 然后在git项目目录执行:\n1 git config --global credential.helper store 执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\nhelper = store 注意: Linux用户主目录一般在~/下,而Windows下一般为C:\\users\\Administrator\n这样以后push就不需要用户名和密码了\n2. 使用ssh协议 首先生成密钥对,执行\n1 ssh-keygen -t rsa -C \u0026#34;youremail\u0026#34; 接下来按照提示操作，默认可以一路往下。\n然后将生成的位于~/.ssh/的id_rsa.pub的内容复制到你github setting里的ssh key中。\n复制之后，如果你还没有克隆你的仓库，那你直接使用ssh协议用法：git@github.com:yourusername/yourrepositoryname克隆就行了。\n如果已经使用https协议克隆了，那么按照如下方法更改协议：\ngit remote set-url origin git@github.com:yourusername/yourrepositoryname.git\nDone!\n3. 管理多git账号 参考:\nhttps://www.jianshu.com/p/f7f4142a1556 简书 https://segmentfault.com/a/1190000012432367 https://juejin.im/post/5d6a23d45188252bd90f601a 掘金 https://www.cnblogs.com/popfisher/p/5731232.html ","description":"","id":79,"section":"posts","tags":["git","github"],"title":"Git免密push","uri":"https://hugo.jiahongw.com/posts/git/git-push-no-pw/"},{"content":"AES算法是继DES之后比较快且比较简单的加密算法.⚖\n对称加密 对称加密模型 如下图，发送者和接收者共享一个一样的密钥，相当于现实生活中的锁，\n对称加密的使用要求 一个强加密算法 只有发送发和接收方知道私钥 加密算法是公开的，不需保密；并且解密算法本质上是加密算法的反向执行。\n但是，如何安全的分发安全密钥呢？——————安全分发不可能单靠对称加密算法，常常使用的是非对称加密算法。\n所以，对称加密的安全性取决于密钥的保密性而非算法的保密性，通常认为已知密文和加密/加密算法的基础上不能够破译信息。\nAES算法 算法原理： AES密码与分组密码Rijndael基本上完全一致，Rijndael分组大小和密钥大小都可以为128位、192位和256位。然而AES只要求分组大小为128位，因此只有分组长度为128Bit的Rijndael才称为AES算法。\n下面是分组长度为128位的AES算法,而key位数可以是128/192/256,本次实验选择key的大小位128位.\n特点 明文分组被描述为一个字节方阵并复制到状态数组，在每轮替换和移位时都并行处理整个状态分组。 矩阵中字节的顺序是按列排序的，例如128比特的明文分组的前4个字节占输入矩阵的第一列，接下来的4个字节占第二列，依次类推。扩展子密钥数组也类似操作。 假设AES使用128比特的密钥，其密钥被描述为一个字节方阵并将扩展成为一个子密钥数组w[i]（具有44个32比特字），4个不同的字（共128比特）用作每轮的轮密钥。 AES在每轮运算中将进行4个不同的步骤，1个是移位，3个是替换。 数学知识 在AES算法中的MixColumn层中会用到伽罗瓦域中的乘法运算，而伽罗瓦域的运算涉及一些数学知识。\n素域 有限域有时也称伽罗瓦域，它指的是由有限个元素组成的集合，在这个集合内可以执行加、减、乘和逆运算。而在密码编码学中，我们只研究拥有有限个元素的域，也就是有限域。域中包含元素的个数称为域的阶。只有当m是一个素数幂时，即$m=p^n$(其中n为正整数是p的次数，p为素数)，阶为m的域才存在。p称为这个有限域的特征。\n例如，有限域中元素的个数可以是11(p=11是一个素数,n=1)、可以是81(p=3是一个素数，n=4)、也可以是256(p=2是一个素数，n=8)\u0026hellip;..但有限域的中不可能拥有12个元素，因为12=2·2·3，因此12也不是一个素数幂。因此满足p是一个素数且满足$m = p^n$这个公式，m才是一个素数幂。\n有限域中最直观的例子就是阶为素数的域，即n=1的域。域GF(p)的元素可以用整数0、1、\u0026hellip;、p-1l来表示。域的两种操作就是模整数加法和整数乘法模p。加上p是一个素数，整数环Z表示为GF(p)，也成为拥有素数个元素的素数域或者伽罗瓦域。GF(p)中所有的非零元素都存在逆元，GF(p)内所有的运算都是模p实现的。\n素域内的算数运算规则如下 加法和乘法都是通过模p实现的； 任何一个元素a的加法逆元都是由a+(a的逆元)=0 mod p得到的； 任何一个非零元素a的乘法逆元定义为a·a的逆元=1。 举个例子，在素域GF(5)={0、1、2、3、4}中，2的加法逆元为3，这是因为2+(3)=5，5mod5=0,所以2+3=5mod5=0。2的乘法逆元为3，这是因为2·3=6，6mod5=1，所以2·3=6mod5=1。(在很多地方a的加法逆元1用$-a$表示，a的乘法逆元2用$1/a$表示)\n注：GF(2)是一个非常重要的素域，也是存在的最小的有限域，由于GF(2)的加法，即模2加法与异或(XOR)门等价，GF(2)的乘法与逻辑与(AND)门等价，所以GF(2)对AES非常重要。\n模2加法与异或(XOR)门等价:\n$$\n(1 + 0) \\mod 2 = 1\\\\\n(0 + 1) \\mod 2 = 1\\\\\n(0 + 0) \\mod 2 = 0\\\\\n(1 + 1) \\mod 2 = 0\\\\\n$$\n乘法与逻辑与(AND)门等价:\n$$\n(1 \\times 0) \\mod 2 = 0\\\\\n(0 \\times 1) \\mod 2 = 0\\\\\n(0 \\times 0) \\mod 2 = 0\\\\\n(1 \\times 1) \\mod 2 = 1\\\\\n$$\n扩展域 如果有限域的阶不是素数，则这样的有限域内的加法和乘法运算就不能用模整数加法和整数乘法模p表示。而且m\u0026gt;1的域被称为扩展域，为了处理扩展域，我们就要使用不同的符号表示扩展域内的元素，使用不同的规则执行扩展域内元素的算术运算。\n在扩展域$GF(2^m)$中，元素并不是用整数表示的，而是用系数为域$GF(2)$中元素的多项式表示。这个多项式最大的度(幂)为m-1​，所以每个元素共有m个系数，在AES算法使用的域$GF(2^8)$中，每个元素$A∈GF(2^8)$都可以表示为：\n$$\nA(x) = a_7x^7 + a_6x^6 + a_5x^5 + a_4x^4 + a_3x^3 + a_2x^2+a_1x + a_0,x_i \\in GF(2) = 0,1\n$$\n注意：在域GF(2^8)中这样的多项式共有256个，这256个多项式组成的集合就是扩展域GF(2^8)。每个多项式都可以按一个8位项链的数值形式存储：\n$$\nA = (a_7,a_6,a_5,a_4,a_3,a_2,a_1,a_0)\n$$\n像$x^7$、$x^6$等因子都无需存储，因为从位的位置就可以清楚地判断出每个系数对应的幂。\n扩展域$GF(2^m)$内的加减法 在AES算法中的密钥加法层中就使用了这部分的知识，但是不是很明显，因为我们通常把扩展域中的加法当作异或运算进行处理了，因为在扩展域中的加减法处理都是在底层域GF(2)内完成的，与按位异或运算等价。假设$A(x)$、$B(x)∈GF(2^m)$，计算两个元素之和的方法就是：\n$$\nC(x) = A(x) + B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i + b_i) \\mod 2\n$$\n而两个元素之差的计算公式就是：\n$$\nC(x) = A(x) - B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i - b_i) \\mod 2 = (a_i + b_i) \\mod 2\n$$\n注：在减法运算中减号之所以变成加号，这就和二进制减法的性质有关了，大家可以试着验算下。从上述两个公式中我们发现在扩展域中加法和减法等价，并且与XOR等价(异或运算也被称作二进制加法)。\n扩展域GF(2^m)内的乘法 扩展域的乘法主要运用在AES算法的列混淆层(Mix Column)中，也是列混淆层中最重要的操作。我们项要将扩展域中的两个元素用多项式形式展开，然后使用标准的多项式乘法规则将两个多项式相乘：\nAES步骤详解 AES算法主要有四种操作处理，分别是密钥加法层(也叫轮密钥加，英文Add Round Key)、字节代换层(SubByte)、行位移层(Shift Rows)、列混淆层(Mix Column)。而明文x和密钥k都是由16个字节组成的数据(当然密钥还支持192位和256位的长度)，它是按照字节的先后顺序从上到下、从左到右进行排列的。而加密出的密文读取顺序也是按照这个顺序读取的，相当于将数组还原成字符串的模样了，然后再解密的时候又是按照4·4数组处理的。AES算法在处理的轮数上只有最后一轮操作与前面的轮处理上有些许不同(最后一轮只是少了列混淆处理)，在轮处理开始前还单独进行了一次轮密钥加的处理。在处理轮数上，只考虑128位密钥的10轮处理。\n其中字节排列方式需要按照如下转换:\nAES算法流程图如下:\n实现步骤及代码 按照AES流程图,对每一层的代码进行实现.\n密钥加法层 在密钥加法层中有两个输入的参数，分别是明文和子密钥k[0]，而且这两个输入都是128位的。在扩展域中加减法操作和异或运算等价，所以这里的处理也就异常的简单了，只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n如下图：\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4 * 4], word k[4]) { for (int i = 0; i \u0026lt; 4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i + 4] = mtx[i + 4] ^ byte(k2.to_ulong()); mtx[i + 8] = mtx[i + 8] ^ byte(k3.to_ulong()); mtx[i + 12] = mtx[i + 12] ^ byte(k4.to_ulong()); } } AES密钥生成 首先定义位置变换函数RotWord(),作用是接受一个字 $[a0, a1, a2, a3] $作为输入，循环左移一个字节后输出$ [a1, a2, a3, a0]$,代码如下:\n1 2 3 4 5 6 word RotWord(const word \u0026amp;w) { word result(0x0); result = (w \u0026lt;\u0026lt; 8) | (w \u0026gt;\u0026gt; 24); return result; } 定义S盒变换函数SubWord()，接受一个字 $[a0, a1, a2, a3]$ 作为输入，然后每一个byte，例如a0，前四个字节为行，后四个字节为列，从S_Box中查找并且返回四个元素。，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 word SubWord(const word\u0026amp; sw) { word temp; for(int i=0; i\u0026lt;32; i+=8) { int row = sw[i+7]*8 + sw[i+6]*4 + sw[i+5]*2 + sw[i+4]; int col = sw[i+3]*8 + sw[i+2]*4 + sw[i+1]*2 + sw[i]; byte val = S_Box[row][col]; for(int j=0; j\u0026lt;8; ++j) temp[i+j] = val[j]; } return temp; } 轮常数Rcon[]作为一个常量数组，每一轮生成密钥的时候需要作为参数异或\n1 2 3 // 轮常数，密钥扩展中用到。（AES-128只需要10轮） word Rcon[10] = {0x01000000, 0x02000000, 0x04000000, 0x08000000, 0x10000000, 0x20000000, 0x40000000, 0x80000000, 0x1b000000, 0x36000000}; 密钥拓展函数KeyExpansion(),接受一个参数为外部密钥，另外一个为需要拓展的轮密钥数组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //密钥扩展函数 - 对128位密钥进行扩展得到 w[4*(Nr+1),Nr为轮数 void KeyExpansion(byte key[4 * N_key], word w[4 * (N_round + 1)]) { word temp; int i = 0; while (i \u0026lt; N_key)\t//前四个word就是输入的key { w[i] = ToWord(key[4 * i], key[4 * i + 1], key[4 * i + 2], key[4 * i + 3]); ++i; } i = N_key; while (i \u0026lt; 4 * (N_round + 1)) { temp = w[i - 1]; //记录前一个word if (i % N_key == 0) { //temp先位置表换RotWord，再S盒变换，然后与轮常数异或，最后w[i-N_key] 异或 w[i] = w[i - N_key] ^ SubWord(RotWord(temp)) ^ Rcon[i / N_key - 1]; } else { w[i] = w[i - N_key] ^ temp; } i++; } } 字节替换层 S盒字节替换，主要功能就是让输入的数据通过S_box表完成从一个字节到另一个字节的映射，读取S_box数据的方法就是要将输入数据的每个字节的高四位作为第一个下标，第四位作为第二个下标。然后返回数据，字节替换主要是为了扰乱数据。\nS盒：\n逆S盒：\n图解如下：\n正向S盒变换代码如下：\n1 2 3 4 5 6 7 8 9 10 //S盒变换 - 前4位为行号，后4位为列号 void SubBytes(byte mtx[4 * 4]) { for (int i = 0; i \u0026lt; 16; ++i) { int row = mtx[i][7] * 8 + mtx[i][6] * 4 + mtx[i][5] * 2 + mtx[i][4]; int col = mtx[i][3] * 8 + mtx[i][2] * 4 + mtx[i][1] * 2 + mtx[i][0]; mtx[i] = S_Box[row][col]; } } 反向S盒变换代码如下:\n1 2 3 4 5 6 7 8 9 10 // 逆S盒变换 void InvSubBytes(byte mtx[4*4]) { for(int i=0; i\u0026lt;16; ++i) { int row = mtx[i][7]*8 + mtx[i][6]*4 + mtx[i][5]*2 + mtx[i][4]; int col = mtx[i][3]*8 + mtx[i][2]*4 + mtx[i][1]*2 + mtx[i][0]; mtx[i] = Inv_S_Box[row][col]; } } 行移位层 将输入数据作为一个$4·4$的字节矩阵进行处理，然后将这个矩阵的字节进行位置上的置换。在加密时行位移处理与解密时的处理相反，我们这里将解密时的处理称作逆行位移。它之所以称作行位移，是因为它只在$4·4$矩阵的行间进行操作，每行4字节的数据。在加密时，保持矩阵的第一行不变，第二行向左移动8Bit(一个字节)、第三行向左移动2个字节、第四行向左移动3个字节。而在解密时恰恰相反，依然保持第一行不变，将第二行向右移动一个字节、第三行右移2个字节、第四行右移3个字节。最终结束。\n正向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //正向行变换 - 按字节循环移位 void ShiftRows(byte mtx[4 * 4]) { // 第二行循环左移一位 byte temp = mtx[4]; for (int i = 0; i \u0026lt; 3; ++i) mtx[i + 4] = mtx[i + 5]; mtx[7] = temp; // 第三行循环左移两位 for (int i = 0; i \u0026lt; 2; ++i) { temp = mtx[i + 8]; mtx[i + 8] = mtx[i + 10]; mtx[i + 10] = temp; } // 第四行循环左移三位 temp = mtx[15]; for (int i = 3; i \u0026gt; 0; --i) mtx[i + 12] = mtx[i + 11]; mtx[12] = temp; } 反向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 逆行变换 - 以字节为单位循环右移 void InvShiftRows(byte mtx[4*4]) { // 第二行循环右移一位 byte temp = mtx[7]; for(int i=3; i\u0026gt;0; --i) mtx[i+4] = mtx[i+3]; mtx[4] = temp; // 第三行循环右移两位 for(int i=0; i\u0026lt;2; ++i) { temp = mtx[i+8]; mtx[i+8] = mtx[i+10]; mtx[i+10] = temp; } // 第四行循环右移三位 temp = mtx[12]; for(int i=0; i\u0026lt;3; ++i) mtx[i+12] = mtx[i+13]; mtx[15] = temp; } 列混淆层 列混淆子层是AES算法中最为复杂的部分，属于扩散层，列混淆操作是AES算法中主要的扩散元素，它混淆了输入矩阵的每一列，使输入的每个字节都会影响到4个输出字节。行位移子层和列混淆子层的组合使得经过三轮处理以后，矩阵的每个字节都依赖于16个明文字节成可能。\n在加密的正向列混淆中，我们要将输入的$4·4$矩阵左乘一个给定的$4·4$矩阵。而它们之间的加法、乘法都在扩展域$GF(2^8)$中进行，,在矩阵相乘计算中，出现了加法和乘法，而前面提到了在拓展域中加法等同于异或运算，而对于乘法，需要特殊的方式进行处理，于是将+号换成^号，然后将伽罗瓦域的乘法定义成一个有两个参数的函数，并让他返回最后计算结果，最后列混淆代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //正向列变换 void MixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x02, arr[0]) ^ GFMul(0x03, arr[1]) ^ arr[2] ^ arr[3]; mtx[i+4] = arr[0] ^ GFMul(0x02, arr[1]) ^ GFMul(0x03, arr[2]) ^ arr[3]; mtx[i+8] = arr[0] ^ arr[1] ^ GFMul(0x02, arr[2]) ^ GFMul(0x03, arr[3]); mtx[i+12] = GFMul(0x03, arr[0]) ^ arr[1] ^ arr[2] ^ GFMul(0x02, arr[3]); } } 在解密的逆向列混淆中与正向列混淆的不同之处在于使用的左乘矩阵不同，它与正向列混淆的左乘矩阵互为逆矩阵，也就是说，数据矩阵同时左乘这两个矩阵后，数据矩阵不会发生任何变化。下面是图解：\n正向混淆处理：\n逆向混淆处理：\n反向列变换代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //反向列混淆 void InvMixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x0e, arr[0]) ^ GFMul(0x0b, arr[1]) ^ GFMul(0x0d, arr[2]) ^ GFMul(0x09, arr[3]); mtx[i+4] = GFMul(0x09, arr[0]) ^ GFMul(0x0e, arr[1]) ^ GFMul(0x0b, arr[2]) ^ GFMul(0x0d, arr[3]); mtx[i+8] = GFMul(0x0d, arr[0]) ^ GFMul(0x09, arr[1]) ^ GFMul(0x0e, arr[2]) ^ GFMul(0x0b, arr[3]); mtx[i+12] = GFMul(0x0b, arr[0]) ^ GFMul(0x0d, arr[1]) ^ GFMul(0x09, arr[2]) ^ GFMul(0x0e, arr[3]); } } 密钥加法层 这一层主要是明文矩阵盒子密钥矩阵进行异或操作,在密钥加法层中有两个输入的参数，分别是明文和子密钥，而且这两个输入都是128位的。只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4*4], word k[4]) { for(int i=0; i\u0026lt;4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i+4] = mtx[i+4] ^ byte(k2.to_ulong()); mtx[i+8] = mtx[i+8] ^ byte(k3.to_ulong()); mtx[i+12] = mtx[i+12] ^ byte(k4.to_ulong()); } } 实现加密函数 加密函数按照流程图,首先开始是先进行一次轮密钥加,然后开始9轮的字节替换+行移位+列混淆+轮密钥加的操作,循环之后再做一次字节替换+行移位+轮密钥加就完成加密操作了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void encrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); for(int round=1; round\u0026lt;N_round; ++round) { SubBytes(in); ShiftRows(in); MixColumns(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); } SubBytes(in); ShiftRows(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); } 实现解密函数 解密函数与加密差不多,只不过将行移位变成反向行移位,列混淆变成反向列混淆,字节替换变成逆字节替换即可.\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void decrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); for(int round=N_round-1; round\u0026gt;0; --round) { InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); InvMixColumns(in); } InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); } 测试加密解密函数 可以发现上面面的测试中明文与解密之后的明文是完全正确的,说明加密函数与解密函数正确!\n测试代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 void Aes_test() { byte key[16] = {0x2b, 0x7e, 0x15, 0x16, 0x28, 0xae, 0xd2, 0xa6, 0xab, 0xf7, 0x15, 0x88, 0x09, 0xcf, 0x4f, 0x3c}; byte plain[16] = {0x32, 0x88, 0x31, 0xe0, 0x43, 0x5a, 0x31, 0x37, 0xf6, 0x30, 0x98, 0x07, 0xa8, 0x8d, 0xa2, 0x34}; // 输出密钥 cout \u0026lt;\u0026lt; \u0026#34;Key is : \u0026#34;; for (int i = 0; i \u0026lt; 16; ++i) cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; key[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; cout \u0026lt;\u0026lt; endl; word w[4 * (N_round + 1)]; KeyExpansion(key, w); // 输出待加密的明文 cout \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;the plaintext to encrypy:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 加密，输出密文 encrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;cipher : \u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 解密，输出明文 decrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;plain arter decrypt:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; } 实现加解密文件 加密文件函数,返回加密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 string encryptFile(string oname, string suffix, word w[4 * (N_round + 1)]) { string outputfilename = oname + \u0026#34;_cipher.bin\u0026#34;; bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining encrypy...........\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); // 将文件加密到 oname + cipher.bin 中 ifstream in; ofstream out; in.open(oname + suffix, ios::binary); //输入文件 out.open(outputfilename, ios::binary); //输出加密文件 while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); encrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0 } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;encrypy finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;encrypy cost time : \u0026#34; \u0026lt;\u0026lt; (end - start) \u0026lt;\u0026lt; \u0026#34; ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; //返回加密之后的文件 } 解密文件函数,返回解密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 string decryptFile(string filename, string oname, string suffix, word w[4 * (N_round + 1)]) { ifstream in; ofstream out; in.open(filename, ios::binary); string outputfilename = oname + \u0026#34;_decrypt\u0026#34; + suffix; out.open(outputfilename, ios::binary); bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining decrypt............\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); decrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0 } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;decrypt finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;decrypt cost time : \u0026#34; \u0026lt;\u0026lt; end - start \u0026lt;\u0026lt; \u0026#34; ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; } 实现效果:\n加密txt文件:\n加密jpg文件:\n加密mp3文件:\n加密doc文件:\nAES五种加密模式 实现五种加密方式的密钥是一个置换表unsigned char Table[4] = {0x12, 0xb1, 0x53, 0x28};,加密函数是原文与密钥的异或.\nECB模式(电子密码本模式) 加密前根据加密块大小（如AES为128位）分成若干块，之后将每块使用相同的密钥单独加密，解密同理。\nECB模式由于每块数据的加密是独立的因此加密和解密都可以并行计算，ECB模式最大的缺点是相同的明文块会被加密成相同的密文块，这种方法在某些环境下不能提供严格的数据保密性。\n流程图如下:\n实现代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //电子密码本模式,分组大小为4 unsigned char* ECB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for(int j = 0;j \u0026lt; groupSize;++j) temp[j] = plain[count++]; //加密 encrypt(temp,groupSize); for(int j = i*4;j \u0026lt; i*4 + 4;++j) cipher[j] = temp[j - i * 4]; } return cipher;//返回密文 } 解密方法也是让密文与密钥进行异或即可,实现效果如下:\nCBC模式(分组链接模式) CBC模式对于每个待加密的密码块在加密前会先与前一个密码块的密文异或然后再用加密器加密。第一个明文块与一个叫初始化向量的数据块异或。\n可用公式总结为:\n$$\nC_i = E_K(P_i XOR C_{i-1}) \\\nC_{-1} = IV\n$$\n流程图如下:\nCBC模式相比ECB有更高的保密性，但由于对每个数据块的加密依赖与前一个数据块的加密所以加密无法并行。与ECB一样在加密前需要对数据进行填充，不是很适合对流数据进行加密。\n代码如下:\n加密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //CCB加密函数 unsigned char *CCB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = plain[count++]; //加密 for (int j = 0; j \u0026lt; groupSize; ++j) //先与初始向量异或 temp[i] ^= C[i]; encrypt(temp, groupSize); //加密 for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { cipher[j] = temp[j - i * 4]; C[j - i * 4] = temp[j - i * 4];//设置新向量 } } return cipher; } 解密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //CCB解密函数 unsigned char *dCCB(unsigned char *cipher, int N) { int gNum = N / groupSize; //分组数量 //明文 unsigned char *plain = new unsigned char[N]; //设置初始向量 unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = cipher[count++]; //解密 encrypt(temp, groupSize); //先解密 for (int j = 0; j \u0026lt; groupSize; ++j) //然后与初始向量异或 temp[i] ^= C[i]; for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { plain[j] = temp[j - i * 4]; C[j - i * 4] = cipher[j];//设置新向量 } } return plain; } 实现效果:\nCFB模式(密文反馈模式) 与前面的模式不同,CFB模式可以将消息被当成是比特流.可以总结为如下的公式:\n$$\nC_i = P_i XOR E_K(C_{i-1})\\\nC_{-1} = IV\n$$\n流程图如下:\n加密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 //密文反馈模式,加密函数 unsigned char *CFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文,大小为2 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; gsize;++j){ temp[j] ^= C[j]; S[j] = temp[j]; //获取密文的2bit } //设置密文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; } 解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 //密文反馈解密 unsigned char *dCFB(unsigned char *cipher, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //明文 unsigned char *plain = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组密文 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = cipher[count++]; //解密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; 2;++j){ S[j] = temp[j]; temp[j] = C[j] ^ temp[j]; } //设置明文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { plain[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j+gsize] = S[j]; } } return plain; } 实现效果:\nOFB模式(输出反馈模式) OFB是先用块加密器生成密钥流（Keystream），然后再将密钥流与明文流异或得到密文流，解密是先用块加密器生成密钥流，再将密钥流与密文流异或得到明文，由于异或操作的对称性所以加密和解密的流程是完全一样的。\nOFB与CFB一样都非常适合对流数据的加密，OFB由于加密和解密都依赖与前一段数据，所以加密和解密都不能并行。\n流程图如下:\n加密解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 //输出反馈模式,加密解密函数相同 unsigned char *OFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xee, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; 2;++j){ S[j] = C[j]; //取向量加密后的前两位 temp[j] ^= C[j]; } //设置密文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; } 实现效果:\nCTR模式(计数器模式) 类型于CFB，但是加密每个计数值，而不是任何反馈值,对每个明文分组，必须有不同的密钥和计数值 (从不重复使用),,可以用如下公式表示:\n$$\nO_i = E_K(i)\\\nC_i = P_i XOR O_i\n$$\n计数器模式流程图如下:\n计数器模式加密函数与解密函数一样,代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 //计数器模式,加密函数 unsigned char *CTR(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; //设置随机值 unsigned char Counter[groupSize*groupSize] = {0x44, 0xa9, 0x5d, 0x99, 0xe5, 0xf1, 0x3d, 0x91, 0x16, 0xa6, 0xe1, 0x33, 0x22, 0xdd, 0xab, 0x1f}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; //明文分组 unsigned char C[groupSize]; //分组随机值 for (int j = 0; j \u0026lt; groupSize; ++j) { temp[j] = plain[count++]; C[j] = Counter[i*4+j]; } //加迷 //首先加密随机值C encrypt(C, groupSize); //然后与明文进行异或 for(int j = 0;j \u0026lt; groupSize;++j) temp[j] ^= C[j]; //设置密文 for(int j = i*groupSize;j \u0026lt; i*groupSize+groupSize;j++) cipher[j] = temp[j-i*groupSize]; } return cipher; } 实现效果如下:\n参考:\nhttps://www.cnblogs.com/RabbitHu/p/bitset.html bitset用法 https://blog.csdn.net/liushu1231/article/details/8844631 bitset的空间大小 http://c.biancheng.net/cpp/html/2834.html 文件处理 https://bbs.pediy.com/thread-253884.htm AES算法带图解 https://blog.csdn.net/lisonglisonglisong/article/details/41909813 AES算法 CSDN https://blog.csdn.net/sinat_23338865/article/details/72869841 AES五种加密模式 设“+”为一个交换性的二元运算，即对于所有x,y，x+y=y+x。若该集内存在一个元素0，使得对于所有x，x+0=0+x=x，则此元素是唯一的。如果对于一个给定的x，存在一个x\u0026rsquo;使得x+x\u0026rsquo;=x\u0026rsquo;+x=0，则称x\u0026rsquo;是x的加法逆元。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n乘法逆元，是指数学领域群G中任意一个元素a，都在G中有唯一的逆元a‘，具有性质a×a\u0026rsquo;=a\u0026rsquo;×a=e，其中e为该群的单位元。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","description":"","id":80,"section":"posts","tags":["AES","密码学","加密"],"title":"Aes-高级加密标准","uri":"https://hugo.jiahongw.com/posts/cryptography/aes/"},{"content":"走得慢的时候，为什么不跑呢？#️⃣\n哈希散列表 两个概念：\n散列表：\n散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。\n散列函数：\n散列函数，顾名思义，它是一个函数。如果把它定义成 hash(key) ，其中 key 表示元素的键值，则 hash(key) 的值表示经过散列函数计算得到的散列值。\n散列函数特点：\n确定性 散列碰撞（collision） 不可逆性(一个哈希值对应无数个明文，理论上你并不知道哪个是。) 混淆特性 常见的散列函数：\nMD51 SHA-12 为什么哈希算法查找数组元素会更快？\n原来使用下标进行匹配的画，会一个一个从一整个数组进行元素匹配，知道找到相等的元素才得到数组的信息。例如在Arr[20]查找值为12的,就需要从下标0到19进行查找。\n但是哈希散列表将一个一个按顺序的查找转换为使用计算的方式进行查找，将运算结果的下标映射成一个哈希表，实现了跳跃式的查找，从而效率更高。\n问题:散列冲突\n对于散列表而言，无论设置的存储区域（n）有多大，当需要存储的数据大于 n 时，那么必然会存在哈希值相同的情况。这就是所谓的散列冲突。\n解决散列函数的两个方法：\n链表法\n就是使用链表来保存冲突下标的数据，例如$12 % 5 = 2$和$7 % 5 = 2$,那么在下标为2的表下用一个链表存储12和7。\n开放寻址法。\n常见三种方法：线性探测法、二次探测法、双散列\n假设哈希函数为：\n$$\nH(key) = key \\mod10\n$$\n线性探测法：\n还是$12 % 10 = 2 $和$22 % 10 = 2$这两个例子，当22这个数字需要存入哈希表时，发现已经有12这个元素存放在下标为2的哈希表上了，那么对Hash后的数字加一在进行Hash。即对7进行这样的操作：\n$$\nH((H(key)+1)) = ((22 \\mod 10) + 1) \\mod 10 = (2 + 1) \\mod 10 = 3\n$$\n但是这种方式的问题是冲突较多的时候会出现数据聚集在一个区域，这样不利于查询数据。\n二次探测法：\n二次探测法使用下面的函数解决冲突：\n$$\n(H(key) \\pm j^2) \\mod 10,j = 0,1,2\u0026hellip;\n$$\n这种方法较为复杂，而且虽然不会连续的聚集一片，但是会在多个间断的位置聚集。\n双散列：\n双散列，顾名思义就需要增加一个二级散列函数，例如$G(key) = q - (key \\mod q) q为素数且q\u0026lt;N$，发现冲突使用如下操作：\n$$\nH(key) + j * G(key),j = 0,1,2\u0026hellip;\u0026hellip;\n$$\n双散列方法有很多组合的方法，这里只是其中的一种，也有一些例如:$H(key) + G(key)$,没有j这个参数。\n密码学中的哈希算法 hash（散列、杂凑）函数，是将任意长度的数据映射到有限长度的域上。直观解释起来，就是对一串数据m进行杂糅，输出另一段固定长度的数据h，作为这段数据的特征（指纹）。也就是说，无论数据块m有多大，其输出值h为固定长度。到底是什么原理？将m分成固定长度（如128位），依次进行hash运算，然后用不同的方法迭代即可（如前一块的hash值与后一块的hash值进行异或）。如果不够128位怎么办？用0补全或者用1补全随意，算法中约定好就可以了。\n一般来说，公司不会直接将用户的密码保存在数据库中，而是保存经过哈希操作的密码得到的哈希值。这样，当哈希值被不法分子窃取，也不能还原出用户的密码；并且，公司只需要将用户输入的密码进行哈希操作，将哈希值与存储在数据库中的哈希值进行对比就能够验证用户了。\n哈希的其他用法 数据校验：\nGit的- git commit id\n每次git提交后都有一个commit id，比如:\n19d02d2cc358e59b3d04f82677dbf3808ae4fc40\n版权校验\n判断两个文件是不是一样的，对两个文件都进行哈希操作，得到哈希值，若哈希值相同，则两个文件为同一个文件。\n大文件分块校验\n例如使用bt下载，在p2p网络中会把一个大文件拆分成很多小的数据各自传输。这样的好处是如果某个小的数据块在传输过程中损坏了，只要重新下载这个块就好。为了确保每一个小的数据块都是发布者自己传输的，我们可以对每一个小的数据块都进行一个hash的计算，维护一个hash List，在收到所有数据以后，我们对于这个hash List里的每一块进行遍历比对。这里有一个优化点是如果文件分块特别多的时候，如果遍历对比就会效率比较低。可以把所有分块的hash值组合成一个大的字符串，对于这个字符串再做一次Hash运算，得到最终的hash（Root hash）。在实际的校验中，我们只需要拿到了正确的Root hash，即可校验Hash List，也就可以校验每一个数据块了。\n负载均衡：\n一致性hash的基本原理是将输入的值hash后，对结果的hash值进行2^32取模，这里和普通的hash取模算法不一样的点是在一致性hash算法里将取模的结果映射到一个环上。将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一个openid必定会被缓存到固定的服务器上，那么，当下次想要访问这个用户的数据时，只要再次使用相同的算法进行计算，即可算出这个用户的数据被缓存在哪个服务器上，直接去对应的服务器查找对应的数据即可。这里的逻辑其实和直接取模的是一样的。如下图所示：\n这部分不是很深入，之后再补充\u0026hellip;\u0026hellip;🚴‍♂️\n参考链接：\nhttps://www.zhihu.com/question/26762707?sort=created-知乎 动画：什么是散列表？-五分钟算法 什么是 hash？-知乎 MD5 即 Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一，主流编程语言普遍已有 MD5 实现。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\nSHA-1（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种密码散列函数，SHA-1可以生成一个被称为消息摘要的160位（20字节）散列值，散列值通常的呈现形式为40个十六进制数。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","description":"","id":81,"section":"posts","tags":["Hash","Algorithm","md5","sha"],"title":"什么是Hash？","uri":"https://hugo.jiahongw.com/posts/algorithmstructure/hash-circle/"},{"content":"排序是最基本的算法，里面包含了最基础的思想。一个简单的优化可以让排序快很多。\n$O(n^2)$的排序算法 冒泡排序 1 2 3 4 5 6 7 8 9 10 11 12 13 //冒泡排序 template \u0026lt;typename T\u0026gt; void bubbleSort(T *arr, int size) { for (int i = 0; i \u0026lt; size; ++i) { for (int j = 0; j \u0026lt; size - i - 1; ++j) { if (arr[j] \u0026gt; arr[j + 1]) swap(arr[j], arr[j + 1]); } } } 插入排序 ​\n1 2 3 4 5 6 7 8 9 template\u0026lt;typename T\u0026gt; void insertSort(T *arr,int size) { for(int i = 0;i \u0026lt; size;++i) { int j; for(j = i;j \u0026gt; 0 \u0026amp;\u0026amp; arr[j] \u0026lt; arr[j-1];--j){swap(arr[j],arr[j-1]);} } } 选择排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14 //选择排序 复杂度O(n^2) template\u0026lt;typename T\u0026gt; void selectionSort(T *arr,int size) { int k; for(int i = 0;i \u0026lt; size-1; ++i) { k = i; for(int j = i+1;j \u0026lt; size;++j) if(arr[j] \u0026lt; arr[k]) k = j; if(k != i) mySwap(arr[k],arr[i]); } } 测试排序使用时间的时候，总是选择排序快于插入排序，按理说，插入排序应该比选择排序要快啊，因为插入排序可以提前终止循环，这是为什么呢？\n原因是选择排序比较的是下标，而插入排序每一次比较都要交换，而交换所耗费的时间是高于简单的比较的。\n插入排序优化-将交换变成赋值\n1 2 3 4 5 6 7 8 9 10 11 template\u0026lt;typename T\u0026gt; void insertSort(T *arr,int size) { for(int i = 0;i \u0026lt; size;++i) { T e = arr[i]; int j; for(j = i;j \u0026gt; 0 \u0026amp;\u0026amp; arr[j-1] \u0026gt; e;--j){arr[j] = arr[j-1];} arr[j] = e; } } 运行时间明显变快了\n对于近乎有序的数据来说，插入排序的速度要快很多，近乎$O (n)$。而插入排序的实际应用有很多，比如日志，日志的时间是近乎有序的，但是生成日志可能会出错，需要进行时间排序处理，这个时候使用插入排序会更好；还有银行的一些流水单等等\n拓展： C++运算符重载\n一般在类中实现，有两种可以实现的方法\n运算符重载例子，使用在一个类中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class Student { public: string name; int score; bool operator\u0026lt;(const Student \u0026amp;otherStudent) { return this-\u0026gt;score \u0026lt; otherStudent.score; } friend ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream \u0026amp;os, const Student \u0026amp;student) { os \u0026lt;\u0026lt; \u0026#34;Student:\u0026#34; \u0026lt;\u0026lt; student.name \u0026lt;\u0026lt; \u0026#34; \u0026#34;\u0026lt;\u0026lt;student.score\u0026lt;\u0026lt;endl; return os; } }; 使用友元函数\n1 2 3 4 5 6 7 8 返回值类型 operator 运算符(形参表) { ... } //例Complex是一个复数类 friend Complex operator+(const Complex \u0026amp;c1,const Complex \u0026amp;c2){ return Complex(c1.i + c2.i,c1.j + c2.j); } 使用类里面的函数\n1 2 3 4 5 6 7 8 返回值类型 operator 运算符(形参表) { ... } //例Complex是一个复数类 Complex operator+(const Complex \u0026amp;complex){ return Complex(this-\u0026gt;i + complex.i,this-\u0026gt;j + complex.j); } 它们的区别就是参数的个数不同以及需不需要加上fridend这个关键字\n$O(n\\log (n))$的排序算法 归并排序 代码实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 template \u0026lt;typename T\u0026gt; void __merge(T *arr, int l, int middle, int r) { T aux[r - l + 1]; for (int i = l; i \u0026lt;= r; ++i) aux[i - l] = arr[i]; int i = l, j = middle + 1; for (int k = l; k \u0026lt;= r; ++k) { if (i \u0026gt; middle) { arr[k] = aux[j - l]; j++; } else if (j \u0026gt; r) { arr[k] = aux[i - l]; i++; } else if (aux[i - l] \u0026lt; aux[j - l]) { arr[k] = aux[i - l]; i++; } else { arr[k] = aux[j - l]; j++; } } } template \u0026lt;typename T\u0026gt; void __mergeSort(T *arr, int l, int r) { if (l \u0026gt;= r) return; int middle = (l + r) / 2; __mergeSort(arr, l, middle); __mergeSort(arr, middle+1, r); if(arr[middle] \u0026gt; arr[middle+1]) __merge(arr, l, middle, r); } //归并排序 template \u0026lt;typename T\u0026gt; void mergeSort(T *arr, int size) { __mergeSort(arr, 0, size - 1); } 下面这段代码的标记部分需要考虑溢出的问题\n归并排序快是快，但是要耗费多一倍$O(n)$的存储空间，也就是使用空间换时间。\n希尔排序 动画演示(来自@五分钟算法)：\n代码实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 //希尔排序 template \u0026lt;typename T\u0026gt; void shellSort(T *arr, int size) { int dk[] = {5, 3, 1}; for (int index = 0; index \u0026lt; 3; ++index) { for (int i = 0; i \u0026lt; size / dk[index]; ++i) { int j; int e = arr[i]; for (j = i + dk[index]; j \u0026gt; dk[index] \u0026amp;\u0026amp; arr[j] \u0026gt; e; j -= dk[index]) { arr[j] = arr[j - dk[index]]; } arr[j] = e; } } } 希尔排序相当于是插入排序的升级版，增加了一个步长参数，使用希尔排序可以让零散的数据实现跳跃行的交换，最后逐渐将数组转化为有序，这样最后使用步长为1的插入排序就非常快了。\n快速排序 被称为二十世纪影响最大的算法之一！\n动画演示(来自@五分钟算法)：\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 template\u0026lt;typename T\u0026gt; int __partition(T *arr,int l,int r){ T v = arr[l]; int j = l; for(int i = l+1;i \u0026lt;= r;++i){ if(arr[i] \u0026lt; v){ swap(arr[i],arr[++j]); } } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void __quickSort(T *arr,int l,int r) { if(l \u0026gt;= r) return; int p = __partition(arr,l,r); __quickSort(arr,l,p-1); __quickSort(arr,p+1,r); } //快速排序 template\u0026lt;typename T\u0026gt; void quickSort(T *arr,int size) { __quickSort(arr,0,size-1); } 优化一：\n在数组的元素个数小于15个的时候使用插入排序进行优化:\n1 2 3 4 5 6 7 8 template\u0026lt;typename T\u0026gt; void __quickSort(T *arr,int l,int r) { + if(r - l \u0026lt;= 15) insertionSort(arr,l,r); int p = __partition(arr,l,r); __quickSort(arr,l,p-1); __quickSort(arr,p+1,r); } 优化二：\n使用随机值作为划分标准\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 template\u0026lt;typename T\u0026gt; int __partition(T *arr,int l,int r){ + swap(arr[l],arr[rand() % (r-l+1) + l]); T v = arr[l]; int j = l; for(int i = l+1;i \u0026lt;= r;++i){ if(arr[i] \u0026lt; v){ swap(arr[i],arr[++j]); } } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void quickSort(T *arr,int size) { + srand(time(NULL)); __quickSort(arr,0,size-1); } 缺点:\n在近乎有序的数组排序中，快速排序的性能很差。时间复杂度也近乎$O(n^2 )$ 对于有很多重复元素的数组，快速排序的性能也很差 快速排序版本二：两路快排 使用两个下标分别处理大于v与小于v的部分。(v为基准元素)\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 template\u0026lt;typename T\u0026gt; int __partition2(T *arr,int l,int r){ swap(arr[l],arr[rand() % (r-l+1) + l]); T v = arr[l]; int i = l + 1,j = r; while(true) { while(arr[i] \u0026lt; v \u0026amp;\u0026amp; i \u0026lt;= r) ++i; while(arr[j] \u0026gt; v \u0026amp;\u0026amp; j \u0026gt;= l+1) --j; if(i \u0026gt; j) break; swap(arr[i++],arr[j--]); } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void __quickSort2(T *arr,int l,int r) { if(r - l\u0026lt;= 15){ insertSort(arr,l,r); return; } int p = __partition2(arr,l,r); __quickSort2(arr,l,p-1); __quickSort2(arr,p+1,r); } //快速排序版本二，双路快排 template\u0026lt;typename T\u0026gt; void quickSort2(T *arr,int size) { srand(time(NULL)); __quickSort2(arr,0,size-1); } 快速排序版本三：三路快排 使用三个下标分别处理大于v、等于v与小于v的部分。(v为基准元素)\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 template\u0026lt;typename T\u0026gt; void __quickSort3(T *arr,int l,int r) { if(r - l\u0026lt;= 15){ insertSort(arr,l,r); return; } swap(arr[l],arr[rand() % (r-l+1) + l]); T v = arr[l]; int lt = l; //arr[l+1...lt] \u0026lt; v int gt = r + 1; //arr[gt...r] \u0026gt; v int i = l+1; //arr[lt+1...i] == v while(i \u0026lt; gt){ if(arr[i] \u0026lt; v){ swap(arr[i++],arr[++lt]); }else if(arr[i] \u0026gt; v){ swap(arr[i],arr[--gt]); }else{ i++; } } swap(arr[l],arr[lt]); __quickSort3(arr,l,lt-1); __quickSort3(arr,gt,r); } //快速排序版本三，三路快排 template\u0026lt;typename T\u0026gt; void quickSort3(T *arr,int size) { srand(time(NULL)); __quickSort3(arr,0,size-1); } 堆排序 基数排序 桶排序 排序算法总结 图片：\n未完待续\u0026hellip;\u0026hellip;🛴\n参考：\nhttps://www.cnblogs.com/onepixel/p/7674659.html https://github.com/MisterBooo/Article ","description":"","id":82,"section":"posts","tags":["算法","排序","C++"],"title":"排序算法总结","uri":"https://hugo.jiahongw.com/posts/algorithmstructure/sort/"},{"content":"机器学习有这些基本的算法组成，要门机器学习，就需要打个地基✒️\nK近邻算法-KNN-(k-Nearest-Neighbors) 可以解决的问题:\n分类问题 回归问题 预测一个人是天才还是白痴 首先先生成模拟数据，,x1和x2分别表示两个特征\nIQ值低的数据\n1 2 3 x1_low = np.random.random(10) + 3 x2_low = np.random.random(10) + 6 x1_low,y2_low (array([3.72183336, 3.16146551, 3.88914234, 3.85673496, 3.1573191 , 3.4293751 , 3.96033808, 3.78793864, 3.94939642, 3.57378294]), array([6.47227974, 6.49537929, 6.98666118, 6.79440424, 6.99201224, 6.73386195, 6.63275792, 6.65411763, 6.42891099, 6.49695701])) IQ值高的数据\n1 2 3 x1_high = 4 + np.random.random(8) x2_high = 7 + np.random.random(8) x1_high,x2_high (array([4.39543051, 4.73302502, 4.02667743, 4.46232039, 4.68128181, 4.92115752, 4.45267816, 4.84647668]), array([7.40538131, 7.3356809 , 7.90412483, 7.45237382, 7.15550294, 7.3764611 , 7.52492352, 7.67692014])) 总的数据和标签\n1 2 3 4 5 6 x1 = np.append(x1_low,x1_high) x2 = np.append(x2_low,x2_high) x_train = np.c_[x1.T,x2.T] print(x_train) y_train = np.append(np.zeros_like(x_low),np.ones_like(x_high)) print(y_train) [[3.72183336 6.47227974] [3.16146551 6.49537929] [3.88914234 6.98666118] [3.85673496 6.79440424] [3.1573191 6.99201224] [3.4293751 6.73386195] [3.96033808 6.63275792] [3.78793864 6.65411763] [3.94939642 6.42891099] [3.57378294 6.49695701] [4.28739637 7.71057536] [4.31513454 7.70173516] [4.10934692 7.38111019] [4.35094666 7.33731866] [4.01739934 7.41472044] [4.98558165 7.72054925] [4.80075428 7.12604512] [4.48912715 7.08753069]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.] 绘制散点图\n1 2 3 4 5 plt.scatter(x_train[y_train==0,0],x_train[y_train==0,1]) plt.scatter(x_train[y_train==1,0],x_train[y_train==1,1]) plt.xlabel(\u0026#39;t\u0026#39;) plt.ylabel(\u0026#39;IQ\u0026#39;) plt.show() 上图红色表示天才，蓝色表示白痴\n假设输入一个样本的数据为 (4.36,7.465)，判断它天才还是白痴\n1 2 3 4 5 6 7 8 example = np.array([4.36,7.456]) # 首先再图上画出来观察 plt.scatter(x_train[y_train==0,0],x_train[y_train==0,1]) plt.scatter(x_train[y_train==1,0],x_train[y_train==1,1]) plt.scatter(example[0],example[1],color=\u0026#39;black\u0026#39;) plt.xlabel(\u0026#39;t\u0026#39;) plt.ylabel(\u0026#39;IQ\u0026#39;) plt.show() 黑点表示输入的样本\n获取距离列表\n1 2 distance = [sqrt(sum(((x-example)**2))) for x in x_train] distance [1.172587826601725, 1.5359938425092403, 0.6648201732802982, 0.8312548678718089, 1.2890795094301544, 1.177941448784469, 0.9151268590623418, 0.9850226059672444, 1.1061225623709607, 1.2401212526176475, 0.2647260841097585, 0.24979727210937175, 0.26160170347749107, 0.1190261413334191, 0.3450785650776031, 0.6792191910080055, 0.5505765678982287, 0.39044007348145965] 对于KNN，假设k=3，就是求出与样本最近的三个点的数据\n1 2 result = np.argsort(distance) result[:k] array([13, 11, 12], dtype=int64) 可以得知，前三个的训练样本的点的下标分别围殴13，11，12\n接下来根据这三个训练样本的类别来预测输入的样本是天才还是白痴，假如这三个训练样本是天才的数量多于白痴，就认为它是天才；不然，就认为它是白痴\n1 2 3 4 5 6 7 from collections import Counter votes = Counter(r) y_hat = votes.most_common(1)[0][0] if y_hat == 1: print(\u0026#34;预测它为天才\u0026#34;) else: print(\u0026#34;预测它为白痴\u0026#34;) 预测它为天才 主成分分析法-PCA-(Principal Component Analysis) PAC主要用于数据的降维\n二维降到一维\n由上面两个降维的图来看，第二张图片是一个更好的图，因为图二点和点的距离相对比较大，也就是说，点之间的区分度比较高\n更好的降维方案\n此时点和点之间的距离最大，区分度更大\n那么如何定义样本之间的间距呢？\n可以使用方差(Variance),方差可以表示样本整体分布的疏密程度\n$$\nVar(x) = \\frac{1}{m}\\sum_{i = 1}^{m}(x_{i} - \\bar x)^2\n$$\n可以转化成：\n​\t希望找到一条轴，使得样本投影到该轴上的各点之间的方差最大\nPCA操作步骤：\n将样例的均值归为0(demean)\n这样，就相当于坐标轴变成如下的图：\n当均值$\\bar x = 0$时，原来的方差公式变为\n$$\nVar(x) = \\frac{1}{m}\\sum_{i = 1}^{m}(x_{i} - \\bar x)^2 \\Rightarrow Var(x) = \\frac{1}{m}\\sum_{i = 1}^{m}x_{i}^2\n$$\n假设两个维度的特征为$w1$,$w2$,那么需要求得的直线的方向为$w =（w_{1},w_{2}）$,映射到$w$后，有:\n$$\nVar(X_{project}) = \\frac{1}{m} \\sum_{1}^{m} (X_{project}^{(i)} - \\bar X{project})^2\n$$\n使得上面的公式最大\n其实最后的结果还是向量，因为$X$每一个点都包含两个元素，即应该是\n由均值为0，得到\n计算过程\n目标即：\n与线性回归的不同：\nPCA的两个坐标轴表示的是两个特征，而线性回归的横轴是特征，纵轴是输出标记 PCA使得点之间的方差最大，而线性回归则是需要使得输出标记尽量拟合一条直线，是在纵轴上的 决策树 例子：\n数值特征例子：\n特点：\n非参数学习算法 可以解决分类问题 天然的解决多分类问题 也可以解决回归问题 非常好的可解释性 问题：\n每个节点在哪个维度作划分 某个维度的哪个值作划分 支持向量机-SVM-(Support Vector Machine) 主要思想：\nSVM分类:\nHard Margin SVM\t解决的是线性可分问题\nSoft Margin SVM 可解决线性不可分问题\n🤠未完待续\u0026hellip;\u0026hellip;\n","description":"机器学习必须掌握的基础算法，学会这些基础，对后面的理解才会透彻","id":83,"section":"posts","tags":["机器学习","SVM","决策树","kNN","PCA"],"title":"机器学习基本算法","uri":"https://hugo.jiahongw.com/posts/deeplearning/machine-learning-base/"},{"content":"一些英雄的图案🌿\n","description":"","id":84,"section":"gallery","tags":[null],"title":"Hero","uri":"https://hugo.jiahongw.com/gallery/hero/"},{"content":"使用Scrapy爬取文章的一个小项目..\nScrapy 框架图：\n抓取小程序社区文章 创建爬虫项目 创建项目（项目名为MyTest）\n1 scrapy startproject MyTest 创建爬虫🪲(先进入到MyTest目录)\n1 scrapy genspider -t crawl wx wxapp-union.com wx为爬虫的名字，wxapp-union.com为爬取的域名，使用了模板crawl\n定义爬取的数据结构 爬取的数据结构类继承Item类，在items.py文件中，如下是设置需要爬取的数据结构，其中包括:标题、作者、时间、访问者、前言、正文。\n1 2 3 4 5 6 7 8 9 10 from scrapy import Item,Field # 定义文章数据结构 class ArticleItem(Item): title = Field() author = Field() _time = Field() visitors = Field() pre_talk = Field() article_content = Field() 编写爬虫规则与解析规则 爬虫的爬取网页的链接的规则和解析页面的规则都是在新建的spider文件中的类中，也即在wx.py中\n编写的spider类如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import scrapy from scrapy.linkextractors import LinkExtractor from scrapy.spiders import CrawlSpider, Rule from MyTest.items import ArticleItem class WxSpider(CrawlSpider): name = \u0026#39;wx\u0026#39; allowed_domains = [\u0026#39;wxapp-union.com\u0026#39;] start_urls = [\u0026#39;http://www.wxapp-union.com/portal.php?mod=list\u0026amp;catid=2\u0026amp;page=255\u0026#39;] rules = ( Rule(LinkExtractor(allow=r\u0026#39;.+mod=list\u0026amp;catid=2\u0026amp;page=\\d\u0026#39;), follow=True), Rule(LinkExtractor(allow=r\u0026#39;.+article-.+\\.html\u0026#39;),callback=\u0026#34;parse_item\u0026#34;,follow=False) ) def parse_item(self, response): title = response.xpath(\u0026#39;//h1[@class=\u0026#34;ph\u0026#34;]/text()\u0026#39;).get() author = response.xpath(\u0026#39;//p[@class=\u0026#34;authors\u0026#34;]//a\u0026#39;).get() _time = response.xpath(\u0026#39;//span[@class=\u0026#34;time\u0026#34;]/text()\u0026#39;).get() visitors = response.xpath(\u0026#39;//div[contains(@class,\u0026#34;focus_num\u0026#34;)]//a/text()\u0026#39;).get() pre_talk = response.xpath(\u0026#39;//div[@class=\u0026#34;blockquote\u0026#34;]//p/text()\u0026#39;).get() article_content = response.xpath(\u0026#39;//td[@id=\u0026#34;article_content\u0026#34;]\u0026#39;).get() item = ArticleItem(title=title,author=author,_time=_time,visitors=visitors,pre_talk=pre_talk,article_content=article_content) print(\u0026#39;*\u0026#39;*40) print(title) print(\u0026#39;*\u0026#39;*40) return item 首先rules定义了爬取链接规则，有两个规则，第一个规则是爬取页面的链接，每一页有多个文章的链接，而第二个规则则是定义爬取的具体文章内容的链接。 第一个规则需要Follow，因为需要根据每一页的内容查找文章的链接；而第二个规则是文章链接，故不需要继续Follow 第一个页面链接规则不需要回调函数，因为不需要解析，只需要获取文章链接；第二个文章链接规则则需要设置回调函数来对返回的文章网页内容进行解析。 parse_item说明：\nparse_item是解析页面返回内容的函数，其返回Item数据结构，使用Xpath分别获取数据结构各个元素的内容并且返回Item\n保存数据 pipelines是一个最后处理Item的管道\n在pipelines.py文件中新建pipleline对返回的Item进行处理，可以保存为文件，或者存储到数据库。\n首先文件中需要导入必要的库‘\n1 2 3 4 5 import re\t# 正则处理 from html2text import HTML2Text\t# 将网页转化为Markdown格式 from scrapy.exporters import JsonLinesItemExporter\t# 输出Json文件输出器 from urllib.parse import urljoin\t# 补全URL，因为有些URL只显示相对位置 import pymongo\t# MongoDB操作库 第一个Pipeline：保存到Json文件 程序的构造函数新建一个Json文件输出器，process_item进行数据的存储，关闭的时候close_spider会调用关闭文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 存储到Json文件中 class JsonPipeline(object): def __init__(self): self.f = open(\u0026#39;wxjc.json\u0026#39;,\u0026#39;wb\u0026#39;) self.exporter = JsonLinesItemExporter(self.f, ensure_ascii=False,encoding=\u0026#34;utf-8\u0026#34;) def process_item(self, item, spider): # 将内容转化为MarkDown格式 item[\u0026#39;article_content\u0026#39;] = convert_md(item[\u0026#39;article_content\u0026#39;]) self.exporter.export_item(item) return item def close_spider(self,spider): self.f.close() 第二个Pipeline：保存到Markdown文件 方法与第一发Pipeline类似，只是写文件使用最简单的追加方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 写入Markdown class MDPipeline(object): def __init__(self): self.f = open(\u0026#39;wx_teaches.md\u0026#39;,\u0026#39;a\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) def process_item(self,item,spider): if self.f: self.f.write(\u0026#39;\\n\u0026#39;) self.f.write(\u0026#34;# \u0026#34; + item[\u0026#39;title\u0026#39;] + \u0026#39;\\n\u0026#39;) header_info = \u0026#34;作者:{} 发布时间:{} Visitors:{}\\n\u0026#34;.format(item[\u0026#39;author\u0026#39;],item[\u0026#39;_time\u0026#39;],item[\u0026#39;visitors\u0026#39;]) self.f.write(header_info) self.f.write(\u0026#39;\u0026gt; \u0026#39; + item[\u0026#39;pre_talk\u0026#39;] + \u0026#39;\\n\u0026#39;) self.f.write(item[\u0026#39;article_content\u0026#39;]) return item def close_spider(self,spider): self.f.close() 第三个Pileline：保存到MongoDB 其中使用了类方法装饰器@classmethod,意思就是直接用类名调用该函数，就能够直接返回一个MongoPipeline类了，还定义了打开spider与关闭spider的操作，就是连接数据库与关闭数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 存储到MongoDB数据库 class MongoPipeline(object): def __init__(self,mongo_uri,mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls,crawler): return cls(mongo_uri = crawler.settings.get(\u0026#39;MONGO_URI\u0026#39;), mongo_db = crawler.settings.get(\u0026#39;MONGO_DB\u0026#39;)) def open_spider(self,spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db =self.client[self.mongo_db] def process_item(self,item,spider): name = item.__class__.__name__ # \u0026lt;a href=\\\u0026#34;space-uid-17761.html\\\u0026#34;\u0026gt;Rolan\u0026lt;/a\u0026gt; item[\u0026#39;author\u0026#39;] = re.search(\u0026#39;\u0026lt;a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;\u0026#39;,item[\u0026#39;author\u0026#39;]).group(1) self.db[name].insert(dict(item)) return item def close_spider(self,spider): self.client.close() 最后需要在settings.py中添加如下字段:\n1 2 MONGO_URI = \u0026#39;localhost\u0026#39; MONGO_DB = \u0026#39;WX\u0026#39; 最后需要在settings.py中添加如下字段 1 2 3 4 5 6 7 8 9 ITEM_PIPELINES = { \u0026#39;MyTest.pipelines.JsonPipeline\u0026#39;: 300, \u0026#39;MyTest.pipelines.MDPipeline\u0026#39;: 301, \u0026#39;MyTest.pipelines.MongoPipeline\u0026#39;: 400, } # 修改为False ROBOTSTXT_OBEY = False # 设置延迟1s DOWNLOAD_DELAY = 1 开始爬取 可以在项目目录中新建一个脚本start.py，文件内容如下，自动运行脚本\n1 2 from scrapy import cmdline cmdline.execute(\u0026#39;scrapy crawl test\u0026#39;.split(\u0026#39; \u0026#39;)) 爬取结果 Json结果 Markdown结果 Markdown文件由于太大了使用Markdown文件打不开，只好使用文本编辑器打开\nMongoDB结果 ","description":"","id":85,"section":"posts","tags":["爬虫","Scrapy"],"title":"Scrapy框架","uri":"https://hugo.jiahongw.com/posts/spider/scrapy-1/"},{"content":"在 Pt 页面增加了一些用 JS 实现的 PPT，主要展示一些效果。🔌\n网页 PPT 主题 beige black blood monokai league moon night serif simple solarized sky white 使用方法 在 markdown 文件的 ymal 头部添加:revealTheme: serif\n在线制作 PPT Slides https://slides.com/\n","description":"","id":86,"section":"posts","tags":["ppt","blog"],"title":"Slides和网页PPT","uri":"https://hugo.jiahongw.com/posts/usefulpower/ppt-use/"},{"content":"使用MXNet的好处你永远想象不到。🉑\n本地环境搭建教程 参考:\nhttps://discuss.gluon.ai/t/topic/13576?u=bigbigwolf-ai\n范数 L0范数：指向量中非0元素的个数。（难优化求解）\nL1范数：指向量中各个元素的绝对值之和\nL2范数：指向量各元素的平方和然后求平方根\n设$n$维向量$x$中的元素为$x_1, \\ldots, x_n$。向量$x$的$L_{p}$范数为:\n$$\n|\\boldsymbol{x}|p = \\left(\\sum{i=1}^n \\left|x_i \\right|^p \\right)^{1/p}.\n$$\n$L_{1}$范数：\n$$\n|\\boldsymbol{x}|1 = \\sum{i=1}^n \\left|x_i \\right|.\n$$\n$L_{2}$范数：\n$$\n|\\boldsymbol{x}|2 = \\sqrt{\\sum{i=1}^n x_i^2}.\n$$\n设$X$是一个$m$行$n$列矩阵。矩阵$X$的Frobenius范数为该矩阵元素平方和的平方根：\n$$\n|\\boldsymbol{X}|F = \\sqrt{\\sum{i=1}^m \\sum_{j=1}^n x_{ij}^2},\n$$\n查阅文档 1 2 from mxnet import nd print(dir(nd.random)) ['NDArray', '_Null', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_internal', '_random_helper', 'current_context', 'exponential', 'exponential_like', 'gamma', 'gamma_like', 'generalized_negative_binomial', 'generalized_negative_binomial_like', 'multinomial', 'negative_binomial', 'negative_binomial_like', 'normal', 'normal_like', 'numeric_types', 'poisson', 'poisson_like', 'randint', 'randn', 'shuffle', 'uniform', 'uniform_like'] help函数可以查询具体的函数作用及用法\n1 help(nd.ones_like) Help on function ones_like: ones_like(data=None, out=None, name=None, **kwargs) Return an array of ones with the same shape and type as the input array. Examples:: x = [[ 0., 0., 0.], [ 0., 0., 0.]] ones_like(x) = [[ 1., 1., 1.], [ 1, 1., 1.]] Parameters ---------- data : NDArray The input out : NDArray, optional The output NDArray to hold the result. Returns ------- out : NDArray or list of NDArrays The output of this function. 线性回归 导入必要的库\n1 2 3 4 5 %matplotlib inline from IPython import display from matplotlib import pyplot as plt from mxnet import autograd, nd import random 生成数据集，其中每个例子输入数据个数为2，有1000个数据\n1 2 3 4 5 6 7 num_inputs = 2 num_examples = 1000 true_w = nd.array([2, -3.4]) true_b = nd.array([4.2]) features = nd.random.normal(scale=1, shape=(num_examples, num_inputs)) labels = nd.dot(true_w,features.T) + true_b labels += nd.random.normal(scale=0.01, shape=labels.shape) 查看数据\n1 features[0], labels[0] ( [ 0.28752208 -0.04466231] \u0026lt;NDArray 2 @cpu(0)\u0026gt;, [4.927063] \u0026lt;NDArray 1 @cpu(0)\u0026gt;) 定义相关函数\n1 2 3 4 5 6 7 8 9 10 11 def use_svg_display(): # 用矢量图显示 display.set_matplotlib_formats(\u0026#39;svg\u0026#39;) def set_figsize(figsize=(3.5, 2.5)): use_svg_display() # 设置图的尺寸 plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = figsize set_figsize() plt.scatter(features[:, 1].asnumpy(), labels.asnumpy(), 1); # 加分号只显示图 data_iter函数作用:\n扰乱读取顺序，使得读取随机 按Batch_size分段取数据，需要判断是否到结尾，使用yield构建生成器节省内存 1 2 3 4 5 6 7 8 # 本函数已保存在d2lzh包中方便以后使用 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) random.shuffle(indices) # 样本的读取顺序是随机的 for i in range(0, num_examples, batch_size): j = nd.array(indices[i: min(i + batch_size, num_examples)]) yield features.take(j), labels.take(j) # take函数根据索引返回对应元素 1 2 3 4 5 batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, y) break [[-0.65439206 0.74410725] [ 0.69013244 -0.6483847 ] [-0.59409887 0.3589477 ] [-0.47491348 0.6438462 ] [ 0.5074032 0.42834154] [-0.18589513 -0.21707669] [ 0.70281196 -1.3320632 ] [ 1.2072632 1.6909351 ] [-0.17264698 -1.5742793 ] [-1.6516455 -0.29966688]] \u0026lt;NDArray 10x2 @cpu(0)\u0026gt; [ 0.37379816 7.7938933 1.7758217 1.0414512 3.743439 4.5605783 10.148926 0.84148276 9.19984 1.9295483 ] \u0026lt;NDArray 10 @cpu(0)\u0026gt; 初始化\n1 2 w = nd.random.normal(scale=0.01, shape=(num_inputs, 1)) b = nd.zeros(shape=(1,)) 添加保存梯度的空间\n1 2 w.attach_grad() b.attach_grad() 1 2 def linreg(X, w, b): # 本函数已保存在d2lzh包中方便以后使用 return nd.dot(X, w) + b 1 2 def squared_loss(y_hat, y): # 本函数已保存在d2lzh包中方便以后使用 return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2 1 2 3 def sgd(params, lr, batch_size): # 本函数已保存在d2lzh包中方便以后使用 for param in params: param[:] = param - lr * param.grad / batch_size 开始训练\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期 # 在每一个迭代周期中，会使用训练数据集中所有样本一次（假设样本数能够被批量大小整除）。X # 和y分别是小批量样本的特征和标签 for X, y in data_iter(batch_size, features, labels): with autograd.record(): l = loss(net(X, w, b), y) # l是有关小批量X和y的损失 l.backward() # 小批量的损失对模型参数求梯度 sgd([w, b], lr, batch_size) # 使用小批量随机梯度下降迭代模型参数 train_l = loss(net(features, w, b), labels) print(\u0026#39;epoch %d, loss %f\u0026#39; % (epoch + 1, train_l.mean().asnumpy())) epoch 1, loss 0.040809 epoch 2, loss 0.000157 epoch 3, loss 0.000051 对比\n1 true_w, w ( [ 2. -3.4] \u0026lt;NDArray 2 @cpu(0)\u0026gt;, [[ 1.9991481] [-3.3992586]] \u0026lt;NDArray 2x1 @cpu(0)\u0026gt;) 1 true_b, b ( [4.2] \u0026lt;NDArray 1 @cpu(0)\u0026gt;, [4.19921] \u0026lt;NDArray 1 @cpu(0)\u0026gt;) ","description":"","id":89,"section":"posts","tags":["python","MXNet","深度学习","liner"],"title":"MXNet回顾","uri":"https://hugo.jiahongw.com/posts/deeplearning/mxnet-begin/"},{"content":"👱‍♀️介绍一些 markdown 中比较实用的一些写作方法。\n任务列表✍ a task list item list syntax required normal formatting, @mentions, #1234 refs incomplete completed 上面的代码如下：\n1 2 3 4 5 - [ ] a task list item - [ ] list syntax required - [ ] normal **formatting**, @mentions, #1234 refs - [ ] incomplete - [x] completed 数学公式:triangular_ruler 使用 MathJax 渲染 LaTeX 数学表达式。💡\n$$\n\\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix}\n\\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\\n\\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\\\\n\\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\\\\n\\end{vmatrix}\n$$\n上面的代码如下：\n1 2 3 4 5 6 7 $$ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\\\\\ \\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\\\\\\\ \\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\\\\\\\ \\end{vmatrix} $$ $$\n\\begin{align*}\ny = y(x,t) \u0026amp;= A e^{i\\theta} \\\\\n\u0026amp;= A (\\cos \\theta + i \\sin \\theta) \\\\\n\u0026amp;= A (\\cos(kx - \\omega t) + i \\sin(kx - \\omega t)) \\\\\n\u0026amp;= A\\cos(kx - \\omega t) + i A\\sin(kx - \\omega t) \\\\\n\u0026amp;= A\\cos \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) + i A\\sin \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) \\\\\n\u0026amp;= A\\cos \\frac{2\\pi}{\\lambda} (x - v t) + i A\\sin \\frac{2\\pi}{\\lambda} (x - v t)\n\\end{align*}\n$$\n上面代码如下：\n1 2 3 4 5 6 7 8 9 10 $$ \\begin{align*} y = y(x,t) \u0026amp;= A e^{i\\theta} \\\\\\\\ \u0026amp;= A (\\cos \\theta + i \\sin \\theta) \\\\\\\\ \u0026amp;= A (\\cos(kx - \\omega t) + i \\sin(kx - \\omega t)) \\\\\\\\ \u0026amp;= A\\cos(kx - \\omega t) + i A\\sin(kx - \\omega t) \\\\\\\\ \u0026amp;= A\\cos \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) + i A\\sin \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) \\\\\\\\ \u0026amp;= A\\cos \\frac{2\\pi}{\\lambda} (x - v t) + i A\\sin \\frac{2\\pi}{\\lambda} (x - v t) \\end{align*} $$ 脚注:footprints 如下是使用的代码，将鼠标悬停在“ fn1”或“ fn2”上标上可以查看脚注的内容。您可以将任何喜欢的唯一标识用作脚注标记（例如“ fn1”）。\n1 2 [^fn1]: Here is the *text* of the first **footnote**. [^fn2]: Here is the *text* of the second **footnote** 你也可以内嵌脚注，就像^[Here is the text of the first footnote.]\n水平线:wavy_dash 🌟在空行输入***或---，如下：\nYMAL 首要事项:thinking 包含 YAML 前事块的文件将作为特殊文件进行处理，下面是一个例子\n1 2 3 4 --- layout: post title: Blogging Like a Hacker --- 目录:bookmark_tabs 输入[toc]并回车即可。\n内部链接:link 这是一个跳转到任务列表的链接,this link ！\n代码如下：\n1 [this link](#任务列表✍) 参考链接:book 参考链接使用两组方括号的格式，第一个是显示的文字，第二个括号内是查找的 id，代码如下：\n1 2 3 4 5 This is [an example][id] reference-style link. Then, anywhere in the document, you define your link label on a line by itself like this: [id]: http://example.com/ \u0026#34;Optional Title Here\u0026#34; 隐式链接，直接使用Google查阅：\n1 2 3 4 [Google][] And then define the link: [Google]: http://google.com/ 删除线:x 删除Mistaken text.，代码为~~Mistaken text.~~\n高亮:high_brightness ==highlight==，使用两个等号在两边进行包围，代码如下：\n1 ==highlight== 插入视频:video_camera Your browser does not support the video tag.\n上面的代码即：\n1 \u0026lt;video poster=\u0026#34;https://i.loli.net/2020/02/29/S4oN2djFDZYiqAx.png\u0026#34; src=\u0026#34;https://files.catbox.moe/bqrntc.flv\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; loop=\u0026#34;loop\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the video tag.\u0026lt;/video\u0026gt; 插入音乐:musical_score Your browser does not support the audio tag.\n上面的代码即：\n1 \u0026lt;audio src=\u0026#34;https://files.catbox.moe/wjiywu.mp3\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; loop=\u0026#34;loop\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the audio tag.\u0026lt;/audio\u0026gt; 更多：\n随机图片:deciduous_tree 网址:https://picsum.photos/1920/1080\n","description":"","id":90,"section":"posts","tags":["markdown","Typora"],"title":"Markdown使用笔记","uri":"https://hugo.jiahongw.com/posts/usefulpower/markdown-deep/"},{"content":" HUGO + Github + Github Action 持续集成部署个人博客\n安装 HUGO 本地环境 首先在 HUGO 的官网下载Hugo的 Windows 安装包，然后将路径添加到环境变量即可。\nstep1:下载 hugo\nstep2:配置环境变量\n其他系统安装 HUGO 的方法：\nMac：brew install hugo HUGO 站点配置及主题配置 创建站点 在目录下直接输入下面的代码即可创建一个名为 blog 的 hugo 站点(注意：新建的站点是没有自带主题的)\n1 hugo new site blog 或者进入 blog 文件夹内直接输入以下语句：\n1 hugo new site . 下载主题 可以在hugo theme下载主题，然后根据主题的文档进行配置\n放到站点文件夹 themes 内，配置 config.toml\n本地测试运行 输入hugo server测试\nGithub 配置 创建站点仓库并且设置 GithubPage 可以在 Setting 中看见如下：\n创建另一个存储项目的仓库 创建另一个存储项目的仓库，存储写的博客文章\n配置 Github Action 首先在项目仓库点击 action，选择Simple workflow，输入一下的配置代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 name: HUGO_CI #自动化的名称 on: push: # push的时候触发 branches: # 那些分支需要触发 - master jobs: build: runs-on: ubuntu-latest # 镜像市场 steps: - name: checkout # 步骤的名称 uses: actions/checkout@v3 #软件市场的名称 with: # 参数 submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2.2.2 with: hugo-version: \u0026#39;0.64.1\u0026#39; # 设置HUGO框架的版本 extended: true # 是否选择拓展版HUGO框架，选择是 - name: Build run: hugo -D - name: Deploy uses: peaceiris/actions-gh-pages@v2.5.1 env: ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }} EXTERNAL_REPOSITORY: redisread/redisread.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public 准备部署，我们开发的项目及github pages实际是分开的，一个用于保存项目，相当于源代码，另外一个用于保存最终的网页文件。\n使用 git 生成 ssh key(相当于生成对密钥)\n1 2 3 4 ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) 假设 开发项目为 HUGO_blog 部署的项目为 redisread.github.io\n打开HUGO_blog仓库的 settings，再点击Secrets，然后添加刚刚生成的私钥，name 为ACTIONS_DEPLOY_KEY\n同理，打开redisread.github.io，点击Deploy keys，添加公钥，Allow write access一定要勾上，否则会无法提交\n然后，你就可以提交代码了，push 成功后，打开仓库actions，至此部署成功，大功告成！\n后续可以自己写文章然后 push 了，github action会自动帮你部署。\n","description":"Guide to set Hugo site.","id":91,"section":"posts","tags":["Hugo","Github"],"title":"部署HUGO博客","uri":"https://hugo.jiahongw.com/posts/hugo/hugo_setup/"},{"content":"我是一个不够严谨的程序员🙉.\n我喜欢📖,还有🏓.\n或许有时候我想的不够远，但是有时候我想的很深入。\n我最喜欢的 Aaron Swartz 语录:\n在长大的过程中，我才慢慢发现，我身边的所有事，别人跟我说的所有事，那些所谓本来如此，注定如此的事，它们其实没有非得如此，事情是可以改变的。更重要的是，有些事既然错了，那就该做出改变。\n我对学校十分失望，我觉得老师们根本不懂自己所讲的是什么，他们居高临下，管这管那；作业就像是种把戏，就好像知识一种强制所有学生一起庸庸碌碌的手段。于是我就开始去阅读那些关于教育史和这套教育体系演变的书籍。然后你就能发现，如果要真正学到东西，那就不能机械重复老师所教的，这有点儿使得我渐渐学会了质疑。我质疑我所上的学校，我质疑简历这所学校的这个社会，我质疑学校教人们追求的那套事理，我质疑建立起这整个体系的政府。\n我总是深入思考，我希望别人也能想远一点。我为理想而工作，并从别人身上学习，我不喜欢拒人于外。我是个完美主义者，但我不会要求出版界也精益求精。除了教育和娱乐以外，我不会浪费时间在那些不会有影响的事情上。我试着和每个人都友好相处，但我讨厌人们不认真对待我。我不记恨他人，因为这于创造无益。但我从自身经历中学习，我想让世界变得更美好。\n我深深地觉得，光安生与当下这世界是不够的，那样子知识别人给什么你就照收，大人们说什么你就照做，你照着父母说的去做，照着社会说的去做。我觉得你应该总持有质疑，我觉得从科学的角度看，你所学的一切都知识暂时性的，任何所学都有改口、驳斥、质疑的余地。我觉得这情况对社会也适用。当我意识到社会上有着我能尽份力去解决的真正严重的、基础性的问题时，我没法去遗忘它、回避它。\n","description":"Zzo about page","id":92,"section":"","tags":null,"title":"About","uri":"https://hugo.jiahongw.com/about/"},{"content":"盒子 支持 Markdown 语法的盒子 语法：\n或者：\n1 \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;This is \u0026lt;strong\u0026gt;boxmd\u0026lt;/strong\u0026gt; shortcode\u0026lt;/div\u0026gt; 渲染显示：\nThis is boxmd shortcode 简单盒子 语法：\n渲染显示：\nThis is **box** shortcode 代码选项卡 可以在不同的代码块之间切换，语法：\n渲染显示：\njava javascript 1 System.out.println(\u0026#39;Hello World!\u0026#39;); 1 console.log(\u0026#39;Hello World!\u0026#39;); 常规选项卡 这个和代码选项卡类似，不同的是，这种选项卡更加“常规”。语法：\n渲染显示：\nWindows MacOS Ubuntu Windows section 1 console.log(\u0026#39;Hello World!\u0026#39;); ⚠️Becareful that the content in the tab should be different from each other. The tab makes unique id hashes depending on the tab contents. So, If you just copy-paste the tabs with multiple times, since it has the same contents, the tab will not work.\nMacOS section Hello world! Ubuntu section Great! 展开栏 语法：\n渲染显示：\nExpand me Title contents Expand me2 Title2 contents2 彩色文本框 语法：\n渲染显示：\nthis is a text this is a text this is a text this is a text 彩色注意框 语法：\n渲染显示：\nsuccess text info text warning text error text 图片描述 使用语法：\n渲染显示：\nSample Image: Image with title, caption, alt, ... 按钮 语法：\n简单按钮：\nbutton 设置宽度高度：\nbutton 设置颜色：\nbutton ","description":"tabs, code-tabs, expand, alert, warning, notice, img, box","id":93,"section":"posts","tags":["shortcode"],"title":"Shortcodes使用","uri":"https://hugo.jiahongw.com/posts/hugo/shortcodes/"},{"content":"A Short Video： ——以下 Aaron Swartz的宣言，我想这才是信息革命的真谛——\n信息就是力量。但就像所有力量一样，有些人只想占为己有。世界上所有的科学和文化遗产，已在书籍和期刊上发布了数个世纪，正渐渐地被少数私有的公司数字化并上锁。想要阅读那些有着最著名研究成果的论文？你必须支付给如 Reed Elsevier 这样的出版商大把钱。\n有人努力去改变这种状况。开放访问运动 (Open Access Movement) 奋勇斗争，确保科学家们没有将他们的版权签署给别人，而是将他们的成果发布到网络上，允许任何人访问它们。但即便是最好的情况，他们的行为也只作用于未来发布的东西。之前的都将失去。\n这样的代价实在太高。强制学者付钱以阅读他们同行的成果？扫描整个图书馆却只允许 Google 的人阅读它们？提供科学文章给那些第一世界的精英大学，却不给身在南半球的儿童？这实在蛮横且无法接受。\n“我同意，”有些人就说了，“但是我们能做什么呢？那些公司握有版权，他们靠限制访问赚取大把的钱，而且这是完全合法的 - 我们没有办法阻止他们。”但有些事我们能做，这些事我们已经在做：我们可以反击。\n那些能够访问这些资源的人 - 学生，图书管理员，科学家 - 你们被赋予了特权。你们能享受到这知识的盛宴，而其他人却被排除在外。但是你们不必 - 事实上，从道义层面来说，你们不能 - 为保留自己保留这份特权。你们有义务和全世界分享它。而且你们已经在做了：和同行们交换密码，回应朋友们的下载请求。\n同时，那些被拒之门外的人们并没有袖手旁观。你们溜过洞穴，翻越围墙，解放那些被出版商封锁的信息并分享给你的朋友们。\n但所有这些行动都是在黑暗中进行，隐藏于地底。它们被称作偷窃或盗版，仿佛分享大量的知识精神上等同于抢劫一艘船只并谋杀其船员。但是分享绝非不道德的，它是一种道德使命。只有那些利欲熏心的人才会拒绝让朋友复制一份。\n大公司，当然，就是利欲熏心。使它们运转的法律要求使然 - 稍微出点事投资人就得叛乱。它们收买的政治家们支持它们，通过法案让它们拥有专属的权力决定谁可以复制。\n遵从不公正的法律不会带来公正。步入光明的时候到了，在公民不服从的伟大传统下，宣告我们对这种私人盗窃公共文化的反抗。\n我们要夺回信息，无论它们被存在何处，制作我们的副本并和全世界分享。我们要取到版权到期的东西并将它们归档，我们要买下秘密的资料库并将它们放到网上。我们要下载科学期刊并将它们上传到文件分享网络。我们要为游击队开放访问而战。\n只要全世界有足够多的我们，那就不仅是传达了一个反对知识私有化的强有力信号，我们还将让它成为过去。你愿意和我们一起吗？\n亚伦·斯沃茨 (Aaron Swartz)\n2008 年 7 月，意大利 Eremo\nInformation is power. But like all power, there are those who want to keep it for themselves. The world\u0026rsquo;s entire scientific and cultural heritage, published over centuries in books and journals, is increasingly being digitized and locked up by a handful of private corporations. Want to read the papers featuring the most famous results of the sciences? You\u0026rsquo;ll need to send enormous amounts to\npublishers like Reed Elsevier.\nThere are those struggling to change this. The Open Access Movement has fought valiantly to ensure that scientists do not sign their copyrights away but instead ensure their work is published on the Internet, under terms that allow anyone to access it. But even under the best scenarios, their work will only apply to things published in the future. Everything up until now will have been lost.\nThat is too high a price to pay. Forcing academics to pay money to read the work of their colleagues? Scanning entire libraries but only allowing the folks at Google to read them? Providing scientific articles to those at elite universities in the First World, but not to children in the Global South? It\u0026rsquo;s outrageous and unacceptable.\n\u0026ldquo;I agree,\u0026rdquo; many say, \u0026ldquo;but what can we do? The companies hold the copyrights, they make enormous amounts of money by charging for access, and it\u0026rsquo;s perfectly legal - there\u0026rsquo;s nothing we can do to stop them.\u0026rdquo; But there is something we can, something that\u0026rsquo;s already being done: we can fight back.\nThose with access to these resources - students, librarians, scientists - you have been given a privilege. You get to feed at this banquet of knowledge while the rest of the world is locked out. But you need not - indeed, morally, you cannot - keep this privilege for yourselves. You have a duty to share it with the world. And you have: trading passwords with colleagues, filling download requests for friends.\nMeanwhile, those who have been locked out are not standing idly by. You have been sneaking through holes and climbing over fences, liberating the information locked up by the publishers and sharing them with your friends.\nBut all of this action goes on in the dark, hidden underground. It\u0026rsquo;s called stealing or piracy, as if sharing a wealth of knowledge were the moral equivalent of plundering a ship and murdering its crew. But sharing isn\u0026rsquo;t immoral - it\u0026rsquo;s a moral imperative. Only those blinded by greed would refuse to let a friend make a copy.\nLarge corporations, of course, are blinded by greed. The laws under which they operate require it - their shareholders would revolt at anything less. And the politicians they have bought off back them, passing laws giving them the exclusive power to decide who can make copies.\nThere is no justice in following unjust laws. It\u0026rsquo;s time to come into the light and, in the grand tradition of civil disobedience, declare our opposition to this private theft of public culture.\nWe need to take information, wherever it is stored, make our copies and share them with the world. We need to take stuff that\u0026rsquo;s out of copyright and add it to the archive. We need to buy secret databases and put them on the Web. We need to download scientific journals and upload them to file sharing networks. We need\nto fight for Guerilla Open Access.\nWith enough of us, around the world, we\u0026rsquo;ll not just send a strong message opposing the privatization of knowledge - we\u0026rsquo;ll make it a thing of the past.\nWill you join us?\nAaron Swartz\nJuly 2008, Eremo, Italy\n","description":"","id":94,"section":"talks","tags":[null],"title":"互联网之子的故事","uri":"https://hugo.jiahongw.com/talks/mylinks/"},{"content":"Sample images about life.\n","description":"my gallery","id":96,"section":"gallery","tags":[null],"title":"life","uri":"https://hugo.jiahongw.com/gallery/life/"},{"content":"between 70 and 240 in movies\ngood movies！🎥\n","description":"my gallery","id":97,"section":"gallery","tags":[null],"title":"movie","uri":"https://hugo.jiahongw.com/gallery/movie/"}]