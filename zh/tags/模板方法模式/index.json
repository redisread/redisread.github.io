[{"content":" 组合模式跟我们之前讲的面向对象设计中的“组合关系(通过组合来组装两个类)”，完全是两码事。这里讲的“组合模式”，主要是用来处理树形结构数据。\n定义 组合模式允许你将对象组合成树形结构来表示“整体/部分”的层次结构。组合能够让客户以一致的方式处理个别对象以及对象组合。\n架构 @startuml 'https://plantuml.com/class-diagram class Client class Component { + operation() + add(Component) + remove(Component) + getChild(int) } class Leaf extends Component { + operation() } note bottom of Leaf : 叶子节点没有孩子 class Composite extends Component { + operation() + add(Component) + remove(Component) + getChild(int) } note bottom of Composite : 组合节点具有叶子节点，也依赖Component接口 Client -\u0026gt; Component @enduml 使用场景 使用组合模式的前提在于，你的业务场景必须能够表示成树形结构。所以，组合模式的应用场景也比较局限，它并不是一种很常用的设计模式。\n 理解“整体和部分”的关系。\n Reference:\n","description":"","id":0,"section":"posts","tags":[""],"title":"组合模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/compositepattern/"},{"content":" 迭代器模式也叫游标模式。\n  定义 迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示。\n 迭代器模式封装了遍历。并且迭代器模式还将在元素之间进行游走的责任交给迭代器，使得职责更加单一。\n 架构 @startuml class Client interface Collection { + createIterator() } class ConcreteCollection implements Collection { + createIterator() } interface Iterator { + hasNext() + next() + remove() } class ConcreteIterator implements Iterator{ + hasNext() + next() + remove() } Client -left-\u0026gt; Collection Client -right-\u0026gt; Iterator ConcreteCollection -right-\u0026gt; ConcreteIterator @enduml 使用场景  Java Iterator 解耦容器代码和遍历代码，使得职责更加单一  问题   Java中如果使用迭代器的同时删除容器中的元素，会导致迭代器的错误，这是为什么？如何解决呢？\n不只是删除容器，增加元素也可能会出现问题。\n在使用迭代器遍历到后面的元素时，删除了前面的元素，会导致遍历元素少了一个。(2被跳过了)\n在使用迭代器遍历到后面的元素时，在前面增加了元素，会导致前面遍历的一个元素又遍历了一次。（1重复遍历了）\n如何解决？\nJava语言中的解决方法是增删元素之后，让遍历报错。\n 在 ArrayList 中定义一个成员变量 modCount，记录集合被修改的次数，集合每调用一次增加或删除元素的函数，就会给 modCount 加 1。当通过调用集合上的 iterator() 函数来创建迭代器的时候，我们把 modCount 值传递给迭代器的 expectedModCount 成员变量，之后每次调用迭代器上的 hasNext()、next()、currentItem() 函数，我们都会检查集合上的 modCount 是否等于 expectedModCount，也就是看，在创建完迭代器之后，modCount 是否改变过。\n 如果两个值不相同，那就说明集合存储的元素已经改变了，要么增加了元素，要么删除了元 素，之前创建的迭代器已经不能正确运行了，直接抛出错误让程序员解决。\n迭代器内部也实现了一个remove() 方法，能够在遍历集合的同时，安全地删除集合中的元素。它作用有限，只能删除游标指向的前一个元素，而且一个 next() 函数之后，只能跟着最多一个 remove() 操 作，多次调用 remove() 操作会报错。\n  区别和关系  你可以使用迭代器模式来遍历组合模式树。  Reference:\n","description":"迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示。","id":1,"section":"posts","tags":["设计模式","迭代器模式"],"title":"迭代器模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/iteratorpattern/"},{"content":" 定义 模板方法模式在一个方法中定义一个算法的架构，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。\n 模板方法模式体现了好莱坞原则：别调用我们，我们会调用你。简单的说，模板方法的抽象类会告诉子类，你不要调用我们，我们会调用你。\n 使用场景 模板方法模式还可以在抽象类中定义一个什么都不做的函数步骤，子类根据情况考虑是否实现这个接口，而这个接口就是一个钩子，可以在模板步骤的指定位置做一些事。\nJava中的排序算法也是一种模板方法，排序的列表元素类型需要实现compareTo方法，这就类似模板方法里面的一个步骤。实现了之后，才能完成排序的过程。\n1 复用\n因为模板方法是基于继承实现，可以将固定的算法步骤封装在抽象类，抽象类可以实现一些固定的步骤，子类直接进行复用就可以了。\n例子：Java中的InputStream的read()函数(子类实现参数不同的read函数)和AbstractList的addAll()函数(子类实现add函数)。\n2 框架拓展性\n HttpServlet的service()方法就是一个模板方法，它实现了整个http请求的执行流程，而doGet()和doPost()是模板中可以由子类自定义的部分。相当于框架为用户提供了拓展点，使得不需要修改框架源码就能将拓展点添加到框架中。 Junit框架也提供了一些功能拓展点setUp()和setDown()，可以在开始和结束的时候做一些事情，而runBase()函数是一个模板方法，定义了执行测试用例的整体流程。  架构 @startuml 'https://plantuml.com/class-diagram abstract class AbstractClass { + templateMethod() + stepOperation1() + {abstract} stepOperation2() + stepOperation3() } note right of AbstractClass::templateMethod 模板方法定义算法步骤： stepOperation1(); stepOperation2(); stepOperation3(); end note class ConcreteClassB extends AbstractClass { + stepOperation2() } class ConcreteClassA extends AbstractClass { + stepOperation2() } note right of ConcreteClassB::stepOperation2 子类实现一个或者多个具体的步骤 end note @enduml 区别  策略模式和模板方法模式都封装算法，但是一个组合，一个继承。 工厂方法是模板方法的一个特殊版本。  Reference:\n","description":"模板方法模式是对抽象的有一种体现，这次，抽象的是算法流程。模板方法定义了一个算法的步骤，将允许子类为一个或者多个步骤提供实现。","id":2,"section":"posts","tags":["设计模式","模板方法模式"],"title":"模板方法模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/templatemethodpattern/"},{"content":"定义 外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。\n 外观模式可以解决接口的复用性和易用性的问题，并且，外观模式可以让层级更加清晰，满足最少知识原则，让暴露的接口或者函数更加少。\n 使用场景 1 解决易用性\n当接口越来越多，越来越复杂的时候，提供一层更加简单易用，更加高层的接口。例子：Linux系统调用函数封装了Linux内核调用、Linux的Shell命令封装了复杂的系统调用。\n 单独起起一个API网关层服务做转发和聚合也很类似门面设计模式。\n 2 解决性能问题\n将多个接口调用封装成一个简单的门面接口，在一些需要多次请求的网络通信中可以减少通信的次数，降低网络通信的成本，提高APP响应的速度。\n 经验：\n如果门面接口不多，此时可以将门面接口和原来的接口放在同一个类中，不需要特殊的标记；如果门面接口很多，可以在已有的接口之上，再重新抽象出一层，转门放置门面接口，可以新建一个类或者包；如果门面接口特别多了，并且很多都是跨多个子系统的，可以将门面系统接口放到一个新的子系统中。\n 3 解决分布式事务问题\n门面接口可以将一个事务的多个接口封装在一个接口中，方面进行事务的回滚或者重试。\n架构 @startuml 'https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026quot;子系统\u0026quot; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml 比较  适配器是做接口转换，解决的是原接口和目标接口不匹配的问题。门面模式做接口整合，解决的是多接口调用带来的问题。 适配器模式注重的是兼容性，而门面模式注重的是易用性。  Reference:\n","description":"外观模式也叫做门面模式，外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。","id":3,"section":"posts","tags":["设计模式","外观模式","门面模式"],"title":"外观模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/facadepattern/"},{"content":"定义 适配器将一个类的接口，转换成客户端期望的另一个接口。适配器让原本不兼容的类达到兼容。\n（可以让客户从实现的接口解耦）\n 适配器模式下必须有一个接口的”转换“过程。\n  形象的比喻：USB转接头就是一个适配器！\n 架构 @startuml ' 适配器模式 class client interface Targert { + request() } note top of Targert : 目标接口 class Adaptor implements Targert { + request() } note bottom of Adaptor : 适配器实现目标接口 class Adaptee { + specificRequest() } Adaptor -\u0026gt; Adaptee : 并且包含被适配的接口对象 client -\u0026gt; Targert @enduml  上面的是对象适配器的架构，在支持多重继承的语言中，可以使用类适配器：\n@startuml ' 适配器模式 class client interface Targert { + request() } note top of Targert : 目标接口 class Adaptor implements Targert,Adaptee { + request() } class Adaptee { + specificRequest() } client -\u0026gt; Targert @enduml  使用场景 一般来说，适配器模式可以看作是一宗“补偿模式”，用来补救设计上的缺陷，也是一种无奈之举。一般也不会优先推荐使用这种模式。\n主要场景 1 封装有缺陷的接口设计\n例如外部引入的接口都是静态方法，会影响代码的可测试性。此时使用适配器进行适配接口，将静态方法都“封装“起来，这样就可以进行测试了。\n2 替换依赖的外部系统\n当需要将外部依赖的一个系统替换成另一个系统的时候，也就是一些系统迁移或者接口切换的场景，使用适配器模式可以减少对代码的改动。\n@startuml ' 适配器模式 interface IA { + fa() } note top of IA : 系统A interface IB { + fb() } note top of IB : 系统B class Client class BAdaptor implements IA { IB b + fa() } note left of BAdaptor : 实际fa函数调用fb函数 BAdaptor -\u0026gt; IB Client -\u0026gt; IA @enduml 3 兼容老版本的接口\n在进行一些版本升级的时候，对于一些废弃的接口，我们不会直接删除，而是暂时保留，并且标注为deprecate，并且将内部实现逻辑委托为新的实现逻辑。\n例如JDK中包含一个遍历集合容器的类Enumeration，JDK2.0对这个类进行了重构，将它改名为Iterator类，并且对它的代码实现做了优化。但是如果将Enumeration直接从JDK2.0删除，那么那些从JDK1.0升级到JDK2.0的项目，就会编译报错。但是修改散落在各处的Enumeration调用又多又杂，导致升级困难。为了避免这种情况，可以暂时保留Enumeration类，并且将其内部实现替换为Iterator的实现。下面是一个例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  public class Collections { public static Emueration emumeration(final Collection c) { return new Enumeration() { Iterator i = c.iterator(); public boolean hasMoreElments() { return i.hashNext(); } public Object nextElement() { return i.next(): } } } }   适配器模式在Java日志中的应用 Slf4j这个日志框架相当于JDBC规范，提供了一套打印日志的统一接口规范。但是，它只定义了接口，没有具体的实现，需要配合其他日志框架(log4j、logback、JUL)来使用。Slf4j的出现稍晚于这些框架，为了适配原来的日志框架，Slf4j框架不仅提供可统一的接口定义，还提供了针对不同日志框架的适配器。对不同的日志框架接口进行二次封装，适配成统一的Slf4j接口定义。\n比较 装饰器和适配器的区别：\n装饰器包装一个实现同一个接口的类对象，添加一些责任，并且接口不变；适配器则包装实现不同接口的被适配的对象，进行接口的转换和适配，以达到兼容的效果。\n 实现都差不多，主要还是设计的思想大不同。\n Reference:\n 《Head First 设计模式》  ","description":"适配器使得新的调用可以适配老的接口而不需要修改旧的代码。达到了对拓展开发，对修改关闭的设计原则。","id":4,"section":"posts","tags":["设计模式","适配器模式"],"title":"适配器模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/adaptorpattern/"},{"content":" 定义 命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。\n 命令模式主要是将“命令的请求者”从“命令的执行者”对象中解耦。\n 应用场景  异步、延迟、排队执行命令、撤销重做命令、存储命令、命令记录日志 Hystix熔断框架就用到了命令模式 redis使用命令模式处理指令  架构 @startuml class client class Invoker { + setCommand() } interface Command { + execute() + undo() } class ConcreteCommand implements Command{ + execute() + undo() } class Receiver { + action() } Invoker -\u0026gt; Command Receiver \u0026lt;- ConcreteCommand client -\u0026gt; Receiver client -\u0026gt; ConcreteCommand @enduml 命令模式对象可以包含接受者的引用，也可以不包含，因为在远程调用的情况下，不能获取引用。\nReference:\n","description":"命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。","id":5,"section":"posts","tags":["设计模式","命令模式"],"title":"命令模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/commandpattern/"},{"content":"类图绘制  参考：【程序员小知识】使用 PlantUML 画 UML（上）类图 - 掘金\n 一览：\n 需要注意，一组@startuml/@enduml 对应一张 png，如果一个文件中有多组，则生成的 png 文件名会添加自增数字后缀。 此外也可以紧跟在 @startuml 之后指定文件名：\n@startuml foo class Foo @enduml @startuml bar class Bar @enduml @startuml baz class Baz @enduml  注释 ' 这是注释 可以使用 note left of , note right of , note top of , note bottom of 等关键字定义相对于对象位置的注释。\n标题 ' 标题为Hello Title title Hello Title 图注 caption 图１ 脚注 footer World 放大率 @startuml scale-1.5 scale 1.5 Hello \u0026lt;|-- World @enduml 定义常见结构 ' 定义类hello class Hello ' 定义接口hello interface Hello ' 定义抽象类hello abstract Hello ' 定义枚举 enum HelloWorld { ONE TWO THREE } @startuml ' 定义类hello class Hello ' 定义接口hello interface Hello ' 定义抽象类hello abstract Hello ' 定义枚举 enum HelloWorld { ONE TWO THREE } @enduml UML中类型之间有六大关系：\n 泛化（Generalization） 实现（Realization） 关联（Association) 聚合（Aggregation） 组合(Composition) 依赖(Dependency)  泛化（继承）  \u0026lt;|-- --|\u0026gt; 指定继承关系\n @startuml Child --|\u0026gt; Parent Parent2 \u0026lt;|-- Child2 @enduml @startuml Child --|\u0026gt; Parent Parent2 \u0026lt;|-- Child2 @enduml 使用extends 关键字也可以\n实现  ..|\u0026gt;, \u0026lt;|.. ， 圆点表示虚线\n @startuml Plane ..|\u0026gt; Flyable Flyable \u0026lt;|.. Plane @enduml @startuml Plane ..|\u0026gt; Flyable Flyable \u0026lt;|.. Plane @enduml 使用implements 关键字也可以。\n依赖 @startuml Chef ..\u0026gt; Recipe @enduml @startuml Chef ..\u0026gt; Recipe @enduml  依赖表示使用关系，java中, 被依赖的对象/类, 以方法参数, 局部变量和静态方法调用的形式出现。比如, 厨师在烹饪的时候看了一眼菜谱, 厨师\u0026quot;使用\u0026quot;了菜谱, 照着它炒完菜后，这种使用关系就结束了(临时性).\n 关联  关联关系，表示\u0026quot;拥有\u0026rdquo;。 相比依赖关系的临时性和单向性，关联关系具有长期性、平等性(可双向)，所以关联表示的关系比依赖更强。比如现实生活中的夫妻, 师生等关系。长期存在并且是相互的关系。 此外关联可以表示一对一，一对多，多对一，多对多等各种关系。\n @startuml Address \u0026lt;-- Husband Husband \u0026lt;--\u0026gt; Wife Husband2 -- Wife2 @enduml @startuml Address \u0026lt;-- Husband Husband \u0026lt;--\u0026gt; Wife Husband2 -- Wife2 @enduml 聚合  聚合关系相对于组合弱一些，整体与部分是可分离的。 比如部门与员工，部门有许多员工，员工离职了部门仍然存在，不受影响。反之部门解散了，员工可以去其他部门(整体与部分可分离)\n @startuml Department o-- Employee @enduml o 表示空心菱形\n@startuml Department o-- Employee @enduml 组合  组合关系中，整体与部分是不可分离的，整体与部分的生命周期保持一致，少了对方自己的存在无意义。例如人体是有四肢组成的，四肢不能脱离人体存在，人体少了四肢也难言完整。\n @startuml Body \u0026quot;1\u0026quot; *-- \u0026quot;2\u0026quot; Arm Body \u0026quot;1\u0026quot; *-- \u0026quot;2\u0026quot; Leg @enduml * 表示实心菱形\n@startuml Body \u0026quot;1\u0026quot; *-- \u0026quot;2\u0026quot; Arm Body \u0026quot;1\u0026quot; *-- \u0026quot;2\u0026quot; Leg @enduml 抽象方法和静态方法 @startuml class Hello { {abstract} one: int {abstract} two(): int } @enduml @startuml class Hello { {static} ONE: int {static} two(): int } @enduml @startuml class Hello { {abstract} one: int {abstract} two(): int } @enduml @startuml class Hello { {static} ONE: int {static} two(): int } @enduml 泛型 @startuml class Hello\u0026lt;H\u0026gt; class World\u0026lt;W\u0026gt; @enduml @startuml class Hello\u0026lt;H\u0026gt; class World\u0026lt;W\u0026gt; @enduml 包图 @startuml package one.two { class Hello } package three.four { World -- Hello } @enduml @startuml package one.two { class Hello } package three.four { World -- Hello } @enduml 包可以使用颜色和替换样式：\n@startuml 'https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026quot;子系统\u0026quot; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml @startuml 'https://plantuml.com/class-diagram class Client class Facade Client -\u0026gt; Facade package \u0026quot;子系统\u0026quot; \u0026lt;\u0026lt;cloud\u0026gt;\u0026gt; #DDDDDD{ class A class B class C class D class E } Facade -- A Facade -- C A - C A -- B A -- E C - E B - D @enduml 样式列表：\n@startuml scale 750 width package foo1 \u0026lt;\u0026lt;Node\u0026gt;\u0026gt; { class Class1 } package foo2 \u0026lt;\u0026lt;Rectangle\u0026gt;\u0026gt; { class Class2 } package foo3 \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; { class Class3 } package foo4 \u0026lt;\u0026lt;Frame\u0026gt;\u0026gt; { class Class4 } package foo5 \u0026lt;\u0026lt;Cloud\u0026gt;\u0026gt; { class Class5 } package foo6 \u0026lt;\u0026lt;Database\u0026gt;\u0026gt; { class Class6 } @enduml @startuml scale 750 width package foo1 \u0026lt;\u0026lt;Node\u0026gt;\u0026gt; { class Class1 } package foo2 \u0026lt;\u0026lt;Rectangle\u0026gt;\u0026gt; { class Class2 } package foo3 \u0026lt;\u0026lt;Folder\u0026gt;\u0026gt; { class Class3 } package foo4 \u0026lt;\u0026lt;Frame\u0026gt;\u0026gt; { class Class4 } package foo5 \u0026lt;\u0026lt;Cloud\u0026gt;\u0026gt; { class Class5 } package foo6 \u0026lt;\u0026lt;Database\u0026gt;\u0026gt; { class Class6 } @enduml note笔记 一般可以使用下面的语句进行在组件的上下左右添加笔记：\n@startuml class A class B class C class D ‘ 在组件A左边添加笔记 note left of A : 笔记A ‘ 在组件B右边添加笔记 note right of B : 笔记B ‘ 在组件C上边添加笔记 note top of C : 笔记C ‘ 在组件D下边添加笔记 note bottom of D : 笔记D @enduml @startuml class A class B class C class D ‘ 在组件A左边添加笔记 note left of A : 笔记A ‘ 在组件B右边添加笔记 note right of B : 笔记B ‘ 在组件C上边添加笔记 note top of C : 笔记C ‘ 在组件D下边添加笔记 note bottom of D : 笔记D @enduml 可以在字段（field、attribute、member）或方法上添加注释。 这不能与命名空间分隔符(namespaceSeparator) :: 一起使用\n注释属性和方法：\n@startuml class A { {static} int counter +void {abstract} start(int timeout) } note left of A::counter 该成员已注释 end note note right of A::start 在 UML 注释了此方法 end note @enduml @startuml class A { {static} int counter +void {abstract} start(int timeout) } note left of A::counter 该成员已注释 end note note right of A::start 在 UML 注释了此方法 end note @enduml 注释同名方法：\n@startuml class A { {static} int counter +void {abstract} start(int timeoutms) +void {abstract} start(Duration timeout) } note left of A::counter 该成员已注释 end note note right of A::\u0026quot;start(int timeoutms)\u0026quot; 这个start方法的参数是int类型 end note note right of A::\u0026quot;start(Duration timeout)\u0026quot; 这个start方法的参数是Duration类型 end note @enduml @startuml class A { {static} int counter +void {abstract} start(int timeoutms) +void {abstract} start(Duration timeout) } note left of A::counter 该成员已注释 end note note right of A::\u0026quot;start(int timeoutms)\u0026quot; 这个start方法的参数是int类型 end note note right of A::\u0026quot;start(Duration timeout)\u0026quot; 这个start方法的参数是Duration类型 end note @enduml 时序图  序列图是仅次于类图的最常用 UML 图。 序列图将交互关系表示为一个二维图，纵向是时间轴，时间沿竖线向下延伸；横向轴代表了在协作中各个角色，一般是一个 Class 的对象，用一条虚线代表各角色的生命线，生命线上用矩形竖条表示是否处于活跃状态。对象之间可以发送同步或异步消息。\n 序列图的基本内容构成：\n\u0026lt;角色\u0026gt; \u0026lt;消息类型\u0026gt; \u0026lt;角色\u0026gt; : \u0026lt;消息内容\u0026gt;\n 消息类型中 -\u0026gt; 表示同步消息 --\u0026gt; 虚线表示返回消息  同步消息 @startuml Alice -\u0026gt; Bob: Hi Bob --\u0026gt; Alice: Hi Alice -\u0026gt; Bob: Is this a pen? Bob --\u0026gt; Alice: No! This is an apple!! @enduml @startuml Alice -\u0026gt; Bob: Hi Bob --\u0026gt; Alice: Hi Alice -\u0026gt; Bob: Is this a pen? Bob --\u0026gt; Alice: No! This is an apple!! @enduml 异步消息 @startuml Alice -\u0026gt;\u0026gt; Bob: Hi Alice -\u0026gt;\u0026gt; Bob: Is this a pen? Alice -\u0026gt;\u0026gt; Bob: Is this a pen?? Alice -\u0026gt;\u0026gt; Bob: Is this a pen??? Alice -\u0026gt;\u0026gt; Bob: Is this a pen???? Bob -\u0026gt; Alice: This is an apple!!! @enduml 角色生命线  多个participant 会按照从左往右的顺序显示各角色生命线 如果没有任何 participant, 则会角色出现的顺序显示从左往右显示其生命线  角色图例 @startuml actor Actor boundary Boundary control Control entity Entity database Database collections Collections @enduml @startuml actor Actor boundary Boundary control Control entity Entity database Database collections Collections @enduml 箭头样式 @startuml Bob -\u0026gt;x Alice Bob -\u0026gt; Alice Bob -\u0026gt;\u0026gt; Alice Bob -\\ Alice Bob \\\\- Alice Bob //-- Alice Bob -\u0026gt;o Alice Bob o\\\\-- Alice Bob \u0026lt;-\u0026gt; Alice Bob \u0026lt;-\u0026gt;o Alice @enduml @startuml Bob -\u0026gt;x Alice Bob -\u0026gt; Alice Bob -\u0026gt;\u0026gt; Alice Bob -\\ Alice Bob \\\\- Alice Bob //-- Alice Bob -\u0026gt;o Alice Bob o\\\\-- Alice Bob \u0026lt;-\u0026gt; Alice Bob \u0026lt;-\u0026gt;o Alice @enduml 发给自己的消息 @startuml Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself @enduml @startuml Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself Aclie -\u0026gt; Aclie: do something by yourself @enduml 消息序号 添加关键字autonumber\n@startuml Alice -\u0026gt; Bob: Hi autonumber Bob -\u0026gt; Carol: Hi Carol -\u0026gt; Dave: Hi Bob -\u0026gt; Dave: Hi @enduml  autonumber stop: 自动序号暂停 autonumber resume: 自动序号继续  @startuml Alice -\u0026gt; Bob: Hi autonumber Bob -\u0026gt; Carol: Hi Carol -\u0026gt; Dave: Hi Bob -\u0026gt; Dave: Hi @enduml 消息组  @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: No! This is an apple!!!!! end @enduml @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: No! This is an apple!!!!! end @enduml 有时候需要多个消息表示一组相关的逻辑，此时可以使用预置的关键字来表示各种逻辑，例如\n alt/else opt loop par break critical  关键词之后添加表示逻辑的文字，例如 yes， no等\n消息信息的缩进不是必须的，但是加上可读性更好\n消息组嵌套\n@startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: Noooooooo! This is an apple!!!!! loop ∞ Alice -\u0026gt; Bob: Oh sorry! By the way, is this a pen? Alice \u0026lt;-- Bob: No!!!! end end @enduml @startuml Alice -\u0026gt; Bob: Is this a pen? alt yes Alice \u0026lt;-- Bob: Yes! This is a pen!! else no Alice \u0026lt;-- Bob: Noooooooo! This is an apple!!!!! loop ∞ Alice -\u0026gt; Bob: Oh sorry! By the way, is this a pen? Alice \u0026lt;-- Bob: No!!!! end end @enduml 自定义消息组\n@startuml group copy Alice -\u0026gt; Bob: Is this a pen? Alice \u0026lt;-- Bob: No! This is an apple!! end @enduml @startuml group copy Alice -\u0026gt; Bob: Is this a pen? Alice \u0026lt;-- Bob: No! This is an apple!! end @enduml group 之后添加消息组的名字\n生命线活跃状态  activate \u0026lt;name\u0026gt; 指定name的生命线进入活跃状态 deactive \u0026lt;name\u0026gt; 指定name的生命线退出活跃状态  @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml 嵌套活跃状态 @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml @startuml activate Alice Alice -\u0026gt; Bob activate Bob Bob -\u0026gt; Bob activate Bob Bob -\u0026gt; Carol activate Carol Bob \u0026lt;-- Carol deactivate Carol Alice \u0026lt;-- Bob deactivate Bob @enduml ​\tactivate 中继续 activate 可以嵌套活跃状态\n创建角色和生命线 @startuml Alice -\u0026gt; Bob create Carol Bob -\u0026gt; Carol: new Bob -\u0026gt; Carol Bob \u0026lt;-- Carol Alice \u0026lt;-- Bob @enduml @startuml Alice -\u0026gt; Bob create Carol Bob -\u0026gt; Carol: new Bob -\u0026gt; Carol Bob \u0026lt;-- Carol Alice \u0026lt;-- Bob @enduml create \u0026lt;name\u0026gt; 用来创建一个角色和其生命线，此时消息箭头会执行角色图例\n参考、引用 @startuml Alice -\u0026gt; Bob ref over Bob, Carol: ... Alice \u0026lt;-- Bob ref over Alice ... ... end ref @enduml  ref over \u0026lt;生命线名称\u0026gt; : \u0026lt;内容\u0026gt; : reference 的范围和参考内容 ref over ... end ref: 可以换行写参考内容  @startuml Alice -\u0026gt; Bob ref over Bob, Carol: ... Alice \u0026lt;-- Bob ref over Alice ... ... end ref @enduml 边界线 @startuml == Foo == Alice -\u0026gt; Bob Alice \u0026lt;-- Bob == Bar == Bob -\u0026gt; Carol Bob \u0026lt;-- Carol @enduml == \u0026lt;name\u0026gt; == 添加边界线，跨越所有角色的生命线\n@startuml == Foo == Alice -\u0026gt; Bob Alice \u0026lt;-- Bob == Bar == Bob -\u0026gt; Carol Bob \u0026lt;-- Carol @enduml 外部消息 @startuml [-\u0026gt; Alice: Hello Alice -\u0026gt;]: Hello @enduml 消息箭头的前后使用 [ ， ] ，表示一个来自外部或者指向外部的消息\n@startuml [-\u0026gt; Alice: Hello Alice -\u0026gt;]: Hello @enduml 消息间隔 @startuml Alice -\u0026gt; Bob Alice \u0026lt;-- Bob Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||80|| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob @enduml  消息之间加 ||| , 会适当拉开消息间隔 ||\u0026lt;pixel\u0026gt;||：pixel可以指定具体间隔的像素数  @startuml Alice -\u0026gt; Bob Alice \u0026lt;-- Bob Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob ||80|| Alice -\u0026gt; Bob Alice \u0026lt;-- Bob @enduml 备注 @startuml Alice -\u0026gt; Bob note left: Hello Alice \u0026lt;-- Bob note right: World Alice -\u0026gt; Alice note left Hello World end note @enduml @startuml Alice -\u0026gt; Bob note left: Hello Alice \u0026lt;-- Bob note right: World Alice -\u0026gt; Alice note left Hello World end note @enduml 组件\u0026amp;部署图 箭头方向 -\u0026gt;表示向右，\t--\u0026gt;表示向下。还可以使用关键字left, right, up or down改变箭头方向。-left-\u0026gt;或-l-\u0026gt;表示向左。\n@startuml component componentA as A component componentB as B component componentC as C component componentD as D ' 表示箭头向右 A -\u0026gt; B ' 表示箭头向下 C --\u0026gt; D @enduml @startuml component componentA as A component componentB as B component componentC as C component componentD as D ' 表示箭头向右 A -\u0026gt; B ' 表示箭头向下 C --\u0026gt; D @enduml 还有虚线(..)、直线(--)\n组件 关键字component定义一个组件。\n@startuml component componentA as A component componentB as B component componentGroup as group { component componentC as C component componentD as D } @enduml @startuml component componentA as A component componentB as B component componentGroup as group { component componentC as C component componentD as D } @enduml 接口 接口可以使用()来定义，也可以使用关键字interface来定义接口。\n@startuml () \u0026quot;interfaceA\u0026quot; as iA interface interfaceB as iB @enduml @startuml () \u0026quot;interfaceA\u0026quot; as iA interface interfaceB as iB @enduml 组合组件 可以使用多个关键字将组件和接口组合在一起。\n package node folder frame cloud database  @startuml package \u0026quot;Some Group\u0026quot; { HTTP - [First Component] [Another Component] } node \u0026quot;Other Groups\u0026quot; { FTP - [Second Component] [First Component] --\u0026gt; FTP } cloud { [Example 1] } database \u0026quot;MySql\u0026quot; { folder \u0026quot;This is my folder\u0026quot; { [Folder 3] } frame \u0026quot;Foo\u0026quot; { [Frame 4] } } [Another Component] --\u0026gt; [Example 1] [Example 1] --\u0026gt; [Folder 3] [Folder 3] --\u0026gt; [Frame 4] @enduml @startuml package \u0026quot;Some Group\u0026quot; { HTTP - [First Component] [Another Component] } node \u0026quot;Other Groups\u0026quot; { FTP - [Second Component] [First Component] --\u0026gt; FTP } cloud { [Example 1] } database \u0026quot;MySql\u0026quot; { folder \u0026quot;This is my folder\u0026quot; { [Folder 3] } frame \u0026quot;Foo\u0026quot; { [Frame 4] } } [Another Component] --\u0026gt; [Example 1] [Example 1] --\u0026gt; [Folder 3] [Folder 3] --\u0026gt; [Frame 4] @enduml 长描述 可以用方括号\u0026rdquo;[ ]\u0026ldquo;在连线上添加描述。\n@startuml component comp1 [ This component has a long comment on several lines ] @enduml @startuml component comp1 [ This component has a long comment on several lines ] @enduml 颜色 在声明一个组件时加上颜色的声明，在后面加上#颜色名可以改变颜色/\n@startuml component [Web Server] #yellow @enduml @startuml component [Web Server] #yellow @enduml 声明元素 @startuml actor actor actor/ \u0026quot;actor/\u0026quot; agent agent artifact artifact boundary boundary card card circle circle cloud cloud collections collections component component control control database database entity entity file file folder folder frame frame interface interface label label node node package package queue queue rectangle rectangle stack stack storage storage usecase usecase usecase/ \u0026quot;usecase/\u0026quot; @enduml @startuml actor actor actor/ \u0026quot;actor/\u0026quot; agent agent artifact artifact boundary boundary card card circle circle cloud cloud collections collections component component control control database database entity entity file file folder folder frame frame interface interface label label node node package package queue queue rectangle rectangle stack stack storage storage usecase usecase usecase/ \u0026quot;usecase/\u0026quot; @enduml 分隔符 @startuml folder folder [ 这是个 \u0026lt;b\u0026gt;文件夹 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] node node [ 这是个 \u0026lt;b\u0026gt;结点 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] database database [ 这是个 \u0026lt;b\u0026gt;数据库 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] usecase usecase [ 这是个 \u0026lt;b\u0026gt;用例 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] @enduml @startuml folder folder [ 这是个 \u0026lt;b\u0026gt;文件夹 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] node node [ 这是个 \u0026lt;b\u0026gt;结点 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] database database [ 这是个 \u0026lt;b\u0026gt;数据库 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] usecase usecase [ 这是个 \u0026lt;b\u0026gt;用例 ---- 您可以使用 ==== 不同类型 .... 的分隔符 ] @enduml 隐藏线 -[hidden]-可以画一条隐藏的线条，常常用于布局。\n排列 可以添加下面的一行进行竖排列：\nleft to right direction 相关配置 安装graphviz Mac执行：\nbrew install graphviz 然后在IDEA进行设置。\nReference:\n 开源工具，使用简单的文字描述画UML图。 程序员必备画图技能之——时序图 - 程序员自由之路 - 博客园 【程序员小知识】使用 PlantUML 画 UML（上）类图 - 掘金 在 Hugo 博客上使用 PlantUML – Mogeko\u0026rsquo;s Blog https://crashedmind.github.io/PlantUMLHitchhikersGuide/layout/layout.html  ","description":"使用plantUML表示一些关系和状态图更加清晰。","id":6,"section":"posts","tags":["工具","plantUML"],"title":"plantUML使用笔记","uri":"https://hugo.jiahongw.com/zh/posts/efficient/plantuml-note/"},{"content":" 定义 装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案。\n架构（类图） classDiagram class Component { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateComponent { + methodA() + methodB() } class Decrator { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateDecratorA { + methodA() + methodB() + newMethod() } class ConcreateDecratorB { + methodA() + methodB() } ConcreateComponent --|\u0026gt; Component : 继承 Decrator --|\u0026gt; Component : 继承 ConcreateDecratorA --|\u0026gt; Decrator : 继承 ConcreateDecratorB --|\u0026gt; Decrator : 继承 装饰的技巧可以在不修改任何底层代码的情况下增强功能。\nKey：\n 装饰者和被装饰者有相同的超类型  使用场景   Java IO类库（InputStream、OutputStream）\n 装饰器模式可以很好的使用韦恩图进行解释，装饰器的包装对象类似于递归调用的形式，一层套一层去调用被包装对象的操作。\n   在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。\n  使用缺点  使用装饰器模式，常常造成设计中有大量的类。  Reference:\n 《Head First 设计模式》 装饰设计（装饰者模式 / 装饰器模式）  ","description":"装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案。","id":7,"section":"posts","tags":["装饰器模式","设计模式"],"title":"设计模式-装饰器模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/decoratorpattern/"},{"content":" 定义 观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并且自动更新。\n 一个比喻：报纸订阅（出版者和订阅者）\n 架构 classDiagram class Subject { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + registerObserver() + removeObserver() + notifyObserver() } class ConcreteSubject { - List\u0026lt;Observer\u0026gt; observers + registerObserver() + removeObserver() + notifyObserver() } class Observer { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + update() } class ConcreteObeserver { - Subject subject + update() } Subject --\u0026gt; Observer : 多个观察者 ConcreteSubject ..|\u0026gt; Subject : 实现 ConcreteObeserver ..|\u0026gt; Observer : 实现 ConcreteObeserver --\u0026gt; ConcreteSubject : 订阅主题 观察者依赖主题。观察者模式提供了一种对象设计，让主题和观察者之间松耦合。他们依然可以交互，但是不必清楚彼此的细节。\n主题主动推数据和观察者自己拉数据都可以，但是关键在于主题必须得通知观察者。\nQ \u0026amp; A：\n  为什么观察者要包含一个主题（subject）的引用？\n以后可能需要取消注册，保存一个引用会更加方便。\n  “生产者-消费者”模型和观察者模式的区别和联系？\n生产-消费模型，是多对多的关系，一般以异步的方式实现；而观察者模式（发布-订阅模型），是一对多的关系，可以以同步的方式实现，也可以以异步的方式实现。\n 发布订阅和生产消费模型最大的区别在于：发布者（可观测对象）是知道订阅者（观察对象）的存在，因为它需要遍历订阅列表去发布事件；而生产消费模型因为有中间消息代理的存在，生产者和消费者完全不知道对方的存在，完全解耦！\n   Java内置的观察者模式 java.util包下的Observable和Observer。\nGoogle EventBus 异步非阻塞观察者模式的实现。\n简单的实现方法：\n 在可观察对象了里面对各个观察者的通知改成异步操作。（可用线程池） 在观察者内部的处理消息改为异步操作。（不可用线程池）   两者都能够开启线程去跑，很快就返回，不阻塞。\n 针对异步非阻塞观察者模式的实现，抽象的EventBus框架可以让我们聚焦于业务。\n使用场景  消息队列 回调就是一种观察者模式 Google EventBus 邮件订阅 RSS 反应式RxJava JDK(CompletableFuture)  Reference:\n 极客时间-观察者模式 观察者设计模式  ","description":"一个比喻：报纸订阅（出版者和订阅者）。","id":8,"section":"posts","tags":["观察者模式","行为模式"],"title":"观察者模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/observerpattern/"},{"content":"1 SequenceDiagram 序列化图\n2 JRebel 简介：\n热部署工具。在我们每次修改代码后，不用重启程序，JRebel 会自动将所有的代码变更生效。这样，相当于“跳过”频繁的 Java 代码的编译、启动的过程，大大的提升了我们的开发效率。\n参考链接：\n https://www.iocoder.cn/Fight/IDEA-JRebel-plug-in-hot-deployment/?self https://www.jianshu.com/p/882872a7339d  配置：\n 激活JRebel 配置信息 快捷键：Commond + shift + F9  3 Maven Helper 简介：可以查看 Maven 的依赖树和列表\n使用参考：\n 要想查看maven的依赖树就要使用Maven命令maven dependency:tree来查看依赖\n 当Maven Helper 插件安装成功后，打开项目中的pom文件，下面就会多出一个试图\n4 LeetCode Editor 胖友可以后续看看 LeetCode Editor 插件的作者写的 https://git.io/JLMce 指南。\n5 Alibaba Java Coding Guidelines Alibaba Java Coding Guidelines 插件，基于 《阿里巴巴 Java 开发手册》 的代码规范的检测工具。\n6 Translation 简介：Translation 插件，翻译神器，支持有道、百度、谷歌三种翻译引擎。\n功能：\n  选中一个单词，进行翻译\n  输入一个单词，进行翻译\n 翻译框的呼出，Windows 使用 ctrl + shift + o 快捷键，MacOS 使用 control + command + i 快捷键。\n   7 GenerateAllSetter 简介：GenerateAllSetter 插件，一键调用一个对象的所有的 setter 方法。\n功能：\n 生成对象，并设置默认值 生成对象，并设置传入参数作为值 生成 List / Set / Map 返回结果  快捷键：Mac：alt + Enter\nMore IDEA多线程调试，参考：\n Idea debug调试时获取异步调用栈 - 简书 (1条消息) java高并发实战（十）——并发调试和JDK8新特性_平凡之路无尽路的博客-CSDN博客_jdk8并发新特性   (!(Thread.currentThread().getName().equals(\u0026quot;main\u0026quot;)))  只能使用IDEA自带的Debugger\nReference:\n","description":"IDEA实用的插件列表","id":9,"section":"talks","tags":["IDEA"],"title":"IDEA实用的插件列表","uri":"https://hugo.jiahongw.com/zh/talks/idea-plugins/"},{"content":"安装更新卸载 参考：https://nvchad.github.io/getting-started/setup\n参考指令 参考：https://neovim.io/doc/user/quickref.html\n自定义 自定义需要在目录lua/custom/,防止在更新的时候覆盖了。\n一开始该目录只有下面两个文件：\n要根据您的需要开始设置 NvChad，请复制这些模板文件：\n1 2  cp example_init.lua init.lua cp example_chadrc.lua chadrc.lua    custom/init.lua 在 NeoVim 设置期间运行，这是一种运行通用代码并运行大量 NvChad 修改的方法 custom/chadrc.lua用于覆盖core/default_config.lua，您只需要包含您希望从默认文件更改的值  切换主题 \u0026lt;leader\u0026gt; + th\nLua笔记 编译器使用IDEA + EmmyLua插件\n输出和评论 1 2  -- a comment print(\u0026#34;hi\u0026#34;) -- another comment   变量的定义 1 2 3 4 5  -- Different types local x = 10 -- number local name = \u0026#34;Sid\u0026#34; -- string local isAlive = true -- boolean local a = nil --no value or invalid value   local的作用域只在当前的函数内，在外部的话就是文件内。\n字符串操作 1 2 3 4 5 6 7 8  -- 字符串拼接 local name_first = \u0026#34;Victor\u0026#34; local name_Second = \u0026#34;Hong\u0026#34; print(name_first .. name_Second) -- 多个字符串拼接 print(name_first .. \u0026#34;and\u0026#34; .. name_Second)   输出为：\nVictorHong VictorandHong 比较判断 多了一个不等的符号~= ,其他的和其他语言一样。\n 另外，使用not表示!，常在条件判断语句使用。\n 条件判断语法 类似shell语言，条件判断语句不需要花括号，但是增加了两个关键字then和end\n例子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  -- number comparisions local age = 10 if age \u0026gt; 18 then print(\u0026#34;over 18\u0026#34;) -- this will not be executed end -- elseif and else age = 20 if age \u0026gt; 18 then print(\u0026#34;over 18\u0026#34;) elseif age == 18 then print(\u0026#34;18 huh\u0026#34;) else print(\u0026#34;kiddo\u0026#34;) end   复合判断语句：\n1 2 3 4 5 6 7 8 9  local age = 22 if age == 10 and x \u0026gt; 0 then -- both should be true print(\u0026#34;kiddo!\u0026#34;) elseif x == 18 or x \u0026gt; 18 then -- 1 or more are true print(\u0026#34;over 18\u0026#34;) end --result: over 18   函数 函数定义：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  function num(a) print(a) end -- or local num = function(a) print(a) end -- 多参数函数定义 function sum(a,b) local result = a + b print(result) end   函数调用：\n1 2  num(5) sum(2,3)   循环 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  -- while loop local i = 0 while i \u0026lt;= 3 do print(\u0026#34;hi\u0026#34;) i = i + 1 end OR --for loop for i = 0, 3 do print(\u0026#34;hi\u0026#34;) i = i + 1 end -- result hi hi hi   tables（数组） 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  -- basic table local colors = { \u0026#34;red\u0026#34;, \u0026#34;green\u0026#34;, \u0026#34;blue\u0026#34; } print(colors[1]) --red print(colors[2]) --green print(colors[3]) --blue -- use a loop to iterate though the table for i=1, #colors do print(colors[i]) end --tables within tables local data = { { \u0026#34;billy\u0026#34;, 12 }, { \u0026#34;john\u0026#34;, 20 }, } for i = 1, #data do print(data[i][1] .. \u0026#34;is \u0026#34; .. data[i][2] .. \u0026#34;years old\u0026#34;) end   模块 使用模块\n1 2  require(\u0026#34;otherfile\u0026#34;)   自定配置 目录树：\nNvchad的配置目录下有一个 lua 文件夹和一个 init.lua 文件， 而 init.lua 主要加载核心的配置。\n假如你在 chadir 目录下有一个自定义文件 test.lua ,你可以在 init.lua 文件中加载使用它：\n1  require(\u0026#34;chadir.test\u0026#34;) or require \u0026#34;chadir.test\u0026#34;.   你也可以将 test.lua 重命名为 init.lua ，这样你就可以直接：\n1 2  require \u0026#34;chadir\u0026#34;. -- which calls the init.lua present in the chadir   颜色 颜色配置目录 lua/colors/ ,该目录有两个文件 init.lua 和 highlight.lua ,主题是用nvim-base16.lua 插件完成的.\n使用 空格 + th更换主题。\ncustom配置 添加插件，在 custom/init.lua 取消注释包含“install_plugins”内容的 hooks.add 行,添加：\n1 2 3 4 5 6 7 8 9 10 11 12  hooks.add(\u0026#34;install_plugins\u0026#34;, function(use) use { \u0026#34;folke/which-key.nvim\u0026#34; event = \u0026#34;something\u0026#34;, config = function() require(\u0026#34;custom.plugin_confs.whichkey\u0026#34;) end } end) -- so the path of the config here basically is in the custom/plugin_confs/whichkey.lua   然后使用 :PackSync 进行同步\n添加Markdown预览插件：\n1 2 3 4 5  hooks.add(\u0026#34;install_plugins\u0026#34;, function(use) use { \u0026#34;davidgranstrom/nvim-markdown-preview\u0026#34;, }   相关插件的使用 文件浏览器： kyazdani42/nvim-tree.lua: A file explorer tree for neovim written in lua\n触发条件：:NvimTreeToggle 或者 Ctrl + n\n刷新文件树：:NvimTreeRefresh 或者 \u0026lt;leader\u0026gt;r\n寻找文件：:NvimTreeFindFile 或者 \u0026lt;leader\u0026gt;n\n键入s将使用系统默认的软件打开文件，Ctrl+t将在新标签页打开\nReference:\n NvChad  ","description":"","id":10,"section":"posts","tags":["Nvchad","nvim","vim"],"title":"Nvchad使用","uri":"https://hugo.jiahongw.com/zh/posts/efficient/nvchad%E4%BD%BF%E7%94%A8/"},{"content":" 当我们使用new创建一个对象的时候，需要指定一个具体类，这就是针对实现进行编程。当我们将创建对象的过程封装成一个方法或者接口的时候，就可以避免针对实现编程，变成针对接口编程。\n 针对接口编程，可以隔离掉以后系统可能发生的一大堆改变。为什么呢？\n 通过多态，可以让任何实现类实现改接口。 然后替换掉你原来的实现。   对拓展开放，对修改关闭。\n 定义 工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法将实例化推迟到子类。\n 核心在将创建对象的过程解耦出来。\n 架构 @startuml interface Product class ConcreteProduct implements Product abstract class Creator { * factoryMethod() + anyOperation() } class ConcreteCreator extends Creator { * factoryMethod() + anyOperation() } note top of Creator: Creator是一个类，实现所有操作产品的方法，但是不实现工厂方法 note bottom of ConcreteProduct: 所有产品必须实现共同接口 note bottom of ConcreteCreator: 实现工厂方法，以实际制造出产品 ConcreteProduct \u0026lt;-r- ConcreteCreator @enduml 工厂模式体现了一个原则：依赖倒置原则。（Spring叫依赖反转）\n 原来依赖具体类，现在依赖一个抽象的接口。\n @startuml abstract class \u0026quot;抽象接口类\u0026quot; as abstractClass { } class \u0026quot;实现类A\u0026quot; extends abstractClass class \u0026quot;实现类B\u0026quot; extends abstractClass class \u0026quot;实现类C\u0026quot; extends abstractClass class \u0026quot;Factory\u0026quot; as factory factory --\u0026gt; abstractClass @enduml Key:\n 工厂只有一个功能——创建指定的类。（单一职责） 将原来的if-else判断，转换成对象进行处理。 抽象成一个方法 -》 抽象成一个类 -〉 抽象成一个接口  抽象工厂模式 定义：抽象工厂模式提供一个接口，用于创建相关或者依赖对象的家族，而不需要明确指定具体类。\n架构：\nclassDiagram class AbstractFactory { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + createProductA() + createProductB() } class ConcreteFactoory1 { + createProductA() + createProductB() } class ConcreteFactoory2 { + createProductA() + createProductB() } class AbstractProductA { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttA1 class ProducttA2 ProducttA1 ..|\u0026gt; AbstractProductA : 实现 ProducttA2 ..|\u0026gt; AbstractProductA : 实现 class AbstractProductB { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttB1 class ProducttB2 ProducttB1 ..|\u0026gt; AbstractProductB : 实现 ProducttB2 ..|\u0026gt; AbstractProductB : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory1 : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory2 : 实现 ConcreteFactoory1 --\u0026gt;ProducttA1 : 创建 ConcreteFactoory1 --\u0026gt;ProducttB1 : 创建 ConcreteFactoory2 --\u0026gt;ProducttA2 : 创建 ConcreteFactoory2 --\u0026gt;ProducttB2 : 创建 抽象工厂模式类似于一个二维的分类，将更加复杂的系统进行整理并且划分。以达到解耦的效果。\n一个披萨商店的例子，可以很清晰的解释这种架构：\nclassDiagram class PizzaIngredientFactory { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } class NYPizzaIngredientFactory { + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } class ChicagoPizzaIngredientFactory { + createDough() + createSauce() + createCheese() + createVeggies() + createPepperoni() + createCalm() } PizzaIngredientFactory \u0026lt;|.. NYPizzaIngredientFactory PizzaIngredientFactory \u0026lt;|.. ChicagoPizzaIngredientFactory class Dough { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ThickCrustDough class ThinCrustDough ThickCrustDough ..|\u0026gt; Dough ThinCrustDough ..|\u0026gt; Dough class Sauce { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class PlumTomatoSauce class MarinaraSauce PlumTomatoSauce ..|\u0026gt; Sauce MarinaraSauce ..|\u0026gt; Sauce class Cheese { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class MozzarellaCheese class ReggianoCheese MozzarellaCheese ..|\u0026gt; Cheese ReggianoCheese ..|\u0026gt; Cheese class Clams { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class FrozenClams class FreshClams FrozenClams ..|\u0026gt; Clams FreshClams ..|\u0026gt; Clams ChicagoPizzaIngredientFactory --\u0026gt; ThickCrustDough ChicagoPizzaIngredientFactory --\u0026gt; PlumTomatoSauce ChicagoPizzaIngredientFactory --\u0026gt; MozzarellaCheese ChicagoPizzaIngredientFactory --\u0026gt; FrozenClams NYPizzaIngredientFactory --\u0026gt; ThinCrustDough NYPizzaIngredientFactory --\u0026gt; MarinaraSauce NYPizzaIngredientFactory --\u0026gt; ReggianoCheese NYPizzaIngredientFactory --\u0026gt; FreshClams 工厂方法就隐含在抽象工厂里面。\n问题   什么是静态工厂方法，和静态工厂有什么区别？\n静态工厂方法有不需要创建对象就能够调用静态方法的优势，但是缺点是不能通过继承来改变创建的方法。\n  Reference:\n Factory Design Pattern in Java - JournalDev  ","description":"相对于直接new来创建对象，用工厂模式来创建究竟有什么好处呢？","id":11,"section":"posts","tags":["设计模式","工厂方法","抽象工厂","简单工厂"],"title":"工厂方法模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/factorymethodpattern/"},{"content":"什么是单例 单例设计模式（Singleton Design Pattern）理解起来非常简单。一个类只允许创建一个对象（或者实例），那这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。\n为什么使用单例 同一个类创建了多个对象，然后干的事情是一样的，在多线程环境下还需要考虑线程同步。而单例模式：\n 不用创建那么多Logger对象，一方面节省内存空间。 另一方面节省系统文件句柄。  单例加锁的时候只需要添加对象锁即可，不用像之前使用类锁。\n 从业务概念上，如果有些数据在系统中只应保存一份，那就比较适合设计为单例类。\n 另外一种使用场景是需要一个全局唯一类，比如配置信息类，唯一递增ID号码生成器。\n单例的实现 各种单例模式的实现如下：\n  饿汉单例\ninstance的创建过程是线程安全的。但是不支持延迟加载，因为在类创建的时候就将单例创建了。\n  懒汉单例（支持延迟加载）\n  静态阻塞初始化单例\n  线程安全单例（并发度低）\n  双重检测单例（支持高并发和延迟加载）\n  内部静态类单例（既保证了线程安全，又能做到延迟加载）\n  Enum 单例\n  序列化单例\n  Code：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178  package com.sankuai.stafftraining.wujiahong.demo.springdemo.designpattern.creational; import java.io.Serializable; /** * 单例模式 */ public class SingletonPattern { public static void main(String[] args) { // Enum 单例模式使用  String myField = \u0026#34;Singleton\u0026#34;; EnumSingleton.INSTANCE.setField(myField); System.out.println(EnumSingleton.INSTANCE.getField()); } /** * 1.饿汉单例模式 这样的实现方式不支持延迟加载（在真正用到IdGenerator的时候，再创建实例） */ static class SingletonV1 { private static SingletonV1 instance = new SingletonV1(); private SingletonV1() { } public static SingletonV1 getInstance() { return instance; } } /** * 2.懒汉单例模式 */ static class SingletonV2 { private static SingletonV2 instance; private SingletonV2() { } public static SingletonV2 getInstance() { if (instance == null) { instance = new SingletonV2(); } return instance; } } /** * 3.静态阻塞初始化 */ static class SingletonV3 { private static SingletonV3 instance; private SingletonV3() { } static { try { instance = new SingletonV3(); } catch (Exception e) { throw new RuntimeException(\u0026#34;Exception occured in creating singleton instance\u0026#34;); } } public static SingletonV3 getInstance() { return instance; } } /** * 线程安全单例 */ static class SingletonV4 { private static SingletonV4 instance; private SingletonV4() { } public static synchronized SingletonV4 getInstance() { if (instance == null) { instance = new SingletonV4(); } return instance; } } /** * 双重检查并且加锁避免额外的开销 */ static class SingletonV5 { private static SingletonV5 instance; private SingletonV5() { } public static SingletonV5 getInstance() { if (instance == null) { // 只有在第一次创建对象的时候才会进行同步锁定，其他情况不需要，提高了性能  synchronized (SingletonV5.class) { if (instance == null) { instance = new SingletonV5(); } } } return instance; } } /** * 内部静态类单例模式,不需要同步 */ static class SingletonV6 { private SingletonV6() { } private static class SingletonHelper { private static final SingletonV6 INSTANCE = new SingletonV6(); } public SingletonV6 getInstance() { return SingletonHelper.INSTANCE; } } /** * Enum 单例模式 */ public enum EnumSingleton { INSTANCE; private String field; public String getField() { return field; } public void setField(String field) { this.field = field; } } /** * 序列化单例模式 */ static class SerializedSingleton implements Serializable { private static final long serialVersionUID = -7604766932017737115L; private SerializedSingleton() { } private static class SingletonHelper { private static final SerializedSingleton instance = new SerializedSingleton(); } public static SerializedSingleton getInstance() { return SingletonHelper.instance; } protected Object readResolve() { return getInstance(); } } }    question ❓\n  为什么使用双检锁？\n避免额外的开销。在两次判断instance是否为null的中间加入synchronized关键字，将synchronize的返回从整个方法降到判断里面。\n    单例的问题   对OOP对象不友好\n封装、继承、多态、抽象这些面向对象的的特性，单例这种设计模式对于其中的抽象、继承、多态都支持得不好。\n  隐藏子类之间的依赖关系\n构造函数是private的，因为不能够显示的在外部调用构造函数，所以我们不知道单例道到底需要依赖那些东西。如果代码比较复杂，这种调用关系就会非常隐蔽。\n  对拓展不好\n单例只有一个对象，如果后面需要创建多个实例，就需要对代码有较大的改动。（常常在多线程并发的情况下有这种需求）\n  可测试性不好\n  不支持带参数的构造函数\n 使用辅助函数进行set 将参数上放至getInstance 使用全局变量Config    单例的替代方法  静态方法。 工厂模式、IOC容器（比如Spring IOC容器）来保证 程序员自己保证  理解单例的唯一性 唯一的维度：\n  同一线程唯一\n  同一进程唯一\n  分布式系统唯一\n进程内唯一，进程间也唯一。\n具体来说，我们需要把这个单例对象序列化并存储到外部共享存储区（比如文件）。进程在使用这个单例对象的时候，需要先从外部共享存储区中将它读取到内存，并反序列化成对象，然后再使用，使用完成之后还需要再存储回外部共享存储区。\n为了保证任何时刻，在进程间都只有一份对象存在，一个进程在获取到对象之后，需要对对象加锁，避免其他进程再将其获取。在进程使用完这个对象之后，还需要显式地将对象从内存中删除，并且释放对对象的加锁。\n  使用场景  线程池 缓存 对话框 注册表对象 日志对象  Reference:\n 单例设计模式 43 42 | 单例模式（中）：我为什么不推荐使用单例模式？又有何替代方案？ Java Singleton Design Pattern Example Best Practices - JournalDev Design Patterns for Humans  ","description":"单例模式是一种创建型设计模式， 让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点。","id":12,"section":"posts","tags":["设计模式","单例模式"],"title":"单例模式","uri":"https://hugo.jiahongw.com/zh/posts/designpattern/singletonpattern/"},{"content":" 什么是软件架构 软件架构的三种定义：\n 维基百科：软件架构可以和建筑物的架构相比拟。软件架构是构建计算机，开发系统以及计划进行的基础，可以列出开发团队的需要完成的任务。 IEEE：架构是环境中该系统一组基础概念和属性，具体表现是它的元素、关系，以及设计演进的基本原则。 《clean architecture》：架构是创建者给予该系统的形态（shape）。这个形态的具体形式来源于对系统组件（components）的划分和排列，以及这些组件之间互相通讯的方式。   架构体现的是一个整体的结构，以及组件（元素）之间的关系。\n 软件架构的要素  元素：将系统拆分为一组元素（模块、组件、结构体、子系统） 属性：每个元素具备的属性（名称、职责、接口、实现限制等） 关系：不同元素之间的关系（交互、依赖、继承、组合、聚合） 原理：为什么这么设计（拆分依据、设计原则、决策原因等）  架构域分类（TOGAF） 4A架构\n业务架构图：\n 商业模式画布 业务能力图 价值流 + 业务能力 + 热点图 用例图 价值链图 流程图  数据架构图：\n数据库：ES、Redis、MySQL、Tail\n其中：\n  业务架构是软件架构的灵魂。有业务架构才有技术架构。\n业务架构是一种对组织如何利用其基本能力实现其战略意图和目标的正式描述。\n  应用架构是系统设计的顶层。\n应用架构是一组应用系统及其交互关系的描述，其中的每个应用系统都是一个逻辑功能组，用于支撑业务功能、管理数据资产。只关注支持业务和处理数据需要那些应用系统，不关注应用本身的架构和实现的技术。\n  数据架构是数据资产管理蓝图。\n数据架构定义了用来支持业务的各种数据，以及他们之间的关系，关注点是持久化数据的组织。关注点在：系统需要什么数据、数据间有什么关系、如何存储这些数据\n  技术架构是比特世界的布局。\n技术架构是将产品需求转变为技术实现的过程。关注点在于识别技术需求、技术选型、非功能性需求设计。\n  架构师也分为多种，有业务架构师和技术架构师。在开发一套系统的时候，首先是由公司管理层定下一个战略，然后业务架构师根据战略绘制业务架构图，然后技术架构师拿到业务架构图，进行识别技术需求和技术选型，编写出技术架构图，若还有数据架构师和应用架构师，那么也是在技术架构生成之前要设计相关的数据架构和应用架构，总之，技术架构总是在最后一步进行设计，而业务架构总是在前面设计。\n为什么需要软件架构图  两种开发流程：\n 瀑布流程。 迭代流程     架构是系统实现的蓝图。\n  架构是沟通协作的桥梁。\n  架构是产品质量的基础。\n  重要在哪：\n 促进协作 增强沟通 描绘愿景 提供指导  描述架构的方式  文字（标准、详尽、易于版本管理） 图（直观、形象、表达能力强）  尽管人们日常的工作场所大多是语言性或非图示化的（口语、文字和数字等），但事实上人脑的80%功能都是用于处理视觉信息的，人们对接受视觉信息具有天生的敏感度。——罗伯特-豪恩《VisualLanguage》\n最好使用图来描述架构。\n如何画软件架构图  “法”：架构设计原则\u0026amp;模式 “术”：常用制图方法 “器”：常用制图工具 “道”：架构制图方法论  “法”：架构设计原则\u0026amp;模式  SOLID原则 设计模式原则 架构模式（C/S模式、主从模式、管道模式、微服务模式、云原生模式） 设计模式（观察者模式\u0026hellip;）  常见的架构模式设计图：\nMVC架构：\n分层架构：\n微服务架构：\n洋葱架构：\n微内核架构：\n还有事务驱动架构、云化架构、六边形架构。\n“术”：常用制图方法 UML 统一建模语言（Unified Modeling Language，缩写UML）是一种用于说明、可视化、构建和编写一个正在开发的、面向对象的、软件密集系统的制品的开放方法。UML在对大规模，复杂系统进行建模方面，特别是在软件架构层次已经被验证有效。\n主要模型：\n 功能模型：用例图 对象模型：类图 动态模型：时序图、活动图、状态图   UML的学习成本有点高。\n 4+1ViewModel 哪四个视图？\n 逻辑视图：关注系统提供给终端用户的功能，一般会通过UML中的类图和状态图来表示 流程视图：关注系统的动态部分、运行时行为，包括系统的执行流程和交互方式，一般会通过UML中的时序图、活动图和通讯图来表示。 开发视图：也称为实现视图，以程序员视角阐述系统的组件等，一般会通过UML中的组件图和包图来表示。 物理视图：也称为部署视图，以系统工程师角度描述系统各组件在物理层的拓扑，一般会通过UML中的部署图来表示。  哪一个场景？\n场景：也称为用例视图，通过一组用例（场景）描述系统中对象和流程之间的交互与时序。\n 实际是一种模型，不限制使用哪种方法实现。\n C4Model   第 1 层：系统上下文图（System Context diagram）\n在这一层级中细节并不重要，只需要显示系统概况。 重点应该放在人员（角色）和软件系统上，而不是技术，协议和其他低层级细节上，从而使非技术人员也能够看得懂。这个图也是明确需求的重要图示。\n  第 2 层：容器图（Container diagram）\n“容器”类似于服务器端Web应用程序，单页应用程序，桌面应用程序，移动应用程序，数据库架构，文件系统等。本质上，容器是可单独运行/可部署的单元（例如，单独的进程空间） ）执行代码或存储数据。容器图显示了软件体系结构的高层结构以及如何在其间分配职责。 它还显示了主要的技术选择以及容器之间的通信方式。\n  第 3 层：组件图（Component diagram）\n组件图显示了容器如何由多个“组件”组成，每个组件是什么，它们的职责以及技术/实现接口（API）或者细节。\n  第 4层：（Code）\n这一层是可选的，可以使用UML类图，实体关系图或类似的图。理想情况下，该图可以使用工具（例如IDE或UML建模工具）自动生成。\n  关键思想：\n 自顶向下对系统的静态结构进行逐级拆分，描述各层次对象的职责、关系和外部依赖。 对于关键链路，使用动态视图描述运行时的交互行为和时序关系。 面向部署实施，使用部署视图描述系统逻辑节点与物理资源之间的映射关系。  “器”：常用制图工具 可视化制图工具有这些：\n draw.io ProcessOn Visio  代码化制图：\n PlantUML Structurizr Graphviz  “道”：架构制图方法论 什么是一张好的架构图？\n 准确：错的图比没有图还糟糕 完整：覆盖架构的核心要素和关键信息 清晰：清晰的图例（形状、颜色、箭头）、标注（内部系统or外部依赖） 一致：同一类型的图，使用相同的记号风格 简洁：不要企图用一张图讲清楚所有，化繁为简，更容易被理解  ","description":"如何做好系统设计，架构制图是重要的一环。","id":13,"section":"posts","tags":["架构"],"title":"架构制图","uri":"https://hugo.jiahongw.com/zh/posts/systemarchitecture/architecture-drawing/"},{"content":" 多参数构造函数的问题 静态工厂和构造函数都有一个局限：它们不能对大量可选参数做很好的扩展。以一个类为例，它表示包装食品上的营养标签。这些标签上有一些字段是必需的，如：净含量、毛重和每单位份量的卡路里，另有超过 20 个可选的字段，如：总脂肪、饱和脂肪、反式脂肪、胆固醇、钠等等。大多数产品只有这些可选字段中的少数，且具有非零值。\n应该为这样的类编写什么种类的构造函数或静态工厂呢？传统的方式是使用可伸缩构造函数，在这种模式中，只向构造函数提供必需的参数。即，向第一个构造函数提供单个可选参数，向第二个构造函数提供两个可选参数，以此类推，最后一个构造函数是具有所有可选参数的。这是它在实际应用中的样子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  // Telescoping constructor pattern - does not scale well! public class NutritionFacts { private final int servingSize; // (mL) required  private final int servings; // (per container) required  private final int calories; // (per serving) optional  private final int fat; // (g/serving) optional  private final int sodium; // (mg/serving) optional  private final int carbohydrate; // (g/serving) optional  public NutritionFacts(int servingSize, int servings) { this(servingSize, servings, 0); } public NutritionFacts(int servingSize, int servings, int calories) { this(servingSize, servings, calories, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat) { this(servingSize, servings, calories, fat, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium) { this(servingSize, servings, calories, fat, sodium, 0); } public NutritionFacts(int servingSize, int servings, int calories, int fat, int sodium, int carbohydrate) { this.servingSize = servingSize; this.servings = servings; this.calories = calories; this.fat = fat; this.sodium = sodium; this.carbohydrate = carbohydrate; } }    拓展，在Java8之后，对于那些可有可无的成员变量最好使用Optional进行限制。\n 当你想要创建一个实例的时候，这样进行调用：\n1  NutritionFacts cocaCola =new NutritionFacts(240, 8, 100, 0, 35, 27);   通常，这个构造函数包含许多额外的参数，但是你必须为它们传递一个值。在本例中，我们为 fat 传递了一个值 0（因为我们必须填入一个数，这样才能匹配函数）。只有六个参数时，这可能看起来不那么糟，但随着参数的增加，它很快就会失控。\n 简单地说，可伸缩构造函数模式可以工作，但是当有很多参数时，编写客户端代码是很困难的，而且读起来更困难。 读者想知道所有这些值是什么意思，必须仔细清点参数。相同类型参数的长序列会导致细微的错误。如果客户端不小心倒转了两个这样的参数，编译器不会报错，但是程序会在运行时出错\n 解决办法1-使用JavaBean模式 这种模式是这样运作的：先通过一个无参构造函数创建对象，然后调用对象的setter方法设置需要设置的值。\n JavaBean是一种符合命名规范的class，它通过getter和setter来定义属性\n 例如定义一个JavaBean模式的类：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // JavaBeans Pattern - allows inconsistency, mandates mutability public class NutritionFacts { // Parameters initialized to default values (if any)  private int servingSize = -1; // Required; no default value  private int servings = -1; // Required; no default value  private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public NutritionFacts() { } // Setters  public void setServingSize(int val) { servingSize = val; } public void setServings(int val) { servings = val; } public void setCalories(int val) { calories = val; } public void setFat(int val) { fat = val; } public void setSodium(int val) { sodium = val; } public void setCarbohydrate(int val) { carbohydrate = val; } }   在实际的使用是这样的：\n1 2 3 4 5 6  NutritionFacts cocaCola = new NutritionFacts(); cocaCola.setServingSize(240); cocaCola.setServings(8); cocaCola.setCalories(100); cocaCola.setSodium(35); cocaCola.setCarbohydrate(27);   虽然JavaBean模式可以很方便的让我们自由的设置我们需要设置的值，但是因为构建是在多个调用之间进行的，所以 JavaBean 可能在构建的过程中处于不一致的状态。（并发情况）\n该类不能仅通过检查构造函数参数的有效性来强制一致性。在不一致的状态下尝试使用对象可能会导致错误的发生，而包含这些错误的代码很难调试。\n另外一个相关的缺点是，JavaBean 模式排除了使类不可变的可能性，因为Setter方法已经暴露内部数据修改的方法。除非程序员自己来确保线程安全。\n解决办法2-使用建造者模式  建造者模式结合了可伸缩构造函数模式的安全性和 JavaBean 模式的可读性。\n 客户端不直接生成所需的对象，而是使用所有必需的参数调用构造函数（或静态工厂），并获得一个 builder 对象。然后，客户端在构建器对象上调用像 setter 这样的方法来设置每个感兴趣的可选参数。最后，客户端调用一个无参数的构建方法来生成对象，这通常是不可变的。构建器通常是它构建的类的静态成员类。下面是它在实际应用中的样子：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58  // Builder Pattern public class NutritionFacts { private final int servingSize; private final int servings; private final int calories; private final int fat; private final int sodium; private final int carbohydrate; public static class Builder { // Required parameters  private final int servingSize; private final int servings; // Optional parameters - initialized to default values  private int calories = 0; private int fat = 0; private int sodium = 0; private int carbohydrate = 0; public Builder(int servingSize, int servings) { this.servingSize = servingSize; this.servings = servings; } public Builder calories(int val) { calories = val; return this; } public Builder fat(int val) { fat = val; return this; } public Builder sodium(int val) { sodium = val; return this; } public Builder carbohydrate(int val) { carbohydrate = val; return this; } public NutritionFacts build() { return new NutritionFacts(this); } } private NutritionFacts(Builder builder) { servingSize = builder.servingSize; servings = builder.servings; calories = builder.calories; fat = builder.fat; sodium = builder.sodium; carbohydrate = builder.carbohydrate; } }    这里为了简洁，省略了有效性检查。\n 使用：\n1 2  NutritionFacts cocaCola = new NutritionFacts.Builder(240, 8) .calories(100).sodium(35).carbohydrate(27).build();    NutritionFacts 类是不可变的，因为构造对象并没有调用setter方法，所有参数默认值都在一个位置。构建器的 setter 方法返回构建器本身，这样就可以链式调用，从而得到一个流畅的 API。\n 建造者模式非常适合于类层次结构。使用构建器的并行层次结构，每个构建器都嵌套在相应的类中。抽象类有抽象类构建器；具体类有具体类构建器。\n继承的话需要双继承，子类和子类构造器对应继承父类的。\n建造者模式的缺点  为了创建一个对象，你必须首先创建它的构建器。 虽然在实际应用中创建这个构建器的成本可能并不显著，但在以性能为关键的场景下，这可能会是一个问题。 建造者模式比可伸缩构造函数模式更冗长。因此只有在有足够多的参数时才值得使用，比如有 4 个或更多参数时，才应该使用它。   如果你以构造函数或静态工厂开始，直至类扩展到参数数量无法控制的程度时，也会切换到构建器，但是过时的构造函数或静态工厂将很难处理。因此，最好一开始就从构建器开始。\n 总结 总之，在设计构造函数或静态工厂的类时，建造者模式是一个很好的选择，特别是当许多参数是可选的或具有相同类型时。与可伸缩构造函数相比，使用构建器客户端代码更容易读写，而且构建器比 JavaBean 更安全。\nReference：\n 秒懂设计模式之建造者模式（Builder pattern） - 知乎 Effective-Java-3rd-edition-Chinese-English-bilingual/Chapter-2-Item-2-Consider-a-builder-when-faced-with-many-constructor-parameters.md at dev · clxering/Effective-Java-3rd-edition-Chinese-English-bilingual  ","description":"Consider a builder when faced with many constructor parameters。使用建造者模式创建允许部分参数没有的类。","id":14,"section":"posts","tags":["EffectiveJava"],"title":"2-当构造函数有多个参数时，考虑改用构建器","uri":"https://hugo.jiahongw.com/zh/posts/bookeffectivejava/2%E5%9C%A8%E9%9D%A2%E5%AF%B9%E5%A4%9A%E4%B8%AA%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%E6%97%B6%E8%AF%B7%E8%80%83%E8%99%91%E6%9E%84%E5%BB%BA%E5%99%A8/"},{"content":" 什么是静态工厂方法？ 一个类可以提供公共静态工厂方法，它只是一个返回类实例的静态方法。\n例如Boolean （boolean 的包装类）的简单示例。该方法将 boolean 基本类型转换为 Boolean 对象的引用：\n1 2 3  public static Boolean valueOf(boolean b) { return b ? Boolean.TRUE : Boolean.FALSE; }    要注意的是静态工厂方法与来自设计模式的工厂方法模式不同 [Gamma95]。本条目中描述的静态工厂方法在设计模式中没有直接等价的方法。\n 静态工厂方法的优点 1 静态工厂方法有确切名称（更加清晰） 如果构造函数的参数本身并不能描述返回的对象，那么具有确切名称的静态工厂则更容易使用，生成的客户端代码也更容易阅读。最简单的例子，返回可能为素数的 BigInteger 类的构造函数 BigInteger(int, int, Random) 最好表示为名为 BigInteger.probablePrime 的静态工厂方法。\n 一个类只能有一个具有给定签名的构造函数。但是程序员可以通过提供多个构造函数来绕过这个限制，这些构造函数的参数列表仅在参数类型、个数或顺序上有所不同。面对这样一个 API，用户将永远无法记住该用哪个构造函数，并且最终会错误地调用不适合的构造函数。如果不参考类文档，阅读使用这些构造函数代码的人就不会知道代码的作用。\n 2 静态工厂方法不需要在每次调用时创建新对象（节省内存） Boolean.valueOf(boolean) 方法说明了这种技术：它从不创建对象。这种技术类似于享元模式 [Gamma95]。如果经常请求相同的对象，特别是在创建对象的代价很高时，它可以极大地提高性能。\n 什么是享元模式（Flyweight Design Pattern）？\n所谓“享元”，顾名思义就是被共享的单元。享元模式的意图是复用对象，节省内存，前提是享元对象是不可变对象。\n 枚举类型也提供了这种保证。\n3 可以通过静态工厂方法获取原返回类型的任何子类的对象（隐藏实现类） 这种灵活性的一个应用是 API可以返回对象，但又不会使对象的类变成共有的。（类可以是私有的，通过共有的静态工厂方法进行返回）以这种方式隐藏实现类会形成一个非常紧凑的 API。这种技术适用于基于接口的框架，其中接口为静态工厂方法提供了自然的返回类型。\n Collections 框架 API 比它导出 45 个独立的公共类要小得多，每个公共类对应一个方便的实现。减少的不仅仅是 API 的数量，还有概念上的减少：程序员为了使用 API 必须掌握的概念的数量和难度。程序员知道返回的对象是由相关的接口精确地指定的，因此不需要为实现类阅读额外的类文档。此外，使用这种静态工厂方法需要客户端通过接口而不是实现类引用返回的对象，这通常是很好的做法。\n 4 返回对象的类可以随调用的不同而变化，作为输入参数的函数 也就是说，在构造函数(或者是我们需要构造的对象)和外界之间增加了一个静态工厂的方法作为中间层，这个中间层做一个小解耦，可以在中间层也就是静态工厂方法上执行自己的逻辑。例如：\n​ EnumSet 类没有公共构造函数，只有静态工厂。在 OpenJDK 实现中，它们返回两个子类中的一个实例，这取决于底层 enum 类型的大小：如果它有 64 个或更少的元素，就像大多数 enum 类型一样，静态工厂返回一个 long 类型的 RegularEnumSet 实例；如果 enum 类型有 65 个或更多的元素，工厂将返回一个由 long[] 类型的 JumboEnumSet 实例。\n 客户端看不到这两个实现类的存在。如果 RegularEnumSet 不再为小型 enum 类型提供性能优势，它可能会在未来的版本中被消除，而不会产生不良影响。类似地，如果事实证明 EnumSet 有益于性能，未来的版本可以添加第三或第四个 EnumSet 实现。客户端既不知道也不关心从工厂返回的对象的类；它们只关心它是 EnumSet 的某个子类。\n 5 当编写包含方法的类时，返回对象的类不需要存在（解耦，隔离） 这种灵活的静态工厂方法构成了服务提供者框架的基础，比如 Java 数据库连接 API（JDBC）。服务提供者框架是一个系统，其中提供者实现一个服务，系统使客户端可以使用这些实现，从而将客户端与实现分离。\n 也就是说，当需要一个对象的时候，使用静态工厂方法进行返回就可以了，不必真正的去创建这个类。\n 静态工厂方法的局限 1 没有公共或受保护构造函数的类不能被子类化 例如，不可能在集合框架中子类化任何方便的实现类。这可能是一种因祸得福的做法，因为它鼓励程序员使用组合而不是继承，并且对于不可变的类型是必需的。\n 因为构造函数不是共有的或者是受保护的，子类就不能够访问父类的构造函数，从而不能够创建子类。（子类创建需要调用弗父类的构造函数在调用自己的构造函数）\n 2 程序员很难找到这些静态工厂方法 它们在 API 文档中不像构造函数那样引人注目，因此很难弄清楚如何实例化一个只提供静态工厂方法而没有构造函数的类。与此同时，你可以通过在类或接口文档中对静态工厂方法多加留意，以及遵守通用命名约定的方式来减少这个困扰。下面是一些静态工厂方法的常用名称。这个列表还远不够详尽：\n   关键字 描述 使用     from 一种型转换方法，该方法接受单个参数并返回该类型的相应实例 Date d = Date.from(instant);   of 一个聚合方法，它接受多个参数并返回一个包含这些参数的实例 Set\u0026lt;Rank\u0026gt; faceCards = EnumSet.of(JACK, QUEEN, KING);   valueOf 一种替代 from 和 of 但更冗长的方法 BigInteger prime = BigInteger.valueOf(Integer.MAX_VALUE);   instance /getInstance 返回一个实例，该实例由其参数（如果有的话）描述，但不具有相同的值 StackWalker luke = StackWalker.getInstance(options);   create /newInstance 与 instance 或 getInstance 类似，只是该方法保证每个调用都返回一个新实例 Object newArray = Array.newInstance(classObject, arrayLen);   getType 类似于 getInstance，但如果工厂方法位于不同的类中，则使用此方法。其类型是工厂方法返回的对象类型 FileStore fs = Files.getFileStore(path);   newType 与 newInstance 类似，但是如果工厂方法在不同的类中使用。类型是工厂方法返回的对象类型 BufferedReader br = Files.newBufferedReader(path);   type 一个用来替代 getType 和 newType 的比较简单的方式 List\u0026lt;Complaint\u0026gt; litany = Collections.list(legacyLitany);         总结 静态工厂方法和公共构造器都有各自的用途，理解它们相比而言的优点是值得的。通常静态工厂的方式更可取，因此应避免在没有考虑静态工厂的情况下就提供公共构造函数。\nReference：\n Effective-Java-3rd-edition-Chinese-English-bilingual/Chapter-2-Item-1-Consider-static-factory-methods-instead-of-constructors.md at dev · clxering/Effective-Java-3rd-edition-Chinese-English-bilingual  ","description":"Consider static factory methods instead of constructors。","id":15,"section":"posts","tags":["EffectiveJava"],"title":"1-考虑以静态工厂方法代替构造函数-《Effective Java》笔记","uri":"https://hugo.jiahongw.com/zh/posts/bookeffectivejava/1%E8%80%83%E8%99%91%E4%BB%A5%E9%9D%99%E6%80%81%E5%B7%A5%E5%8E%82%E6%96%B9%E6%B3%95%E4%BB%A3%E6%9B%BF%E6%9E%84%E9%80%A0%E5%87%BD%E6%95%B0/"},{"content":"出发前的准备 我这里列了一个大致的攻略（虽然最后崂山没去成）：\n青岛攻略\n还准备了一个行程路线：\n第一站 我们下车的地方是青岛站，一下来，就是一种欧式建筑的感觉，这就是青岛的特色吗\n看海 来青岛怎么能不看海，青岛三面环海，来的这几天，海浪还挺大，吹着挺舒服\n波涛汹涌\n有意境的一瞬间\n青岛标志性建筑——栈桥\n吃海鲜 在青岛吃海鲜🦞，喝🍺啤酒。\n买海鲜\n找别人加工\n逛青岛街头 在十月份的青岛树木非常绿，而且青岛的街道也很有特色，就是那种林荫道的感觉，让人很舒服\n青岛的道路命名很有意思，都是拿其他省名作为道路名，据说青岛的版图就是一个小型的中国\n夜晚在教堂还有人组织一起看电影，好久没有这样的文艺活动了\n光圈内的人\n夜晚的街道和行人\n总结 青岛是一个非常漂亮的城市，非常适合旅游。青岛不仅有海，有海鲜，还有很多美女。此行前前后后也做了一些攻略，其实攻略是次要的，不一定非要将攻略中的各个景点都逛了才算完美，在行程中享受过程才是更重要的。\n彩蛋～\n","description":"国庆期间，去了一趟青岛。","id":16,"section":"posts","tags":["青岛","Life"],"title":"青岛之旅","uri":"https://hugo.jiahongw.com/zh/posts/life/qingdao-travel/"},{"content":"The photo about Beijing with me.📹\n","description":"记录北京的照片生活","id":17,"section":"gallery","tags":[""],"title":"北京的日子","uri":"https://hugo.jiahongw.com/zh/gallery/beijing/"},{"content":"Bash Shell 命令行通用快捷键：\n| 快捷键 | 作用 |\n|\u0026mdash;\u0026mdash;\u0026ndash;|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;-|\n|  | 删除前一个字符 |\n|  | 删除前一个单词 |\n|  | 删除至行首 |\n| | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\n| \u0026lt;++\u0026gt; | \u0026lt;++\u0026gt; |\nKey Mapping:\n map表示递归的映射 unmap表示删除某个映射     key explain map     nore 表示非递归 noremap   n 表示在普通模式下生效 nmap   v 表示在可视和选择模式下生效 vmap   i 表示在插入模式下生效 imap   c 表示在命令模式下生效 cmap   x 可视模式下生效 xmap    vim配置快捷键参考：\n   快捷键 作用 助记     Ctrl j 下移当前行或者段落    Ctrl k 上移当前行或者段落    Ctrl h     Ctrl l      清空高亮    r 调出替换命令    rc 调出替换命令（需要确认）    su 上分屏 鼠标在上分屏 split up   se 下分屏 鼠标在下分屏 split end   sn 右分屏 鼠标在右分屏    S 保存 :w save   Q 退出 :q quit   tu 创建新的标签页    tn 左移标签页    ti 右移标签页    tmn 交换左边标签页    tmi 交换右边标签页    ev 编辑.vimrc文件    sv 使.vimrc生效    cp 拷贝当前的缓存路径到剪切板     自动显示所有的空格     拼写检查     设置相对行    f 查找文件          原始快捷键\n   键位 作用      Ctrl w 删除前一个单词    Ctrl h 删除前一个字符    Ctrl u 删除至行首     切换普通模式    Ctrl [ 切换普通模式    Ctrl o 切换到插入-普通模式     数字+1 18表示数字+180    数字-1    g~ 反转大小写 配合aw使用   gu 转化为小写 配合aw使用   gU 转化为答谢 配合aw使用   \u0026gt; 增加缩进    \u0026lt; 减小缩进     向下翻一页     向上翻一页     回到上次修改的地方     撤销撤销     常见的等效命令：\n| 符合命令 | 等效的长命令 |\n|\u0026mdash;\u0026mdash;\u0026mdash;-|\u0026mdash;\u0026mdash;\u0026mdash;\u0026mdash;\u0026ndash;|\n| C | c$ |\n| s | cl |\n| S | ^c |\n| I | ^i |\n| A | $a |\n| o | A |\n| O | ko |\n尽量使用符合命令，减少敲击键盘的次数。\nvim-markdown快捷键参考：\n   快捷键 作用     ,b 加粗   ,p 斜体   ,q 行内代码块   ,c 代码块   ,g todo   ,p 图片   ,a 链接   ,n 几号 标题    vim-table-mode插件参考使用:\nvim中写table\n   按键 功能     \\tm 开启或者关闭table mode   \\T 将内容转化为表哥   \\tdd 删除某一行   \\tdc 删除当前列   \\tfa 添加公式   \\tfe 计算公式   \\ts 对某一列排序    其他参考：\n可视模式 Vim 有 3 种不同的可可视模式，分别用于操作字符文本、行文本和块文本。\n面向字符 适合操作单词和短语。激活：v\n行文本 适合操作行文本。激活：V。\n选择多行执行命令：\n例如：Vj + \u0026gt;. 表示将下面两行进行两次缩进\n块文本 适合操作表格或者csv文件。激活：\n在长短不一的高亮块后面添加文本。操作： + 2j + $ + A + “添加的字符串” + \n   命令 作用     viw 高亮一个词(然后按c进行修改)    or v 可以在可视模式和选择模式之间切换   b 选择前一个词   w 选择后一个词   o 回到选择的初始位置   e 选择到末尾   vit 高亮选中标签内部的内容   U 选中的字符变为大写(普通模式使用gUit更为准确)   u 选中的字符变为小写   r+字符 选择区域替换为字符    使用点命令最好避免可视模式。\n命令行模式 待补充。。。\nvim实用技巧：\n 把撤销单元切成块。 从进入插入模式开始，直到返回普 通模式为止，在此期间输入或删除的任何内容都被当成一次修改。因此，只要我们控制 好对  键的使用，就可使撤销命令作用于单词、句子或段落 当处于插入模式时，如果光标位于行尾的话，另起一行最快的方式是按。不 过有时我更喜欢按 o，这是因为我有预感，也许在撤销时我想拥有更细的粒度 124  坑  打开vim回到上次的位置：https://www.dyxmq.cn/linux/vim-setting-mouse-place.html  ","description":"","id":18,"section":"posts","tags":["vim"],"title":"vim使用笔记","uri":"https://hugo.jiahongw.com/zh/posts/efficient/vim/"},{"content":"不经意间看见了下面的这篇博文，联想到自己，我自己和父亲的关系就非常类似下面博主和他父亲的关系。\n 文章链接(可能需要翻墙)   我自己对待父亲其实一直以来都很冷漠，之前有段时间还经常的吵架，因为一些事。仔细想一下，很多东西是失去了之后才懂得珍惜，也有很多东西，是自己亲身体验了之后才知道里面的苦楚。我对父亲的不理解，或许只是我没有经历过他经历的，也或许是我自己的傲慢。\n但是不管怎么说，这篇文章都直接给了我一个警示，让我思考和父亲相处的方式。我的父亲也将近五十岁了，一路走来也不容易，我还是应该感谢他，为我付出了这么多，而且可能很多背后的付出是我没有看到的。我都应该在接下来的日子里面好好的回馈他。以前我没有什么可以给他，但是现在我工作了，至少还是能够有一些资本可以给他买点东西或者让他生活的更好，也希望之后的他能够更加的快乐。\n同时，这篇博文也说了，健康才是最重要的，要过就过有意义的生活，比起他什么都重要。下面引用文章作者的一句话，我觉得非常有道理：\n如果说我从这段亲子关系里学到了什么，那就是自己的身体健康，和重要的人度过有质量、有意义的时光，比什么狗屁成绩、职位、收入，都重要的多，你必须自己照顾好自己。 ","description":"生活中很少注意一些东西，错过了就将不复存在。珍惜当下！","id":19,"section":"posts","tags":["Life"],"title":"一篇文章想到父亲","uri":"https://hugo.jiahongw.com/zh/posts/life/myfather-some/"},{"content":"Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否解决一些初级的编程问题，解决问题的能够得到100美元，非常有意思。对于我们来说这些问题非常的简单，但是对于普通人来说，还是有一定的难度的。似乎在芝加哥的街头上也会编程的也不是挺多人，或者，程序猿都在上班吧🐶。\n 在第二期的问题变得比较难一点，是college水平的，解决问题的能够得到200美元。后面那个熟悉的判断回文串😄。\n 想象这个活动要是在中国试一试，感觉街头很多人能够做出来，因为中国的程序员越来越多了。\n","description":"Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否姐姐一些初级的编程问题。","id":20,"section":"posts","tags":["FunnySharing"],"title":"街头代码编程","uri":"https://hugo.jiahongw.com/zh/posts/funnysharing/code-problem-solving-onstreet/"},{"content":"Java语言虽然号称一切都是对象，但原始数据类型是例外。\n 在Java 5中，引入了自动装箱和自动拆箱功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大地简化了相关编程。\n 自动装箱实际上算是一种语法糖 。就是保证不同的写法在运行时是等价的。它们发生在编译阶段 ，也就是生成的字节码是一致的。\n  装箱表示将原始数据类型进行封装起来，然后添加一些操作例如数学计算和字符串转换等。\n  拆箱表示将一个封装了原始数据类型的对象转回为原始数据类型。\n  Java的8个原始数据类型（boolean、byte 、short、char、int、float、double、long)分别对应的8个封装对象为Boolean、Byte、Short、Character、Integer、Float、Double、Long。\n在Java中，几乎所有的基本类型封装类在进行自动装箱的时候都实现了缓存。\n  Integer，缓存了-128到127之间的数值\n  Boolean，缓存了true/false对应实例，确切说，只会返回两个常量实例Boolean.TRUE/FALSE。\n  Short，同样是缓存了-128到127之间的数值。\n  Byte，数值有限，所以全部都被缓存。\n  Character，缓存范围’u0000’ 到 ‘u007F’\n  这在一定程度能够节省内存，提高性能。但是原则上，建议避免无意中的装箱、拆箱行为 ，尤其是在性能敏感的场合，创建10万个Java对象和10万个整数的开销可不是一个数量级的 ，不管是内存使用还是处理速度，光是对象头的空间占用就已经是数量级的差距了。一些追求极致性能的产品或者类库，会极力避免创建过多对象。当然，在大多数产品代码里，并没有必要这么做，还是以开发效率优先。需要权衡利弊。\nInteger例子 javac替我们自动把装箱转换为Integer.valueOf()，把拆箱替换为Integer.intValue()，既然调用的是Integer.valueOf，自然能够得到缓存的好处。\n下面的调用了自动装箱和自动拆箱：\n1 2  Integer integer = 1;// 自动装箱 int unboxing = integer ++;//自动拆箱   反编译得到：\n1 2 3 4  1: invokestatic #2 // Method java/lang/Integer.valueOf:(I)Ljava/lang/Integer; 8: invokevirtual #3 // Method java/lang/Integer.intValue:()I   即装箱转换为Integer.valueOf()，把拆箱替换为Integer.intValue()，在Java源码可见这个值默认缓存是-128到127之间。\n源码\n缓存范围：\n装箱操作\n拆箱操作\n","description":"在Java 5中，引入了自动装箱和自动拆箱功能（boxing/unboxing），Java可以根据上下文，自动进行转换，极大地简化了相关编程。","id":21,"section":"posts","tags":["Java"],"title":"Java装箱拆箱","uri":"https://hugo.jiahongw.com/zh/posts/java/boxing-unboxing/"},{"content":"极化编码的基本思想是：只在$Z\\left( W_{N}^{\\left( i \\right)} \\right)$近于0的坐标信道$W_{N}^{\\left( i \\right)}$上发送数据比特。极化码具有一般的二元线性分组码的基本编码要素，因而可以通过显示地写出其生成矩阵来完成编码：\n$$\nx_{1}^{N}=u_{1}^{N}{G_{N}}\n$$\n其中，编码生成矩阵${G_{N}}\\text{=}{B_{N}}{F^{\\otimes n}}$，$B_{N}$是排序矩阵，完成比特的反序操作，$F^{\\otimes n}$表示矩阵$F$进行$n$次$Kronecker$积操作，有递归公式${F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}$且${F^{\\otimes 1}}\\text{=}F=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]$。\n主要的步骤为：\n可靠性估计 可靠性估计就是极化码的构造，这个过程我们选出信道容量高的子信道进行传输，信道容量低的子信道传输冻结比特。\n常见的几种可靠性估计的方法（极化码构造方法）有：\n  巴士参数估计法。\n  蒙特卡洛法。\n  密度进化法。\n  高斯近似法。\n  比特混合 假设通过错误概率进行极化码构造之后得到极化序列为$\\left{ 3,5,6,7,0,1,2,4 \\right}$ ，选择前面K个信道即$A=\\left{ 3,5,6,7\\right}$发送信息比特；另外的信道集合${A^{c}}=\\left{ 0,1,2,4\\right}$作为固定比特传输。设信息比特集合为$\\left( {i_{0}},{i_{1}},{i_{2}},{i_{3}} \\right)=\\left( 1,1,1,1 \\right)$，固定比特设置为0，则最终得到待编码的信息比特：\n$$\nu_{0}^{7}=\\left[ 0,0,0,{i_{0}},0,{i_{1}},{i_{2}},{i_{3}} \\right]=\\left[ 0,0,0,1,0,1,1,1 \\right]\n$$\n经过上面的过程我们就完成了对信息位和冻结位的比特混合。\n构造生成矩阵 首先我们求出排序矩阵$B_{N}$，其有递归式：\n$$\n{B_{N}}={R_{N}}\\left( {I_{2}}\\otimes {B_{N/{2};}} \\right)\n$$\n$$\n{B_{2}}={I_{2}}\n$$\n我们得到排序矩阵$B_{N}$，对输入序列完成奇序元素和偶序元素的分离，即先排奇序元素，再排偶序元素，其作为效果如下:\n$$\n\\left( {u_{1}},{u_{2}},{u_{3}},{u_{4}},\u0026hellip;,u{}*{N} \\right)\\times {R* {N}}=\\left( {u_{1}},{u_{3}},{u_{5}},\u0026hellip;,{u_{N-1}},{u_{2}},{u_{4}},{u_{6}},\u0026hellip;,{u_{N}} \\right)\n$$\n$F$矩阵我们可以根据下面的递归式进行求解：\n$$\n{F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}\n$$\n$$\nF=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]\n$$\n最后，我们将求得的排序矩阵和$F$矩阵相乘，得到生成矩阵$G_{N}$：\n$$\n{G_{N}}={B_{N}}{F^{\\otimes n}}\n$$\n假设我们求得的生成矩阵是：\n生成极化码 将信息比特与生成矩阵$G_{N}$相乘得到最终编码后的极化码，例如：\n参考：\n Polar Code（2）编码原理 | Marshall - Comm. Tech. Blog  ","description":"极化码的编码就是一些简单的线性运算，通过矩阵进行简化多维的运算，归根到底还是基于基本的异或操作。","id":22,"section":"posts","tags":["PolarCode","编码"],"title":"极化码-编码","uri":"https://hugo.jiahongw.com/zh/posts/polarcode/polar-code-encode/"},{"content":"基本概念 信噪比 信噪比，英文名称叫做SNR（SIGNAL-NOISE RATIO )，是指一个电子设备或者电子系统中信号与噪声的比例。信噪比的计算可以为有用信号功率与噪声功率的比 ：\n$$\nSNR = \\frac {P_{signal}} {P_{noise}}\n$$\n它的单位一般使用分贝，其值为十倍对数信号与噪声功率比:\n$$\nSNR(dB) = 10\\log_{10}(\\frac {P_{sibnal}} {P_{noise}})\n$$\n其中，$P_{signal}$为信号功率，$P_{noise}$为噪声功率。\n转移概率 一个二进制输入离散无记忆信道（B-DMC）可表示为$W:X\\to Y$，$X$是输入符号集合，$Y$是输出符号集合，转移概率为$W\\left( y|x \\right),x\\in X,y\\in Y$。由于信道是二进制输入，集合$X=\\left{ 0,1 \\right}$；$Y$和$W\\left( y|x \\right)$是任意值。对信道$W$的$N$次使用后的信道可表示为${W^{N}}$，则信道${W^{N}}:{X^{N}}\\to {Y^{N}}$的转移概率为：\n$$\n{W^{N}}\\left( y_1^{N}|x_{1}^{N} \\right)=\\prod\\nolimits_{i=1}^{N}{W\\left( y|x \\right)}\n$$\n对称容量 对称容量是对信道速率的度量，记作$I(W)$，表示信道$W$在等概率输入下的可靠传输时的最大速率,计算公式如下：\n$$\nI\\left( W \\right)\\triangleq \\sum\\limits_{y\\in Y}{\\sum\\limits_{x\\in X}{\\frac{1}{2}}}W\\left( y|x \\right)\\log \\frac{W\\left( y|x \\right)}{\\frac{1}{2}W\\left( y|0 \\right)+\\frac{1}{2}W\\left( y|1 \\right)}\n$$\n当码长$N$趋近于无穷的时候，信道容量趋近于1的分裂信道比例约为$K=N×I(W)$，这部分是用来传输信息比特的信道数量，而信道容量趋近于0的比例约为$N×(1−I(W))$，这部分表示冻结比特的信道数量。对于信道容量为1的可靠信道，可以直接放置消息比特而不采用任何编码，即相当于编码速率为$R=1$；而对于信道容量为0的不可靠信道，可以放置发送端和接收端都事先已知的冻结比特，即相当于编码速率为$R=0$。那么当码长$N \\to\\infty$时，极化码的可达编码速率$R= \\frac {K}{N}= \\frac {N×I(W)}{N}=I(W)$，即在理论上，极化码可以被证明是可达信道容量的。\n信道极化 信道极化分为信道联合和信道分裂两个阶段。对于长度为$N={2^{n}}$（$n$为任意整数）的极化码，它利用信道$W$的$N$个独立副本，进行信道联合和信道分裂，得到新的$N$个子信道$\\left{ W_{N}^{\\left( 1 \\right)},W_{N}^{\\left( 2 \\right)},\u0026hellip;,W_{N}^{\\left( N \\right)} \\right}$。随着码长的增加，分裂之后的信道将向两个极端发展：其中一部分分裂信道会趋近于完美信道，即信道容量趋近于1的无噪声信道；而另一部分分裂信道会趋近于完全噪声信道，即信道容量趋近于0的信道。\n我们主要研究二进制离散无记忆信道，将上面的信道模型（包括BEC、BSC、AWGN）进行抽象，我们可以得出下面的信道传输模型：\n图中的W可以是BEC信道，也可以是BSC信道或者AWGN信道，其中I(W)为信道容量。\n信道联合 信道联合是将多个子信道进行蝶形的异或操作的过程。对于码长为N=2的极化码，我们可以通过下面的蝶形异或操作将两个信道进行混合：\n由上图可以发现，进行信道联合之后，坐标不同信道的信道容量发生了极化现象，有一个比特的信道信道容量$I(W)$增加了，另外一个比特的信道容量$I(W)$减少了。信道容量小的，我们称为差信道，信道容量大的，我们称为号好信道。因为进行了信道联合之后，因为要求得左边的信道$u1$，必须是在右边的信道$y1$和$y2$同时都收到的情况下才能够得出$u1$，所以$u1$的信道容量就是信道$y1$和$y2$的信道容量乘积；相应的，对于信道$u2$，只有$y1$和$y2$都收不到的情况下，才接收不到信道，所以它的信道容量$I(W)$为$2*0.5 - 0.5^{2}$。\n我们也可以使用一个二维表格来计算它们传输的概率：\n   y1 y2 u1 u2     √ √ √ √   √ x x √   x √ x √   x x x x    由表格1可以发现，对于接收方收到的信号y1和y2，总共有4种情况，X表示该信道发生错误，未收到信道；√表示该信道收到了信道。对于子信道u1，在四种情况中，只有一种情况能够接受得到u1，也就是同时接收到y1和y2的情况,所以信道容量为1/4；而对于u2,只要能够收到y1或y2的任意一个它就能够解出来,根据信道极化理论，我们在进行极化的过程中，就已经知道信道u1的信道容量比较小，我们会把它作为冻结比特，填充为0，不传输信息比特，仅传输冻结比特，所以在没有接收到y2的情况下我们也能够得出u2。\n对于N=4的码长，我们可以递归的进行信道联合，如图，只不过相比于N=2的码长的极化码，我们需要增加一次的信道联合过程：\n按照这样不断的递归下去，到n级之后，可以得到递归的一般式：${W_{N/{2};}}$的2个独立副本联合产生信道${W_{N}}$，我们可以的到任意码长为$N=2^{n}$的极化码。\n信道分裂 信道分裂体现在信道联合之中 ，参考文献中对于信道分裂的解释，其大致过程是将两个信道$W_{N/2}$联合成一个信道$W_N$之后，再将联合的信道$W_N$分裂成两个子信道$W_{N/2}$，此时，这两个子信道的转移概率也改变了，这样极化码就完成了信道分裂。更具体的来说，它存在以下两个递推公式计算子信道的转移概率：\n$$\nW_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},u_{1}^{2i-2}|{u_{2i-1}} \\right)=\\sum\\limits_{u_{2i}}{\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)}\n$$\n$$\nW_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},u_{1}^{2i-1}|{u_{2i}} \\right)=\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)\n$$\n参考：\n 《“太极混一”——极化码原理及5G应用》  ","description":"介绍关于极化码的一些基本的数学与计算原理，包括如何进行概率的转移的。","id":23,"section":"posts","tags":["PolarCode","基本原理"],"title":"极化码-基本原理","uri":"https://hugo.jiahongw.com/zh/posts/polarcode/polar-code-fundamentals/"},{"content":"在通信过程中，物理层传输的就是电信号，假如我们只用0和1传输信号，并且这些信道互相都没有关系，我们称为二进制离散无记忆信道。信道模型是研究信道编码的基础，常见的几种信道模型分别有：二进制删除信道（BEC）、二进制对称信道（BSC）、高斯信道（AWGN）。设信道的输入和输出分别是长为N的序列，输入是x，输出是y，其信道的转移概率满足：\n$$\np\\left( {y|x} \\right) = \\sum_{i=1}^N p\\left( {y_{i} | x_{i}} \\right)\n$$\n无损信道 无论发送任何消息，接受方都能够准确无误的接收到，并且不会发生错误，那么这个信道就可以说是一个无损信道。最简单的的就是下面这个模型，不管发送者发送的是0还是1，接收者接受的都是一致的。\n假如我们随机进行传输0或者1的数据，其传输的数值图为下面：\n二进制删除信道 二进制删除信道，简记为BEC（Binary Erasure Channel ）。ϵ称为删除概率，表示有ϵ的概率这个信号会丢失。当接收方得到一个位，它是100%确定的位是正确的。只有当位被擦除时，才会出现唯一的混淆。对于二进制离散无记忆信道，我们有ϵ的概率丢失0或者1的比特位。\nBEC的信道容量为：\n$$\nC= 1 - \\epsilon\n$$\n二进制对称信道 二进制对称信道，简记为BSC（Binary Symmetric Channel ）。p称为交叉概率，表示有p的概率会导致传输过程中0信号和1信号的错乱。（错乱的意思是发送0，收到却是1；或者发送1，收到却是0）\nBSC的信道容量为：\n$$\nC = \\log n + q\\log q + (1-q) \\log \\frac {1-q}{n-1}\n$$\n加性高斯白噪声信道 高斯信道，常指加权高斯白噪声（AWGN）信道。这种噪声假设为在整个信道带宽下功率谱密度（PDF）为常数，并且振幅符合高斯概率分布。\n一般来说，高斯信道需要配合BPSK机制进行调制，在传输之前，我们对0和1比特进行变换，比特0会变成1，比特1变成-1，而这个将比特进行转换的过程就是BPSK调制，最后在BPSK调制后再加上高斯噪声，实际的模型如下：。\n通过BPSK调制之后0比特和1比特都会向1和-1这两个临界线靠经，在这个情况下传入高斯信道，即使存在高斯噪声进行影响，我们也能够减小它的影响，在解码端对码字进行BPSK解调，能够得到较高的准确率。\n由图可以发现，值靠近1的信号表示原来的信号是0，值靠近-1的信号表示原来的信号是1。这样的好处是在传输过程中减少高斯噪声的干扰，让传输的信号更加稳定。\n 特别的，5G标准要求信道编码至少能够在加性高斯白噪声信道（AWGN）下进行传输。\n ","description":"在信息论中，信道是指信息传输的通道。我们在实际通信中所利用的各种物理通道是信道的最典型的例子，如电缆、光纤、电波传布的空间、载波线路等等。但是极化码的信道模型将他们进行了抽象，将信道分成了几类：BEC、BSC、AWGN。","id":24,"section":"posts","tags":["PolarCode","信道模型"],"title":"极化码-信道模型","uri":"https://hugo.jiahongw.com/zh/posts/polarcode/polar-code-channel-model/"},{"content":"Arıkan教授在文献[1]提出了串行抵消SC译码算法。SC译码算法类似一个深度优先搜索的算法，其根据两个判决函数进行迭代计算最大似然对数比LLR，两个判决函数分别叫做f函数和g函数。下面是这两个公式的计算方法：\n$$\n\\begin{align}\nf\\left( a,b \\right)=\\ln \\left( \\frac{1+{ {e}^{a+b}}}{ { {e}^{a}}+{ {e}^{b}}} \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\ng\\left( a,b,{ {u}{s}} \\right)={ {\\left( -1 \\right)}^{ { {u} {s}}}}a+b\n\\end{align}\n$$\n其中，$a,b\\in R,{ {u}_{s}}\\in \\left{ 0,1 \\right}$。LLR的递归运算借助函数f和g表示如下：\n$$\n\\begin{align}\nL_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},\\hat{u}*{1}^{2i-2} \\right)=f\\left( L* {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}*{1,o}^{2i-2}\\oplus \\hat{u}* {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}_{1,e}^{2i-2} \\right) \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\nL_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},\\hat{u}*{1}^{2i-1} \\right)=g\\left( L* {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}*{1,o}^{2i-2}\\oplus \\hat{u}* {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}*{1,e}^{2i-2} \\right),{ { {\\hat{u}}}* {2i-1}} \\right)\n\\end{align}\n$$\n递归的终止条件为当$N=1$时，即到达了信道$W$端，此时$L_{1}^{\\left( 1 \\right)}\\left( { {y}_{j}} \\right)=\\ln \\frac{W\\left( { {y}_{j}}|0 \\right)}{W\\left( { {y}_{j}}|1 \\right)}$。\nSC译码算法依靠一个蝶形单元，如图10，在计算的时候不断进行递归，但是必须是先计算出蝶形单元的上行比特，才能够调用g函数求出下行比特。即图10中必须使用f函数计算出u1，之后才能够通过g函数求出u2。在实际的计算过程中，从接收的比特进行递归执行f函数和g函数，其中假如编码每次进行一次极化，在译码阶段都会多一次递归的计算，中间的计算值就是进行极化的临时值，在一整个蝶形结构中体现，是一个深度优先的算法。\nSCL译码算法[3]类似树的广度优先遍历，它的好处就是能够进行剪枝操作，不用计算所有的节点。它从根节点开始往树底部进行广度遍历搜索，每一层会计算出一个估计比特，然后在这个估计比特的基础上往下进行估计下一个比特的值，另外，SCL译码算法还增加了惩罚因子，对于惩罚因子过高的节点，我们可以直接跳过它以及它子节点的计算，因为它是正确的码的可能性极低，这样排除了不可能的路径，同时，这也能达到对树进行剪枝的效果，提高译码的速度。图11展示了进行SCL译码的基本过程：\n","description":"译码和编码类似，基于递归的结构。","id":25,"section":"posts","tags":["PolarCode","极化码译码"],"title":"极化码-译码","uri":"https://hugo.jiahongw.com/zh/posts/polarcode/polar-code-decode/"},{"content":"基本运作流程 Maven工具在本地有一个存储库，然后当本地存储库没有的情况下会自动的去中央仓库寻找并且下载到本地存储库，然后在执行自动化构建。\nMaven安装目录   bin/存放Maven的二进制执行程序，分为Linux和Windows的\n  boot/存放Maven的类加载器，用于加载jar包和类\n  conf/存放的是Maven的一些配置文件，例如settings.xml\n  lib/存放Maven工具依赖的jar包\n  usrlibs/是用户自定义保存项目依赖包的位置，用于作为本地仓库\n  Maven项目目录 每次使用Maven生成初始化的项目，项目的基本目录结构如下：\n  src/是源代码保存的位置\n main/业务代码位置  java/ 具体业务代码 构建包 构建类型 resources/ 资源文件 配置文件 静态文件 webapp/ web项目需要包含此文件夹 包含视图文件   test/ 进行测试的文件夹位置    target/是编译构建之后的目标存放位置\n  pom.xml是项目的依赖配置文件\n  ","description":"Maven相当于一个项目管理的框架，它帮助我们进行简便的依赖包下载和引入，并且能够自动化构建项目，避免繁琐的步骤。","id":26,"section":"posts","tags":["Java","Maven"],"title":"maven目录结构","uri":"https://hugo.jiahongw.com/zh/posts/java/maven-dir/"},{"content":"出发前的准备  冲锋衣（防风，防晒，防雨，防寒） 登山鞋或者越野鞋 登山杖 帽子 防晒霜 一次性内裤和一次性雨衣 相机 厚的衣服 口罩 学生证 身份证 驾驶证  基本路线 小环线+稻城亚丁\n川西美景 合照 some word 大学四年一下就过去了，很高兴遇见了一群很棒的朋友。希望未来的我们也更加优秀！旅游真是一件又累又让人重新认识世界事情啊！\n","description":"在大学的最后一次和朋友的旅行......","id":27,"section":"posts","tags":["life"],"title":"毕业旅行-川西","uri":"https://hugo.jiahongw.com/zh/posts/life/biyeluxing/"},{"content":"川西毕业旅行的图片。\n","description":"川西毕业旅行","id":28,"section":"gallery","tags":null,"title":"川西","uri":"https://hugo.jiahongw.com/zh/gallery/chuanxi/"},{"content":"5G下的极化码 这个专栏介绍极化码的相关原理，一方面是因为我目前的毕业设计是关于5G极化码方向的，另一方面我想将自己所学的一些知识记录或者分享起来。\n首先，我想要说的是，极化码是一种编码方式，它的目的是为了使得在传输过程中传输更多有效的消息，也可以理解为让传输更可靠的编码方式。当然，对于信道编码来讲，那最主要的就是编码和解码这两个板块。那什么是信道编码呢？可以这样理解：发送方先对发送的信息进行编码，通过信道进行传输，然后在接受方那边进行解码，得到消息，这就是信道编码的基本过程。我会在之后的文章中分析这些过程。\n专栏的目录分为如下几个板块：\n 信道模型 极化码基本原理 极化码的编码 极化码的译码 极化码的构造（信道的选择） 极化码实现  ","description":"极化码已经入选5G的标准，是唯一一个被证明可以达到香农极限的一种编码方式。","id":29,"section":"posts","tags":["PolarCode"],"title":"5G下的极化码","uri":"https://hugo.jiahongw.com/zh/posts/polarcode/polar-code-intro/"},{"content":" 在home目录下安装的nginx程序d\n 申请证书 letsencrypt的证书 申请网站：https://letsencrypt.osfipin.com/\n腾讯云的证书 申请网站：https://cloud.tencent.com/product/ssl\n证书申请完成之后，记录证书的位置，在nginx.conf文件进行修改即可，修改方式可以参照下面的步骤。\n使用certbot自动化 参考地址：https://blog.csdn.net/xs18952904/article/details/79262646\n检查nginx 查看 nginx 是否安装 http_ssl_module 模块\n/usr/local/nginx/sbin/nginx -V 如果出现 configure arguments: –with-http_ssl_module, 则已安装，不然的话需要重新编译安装，参考下面：\nhttps://segmentfault.com/a/1190000022673232\n安装certbot 1  yum install certbot python2-certbot-nginx   配置 SSL 证书证书时,报错ImportError: cannot import name UnrewindableBodyError，可以参考：https://www.cnblogs.com/codecheng99/p/12620850.html\n部署步骤 申请证书\ncertbot certonly --standalone -d jiahongw.com -d www.jiahongw.com 证书路径：\n/etc/letsencrypt/live/jiahongw.com/fullchain.pem /etc/letsencrypt/live/jiahongw.com/privkey.pem 进入修改\nvim nginx.conf 设置HTTP强制跳转HTTPS\n1 2 3 4 5  server { listen 80; server_name example.com; #这里修改为网站域名  rewrite ^(.*)$ https://$host$1 permanent; }   设置HTTPS\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  server { listen 443 ssl; server_name jiahongw.com www.jiahongw.com; ssl_certificate /etc/letsencrypt/live/jiahongw.com/fullchain.pem; ssl_certificate_key /etc/letsencrypt/live/jiahongw.com/privkey.pem; ssl_session_cache shared:SSL:1m; ssl_session_timeout 10m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #安全链接可选的加密协议  ssl_prefer_server_ciphers on; location / { root html/my_website; # my  index index.html index.htm; } }   测试配置文件的正确性\nnginx -t 重启nginx\n/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 自动续费\necho \u0026quot;0 0,12 * * * root python -c 'import random; import time; time.sleep(random.random() * 3600)' \u0026amp;\u0026amp; certbot renew\u0026quot; | sudo tee -a /etc/crontab \u0026gt; /dev/null 手动续期\ncertbot certonly --standalone -d example.com -d www.example.com 配置https代理\nserver { listen 443 ssl; server_name hostname.com; ssl_certificate cert/214547145790616.pem; ssl_certificate_key cert/214547145790616.key; location / { proxy_pass http://localhost:12345; } } 配置http2.0\nhttps://segmentfault.com/a/1190000017847301\n通过 Certbot 安装 Let\u0026rsquo;s Encrypt 证书，实现免费的全站 HTTPS 访问 | Laravel 学院\n配置Nginx 主要功能：\n 静态资源 反向代理 API服务  Nginx配置反向代理：\nalias与root的区别  root 实际访问文件路径会拼接URL中的路径\nalias 实际访问文件路径不会拼接URL中的路径\n 示例如下：\nlocation ^~ /sta/ { alias /usr/local/nginx/html/static/; } 请求：http://test.com/sta/sta1.html\n实际访问：/usr/local/nginx/html/static/sta1.html 文件\nlocation ^~ /tea/ { root /usr/local/nginx/html/; } 请求：http://test.com/tea/tea1.html\n实际访问：/usr/local/nginx/html/tea/tea1.html 文件\nRef：\n Nginx location匹配规则 - Ryan.Miao - 博客园 Nginx配置文件详解 - 程序员自由之路 - 博客园  检测HTTP3（quic）：HTTP/3 Check\n","description":"使用Nginx + certbot快速的配置一个可以https访问的网站。","id":30,"section":"posts","tags":["nginx"],"title":"Nginx配置SSL证书","uri":"https://hugo.jiahongw.com/zh/posts/nginx/nginx-ssl/"},{"content":"《转载》 https://www.cnblogs.com/fanzhidongyzby/p/3250405.html\n按照冯·诺依曼存储程序原理，程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。\n上图是进程地址空间分布的简单表示。代码存储了用户程序的所有可执行代码，在程序正常执行的情况下，程序计数器（PC指针）只会在代码段和操作系统地址空间（内核态）内寻址。数据段内存储了用户程序的全局变量，文字池等。栈空间存储了用户程序的函数栈帧（包括参数、局部数据等），实现函数调用机制，它的数据增长方向是低地址方向。堆空间存储了程序运行时动态申请的内存数据等，数据增长方向是高地址方向。除了代码段和受操作系统保护的数据区域，其他的内存区域都可能作为缓冲区，因此缓冲区溢出的位置可能在数据段，也可能在堆、栈段。如果程序的代码有软件漏洞，恶意程序会“教唆”程序计数器从上述缓冲区内取指，执行恶意程序提供的数据代码！\n栈溢出 栈的主要功能是实现函数的调用。因此在介绍栈溢出原理之前，需要弄清函数调用时栈空间发生了怎样的变化。每次函数调用时，系统会把函数的返回地址（函数调用指令后紧跟指令的地址），一些关键的寄存器值保存在栈内，函数的实际参数和局部变量（包括数据、结构体、对象等）也会保存在栈内。这些数据统称为函数调用的栈帧，而且是每次函数调用都会有个独立的栈帧，这也为递归函数的实现提供了可能。\n如图所示，我们定义了一个简单的函数function，它接受一个整形参数，做一次乘法操作并返回。当调用function(0)时，arg参数记录了值0入栈，并将call function指令下一条指令的地址0x00bd16f0保存到栈内，然后跳转到function函数内部执行。每个函数定义都会有函数头和函数尾代码，如图绿框表示。因为函数内需要用ebp保存函数栈帧基址，因此先保存ebp原来的值到栈内，然后将栈指针esp内容保存到ebp。函数返回前需要做相反的操作——将esp指针恢复，并弹出ebp。这样，函数内正常情况下无论怎样使用栈，都不会使栈失去平衡。\nsub esp,44h指令为局部变量开辟了栈空间，比如ret变量的位置。理论上，function只需要再开辟4字节空间保存ret即可，但是编译器开辟了更多的空间（这个问题很诡异，你觉得呢？）。函数调用结束返回后，函数栈帧恢复到保存参数0时的状态，为了保持栈帧平衡，需要恢复esp的内容，使用add esp,4将压入的参数弹出。\n之所以会有缓冲区溢出的可能，主要是因为栈空间内保存了函数的返回地址。该地址保存了函数调用结束后后续执行的指令的位置，对于计算机安全来说，该信息是很敏感的。如果有人恶意修改了这个返回地址，并使该返回地址指向了一个新的代码位置，程序便能从其它位置继续执行。\n栈溢出基本原理 上边给出的代码是无法进行溢出操作的，因为用户没有“插足”的机会。但是实际上很多程序都会接受用户的外界输入，尤其是当函数内的一个数组缓冲区接受用户输入的时候，一旦程序代码未对输入的长度进行合法性检查的话，缓冲区溢出便有可能触发！比如下边的一个简单的函数。\n1 2 3 4 5  void fun(unsigned char *data) { unsigned char buffer[BUF_LEN]; strcpy((char*)buffer,(char*)data);//溢出点 }   这个函数没有做什么有“意义”的事情（这里主要是为了简化问题），但是它是一个典型的栈溢出代码。在使用不安全的strcpy库函数时，系统会盲目地将data的全部数据拷贝到buffer指向的内存区域。buffer的长度是有限的，一旦data的数据长度超过BUF_LEN，便会产生缓冲区溢出。\n由于栈是低地址方向增长的，因此局部数组buffer的指针在缓冲区的下方。当把data的数据拷贝到buffer内时，超过缓冲区区域的高地址部分数据会“淹没”原本的其他栈帧数据，根据淹没数据的内容不同，可能会有产生以下情况：\n1、淹没了其他的局部变量。如果被淹没的局部变量是条件变量，那么可能会改变函数原本的执行流程。这种方式可以用于破解简单的软件验证。\n2、淹没了ebp的值。修改了函数执行结束后要恢复的栈指针，将会导致栈帧失去平衡。\n3、淹没了返回地址。这是栈溢出原理的核心所在，通过淹没的方式修改函数的返回地址，使程序代码执行“意外”的流程！\n4、淹没参数变量。修改函数的参数变量也可能改变当前函数的执行结果和流程。\n5、淹没上级函数的栈帧，情况与上述4点类似，只不过影响的是上级函数的执行。当然这里的前提是保证函数能正常返回，即函数地址不能被随意修改（这可能很麻烦！）。\n如果在data本身的数据内就保存了一系列的指令的二进制代码，一旦栈溢出修改了函数的返回地址，并将该地址指向这段二进制代码的其实位置，那么就完成了基本的溢出攻击行为。\n通过计算返回地址内存区域相对于buffer的偏移，并在对应位置构造新的地址指向buffer内部二进制代码的其实位置，便能执行用户的自定义代码！这段既是代码又是数据的二进制数据被称为shellcode，因为攻击者希望通过这段代码打开系统的shell，以执行任意的操作系统命令——比如下载病毒，安装木马，开放端口，格式化磁盘等恶意操作。\nmore：\n参考链接：\n https://www.cnblogs.com/fanzhidongyzby/p/3250405.html 函数栈的实现原理 https://xz.aliyun.com/t/5964  ","description":"程序代码是作为二进制数据存储在内存的，同样程序的数据也在内存中，因此直接从内存的二进制形式上是无法区分哪些是数据哪些是代码的，这也为缓冲区溢出攻击提供了可能。","id":31,"section":"posts","tags":["Linux"],"title":"缓冲区溢出","uri":"https://hugo.jiahongw.com/zh/posts/linux/buffer-overflow/"},{"content":"链接 链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。\n链接可以执行于编译时 (compile time) 也就是在源代码被翻译成机器代码时；也可以执行于加栽时（load time)，也就是在程序被加载器（loader)加载到内存并执行时；甚至执行于运行时（runtime)，也就是由应用程序来执行。\ngcc的编译过程：\n目标文件  编译器和汇编器生成可重定位目标文件(包括共享目标文件）。链接器生成可执行目标文件。\n 可重定位目标文件 包含二进制代码和数据，其形式可以在编译时与其他可重定位目标文件合并起来，创建一个可执行目标文件。\n下图是典型的ELF可重定位目标文件：\n这里需要注意的是，ELF 头（ELF header)以一个 16 字节的序列开始，这个序列描述了生成该文件的系统的字的大小和字节顺序。ELF 头剩下的部分包含帮助链接器语法分析和解释目标文件的信息。\n帮助链接器语法分析和解释目标文件的信息包括：\n 括 ELF 头的大小 目标文件的类型 机器类型（如 X86-64) 节头部表的文件偏移 节头部表中条目的大小和数量   不同节的位置和大小是由节头部表描述的，其中目标文件中每个节都有一个固定大小的条目（entry)\n ELF 可重定位目标文件包含下面几个节：\n .text: 已编译程序的机器代码 .rodata: 只读数据，比如printf语句中的格式串和switch语句的跳转表。 .data: 已初始化的全局和静态 C 变量。(局部 C 变量在运行时被保存在栈中，既不出现在 .data 节中，也不出现在 .bss 节中) .-bss: 未初始化的全局和静态 C 变量，以及所有被初始化为 0 的全局或静态变量。 .symtab: —个符号表，它存放在程序中定义和引用的函数和全局变量的信息。 .rel.text: —个.text 节中位置的列表，当链接器把这个目标文件和其他文件组合时，需要修改这些位置。 .rel.data: 被模块引用或定义的所有全局变量的重定位信息。 .debug: 一个调试符号表，其条目是程序中定义的局部变量和类型定义，程序中定义和引用的全局变量，以及原始的 C 源文件。 .line: 原始 C 源程序中的行号和.text 节中机器指令之间的映射。 .strtab: —个字符串表，其内容包括 .symtab 和 .debug 节中的符号表，以及节头部中的令名字。  可执行目标文件 包含二进制代码和数据，其形式可以被直接复制到内存并执行。\n加载可执行目标文件\n通过调用某个驻留在存储器中称为加载器（loader)的操作系统代码来运行它。任何Linux程序都可以通过execve 函数来调用加载器。\n加载器将可执行目标文件中的代码和数据从磁盘复制到内存中，然后通过跳转到程序的第一条指令或入口点来运行该程序。这个将程序复制到内存并运行的过程叫做加栽。\n在 Linux X86-64系统中，代码段总是从地址 0x400加0 处开始，后面是数据段。运行时堆在数据段之后，通过调用 malloc 库往上增长。\n用户栈总是从最大的合法用户地址（$2^{48}$ —1)开始，向较小内存地址增长。栈上的区域，从地址 $2^{48}$ 开始，是为内核（kernel)中的代码和数据保留的，所谓内核就是操作系统驻留在内存的部分。\nLinux X86-64 运行时内存映像。没有展示出由于段对齐要求和地址空间布局随机化（ASLR)造成的空隙。\n加载器运行时，创建上面所示的内存映像。在程序头部表的引导下,加载器将可执行文件的片(chunk)复制到代码段和数据段。接下来，加载器跳转到程序的人口点，也就是_start函数的地址。这个函数是在系统目标文件 ctrl.o 中定义的，对所有的 C 程序都是一样的。_start 函数调用系统启动函数__libc_start_main，该函数定义在 libc.so 中。它初始化执行环境，调用用户层的 main 函数，处理 main 函数的返回值，并且在需要的时候把控制返回给内核。\n共享目标文件 一种特殊类型的可重定位目标文件，可以在加载或者运行时被动态地加载进内存并链接。\n静态链接  像 Linux LD 程序这样的静态链接器（static linker)以一组可重定位目标文件和命令行参数作为输入，生成一个完全链接的、可以加载和运行的可执行目标文件作为输出。\n 为了构造可执行文件，链接器必须完成两个主要任务：\n 符号解析：每个符号对应于一个函数、一个全局变量或一个静态变量 重定位：编译器和汇编器生成从地址 0 开始的代码和数据节。链接器通过把每个符号定义与一个内存位置关联起来，从而重定位这些节，然后修改所有对这些符号的引用，使得它们指向这个内存位置  为什么使用静态链接库 早期的问题：不使用静态链接库，如何像用户提供标准函数？\n一种方法是让编译器辨认出对标准函数的调用，并直接生成相应的代码。这种方法无疑会增加编译器的复杂性。(而且每次添\n加、删除或修改一个标准函数时，就需要一个新的编译器版本)\n另一种方法是将所有的标准 C 函数都放在一个单独的可重定位目标模块中。\n这种方法的优点是它将编译器的实现与标准函数的实现分离开来，并且仍然对程序员保持适度的便利。然而，一个很大的缺点是系统中每个可执行文件现在都包含着一份标准函数集合的完全副本，这对磁盘空间是很大的浪费。另一个大的缺点是，对任何标准函数的任何改变，无论多么小的改变，都要求库的开发人员重新编译整个源文件，这是一个非常耗时的操作，使得标准函数的开发和维护变得很复杂\n静态库概念被提出来，以解决这些不同方法的缺点。相关的函数可以被编译为独立的目标模块，然后封装成一个单独的静态库文件。\n在链接时，链接器将只复制被程序引用的目标模块，这就减少了可执行文件在磁盘和内存中的大小。\n使用静态链接库 要创建一个静态库，我们将使用 AR 工具\n新建文件夹staticlib，在下面创建两个文件add.c和mul.c\n1 2 3 4  void add(int *x,int *y,int *z) { *z = (*x) + (*y); }   1 2 3 4  void mul(int *x,int *y,int *z) { *z = (*x) * (*y); }   并且新建一个文件mymath.h，里面包含了上面两个文件的函数申明：\n1 2  void add(int *x,int *y,int *z); void mul(int *x,int *y,int *z);   在文件夹staticlib下执行，编译成.o文件(就是一种可重定位文件)\ngcc -c *.c 使用 AR 工具生成静态链接库\nar rcs libmymath.a add.o mul.o  在 Linux 系统中，静态库以一种称为存档（archive)的特殊文件格式存放在磁盘中。存档文件是一组连接起来的可重定位目标文件的集合，有一个头部用来描述每个成员目标文件的大小和位置。存档文件名由后缀**.a** 标识。\n 为了使用这个库，我们可以编写一个应用，与文件夹staticlib同级创建文件main.c\n1 2 3 4 5 6 7 8 9 10 11 12 13  #include \u0026lt;stdio.h\u0026gt;#include \u0026#34;staticlib/mymath.h\u0026#34; int main(int argc,const char *argv) { int x = 1,y = 2; int z; printf(\u0026#34;x = %d y = %d \\n\u0026#34;,x,y); add(\u0026amp;x,\u0026amp;y,\u0026amp;z); printf(\u0026#34;add: Z = %d\\n\u0026#34;,z); return 0; }   gcc - c main.c libc.a没有安装会报错，此时可以执行下面的语句安装：\nyum install glibc-static 下面使用静态链接链接一个可执行文件\ngcc -static -o main main.o ./staticlib/libmymath.a 或者\ngcc -static -o main main.o -L staticlib/ -lmymath -static 参数告诉编译器驱动程序，链接器应该构建一个完全链接的可执行目标文件，它可以加载到内存并运行，在加载时无须更进一步的链接。-lmymath 参数是 libvector.a 的缩写，-L.参数告诉链接器在当前目录下査找 libvector.a\n大概的流程是下面这张图：\n当链接器运行时，它判定 main引用了add.o定义的 add 符号，所以复制add.o 到可执行文件。因为程序不引用任何由 mul.o 定义的符号，所以链接器就不会复制这个模块到可执行文件。链接器还会复制 libc.a 中的 printf.o 模块，以及许多 C 运行时系统中的其他模块。\n ar 是 Linux 的一个备份压缩命令，它可以将多个文件打包成一个备份文件（也叫归档文件），也可以从备份文件中提取成员文件。ar 命令最常见的用法是将目标文件打包为静态链接库。\n对参数的说明：\n 参数 r 用来替换库中已有的目标文件，或者加入新的目标文件。 参数 c 表示创建一个库。不管库否存在，都将创建。　 参数 s 用来创建目标文件索引，这在创建较大的库时能提高速度。   使用静态链接库时，除了需要库文件本身，还需要对应的头文件：库文件包含了真正的函数代码，也即函数定义部分；头文件包含了函数的调用方法，也即函数声明部分。\n当链接器构造一个输出的可执行文件时，它只复制静态库里被应用程序引用的目标模块。\n符号解析 链接器如何解析静态链接库？\n在符号解析阶段，链接器从左到右按照它们在编译器驱动程序命令行上出现的顺序来扫描可重定位目标文件和存档文件。\n链接器维护的三个集合：\n 可重定位目标文件集合E 未解析的符号集合U 已定义的符号集合D  初始时，三个集合都为空；最终的结果应该是集合U为空，才是链接成功，不然会报错。\n假如是目标文件\n假如是存档文件，那么链接器就尝试匹配 U 中未解析的符号和由存档文件成员定义的符号。如果某个存档文件成员 m定义了一个符号来解析 U 中的一个引用，那么就将 m 加到 E中，并且链接器修改U 和 D来反映 m 中的符号定义和引用。对存档文件中所有的成员目标文件都依次进行这个过程，直到 U 和 D都不再发生变化。此时，任何不包含在 E中的成员目标文件都简单地被丢弃，而链接器将继续处理下一个输入文件。\n最后，如果U是空集，它会合并和重定位 E中的目标文件，构建输出的可执行文件。\n在命令行中，如果定义一个符号的库出现在引用这个符号的目标文件之前，那么引用就不能被解析，链接会失败。(因为一开始集合U是空的，存档文件会假如E中，存档文件里面的定义永远不会被解析)\n关于库的一般准则是将它们放在命令行的结尾。\n重定位 此时，链接器就知道它的输人目标模块中的代码节和数据节的确切大小。现在就可以开始重定位步骤了，在这个步骤中，将合并输人模块，并为每个符号分配运行时地址。重定位由两步组成：\n 注意下面一个是符号定义，一个是符号引用，两者不一样！\n   重定位节和符号定义\n在这一步中，链接器将所有相同类型的节合并为同一类型的新的聚合节。例如，来自所有输人模块的.data 节被全部合并成一个节，这个节成为输出的可执行目标文件的.data 节。然后，链接器将运行时内存地址赋给新的聚合节，赋给输人模块定义的每个节，以及赋给输人模块定义的每个符号。当这一步完成时，程序中的每条指令和全局变量都有唯一的运行时内存地址了。也就是指令段与代码段中全局、静态变量、函数入口以及指令的运行时内存地址都已确定。\n 注意：\n.bss段在目标文件和可执行文件中并不占用文件的空间，但是它在装载时占用地址空间（占用的是虚拟地址空间）\n   重定位节中的符号引用\n这一步中，链接器修改代码节和数据节中对于每个符号的引用，使得他们指向正确的运行时地址。 这一步链接器依赖于可重定位目标模块中称为重定位条目的数据结构。\n参考地址：https://blog.csdn.net/weixin_44176696/article/details/106666236\n重定位条目\n无论何时汇编器遇到对最终位置未知的目标引用，它就会生成一个重定位条目 ，告诉链接器在将目标文件合并成可执行文件时如何修改这个引用。代码的重定位条目放在 .rel.text 中。已初始化数据的重定位条目放在 .rel.data 中。\n  动态链接 对于静态链接来说，它还是太消耗内存了。\n共享库（shared library)是致力于解决静态库缺陷的一个现代创新产物。共享库是一个目标模块，在运行或加载时，可以加载到任意的内存地址，并和一个在内存中的程序链接起来。这个过程称为动态链接(dynamic linking)� 是由一个叫做动态链接器（dynamic linker)\n的程序来执行的。\n共享库是以两种不同的方式来“共享”：\n  在任何给定的文件系统，对于一个库只有一个.so 文件。\n所有引用该库的可执行目标文件共享这个.so文件中的代码和数据，而不是像静态库的内容那样被复制和嵌人到引用它们的可执行的文件中。\n  其次，在内存中，一个共享库的 .text 节的一个副本可以被不同的正在运行的进程共享。\n  基本的思路是当创建可执行文件时，静态执行一些链接，然后在程序加载时，动态完成链接过程。\n没有任何 libmymath.so 的代码和数据节真的被复制到可执行文件 main 中。反之，链接器复制了一些重定位和符号表信息，它们使得运行时可以解析对 libmymath.so 中代码和数据的引用。\n动态链接器通过执行下面的重定位完成链接任务：\n 重定位 libc.so 的文本和数据到某个内存段 重定位 libmymath.so 的文本和数据到另一个内存段 重定位 main 中所有对由 libc.so 和 libmymath.so 定义的符号的引用  最后，动态链接器将控制传递给应用程序。从这个时刻开始，共享库的位置就固定了，并且在程序执行的过程中都不会改变。\n使用动态链接库 如果想创建一个动态链接库，可以使用 GCC 的-shared选项。输入文件可以是源文件、汇编文件或者目标文件。\n另外还得结合-fPIC选项。-fPIC 选项作用于编译阶段，告诉编译器产生与位置无关代码（Position-Independent Code）；这样一来，产生的代码中就没有绝对地址了，全部使用相对地址，所以代码可以被加载器加载到内存的任意位置，都可以正确的执行。这正是共享库所要求的，共享库被加载时，在内存的位置不是固定的。\n执行下面的命令，创建和使用动态链接库\ngcc -shared -fpic -o libmymath.so add.c mul.c gcc -o main main.c ./libmymath.so -fPIC 选项作用于编译阶段，在生成目标文件时就得使用该选项，以生成位置无关的代码。\n当然，必须要确保程序在运行时可以找到这个动态链接库。你可以将链接库放到标准目录下，例如 /usr/lib，或者设置一个合适的环境变量，例如 LIBRARY_PATH。不同系统，具有不同的加载链接库的方法。\n参考：\n GCC创建和使用静态链接库（.a文件） GCC生成动态链接库（.so文件） C语言和C++的混合编译  ","description":"链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。","id":32,"section":"posts","tags":["Linux"],"title":"linking","uri":"https://hugo.jiahongw.com/zh/posts/linux/linking/"},{"content":"库打桩机制 LInux链接器有强大的库打桩机制，它允许你对共享库的代码进行截取，从而执行自己的代码。而为了调试，你通常可以在自己的代码中加入一些调试信息，例如，调用次数，打印信息，调用时间等等。\n基本原理 基本思想 给定需要打桩的目标函数，常见一个wrapper函数，其原型和目标函数一致。利用特殊的打桩机制，可以实现让系统调用你的wrapper函数而不是目标函数。wrapper函数中通常会执行自己的逻辑，然后调用目标函数，再将目标函数的返回值传递给调用者。\n 打桩可以发生在编译时、链接时或者程序被加载执行的运行时。不同的阶段都有对应的打桩机制，也有其局限性。\n 打桩时期 创建一个main.c文件，内容：\n1 2 3 4 5 6 7 8 9  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;malloc.h\u0026gt;int main() { char *p = malloc(64); printf(\u0026#34;Hello\\n\u0026#34;); free(p); return 0; }   编译时打桩  使用 C 预处理器在编译时打桩。\n 定义插桩函数头文件 malloc.h\n1 2 3 4 5  #define malloc(size) mymalloc(size)#define freeCptr) myfree(ptr) 23 void *mymalloc(size_t size); void myfree(void *ptr);   定义插桩函数的文件 mymalloc.c\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  // mymalloc.c #ifdef COMPILETIME#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;malloc.h\u0026gt; // malloc wrapper function void * mymalloc(size_t size) { void * ptr = malloc(size); printf(\u0026#34;malloc %p size %u\\n\u0026#34;, ptr, size); return ptr; } // free wrapper function void myfree(void *ptr) { free(ptr); printf(\u0026#34;free %p\\n\u0026#34;, ptr); } #endif  这样编译和链接程序\n1 2  gcc -DCOMPILETIME -c mymalloc.c gcc -I. -o main main.c mymalloc.o   执行：\n1  ./main   链接时打桩  链接(linking)是将各种代码和数据片段收集并组合成为一个单一文件的过程，这个文件可被加载（复制）到内存并执行。\n 这个不需要头文件，直接创建一个插桩函数文件 mymalloc.c:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  #ifdef LINKTIME#include \u0026lt;stdio.h\u0026gt;void *__real_malloc(size_t size); void __real_free(void *ptr); /* malloc wrapper function */ void *__wrap_malloc(size_t size) { void *p = __real_malloc(size); // 调用libc的malloc  printf(\u0026#34;malloc(%d) = %p \\n\u0026#34;,size,p); return p; } /* free wrapper function */ void *__wrap_free(void *ptr) { __real_free(ptr); printf(\u0026#34;free(%p)\\n\u0026#34;,ptr); } #endif  这样编译和链接程序\n1 2 3  gcc -DLINKTIME -c mymalloc.c gcc -c main.c gcc -Wl,--wrap,malloc -Wl,--wrap,free -o main main.o mymalloc.o   执行\n1  ./main   运行时打桩 创建一个插桩函数文件 mymalloc.c:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  #ifdef RUNTIME #define _GNU_SOURCE#include \u0026lt;stdio.h\u0026gt;#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;dlfcn.h\u0026gt; /* malloc wrapper function */ void *malloc(size_t size) { void *(*mallocp)(size_t size); char *error; mallocp = dlsym(RTLD_NEXT,\u0026#34;malloc\u0026#34;); // get the address of libc malloc  if((error = dlerror()) != NULL) { fputs(error,stderr); exit(1); } char *ptr = mallocp(size); printf(\u0026#34;malloc(%d) = %p \\n\u0026#34;,(int)size,ptr); return ptr; } /* free wrapper function */ void free(void* ptr) { void (*freep)(void*) = NULL; char *error; if(!ptr) return; freep = dlsym(RTLD_NEXT,\u0026#34;free\u0026#34;); if((error = dlerror()) != NULL) { fputs(error,stderr); exit(1); } freep(ptr); printf(\u0026#34;free(%p)\\n\u0026#34;,ptr); } #endif  这样编译链接执行程序\n1 2 3  gcc -DRUNTIME -shared -fpic -o mymalloc.so mymalloc.c -ldl gcc -o main main.c LD_PRELOAD=\u0026#34;./mymalloc.so\u0026#34; ./main   GCC相关参数    参数 功能     -c 只激活预处理,编译,和汇编,也就是他只把程序做成obj文件,将生成 .o 的 obj 文件\n例子：gcc -c hello.c   -S 只激活预处理和编译，就是指把文件编译成为汇编代码,将生成 .s 的汇编代码。\n例子：gcc -S hello.c    -E 只激活预处理,这个不生成文件, 你需要把它重定向到一个输出文件里面。\n例子：gcc -E hello.c \u0026gt; pianoapan.txt gcc -E hello.c | more    -o 指定目标名称   -g 只是编译器，在编译的时候，产生调试信息。   -static 此选项将禁止使用动态库，所以，编译出来的东西，一般都很大，也不需要什么动态连接库，就可以运行。   -share 此选项将尽量使用动态库，所以生成文件比较小，但是需要系统由动态库。    我们通过ldd命令查看程序链接的系统库：\n参考链接：\n https://zhuanlan.zhihu.com/p/76036630 https://www.cnblogs.com/tocy/p/Linux-library-Interposition.html GCC 参数详解  ","description":"LInux链接器有强大的库打桩机制，它允许你对共享库的代码进行截取，从而执行自己的代码。而为了调试，你通常可以在自己的代码中加入一些调试信息，例如，调用次数，打印信息，调用时间等等。","id":33,"section":"posts","tags":["MLK"],"title":"打桩机制","uri":"https://hugo.jiahongw.com/zh/posts/mlk/interposition/"},{"content":"DieHard 一个基于概率内存安全的运行时系统。\n基本介绍 源码：https://github.com/emeryberger/DieHard\n支持  Windows Linux Mac OS X  安装  需要C++14支持\n   解压并且进入文件夹\n1 2  unzip DieHard.zip cd DieHard     编译\n1 2 3  cd src/ TARGET=libdiehard make linux-gcc-x86-64-replicated TARGET=libdieharder make linux-gcc-x86-64-replicated   编译完成在目录下会新增3个动态链接库：libdieharder.so和libdiehard.so、libdieharder_r.so\n1 2 3  cd src/util/ g++ -pipe -g -fPIC -I. -I.. -I../../src/archipelago/brokenmalloc -D_REENTRANT=1 -shared libbrokenmalloc.cpp -o libbrokenmalloc.so -ldl g++ -fPIC -pipe -g -I. -I.. -I../../src/archipelago/brokenmalloc/ -D_REENTRANT=1 -shared libtrackalloc.cpp -o libtrackalloc.so -ldl   编译完成会在目录下生成2个动态链接库libbrokenmalloc.so和libtrackalloc.so\n  使用 基本使用方法 基本使用方法：\n在执行程序之前添加提前加载库选项LD_PRELOAD=libdiehard.so\n例如：\n1  LD_PRELOAD=/mnt/MLK/Tools/DieHard/src/libdiehard.so app app_args   原理 错误类型 涵盖的错误类型大概一下几类：\n  Dangling pointers\n迷途指针，或称悬空指针、野指针，指的是不指向任何合法的对象的指针。当所指向的对象被释放或者收回，但是对该指针没有作任何的修改，以至于该指针仍旧指向已经回收的内存地址，此情况下该指针便称迷途指针。\n  Buffer overflflows\n堆缓冲溢出。越界写会损坏堆上活对象的内容。\n  Heap metadata overwrites\n堆元数据被覆盖。如果堆元数据存储在堆对象附近，那么堆越界写可能会损坏它。\n  Uninitialized reads\n未初始化读。从新分配或未分配的内存中读取值会导致未定义的行为。\n  Invalid frees\n非法释放内存。将非法地址传递给free可能会损坏堆或导致未定义的行为。\n  Double frees\n重复释放内存。\n   上面的分类其实有点问题，既然未分配内存读取都能归为未初始化读的问题，那么重复释放内存为什么不能归为非法内存释放呢？\n  DieHard以很高的概率消除或避免了上述所有内存错误\n 概念 probabilistic memory safety(基于概率的内存安全) 将程序定义为完全内存安全，必须满足下面的条件：\n 从不读取未初始化的内存。 在堆上不执行非法操作(非法释放内存/双释放内存)。 不访问已释放的内存(没有悬浮指针错误)。   注意：上面的条件中没有提及堆缓冲溢出。\n 通过中止可能违反这些条件之一的计算，安全的C编译器提供了完整的内存安全。 然而，作者理想地希望有一个执行环境，允许这些程序在面对这些错误时继续正确地执行。(依靠复制版本实现)\n定义一个理想但无法实现的运行时系统。我们叫它无限堆内存管理器。它提供了无限堆语义。\ninfifinite-heap(无限堆) 在这样的系统中，堆的面积是无限大的，因此不存在堆耗尽的风险。 对象永远不会被去分配，所有对象都被分配到彼此无限远的地方(也就是说，它们可以被认为是无限的内存块。\n 从正确的C执行的角度来看，一个不刻意寻求耗尽堆的程序不能判断它是用普通的堆实现运行还是用无限的堆运行。\n 因为每个对象都离其他对象无限远，就算溢出写覆盖的也不是有用的对象数据，而是空数据，分配的对象从未被覆盖。所以不存在堆缓冲溢出问题。\n因为堆内存无限大，所以根本不需要释放内存，所以悬浮指针的问题也消失了。\n对堆的未初始化读取仍然未定义。与Java不同，新分配的C和C对象的内容不一定被定义。\n实际构建的系统 近似无限堆 虽然无限堆内存管理器是不可实现的，但我们可以概率地近似它的行为。\n我们将无限堆替换为一个所需的最大值的堆的M倍内存以获得无限堆语义。 通过在堆中均匀地随机放置对象，我们得到了最小的期望分离间隔。\n$$\nE[minimum separation] = (M - 1) objects\n$$\n使得溢出小于M-1倍对象大小时是无害的。\n最后，通过随机选择要回收的已释放对象，最近释放的对象极不可能被覆盖。\n为了检测对堆的未初始化读，我们要求无限堆和每个分配的对象都充满随机值。然后，我们可以通过同时执行至少两个具有不同随机分配器的副本来检测未初始化的读取并且比较他们的输出。未初始化的读取将在副本中返回不同的结果，如果此读取影响计算，则副本的输出将不同。这样DieHard就能够检测出来。\n随机内存管理器 randomized memory manager 随机内存管理器。允许计算检测或避免内存错误精确的概率。快速随机内存分配器，它构成了独立和复制版本的核心。\nDieHard的随机内存管理器将对象随机放置在一个堆中，堆的大小是所需最大值的几倍。例如下图：\n对象之间的间隔使得缓冲区溢出最终可能只覆盖空闲无用的空间\n随机分配也使得新释放的对象不太可能很快被随后的分配覆盖，从而避免了悬空指针错误。\n它还通过将所有堆元数据从堆中分离（避免大多数堆元数据覆盖）和忽略释放已经创建或无效对象的尝试来提高应用程序的健壮性。\n对于复制版本：\n模式 单独模式 + 复制模式\n而独立版本的Die Hard提供了防止内存错误的实质性保护。复制的版本既增加了保护，又检测了非法读取引起的错误。 在复制模式下，DieHard同时执行同一程序的多个副本，每个副本都有不同的种子给各自的随机分配器。\n复制模式\n对与缓冲区溢出。因为多个副本使用不一样的种子作为随机分配。因此，缓冲区溢出等错误很可能会覆盖不同副本中的不同内存区域。\nDieHard拦截来自所有不同副本的输出，并在发送任何输出之前比较每个副本的内容。 通过很高的概率，当任何两个程序在其输出上达成一致时，它们才安全地执行。\n对于悬浮指针。在任何一致的副本中，任何缓冲区溢出都只覆盖无用的数据。垂的指针从未被覆盖。\n对于未初始化的数据。如果应用程序的输出依赖于未初始化的数据，那么这些数据将在副本中不一致，DieHard将会检测到它们。\n 使用额外的副本可以进一步提高可靠性。 虽然额外的复制自然会增加单处理器平台上的执行时间，但我们认为使用复制的自然设置是在具有多个处理器的系统上。Die Hard可以使用更新处理器上的多个核心来使遗留程序更可靠。\n 优点和缺点 优点  性能好。(论文说) 由于用DieHard替换堆显著提高了可靠性，我们认为它适合于广泛的部署，特别是在提高可靠性值得空间成本的场景中。  缺点  安装复杂，并且需要C++14的支持。 可以报错但是不能提供错误的具体位置信息。 内存消耗大。 复制模式需要多处理器并行。 这种随机分配使得计算机无法根据空间局部性推断，系统中的TLB往往失效。为了保持性能，Die Hard堆的使用中部分应该适合物理RAM。  参考：\n https://securitygossip.com/blog/2018/09/29/guarder-a-tunable-secure-allocator/ https://firmianay.gitbooks.io/ctf-all-in-one/content/doc/8.46_freeguard.html  ","description":"一个基于概率内存安全的运行时系统。","id":34,"section":"posts","tags":["MLK"],"title":"DieHard","uri":"https://hugo.jiahongw.com/zh/posts/mlk/diehard/"},{"content":"Valgrind Valgrind发行版目前包括七个生产质量工具：一个内存错误检测器，两个线程错误检测器，一个缓存和分支预测探查器，一个生成调用图的缓存和分支预测探查器以及两个不同的堆探查器。它还包括一个实验性的SimPoint基本块矢量生成器。\n 在软件开发过程中我们有时需要追踪程序执行、诊断错误、衡量性能等需求。如果有源代码的话可以添加相应代码，没有源代码时这个方法就行不通了。前者可以对源代码分析，后者只能分析二进制了。我的理解是，dynamic Binary Instrumentation (DBI)强调对二进制执行文件的追踪与信息收集，dynamic Binary Analysis (DBA)强调对收集信息的分析，valgrind是一个DBI框架，使用它可以很方便构建一个DBA工具。\n Valgrind作者认为当时的DBI框架都把注意力放在了性能检测上，对程序的质量(原文capabilities)并没有太注意。所以设计了一个新的DBI框架，目标是可以使用它开发重型DBA工具。\n基本介绍 官网： https://valgrind.org/\n文档： https://valgrind.org/docs/manual/index.html\n源码： https://github.com/groleo/mpatrolhttps://valgrind.org/downloads/repository.html\n支持 它可在以下平台上运行：\nX86 / Linux，AMD64 / Linux，ARM / Linux，ARM64 / Linux，PPC32 / Linux，PPC64 / Linux，PPC64LE / Linux，S390X / Linux，MIPS32 / Linux，MIPS64 / Linux，X86 / Solaris ，AMD64 / Solaris，ARM / Android（2.3.x和更高版本），ARM64 / Android，X86 / Android（4.0和更高版本），MIPS32 / Android，X86 / Darwin和AMD64 / Darwin（Mac OS X 10.12）。\n安装   解压安装包\n1 2  tar -jxvf valgrind-3.15.0.tar.bz2 cd valgrind-3.15.0/     创建Makefile\n1  ./configure     安装\n  1 2 3  make make install valgrind --version   使用 编译说明  最好使用debug版本（gcc -g），这样打印的信息中会将错误和分析的信息指定出相关的代码行； 如果是C++最好将内联函数以普通函数对待（gcc -fno-inline），这样更容易看到函数调用链，这有助于减少在大型C ++应用程序中导航时的混淆； 不要使用优化（gcc -O2或gcc-O1等），这会导致Memcheck错误地报告未初始化的值错误或丢失未初始化的值错误； 最好编译时能显示所有警告（gcc -Wall）  错误报告 当错误检查工具检测到程序中发生了错误时，就会向注释中写入一条错误消息。以下是来自Memcheck的一个例子：\n==25832== Invalid read of size 4 ==25832== at 0x8048724: BandMatrix::ReSize(int, int, int) (bogon.cpp:45) ==25832== by 0x80487AF: main (bogon.cpp:66) ==25832== Address 0xBFFFF74C is not stack'd, malloc'd or free'd 这个消息说，程序非法读取了地址0xBFFFF74C的4字节，据Memcheck所知，这不是一个有效的堆栈地址，也不对应于任何当前堆块或最近释放的堆块。发生在bogon.cpp的第45行。从同一文件的第66行调用，等等。对于与已识别的(当前或已释放的)堆块相关的错误，例如读取已释放的内存，Valgrind不仅会报告错误发生的位置，还会报告分配/释放关联堆块的位置。\n命令行选项 最简单的选项：\n--tool=\u0026lt;toolname\u0026gt; [default: memcheck] 运行名为toolname的Valgrind工具，如memcheck, cachegrind, callgrind, helgrind, drd, massif, dhat, lackey, none, expi -bbv等\n基本使用方法 假如你的程序原来是这样执行的：myprog arg1 arg2\n那么使用valgrind可以在前面添加 valgrind \u0026ndash;leak-check=yes 即可使用，例如：\nvalgrind --leak-check=yes myprog arg1 arg2 如果我们想用valgrind的内存检测工具，我们就要用如下方法调用：\n#valgrind --leak-check=full --show-reachable=yes --trace-children= yes ./a.out (2\u0026gt;logfile加上会好些，程序在执行期间stderr会有一些输出。提示比较多) 运行valgrind -h可以查看详细使用方法，命令格式如下：\nvalgrind [valgrind -h中的选项] 待测程序 [待测程序的命令行参数列表] 最重要的选项是–tool决定运行哪种Valgrind工具。\n--tool=\u0026lt;toolname\u0026gt; [default: memcheck]：最常用的选项。运行valgrind中名为toolname的工具。如果省略工具名，默认运行memcheck。 例如，使用内存检查工具Memcheck 运行“ls -l”命令 ，执行命令格式如下：\nvalgrind --tool = memcheck ls -l Memcheck是默认设置，因此如果要使用它，则可以省略该–tool选项，如：\nvalgrind ls -l https://blog.csdn.net/justheretobe/article/details/52986461\n原理 基本架构 Valgrind 的核心花费大部分的时间在制造、寻找、执行 machine code 和 VEX IR 的转换， 而 client program 原本的 machine code 都不会跑到。可以看到 Valgrind 的复杂來自要把 client 和 tool 放在同一個 process， 需要用分享的资源 (例如 registers 和 memory)， 而且 Valgrind 要小心地确保在 system call、signals、threads 参与的狀況下不會對 client 失去掌控。\n正常处理的程序有：\n normal executable code dynamically linked libraries shared libraries dynamically generated code  只有 self-modifying code 會有問題， 而執行過程中只有 system calls 裡面的狀況是 Valgrind 不能掌控的， 但是 system call 的 side-effects 還是可以間接觀察到。\n +--------------------+ +-------------------------+ +--------------+ | libVEX | | IR instrumentation tool | | | | | | | +--------------+ | | | | | | | | | | +--------------+ | | | | | | | | | | x86/Linux +--------------+ | +--------+ | | | AMD64/Linux | machine code | ------------\u0026gt; | VEX IR | --------\u0026gt;| | ARM/Linux +--------------+ | +--------+ | | | x86/MacOSX | | | | | | AMD64/MacOSX +--------------+ | -----------------| | .... | | | | | | | +--------------+ | | | | | | | +---------|----------+ +-------------------------+ +--------------+ | v +--------------+ | machine code | +--------------+ Valgrind Core会反汇编应用程序代码，并将代码片段传递给工具插件以进行检测。工具插件会添加分析代码并将其重新组合。因此，Valgrind提供了在Valgrind框架之上编写我们自己的工具的灵活性。 Valgrind使用影子寄存器和影子存储器来检测读/写指令，读/写系统调用，堆栈和堆分配。\nvalgrind提供了围绕系统调用的包装，并为每个系统调用的前后回调注册，以跟踪作为系统调用一部分访问的内存。因此，Valgrind是Linux操作系统和客户端应用程序之间的OS抽象层。\n该图说明了Valgrind的8个阶段：\n阴影值 Valgrind 把重点放在 shadow values 这概念上， shadow values 是很强大但相关的研究较少、较难实作的 DBA 技术， 在这概念下需要对所有的 register 和 memory 做 shadow (自己维护一份)， 也因为这 feature 让 Valgrind 做出来的 lightweight 工具跑的相对慢，但是 Valgrind 可以做出更多更有趣、更重量级的工具， 这是其他 frameworks 很难做到的 (例如 Pin 或 DynamoRIO)。\nshadow value tools 会维护一份程式的状态， 把原本的程式状态称为 S， 那就会存一份 S’ 里面包含 S 的所有值 (例如 register 和 user-mode address)， 而 shadow values 有九种需求要满足， 九种需求可以依照特性分成四类 (Shadow State、读写操作、Allocation/Deallocation、增加辅助资讯)：\n 阴影值简单来说就是：在软件中或者寄存器中用另外一个映射值来说明一些内容\n 阴影值的各个工具的应用\n memcheck使用阴影值跟踪哪个bit的值是未定义的。 TaintCheck跟踪哪些字节被污染(不受信任的源，或来自受污染的值). McCamant and Ernst’s secret-tracking tool跟踪每一个秘密bit的值，并且确定公共的输出中暴露了多少秘密的信息。 Hobbes跟踪每一个值得类型，因此可以检测后续操作不适合该类型的值。 DynCompB类似地，为程序理解和不变检测目的确定字节值的抽象类型。 Annelid跟踪是数组指针的word，可以检测越界错误。 Redux创建了一个动态数据流图，是程序的整个计算的可视化，从图中可以看到所有有助于每个值创建的先前操作。  可以是：\n 每bit一个shadow bit 每byte一个shadow byte 每word一个shadow word   描述阴影值工具 如何在DBI框架中支持阴影值 DBI框架并不完全相同  为了实现shadow values需要框架实现以下4个部分：\n Shadow State 读写操作 分配和释放操作 透明执行+额外的输出  9个功能\n instrument read/write instructions instrument read/write system calls Allocation and deallocation operations instrument start-up allocations instrument system call (de)allocations instrument stack (de)allocations instrument heap (de)allocations Transparent execution, but with extra output extra output  具体来说就是：\n  Shadow State\n R1：提供阴影寄存器(例如 integer、FP、SIMD)。 R2：提供阴影内存(并且需要在 multithread 下可以安全地存取 shadow memory)。    读写操作\n  R3：插桩读写指令。\n 需要知道每個 instruction 存取了哪些 memory 和 registers 最好能做到跨平台 (跨 ISA)    R4：插桩系统读写调用。\n所有的 system call 都会去存取 register 或 memory，还可能从 register 或 stack 读参数，最后写回 register 或 memory，而且还要注意许多 system call 会存取 user-mode 的 memory (pointer)\n    分配和释放操作\n R5：插桩启动时的分配操作。  在程序开始执行时，所有 register 都會被 “allocated”，因為是 statically allocated memory locations，所以 shadow value tool 必須也這些做好 (create suitable 会hadow values) 对于此时还没 allocated 的也要处理，可能在 allocated 之前发生不当的存取   R6：插桩系统调用的分配和释放。  一些 system call 会 allocate memory (e.g. brk, mmap)，一些会 deallocate memory (e.g. munmap) mremap 會让memory 被 copy，shadow memory 也要 copy 好   R7：插桩栈的分配和释放。  更新 stack pointer 这部份会比较耗时，因为 stack pointer 时常变动，而且有些程式会在多个 stack 之间切换，shadow value tool 会需要把这些 stack allocations 或 deallocations 区分出来，这对于 binary level 来说不容易   R8：插桩堆的分配和释放.  大部分的程式会利用来自 library 的 heap allocator，heap allocator 会把用 system call (brk、mmap) 取得的 large chuncks 中的一块 heap blocks 传回去给 client，每段 heap block 都有 book-keeping data (例如 block size)，这些是 client program 不应该存取的 (读可能还安全，写的话可能会 crash allocator)，所以有 kernel-level addressability 之上盖了一层 library-level addressability 的概念 忽略 large chuncks 的 kernel-level allocations 直到 allocator 把 allocated 的 bytes 转交给 client 之前都不把 memory 当作 active realloc 也要像 mremap 一样被处理      透明执行+额外的输出\n R9：额外的输出。  不影响执行，产生有帮助的 output 另外开个地方來 output，例如沒在用的 stderr 或 file      核心思想就是要把寄存器和内存中的东西自己维护一份，并且在任何情况下都可以安全正确地使用，同时记录程序的所有操作，在不影响程序执行结果前提下，输出有用的信息。使用shadow values技术的DBI框架都使用不同方式实现了上述全部功能或部分功能。\n 阴影状态：一个阴影状态S’包括每一个值对应的阴影值S。\n 阴影值的支持\n  阴影寄存器是一流的实体：\n 在线程状态下为它们提供空间 它们可以像来宿主寄存器一样容易地访问 他们可以用同样的方式操纵和操作    其次，IR提供了不受限制的临时资源，可以在其中操纵来宾寄存器，影子寄存器和中间值。这对于易用性非常重要，因为\n影子操作会引入许多额外的中间值。\n  第三，IR的RISC-ness公开了所有隐式中间值，例如由复杂寻址模式计算的中间值，这可以使测试变得更容易，特别是在像x86这样的CISC体系结构上\n  第四，所有代码一视同仁。 阴影操作充分适合Valgrind的后仪器IR优化器和指令选择器。\n   Valgrind不提供阴影内存的公开支持，例如内置的数据结构，阴影内存从工具到工具的变化足够大。\n 事件系统\nValgrind为每个系统调用提供一个包装器，它根据需要调用这些回调。 每个系统调用都有不同的参数，因此有不同的包装器。\n对于数据的处理 如何知道那些地址是合法的（内存已分配）？\n维护一张合法地址表（Valid-address (A) bits），当前所有可以合法读写（已分配）的地址在其中有对应的表项。该表通过以下措施维护\n全局数据(data, bss section)--在程序启动的时候标记为合法地址 局部变量--监控sp(stack pointer)的变化，动态维护 动态分配的内存--截获 分配/释放 内存的调用 ：malloc, calloc, realloc, valloc, memalign, free, new, new[], delete and delete[] 系统调用--截获mmap映射的地址 其他--可以显示知会memcheck某地字段是合法的 当要读写内存中的某个字节时，首先检查这个字节对应的A bit。如果该A bit显示该位置是无效位置，memcheck则会报告读写错误\n如何知道某内存是否已经被赋值(初始化)？\n维护一张合法值表（Valid-value (V) bits），指示对应的bit是否已经被赋值。因为虚拟CPU可以捕获所有对内存的写指令，所以这张表很容易维护。\n一旦寄存器中的值，被用来产生内存地址，或者该值能够影响程序输出，则memcheck会检查对应的V bits，如果该值尚未初始化，则会报告使用未初始化内存错误。\n图解\n组件 valgrind结构上分为core和tool，不同的tool具有不同的功能。比较特别的是，valgrind tool都包含core的静态链接，虽然有点浪费空间，但可以简化某些事情。当我们在调用valgrind时，实际上启动的只是一个解析命令参数的启动器，由这个启动器启动具体的tool。\n为了实现上述功能，valgrind会利用dynamic binary re-compilation把测试程序（client程序）的机器码解析到VEX中间语言。VEX IR是valgrind开发者专门设计给DBI使用的中间语言，是一种RISC like的语言。目前VEX IR从valgrind分离出去成libVEX了。libVEX采用execution-driven的方式用just-in-time技术动态地把机器码转换为IR，如果发生了某些tool感兴趣的事件，就会hook tool的函数，tool会插入一些分析代码，再把这些代码转换为机器码，存储到code cache中，以便再需要的时候执行。\nMachine Code --\u0026gt; IR --\u0026gt; IR --\u0026gt; Machine Code ^ ^ ^ | | | translate | | | | instrument | | translate valgrind启动后，core、tool和client都在一个进程中，共用一个地址空间。core首先会初始化必要的组件，然后载入client，建立client的stack，完成后会要求tool初始化自己，tool完成剩余部分的初始化，这样tool就具有了控制权，开始转换client程式。从某种意义上说，valgrind执行的都是加工后的client程序的代码。\nDBI framework 有两种基本的方式可以表示code和进行 instrumentation：\n disassemble-and-resynthesise (D\u0026amp;R)。  Valgrind 使用这种把machine code先转成IR，IR会通过加入更IR来instrument。IR最后转回machine code执行，原本的code对 guest state的所有影响都必须明确地转成IR，因为最后执行的是纯粹由IR转成的machine code。   copy-and-annotate (C\u0026amp;A)。instructions会被逐字地复制(除了一些 control flow 改变)  每个instruction都加上注解描述其影响(annotate)，利用这些描述来帮助做instrumentation 通过给每条指令添加一个额外的data structure (DynamoRIO) 通过提供相应的获取指令相关信息的API (Intel Pin) 这些添加的注解可以指导进行相应的instrument，并且不影响原来的native code的执行效果。    基本上 DBI framework 可以分成这两种， 但是混用是可以做到的， 早期的 Valgrind 对 interger instructions 使用 D\u0026amp;R， 而对 floating point insturctions 和 SIMD 使用 C\u0026amp;A (paper 上写说并非设计想往这边走，而是意外)。另外，做一些变化也是可以的，例如 DynamoRIO 允许 instructions 在复制前 in-place 地修改。\n各个设计都有优缺点，而 D\u0026amp;R 的方式需要更多的实作和设计， 而且最后从 IR 生出有效率地 machine code 也需要一些努力， Valgrind JIT 就用了很多编译器的技术。相对地，C\u0026amp;A 的作法就可以比 D\u0026amp;R 少费些心力。\n优点和缺点 优点 1.用valgrind监测内存泄漏，不用重新编译应用程序，不用重新链接应用程序，不用对应用进程做任何修改。如果想查看详细的出错信息，只需要在编译时加上-g选项。\n缺点  通常情况下，使用memcheck工具后应用程序的运行时间会比原生代码慢大约10-50倍。 -内存占用高，因为要维护两张表格，而这两张表的维度正比于程序的内存 -memcheck无法检测global和stack上的内存溢出，因为溢出的地方也在Valid-address (A) bits中。这是由memcheck 的工作原理决定的。 对于一些不停机运行的服务器程序的内存问题，valgrind无能为力。不仅仅是因为valgrind无法使之停止，还有可能是因为服务器进程本身就被设计为申请一些生命周期 与进程生命周期一样长的内存，永远不释放，这些内存会被valgrind报泄漏错误。 valgrind对多线程程序支持得不够好。在多线程程序执行时，valgrind在同一时刻只让其中一个线程执行，它不会充分利用多核的环境。在用valgrind运行您的多线程程序 时，您的宝贵程序的运行情况可能跟不使用valgrind的运行情况千差万别。  参考：\n https://blog.mengy.org/how-valgrind-work/ https://www.valgrind.org/docs/pubs.html https://blog.csdn.net/yinliyinli/article/details/51346431 https://blog.csdn.net/u014652595/article/details/23660347 valgrind如何工作？ http://awhite2008.blog.sohu.com/164824340.html https://wdv4758h-notes.readthedocs.io/zh_TW/latest/valgrind/dynamic-binary-instrumentation.html  ","description":"官方首页上这个骑士与恶龙的绘画由伦敦画家 Rupert Lees 创作。灵感来自于神话传说 St George and the Dragon 。某日，圣乔治到利比亚去，当地沼泽中的一只恶龙（一说鳄鱼）在水泉旁边筑巢，这水泉是Silene城唯一的水源，市民为了取水，每天都要把两头绵羊献祭给恶龙。 到后来，绵羊都吃完了，只好用活人来替代，每天抽签决定何人应选派作牺牲。 有一天，国王的女儿被抽中，国王也没有办法，悲痛欲绝。当少女走近，正要被恶龙吞吃时，圣乔治在这时赶到，提起利矛对抗恶龙，并用腰带把它束缚住，牵到城里当众杀死，救出了公主。","id":35,"section":"posts","tags":["MLK"],"title":"Valgrind","uri":"https://hugo.jiahongw.com/zh/posts/mlk/valgrind/"},{"content":"duma DUMA是一个开源库(在GNU通用公共许可证下)，用于检测C和C++程序中的缓冲区溢出和运行错误，是一个Red-Zone memory allocator。这个库是 Electric Fence库的一个分支，并添加了一些新功能。\n 该库是Buce Perens Electric Fence库的分支，并添加了一些其他功能，例如内存泄漏报告。\n 基本介绍 官网： http://duma.sourceforge.net/\n源码： https://github.com/fortitudepub/duma\n文档： http://duma.sourceforge.net/README.txt\n支持  Linux / Unix MS Windows NT/2K/XP  安装  需要gmake工具\n 1 2 3 4  unzip duma-master.zip cd duma-master gmake gmake install   （不行的话编辑GNUmakefile，在开头添加OS=linux）\n问题\n  Centos8或者高版本C++可能会导致与C++98的抛出异常不一\n解决办法：需要进入GNUmakefile中修改添加参数-std=c++98\n  使用 基本功能  超出动态分配缓冲区的末尾（或开始）。 返回到堆后使用动态分配的缓冲区。 检测内存泄漏。 检测分配/取消分配功能的不匹配：例如，\n使用malloc（）进行分配，但使用运算符delete进行释放。  基本使用方法 使用限制：\n 不能和lmalloc、lmallocdebug等malloc-debugger混用 duma会创建core文件，注意操作系统对core文件的限制 -lduma需要全局安装，否则就要指定路径，也可以环境变量的形式应用于所有动态可执行文件  方法：\n  假如duma已经安装，可以使用-lduma去链接编译或者在命令行添加链接库的位置进行链接。(静态)\n  没有显示安装duma也可以使用动态链接，如下(动态)\n1  (export LD_PRELOAD=/usr/lib/libduma.so; export DYLD_INSERT_LIBRARIES=libduma.dylib; export DYLD_FORCE_FLAT_NAMESPACE=1; exec APP args)   或者\n1  LD_PRELOAD=/usr/lib/libduma.so APP args     如果你的程序有一个被DUMA检测到的错误，它将得到一个错误指令的segmentation fault(SIGSEGV)。使用debugger 找到错误的声明，并修复它。\n下面是使用gdb找到错误位置的具体操作：\n静态(上面第一种方法编译的程序)：\n  使用gdb启动程序，例如：\n1  gdb app     在gdb里面设置环境变量。\n1  set environment DUMA_PROTECT_BELOW 1     在gdb里面设置程序的参数。\n1  set args ..     运行程序等待字段错误。\n1  run     动态(上面第二种方法编译的程序)：\n  设置“ulimit -c unlimited”获取内核文件。\n  运行静态链接的程序或者动态链接的程序。\n  等待字段错误，会在当前文件夹下生成一个内核文件core.pid。可以使用gdb打开：\n1  gdb \u0026lt;program\u0026gt; -c \u0026lt;core file\u0026gt;     环境变量  支持在gdb里面通过命令\u0026rsquo;set environment variable value\u0026rsquo; 设置环境变量\n   DUMA_ALIGNMENT\n这是一个整数，它指定将由malloc()、calloc()和realloc()返回的任何内存分配的对齐大小。因此，值为4将导致内存对齐到32位，除非系统没有8位的char。\n 默认情况下，DUMA_ALIGNMENT设置为特定于环境的最小所需对齐。 最小所需对齐由createconf检测并存储在文件duma_config.h中。\n 因此，分配小于DUMA_ALIGNMENT的块可能会导致更小的对齐-例如，当分配3个字节时，它们将被对齐到2个字节边界。 这可以更好地检测溢出。\n 出于这个原因，您有时希望将DUMA_ALIGNMENT设置为1（没有对齐），这样您就可以检测到超出CPU单词大小的情况\n 如果您只需要对一些特殊缓冲区进行更大的对齐,您不需要更改此设置。 在这种情况下，您可以使用函数\n1  memalign(alignment, userSize).     DUMA_PROTECT_BELOW\nDUMA通常会在每次内存分配后立即放置一个不可访问的页面，这样就会检测到在分配结束后运行的软件。\n 将DUMA_PROTECT_BELOW设置为1将导致DUMA在分配之前将无法访问的页面放置在地址空间中，这样就会检测到运行不足而不是运行过度\n   DUMA_SKIPCOUNT_INIT\n一般使用第一个分配器分配。在某些系统中，这可能会与pthreads或其他libaries的初始化发生冲突并产生挂起。 为了获得DUMA工作，即使在这些情况下，您也可以控制（使用此环境变量）在完成DUMA的全部内部初始化后的分配数量。 默认为0。\n  DUMA_REPORT_ALL_LEAKS\nDUMA通常只报告内存泄漏，其中已知分配指令行号的源文件名。并不报错退出。\n默认值为0，以避免从系统/编译器环境报告无关内存泄漏。\n  DUMA_FILL\n当设置为0到255之间的值时，分配内存的每个字节都被初始化为该值。\n 这可以帮助检测未初始化内存的读取\n 当设置为-1时，DUMA不会在分配时初始化内存。 但是一些内存中充满了零（大多数系统默认的操作系统），一些内存将保留在上次使用期间写入的值。每个默认的DUMA将初始化所有分配的字节到255(=0x FF)。\n  DUMA_SLACKFILL\n当DUMA在整个页面中内部分配内存时，就会保留一个未使用和无法保护的内存块：可用但是还没使用的内存区域。 每个默认的DUMA将初始化这个区域到170(=0x AA)，这是10101010在二进制表示。\n  DUMA_CHECK_FREQ\n将此变量设置为1，以便在每个分配和解除分配时允许DUMA检查无人区。每个默认值都使用0，这意味着只在取消分配时检查\n  DUMA_ALLOW_MALLOC_0\n大小为零的内存分配符合ANSI。 但这往往是软件错误的结果。 因此，DUMA可能会将这样的调用捕获到大小为零的malloc()。 默认情况下，我将禁用此选项，但您可以自由地捕获这些调用，将shell环境中的DUMA_ALLOC_MALLOC_0设置为整数值。\n  DUMA_MALLOC_0_STRATEGY\n此环境变量控制DUMA在malloc（0)上的行为）：\nALLOW_MALLOC_0的值\n0 - abort program with segfault\n1 - 返回空指针\n2 - 返回到某些受保护页面的指针总是相同的\n3 - 返回唯一受保护页的中间地址（=默认）\n 注意：只有1和3是ANSI符合。 但是值1会破坏大多数程序，导致值3策略大多数系统库使用/实现。 所有返回的指针都可以传递给自由()。\n   DUMA_NEW_0_STRATEGY\n此环境变量控制DUMA在大小为零的C操作符上的行为：\n2 - 返回到某些受保护页面的指针总是相同的\n3 - 返回唯一受保护页的中间地址（=默认）\n 注意：只有3是标准符合。 价值2可能会打破一些，但将适用于大多数程序。 值2可以减少内存消耗。\n   等等—\n原理   DUMA使用计算机的虚拟内存硬件，在每次内存分配之后（或之前，选择之前）立即放置一个不可访问的内存页面。读写这个不可访问的也页面会触发段错误，然后使用调试器分析并且解决问题\n  “重载”所有标准内存分配函数及释放函数。\n利用CPU的MMU（内存管理单元）分配并保护一个额外的内存页，以检测超出缓冲区顶部（或底部，由用户选择）之外的任何非法访问。\n  以free()方式释放的内存也被设置为不可访问，任何试图接触它的代码都会得到一个segmentation fault。\n  初始化的内存可以自定义1-255的初始值，默认不设置\n  使用0xAA填充申请页块中未使用但是可以使用的内存\n  内存使用和执行速度 由于DUMA的每个分配至少使用两个虚拟内存页面，这是一个可怕的内存占用。 我有时发现有必要使用swapon（8）添加一个交换文件，这样系统就有足够的虚拟内存来调试我的程序。 此外，我们操作内存的方式导致各种缓存和转换缓冲区条目被刷新，每次调用malloc或免费。 最终的结果是，您的程序将慢得多，并且在使用DUMA调试时使用更多的资源。\n不要用于生产环境！\n优点和缺点 优点  安装方便 预加载库形式，无需修改代码重新编译 支持C++  缺点  性能比较差  执行效率：我们操作内存的方式导致各种缓存和转换缓冲区条目被刷新，每次调用malloc或free。 最终的结果是，您的程序将慢得多 内存开销：每个分配使用至少两个虚拟内存页面    ","description":"DUMA是一个开源库(在GNU通用公共许可证下)，用于检测C和C++程序中的缓冲区溢出和运行错误，是一个Red-Zone memory allocator。","id":36,"section":"posts","tags":["MLK"],"title":"duma","uri":"https://hugo.jiahongw.com/zh/posts/mlk/duma/"},{"content":"Eletric-Fence Electric Fence是另一种malloc（）调试器。它使用系统的虚拟内存硬件来检测软件何时超出了malloc（）缓冲区的边界。它还将检测free（）释放的任何内存访问。因为它使用VM硬件进行检测，所以Electric Fence会在导致边界违反的第一条指令上停止您的程序。\n基本介绍 官网、参考文档：\n1.https://www.bbsmax.com/A/gVdnRMOadW/\n2.https://xsyr.github.io/%E7%BC%96%E7%A8%8B/c/c++/2013/10/13/use-electric-fence-to-detect-heap-overruns-and-underruns.html\n源码： https://github.com/kallisti5/ElectricFence\n支持 支持所有Linux、Unix平台。(Linux kernel version 1.1.83 and above)\n安装  efence库依赖于pthread(多线程)库\n安装依赖于scons工具：yum install scons -y\nSCons是一个基于python的软件构建工具，已经移植到大多数平台上，并且可以在大多数Linux发行库中使用。\n  To compile  scons   To clean  scons -c    使用 基本使用方法 使用步骤：\n  在编译的时候添加参数: -lefence -lpthread\n如果没有安装Efence，则需要指定libefence.a的位置：\ngcc –g –o ef ef.c –lefence –L /usr/lib\n  或者\n  Link the generated static libefence.a archive into your application at build.\n  Preload the generated shared library\nlibefence.so at runtime via the following:\n Linux / Haiku / Solaris / HP-UX  LD_PRELOAD=./path/to/library/libefence.so /bin/myapplication   AIX 5.3+ (32-bit)  LDR_PRELOAD=./path/to/library/libefence.so /bin/myapplication   AIX 5.3+ (64-bit)  LDR_PRELOAD64=./path/to/library/libefence.so /bin/myapplication        编译运行，查看运行产生的core文件，如果没有core文件，说明测试通过\n当发生segmentation fault时就会在当前目录下生产一个core文件，在linux下，我们可以使用GDB来调试core：\nGdb ef core.xxxx\n然后输入where就可以看到程序崩溃时的函数调用堆栈信息了。\n  可以在执行的时候使用gdb调试，例如gdb -q ./test，然后执行run可以看到执行后的结果\n   只需将应用程序与libefence.a连接起来，就可以检测到malloc缓冲区的大部分（但不是全部）溢出和免费内存的访问。\n 可以通过配置以下几个全局变量和环境变量来控制Efence的行为：\n EF_ALIGNMENT：这是Efence malloc分配空间的内存对齐字节数。这个变量的默认值是sizeof(int)，32位字长的CPU对应的该值是4。这个值也是Efence能够检测的内存越界的最小值。 EF_PROTECT_BELOW： 默认情况下Efence是把inaccessible的页面置于分配的空间之后，所以检测到的是高地址方向的越界访问。把这个值设为1可以检测到低地址的越界访问。 EF_PROTECT_FREE： 通常free后的内存块会被放到内存池，等待重新被申请分配。把这个值设为1后，free后的内存块就不会被重新分配出去，而是也被设置为inaccessible，所以Efence能够发现程序再次访问这块已经free的内存。 EF_ALLOW_MALLOC_0： Efence默认会捕捉malloc(0)的情况。把该值设为1后则不会捕捉申请0字节内存的情况。 EF_FILL： 分配内存后Efence会将每一byte初始化成这个值(0-255)。当这个值被设成-1时，内存的值不固定。  调试程序方法  链接efence库并且执行自己的程序。 在debugger上运行程序并且修复溢出或者访问已释放内存的错误。 退出debugger工具。 在shell环境变量中Set EF_PROTECT_BELOW = 1 重复step 2 退出debugger工具。 看是否可以将EF_ALIGNMENT设置为0，重复步骤2。 有时这将是太多的工作，或者在库例程中会有问题，而您没有源，这将阻止您这样做。  原理、功能 字节对齐和溢出检测 在malloc()操作的对齐限制和Electric Fence使用的调试策略之间存在冲突。\nmalloc分配是按照字节对齐的，但是Electric Fence的分配至少是两个虚拟页或者更多，并且最后一页被设置为不可读写，即返回的地址为不可读写的的第一个byte地址减去申请的内存大小。因此，任何分配空间的溢出将导致 segmentation fault。\n如果Electric Fence malloc()要返回对齐地址，则必须将分配的大小增加到word大小的倍数。 此外，函数memalign()和valloc()必须遵守内存分配对齐的显式规范，这也只能通过增加分配的大小来实现。 因此，在某些情况下，内存分配的末尾包含一些填充空间，并且不会检测到该填充空间的访问，即使它们是超支的。(存在漏判？)\nElectric Fence提供了变量EF_ALIGNMENT，以便用户可以控制malloc()、calloc()和realloc()使用的默认对齐方式。\n 若要调试小到单字节的溢出，可以将EF_ALIGNMENT设置为零\n Efence有2个主要的功能：\n 内存越界读写时抛出segmentation fault。当程序用malloc申请内存时，Efence会使用虚拟内存技术将分配的内存空间之后的内存页面设置为inaccessible(不可读写和执行)，所以当程序发生越界读写时，OS会发出SIGSEGV信号，生成core文件(core dump)，进程退出。 当访问已经被释放的内存空间时抛出segmentation fault。当程序把一块空间free之后，Efence同样把这块内存的访问保护级别设置为inaccessible，所以当程序再次访问这块已经释放的内存时也会导致segmentation fault。  性能 内存消耗 由于Electric Fence在每个分配中至少使用两个虚拟内存页面，所以这是一个可怕的内存占用。 我有时发现有必要使用swapon（8）添加一个交换文件，这样系统就有足够的虚拟内存来调试我的程序。\n速度 在对各种缓存和转换缓冲区调用malloc和fredd的操作内存的方式。将导致慢并且用更多的资源。\n优点和缺点 优点  不需要您对程序的源代码进行任何更改。您只需要在编译期间将程序与工具的库链接即可。 调试工具的实现方式可确保在导致边界冲突的第一条指令上产生分段错误，这总是比在以后阶段发现问题要好。  缺点   仅支持Linux，非跨平台\n  每一次分配都是利用一个 semaphore 同步，没有 thread local 的分配\n  malloc 和 free 在 slot 都是线性查找，这也造成了整体性能的落后\n  内存消耗大，特别对于频繁的小内存分配\nreal_size = user_size + (alignment – (user_size % alignment )) + page_size   该工具无法检测到分配给栈的内存溢出\n  不是线程安全的。\n  另一个局限性是它不能明确地指出问题出在程序代码中的什么位置-它所做的只是在检测到与内存相关的错误时就产生分段错误。\n只能配合dbug工具进行分析具体位置。\n  不能检测内存泄漏\n  参考链接：\n https://www.cnblogs.com/jingzhishen/p/6025702.html?utm_source=itdadao\u0026amp;utm_medium=referral https://blog.csdn.net/chessinge/article/details/6743764 https://linux.die.net/man/3/efence http://www.bubuko.com/infodetail-2434473.html https://www.computerworld.com/article/3003957/review-5-memory-debuggers-for-linux-coding.htm  ","description":"Electric Fence是另一种malloc（）调试器。它使用系统的虚拟内存硬件来检测软件何时超出了malloc（）缓冲区的边界。它还将检测free（）释放的任何内存访问。","id":37,"section":"posts","tags":["MLK"],"title":"Eletric-Fence","uri":"https://hugo.jiahongw.com/zh/posts/mlk/eletric-fence/"},{"content":"Dbgmem DBGMEM是用于C和C ++程序的功能丰富的内存调试器。目前仅适用于Linux。\n基本介绍 官网： http://dbgmem.sourceforge.net/\n源码： https://sourceforge.net/p/dbgmem/code/HEAD/tree/\n Github: https://github.com/MoserMichael/cstuff\n 文档： http://dbgmem.sourceforge.net/README.html\n支持 使用Perl编写，只支持Linux。\n安装   解压\n1 2  tar xvfz DBGMEM.tar.gz . cd dbgmem     构建测试集\n1  ./make     也可以构建cpp版本的测试集(尚有问题)\n1  ./make cpp     安装到 /usr/local/dbgmem\n  1  ./make install   使用 基本功能 该工具将覆盖GLIBC内存分配功能，内存和字符串处理功能，以添加其功能。\n基本使用方法  仅内存泄漏检测使用参数：-d simple ；内存检测+内存检查使用参数：-d check 将内存错误附加到该程序的dbg上添加参数：-a gdb 对于内存分配，最多纪录n层栈帧可以使用参数：-s n (例如纪录7层栈帧:-s 7) 将分配和释放的内存初始化使用参数：-b  基础要求：\n 不使用-O选项，或者同时使用-O和-fno-omit-frame-pointer 必须加上-g选项。 不能使用静态链接编译。例如-static-libgcc或-static 链接选项。 停止程序通过信号必须保证信号没有被注册。  基本使用方法：\n日志文件包括下面三个部分：\n 返回信息 内存错误报告 内存泄漏报告  选项 所有工具共有的选项 报告 在程序退出时或应用程序请求时生成包含分配时所有内存块及栈的分配时间跟踪；同时检查所有内存块是否溢出。\n检查 应用程序可以调用服务函数来检查所有内存块是否溢出。或者打印出所有堆内存块；或者，该工具允许您为每个任务安装两个信号处理程序。\n错误处理 每当遇到内存错误时，事件都会被记录到日志文件和标准错误流中；您可以选择下面几种操作进行处理：\n 继续执行 Dump core 将gdb调试器附加到当前正在运行的进程  钩子 该工具hooks以下GLIBC函数，并跟踪由它们返回的动态分配的内存\n malloc calloc realloc memalign posix_memalign valign free strdup strndup getcwd new/new[]/delete/delete[] (for C++ version only) malloc_usable_size returns size of requested block.  填充模式值 (有一个选项-b填充)\n 初始化所有分配的堆内存——用0xDD填充 所有释放的内存——用0xFF填充  这是一个强大的特性，使用已释放的内存或者或者未出世后的内存将导致程序错误，不开启将导致未被发现。 如果已释放/未初始化内存包含一个指针，则取消引用该指针将导致 core dump.。\n信号处理 有一个选项可以安装SIGSEGV/SIGBUS信号处理程序，该处理程序还可以检查所有堆块是否覆盖/越界写。\n并行调试 您可以运行一个选项-a dbg，该选项将程序与调试程序并行调用，以便它专门监视调试过程的内存消耗。\nsimple工具  使用-d simple 选项\n  在最小开销的实时系统中精确定位和跟踪内存泄漏；？？为什么是最小开销，什么原理呢？ 在分配的块之前和分配的块之后，在头中保存额外的内务信息(housekeeping information)，因此堆错误检查并不总是完美的；检查工具更好地支持这些情况 检查双释放和释放未分配的内存。  check工具  使用-d check选项\n   高效地检查堆损坏，精确定位和跟踪活系统中的内存泄漏，跟踪实时系统中的内存泄漏，在匿名共享内存段中，内务信息被保存在堆之外，因此堆检查在这里更好，尽管速度有点慢\n  检查释放未分配的内存。\n  对于一组标准库函数，还检查以下错误\n  受保护的一组函数中的堆越界写\n  Reading past allocated heap memory range\n  栈smash（有限的支持，只有当您粉碎函数返回地址时，检查才触发）被检查的函数集\n检查函数的集合： memcpy、memmove、memset、strncpy、strcat、strncat、strcmp、strncmp\n    原理 术语 一个程序的不同阶段：\n[--- INITIALIZATION ---] [--- ACTIVE STAGE ---] [--- SHUTDOWN ---] [--- EXIT ---] INITIALIZATION 程序初始化。通常在这里读取配置，初始化缓存，并创建和初始化整个进一步阶段使用的对象和资源。\nACTIVE STAGE 这个过程是服务请求，并做一些有用的事情：\n 在此阶段，进程完成一个或多个逻辑处理单元。 每个这样的单元可以是处理来自网络的请求或一系列请求、处理批处理数据作业或处理交互式用户请求。   通常，在处理某些资源和内存的每个逻辑单元期间都会分配然后释放或者直接泄漏。\n SHUTDOWN 进程已经收到一个信号，然后将退出。这个过程正在清理缓存，并且正在释放资源。\n 这是一个常见但可选的阶段\n EXIT 程序退出。\n内存泄漏的原因(Nice)  泄漏是是指一种资源它在进程的实际状态中被分配并且没有释放。\n 下面是几种内存泄漏：\n  简单的内存泄漏：资源被分配然后忘记释放了。\n  坏缓存泄漏：如果对象总是添加到缓存中，并且重用该缓存，则此模式可能导致泄漏。\n  引用计数泄漏：\n参考计数是一种特殊的垃圾收集形式，通常在C/C++程序中实现；存在潜在的问题，如:\n  计数泄漏：只有在释放所有未完成的引用时，才会释放引用计数对象。 当一个对象的至少一个引用仍然存在时，可能会发生泄漏，因为不知何故，我们忘记清除一个突出的对象引用。 如果根对象引用所有其他对象，但忘记清除其引用，则经常会出现这种情况。\n 请注意，这类似于坏缓存泄漏。 请注意，这种情况经常发生在其他编程语言中，如Java。\n   环形引用：对象A引用对象B，B也引用对象A；不管怎样，对象A总是有来自对象B的至少一个引用，所以它永远不会被删除。\n    解决内存泄漏的方法 在不同时间点所作的两份报告：\n在完成SHUTDOWN时期  在进程正常退出之前，此报告总是由DBGMEM生成，除非进程被SIGKILL信号杀死\n 本报告列出了大多数泄漏问题的起源；分配泄漏内存块的堆栈跟踪将给您一个强有力的提示，说明如何修复这些问题。\n 对于与引用计数相关的某些类型的泄漏，您需要更多的信息\n 在SHUTDOWN之前完成ACTIVE STAGE之后 如果您想跟踪引用计数泄漏，此阶段是有用的：\n通常，当这些引用的根对象被删除时，这些泄漏的引用在SHUTDOWN阶段被删除。\n当许多块发生在SHUTDOWN阶段之前的报告中，但在EXIT之前的报告中没有出现时，这可能表示泄漏。\n 这一分析不是由工具完成的，而是由热心的读者完成的，当他比较这两份报告时；热心的读者也掌握了他的程序的工作原理，并将能够总结正在发生的事情。\n 两种方法进入下面两个阶段：\n INITIALIZATION and ACTIVE STAGE ACTIVE STAGE and SHUTDOWN stage  way1：允许dbgmem的命令行选项去设置两个信号处理，每个信号处理程序将执行请求的状态转换\nway2：修改已调试的程序，以便它调用调试库来指示这两个事件；如果您希望从单元测试/系统测试中运行DBGMEM，则这是首选的解决方案。\n组件 该工具由以下组件组成：\n /usr/mdbg/scripts/run脚本：该脚本运行调试程序。 库/usr/local/dbgmem/lib/libdmemc.so和/usr/mdbg/lib/libdmems.so：每个共享库都是内存调试工具中的一个陷入。 库/usr/local/dbgmem libdmems.so实现了在每个分配中添加arena header的简单工具  下一个/先前的块指针 何时分配块的堆栈 块大小 生成标签值类 + 一些分配函数(malloc/new/new[]) 在信息块之后，在用户分配块结束后，一个size of(void*)保护区域是keps，它由哨兵值初始化，以便我们可以检查内存覆盖/覆盖。   库 /usr/local/dbgmem/lib/libdmems.so：实现了更复杂的检查工具 在被调试的进程退出之后，noteate.pl脚本将由运行脚本启动。 脚本/usr/mdbg/scripts/annotate.pl读取原始报告并创建最终报告  优点和缺点 优点  使用简单，直接命令行使用。 可以在运行时进行检测。  缺点  存在误判，一些内存错误判断成内存泄漏。 仅支持Linux  ","description":"DBGMEM是用于C和C ++程序的功能丰富的内存调试器。目前仅适用于Linux。","id":38,"section":"posts","tags":["MLK"],"title":"Dbgmem","uri":"https://hugo.jiahongw.com/zh/posts/mlk/dbgmem/"},{"content":"AddressSanitizer 基本介绍 官网：http://clang.llvm.org/docs/AddressSanitizer.html\n源码：https://github.com/google/sanitizers\n文档：https://github.com/google/sanitizers/wiki/AddressSanitizer\n支持                 OS x86 x86_64 ARM ARM64 MIPS MIPS64 PowerPC PowerPC64   Linux yes yes   yes yes yes yes   OS X yes yes         iOS Simulator yes yes         FreeBSD yes yes         Android yes yes yes yes        安装 llvm==3.4.2，yum -y install clang \u0026amp;\u0026amp; yum -y install gcc gcc-c++  GCC4.8之后直接提供了对这个工具的支持\n 使用 基本要求  llvm\u0026gt;3.1，clang编译 编译时不允许使用-static参数（不支持静态链接） 尽量不加-O2和-O1（实测检测会失效，具体项待验证） Clang与gcc不能混用编译或链接  基本使用方法 选项  用-fsanitize=address选项编译和链接你的程序; 用-fno-omit-frame-pointer编译，以在错误消息中添加更好的堆栈跟踪。 增加-O1以获得更好的性能。 避免使用 -Wl,-z,defs，因为可能会造成链接错误 要获得完美的堆栈跟踪，您可能需要禁用内联(只使用-O1)和尾部调用消除(-fno-optimize-sibling-call)  使用 简单内存检查使用(不包括检查内存泄漏)：\n1  clang -O1 -g -fsanitize=address -fno-omit-frame-pointer {testfile.c} -o {testfile}   单独检查内存泄漏：\n1  clang -O1 -g -fsanitize=leak -fno-omit-frame-pointer {testfile.c} -o {testfile}   检查内存错误和内存泄漏：\n1  clang -fsanitize=address -g {testfile.c} - o {testfile} ; ASAN_OPTIONS=detect_leaks=1 ./testfile   最后执行程序\n1  ./testfile   检查的错误类型 原理 阴影内存 常见方法有两种：一种是直接将实际地址进行缩放+偏移映射到一个shadow地址，从而将整个的应用程序地址空间映射到一个shadow地址空间；一种是增加额外的地址转换表，通过查表完成实际地址到shadow地址的转换。比如Valgrind和Dr.Memory就是将shadow地址分成多个片段，然后通过查找表转换shadow地址。而AddressSanitizer则采用了直接缩放+偏移的方式。\n 典型的直接映射的方法包括TraintTrace和LIFT\n使用多级翻译模式，例如Valgrind和DrMemory。将它们的影子内存分成几部分，并使用表查找来获得影子地址，需要额外的内存加载。\nUmbra结合了灵活的布局和高效性，避免了非均匀查表和动态缩放以及偏移模式\nBoundless将其某些元数据存储在64位指针的高16位中，但会在慢速路径上回退到更传统的影子内存。\nLBC使用存储在应用程序内存中的特殊值执行快速路径检查，并依赖慢速路径上的两级影子内存\n 阴影内存映射\n假设应用程序内存地址为Addr，那么其对应的Shadow地址为(Addr\u0026raquo;3)+Offset。如果虚拟地址空间的最大合法地址为Max-1，那么Offset值的选择需要确保从Offset到Offset+Max/8在启动时不会被占用。对于常见的32位Linux和MacOS系统来说，其虚拟地址空间为0x00000000-0xffffffff，我们令Offset = 0x20000000 (2^29)。对于具有47个地址位的64位系统来说，我们令Offset =0x0000100000000000 (2^44)。\n Sanitizer维护程序的所有地址访问权限，用于判断内存访问是否合法。需要开辟一定的空间存储阴影内存。\n 注意到malloc函数的返回地址都是8字节对齐的, 所以对于heap上的8字节内存空间, 只有9种状态, 分别表示first k (0 \u0026lt;= k \u0026lt;= 8)是否可以访问, 而9种状态只需要1个字节就可以表示, 严格说1字节都用不着, 也就是说只使用1/8的虚拟地址空间的shadow memory就可以描述所有的地址。\n阴影内存的地址的映射计算方法如下：\nShadowAddr = (Addr \u0026gt;\u0026gt; 3) + Offset 图示如下所示：\n  因为shadow memory放在了中间, 所以用户的内存空间分成了上下2个部分 shadow memory本身也使用同样的映射算法, 但是shadow memory会映射到bad区域, 因为这是ASAN添加的内存区域, 程序是不能访问的 bad区域在页表中是禁止访问的   上面简单提过对齐的8字节有9种状态, 在ASAN的实现中采用如下编码:\n 0 - 该8字节均可访问 k (1 \u0026lt;= k \u0026lt;= 7) - 前k个字节可访问 negative - 该8字节均不可访问  负值表示所有8个字节都是不可访问的。同时我们采用不同的负值来标示不同类型的不可访问地址：\nHeap left redzone: fa Heap righ redzone: fb Freed Heap region: fd Stack left redzone: f1 Stack mid redzone: f2 Stack right redzone: f3 Stack partial redzone: f4 Stack after return: f5 Stack use after scope: f8 Global redzone: f9 Global init order: f6 Poisoned by user: f7 组成  AddressSanitizer consists of two parts: an instrumentation module and a run-time library.\n AddressSanitizer 包括两部分：指令模块和运行时库。\n代码插桩模块(instrumentation) 作用：代码插桩模块会对code进行修改以在每次内存访问时检查shadow state，同时负责在栈和全局对象周围创建用于检测overflow和underflow的poisoned redzones。\n基于LLVM编译器指令集。\n 其他工具都不能发现栈溢出的错误。\n 友商比较\n Mudflap使用编译时检测因此能够检查对象的越界访问，但是因为对象之间没有插入红色区域，所以不能检查出所有的栈溢出bug\nCCured编译指令使用静态分析(仅C程序)消除多余的检查；它们的指令与非指令库不兼容。\nLBC使用源到源的转换和基于CCured去消除多余的检查。(仅限C语言和不能处理use-after-free)\nInsure++主要依靠编译时工具，但也使用二进制工具。实施细节尚未公开。\n Mudflap就是采用的编译时代码插入技术，因此它可以检测到栈对象的越界访问。但是，由于它并没有在栈帧上的每个对象之间插入redzone，因此无法发现所有的栈缓冲区溢出bug，同时对于复杂C++代码还存在误报的问题。AddressSanitizer采用了compile-time instrumentation，因此可以发现栈及global对象的相关越界访问。\n 有了shadow memory之后, 还需要在访问内存的时候进行检查, 如果是已经编译好的二进制问题, 它是不知道shadow memory的, 所以这就需要在编译的时候插入相应的指令, 也就是说必须带上ASAN编译才能使用到这个功能.\n ASAN的检查比较简单(意味着高效), 对于8字节内存访问只需要额外的一次内存访问:\n访问8字节内存：\n1 2 3 4 5 6 7  byte *shadow_address = MemToShadow(address); byte shadow_value = *shadow_address; if (shadow_value) { if (SlowPathCheck(shadow_value, address, kAccessSize)) { ReportError(address, kAccessSize, kIsWrite); } }   访问非8字节内存(1-, 2-, 4-byte的内存访问)：\n1 2 3 4 5 6  // Check the cases where we access first k bytes of the qword // and these k bytes are unpoisoned. bool SlowPathCheck(shadow_value, address, kAccessSize) { last_accessed_byte = (address \u0026amp; 7) + kAccessSize - 1; return (last_accessed_byte \u0026gt;= shadow_value); }   这两种情况都是为原始代码中的每一次内存访问(读\u0026amp;写)增加了一次内存读。\n 这里需要注意的是, 对于unaligned access(不对齐的内存访问), ASAN有可能检查不出来.\n 错误报告代码(ReportAndCrash(Addr))最多只会被执行一次{!AddressSanitizer的机制是一旦检测到一个错误，就直接报告错误退出，这样做的理由是实现简单，也减少了记录所有错误的开销}，但是会被插入到代码的很多地方，因此需要确保它的紧凑性。\n如何检测栈区和全局对象？\n 对于globals，在编译时创建redzones，在应用程序启动时将redzones的地址传递给运行时库。运行时库设置红区不可访问并且记录地址以进行进一步的错误报告。 对于栈对象，红区被创建和设置为不可访问在运行时。  例如给一个程序：\n1 2 3 4  void foo() { char a[10]; \u0026lt;function body\u0026gt; }   将被转换为：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  void foo() { char rz1[32] char arr[10]; char rz2[32-10+32]; unsigned *shadow = (unsigned*)(((long)rz1\u0026gt;\u0026gt;8)+Offset); // poison the redzones around arr.  shadow[0] = 0xffffffff; // rz1  shadow[1] = 0xffff0200; // arr and rz2  shadow[2] = 0xffffffff; // rz2  \u0026lt;function body\u0026gt; // un-poison all.  shadow[0] = shadow[1] = shadow[2] = 0; }   运行时库(Run-time Libaray) 作用：替换malloc、free等相关的函数，并且在堆区周围创建用于检测的poisoned redzones，延迟已被free的堆空间的重用(正常情况下为提高内存使用率，已经被free的内存是可以被重用的，但是对于AddressSanitizer来说，因为要检查use-after-free错误，因此被free的空间会被放到一个队列中，这些来确保已被free的内存如果还会被使用的话能够被发现，当然该队列还是有一定的大小限制，按照FIFO的原则进行退出)，同时还会负责报告错误。\n主要工作包括:\n 在程序启动的时候, 申请shadow memory的空间. 注意这里是虚拟地址空间, 并不是实际的物理内存, 设置bad区域为不可访问 malloc/free的重新实现  其实通过shadow memory和instrumentation了, 我们已经可以检查出那些内存是可以访问的, 那么重新实现malloc/free的目的是什么?\n 首先, 合法访问不代表是正确的访问, 比如2次malloc返回连续的地址, 那么out-of-bounds就可能访问到另外一个合法的内存. 如果2次malloc的内存中间加上redzone, 那么就可以尽量抓住这种情况. redzone本身是不会被程序写坏的, 因为在写之前就已经发现这是一次非法访问了 redzone可以用来记录一些额外的信息, 比如malloc的调用栈 (free的调用栈直接记录在内存区域)  另外, 如果free的内存重新被别人malloc了, 那么use-after-free, double free可能不能及时检查出来, 所以在free的时候尽量避免该内存重新被malloc出来.\n 从整体上看，AddressSanitizer采用的方法类似于基于Valgrind的工具AddrCheck：采用Shadow Memory来记录应用程序的每一字节是否可以安全地访问，同时采用代码插桩技术来针对应用的每次load和store对Shadow Memory进行检查。但是AddressSanitizer采用了一种更高效的Shadow映射方式，一种更紧致的Shadow编码技术，除了可以对堆进行检查外还可以检查栈和global对象，另外它要比AddrCheck快一个数量级。\n 精度与资源使用tunning 如下三个因素会影响AddressSanitizer的精度及资源使用，这三个值都是由环境变量控制，可以在程序启动时设置：\n1)Depth of stack unwinding (default: 30)。对于每个malloc和free调用，该工具都会对调用栈进行unwind以为错误报告提供更多信息。该选项会影响工具的执行速度，尤其是对于那些属于malloc调用密集型的调用来说。它不会影响内存占用及查找bug的能力，但是调用栈太短的话不利于定位问题。\n2)Quarantine size (default: 256MB)。即保存到前面提到的FIFO队列中的已free的内存空间大小之和，这个值会影响发现use-after-free类型bug的能力。但是它不影响性能。\n3)Size of the heap redzone (default: 128 bytes)。该选项会影响发现堆异常类型bug的能力。该值越大，会导致性能变低并且占用更多内存，尤其是对那些进行了很多小块内存分配的程序来说。由于redzone会被用来保存malloc的调用栈，因此减少这个值，会导致最大unwinding深度变小。\n优点和缺点 可以从多个方面看：\n 运行速度 内存消耗 支持的内存错误类型 发现错误的可能性(会不会误报) 支持的平台 其他的特性  优点   支持跨平台。\n  支持的错误报告类型多达21种。\n  平均速度为越来的73%,内存消耗大约3.4倍。速度和消耗都不错。\n  支持C与C++。\n  线程安全。\n因为它只会在应用程序内存数据不可访问时(在malloc和free内部，在栈帧被创建和销毁时，在模块初始化时)才会对它进行修改\n  缺点   漏报\n  那些产生局部越界的未对齐的内存访问。\n1 2 3  int *a = new int[2]; // 8-aligned int *u = (int*)((char*)a + 6); *u = 1; // Access to range [6-9]   根据前述的shadow计算方法，u这个地址会被左移3位，实际上得到的ShadowAddr与a没啥区别，这样k = *ShadowAddr;直接就是0，而不会报错。目前AddressSanitizer没有解决这个问题，因为目前能够想到的解决方案都会造成性能损失。\n  跳过redzone的越界访问。\n1 2 3  char *a = new char[100]; char *b = new char[1000]; a[500] = 0; // may end up somewhere in b   陷入到redzone的越界访问，100%会被检测到，但是如上的越界访问，可能刚好已经落到b分配的合法空间内了。如果内存充足，推荐采用128字节的redzone。\n  如果在free和下次use之间，又发生了大量内存的分配和释放，use-after-free错误可能无法被检测到。\n1 2 3 4 5 6  char *a = new char[1 \u0026lt;\u0026lt; 20]; // 1MB delete [] a; // \u0026lt;\u0026lt;\u0026lt; \u0026#34;free\u0026#34; char *b = new char[1 \u0026lt;\u0026lt; 28]; // 256MB delete [] b; // drains the quarantine queue. char *c = new char[1 \u0026lt;\u0026lt; 20]; // 1MB a[0] = 0; // \u0026#34;use\u0026#34;. May land in ’c’       非期望的bug报告\n  与编译器的Load Widening发生冲突。\n1 2 3 4  struct X { char a, b, c; }; void foo() { X x; ... ... = x.a + x.c; }   在该代码中，对象x是3字节大小，4字节对齐的。Load Widening会将x.a+x.c转换成一个4字节的load。按照之前的栈代码插入方式，第4个字节应该是被染毒的，这样在load这4个字节时，就会报错。通过在LLVM中临时关闭load widening解决。\n  与Clone冲突。\n首先进程，采用CLONE VM|CLONE FILES调用了clone，该操作会创建一个与父进程共享内存的子进程。特别是，子进程的栈使用的内存也是属于父进程的。然后子进程调用了一个包含栈上对象的函数，此时AddressSanitizer会将栈对象的redzone区域染毒。最后，子进程调用了一个不会return的函数(比如_exit或exec)，这样该函数对redzone进行消毒(un-poisoning)的那部分代码就不会被执行。这样父进程地址空间仍处于染毒状态，当该内存被再次使用时就会报错。我们通过找到所有的never-return函数(像_exit或exec这样具有该属性的那些函数)，然后在调用它们之前将整个栈内存消毒。与之类似，AddressSanitizer还必须要对longjmp和C++异常进行拦截。\n    不能执行过程添加，需要编译时期进行指定\n  更多工具   ThreadSanitizer\nThreadSanitizer是一个用于C/C++和Go的快速数据竞争检测器。\n  MemorySanitizer\n一个快速的基于llvm的工具，用于检测未初始化内存的使用情况。\n  参考链接：\n .AddressSanitizer使用介绍 https://github.com/google/sanitizers/wiki/AddressSanitizerLeakSanitizer#suppressions 论文《AddressSanitizer: A Fast Address Sanity Checker》 https://zhuanlan.zhihu.com/p/95977383 https://zhuanlan.zhihu.com/p/338158556  ","description":"A Fast Address Sanity Checker","id":39,"section":"posts","tags":["MLK"],"title":"AddressSanitizer Tool","uri":"https://hugo.jiahongw.com/zh/posts/mlk/addresssanitizer/"},{"content":"Find and Note 代码规范 pylint https://www.jianshu.com/p/c0bd637f706d\nhttps://pylint.readthedocs.io/en/latest/tutorial.html\nflake8 https://www.jianshu.com/p/adf743fc8e78\n日志的等级 日志级别 | 描述 \u0026mdash;|\u0026mdash; OFF | 关闭：最高级别，不打印日志。 FATAL | 致命：指明非常严重的可能会导致应用终止执行错误事件。 ERROR | 错误：指明错误事件，但应用可能还能继续运行。 WARN | 警告：指明可能潜在的危险状况。 INFO | 信息：指明描述信息，从粗粒度上描述了应用运行过程。 DEBUG | 调试：指明细致的事件信息，对调试应用最有用。 TRACE | 跟踪：指明程序运行轨迹，比DEBUG级别的粒度更细。 ALL | 所有：所有日志级别，包括定制级别。\n所以，日志优先级别标准顺序为：\n ALL \u0026lt; TRACE \u0026lt; DEBUG \u0026lt; INFO \u0026lt; WARN \u0026lt; ERROR \u0026lt; FATAL \u0026lt; OFF\n 云计算相关社区 https://www.linux-kvm.org/page/Main_Page\nhttps://www.qemu.org/\nhttps://wiki.qemu.org/Features/\nvi vim 查找和替换字符串 命令 https://blog.csdn.net/doubleface999/article/details/55798741\n如何替换文件中的字符串？\nsed是一种流编辑器，它是文本处理中非常中的工具，能够完美的配合正则表达式使用，功能不同凡响。处理时，把当前处理的行存储在临时缓冲区中，称为“模式空间”（pattern space），接着用sed命令处理缓冲区中的内容，处理完成后，把缓冲区的内容送往屏幕。接着处理下一行，这样不断重复，直到文件末尾。文件内容并没有 改变，除非你使用重定向存储输出。Sed主要用来自动编辑一个或多个文件；简化对文件的反复操作；编写转换程序等。\n：%s/vivian/sky/（等同于：g/vivian/s//sky/）替换每一行的第一个 vivian 为 sky\n：%s/vivian/sky/g（等同于：g/vivian/s//sky/g）替换每一行中所有 vivian 为 sky\nLinux文件系统类型差别 在Linux中，ext2文件系统将磁盘划分成若干个block groups，每个block group包含一个inode bitmap, data bitmap, inodes和若干个data blocks，它没有使用日志。\n而在ext3文件系统中，加入了对日志的支持，日志部分单独占据一块磁盘空间。\n什么是linux系统磁盘只读问题？ 只读的原因在系统日志/var/log/messages里有，一般是因为检测到文件系统有错误\n磁盘只读一般的常见原因：\n  磁盘空间满：可以通过df -h命令查看磁盘的使用情况，然后删除多余的文件释放磁盘空间；\n  磁盘inode资源占用完：可以通过df -i命令查看，确认相关的进程；\n  硬件故障：\n  什么是内存ECC？ https://www.crucial.cn/learn-with-crucial/memory/what-is-ecc-memory\n对于大多数企业来说，消除数据损坏是一项关键任务——这正是 ECC（纠错码）内存的目的。ECC 是一种指令纠错技术，能够检测并纠正常见的各种内存数据损坏情况，即Error Checking and Correcting。\nlinux /dev目录 https://www.cnblogs.com/hongzg1982/articles/2168450.html\ndev 是设备(device)的英文缩写。这个目录对所有的用户都十分重要。因为在这个目录中包含了所有Linux系统中使用的外部设备。\n/sbin目录？ https://blog.csdn.net/kkdelta/article/details/7708250\n /bin是系统的一些指令。bin为binary的简写主要放置一些系统的必备执行档例如:cat、cp、chmod df、dmesg、gzip、kill、ls、mkdir、more、mount、rm、su、tar等。 /sbin一般是指超级用户指令**。**主要放置一些系统管理的必备程式例如:cfdisk、dhcpcd、dump、e2fsck、fdisk、halt、ifconfig、ifup、 ifdown、init、insmod、lilo、lsmod、mke2fs、modprobe、quotacheck、reboot、rmmod、 runlevel、shutdown等。 /usr/bin　是你在后期安装的一些软件的运行脚本。主要放置一些应用软体工具的必备执行档例如c++、g++、gcc、chdrv、diff、dig、du、eject、elm、free、gnome*、 gzip、htpasswd、kfm、ktop、last、less、locale、m4、make、man、mcopy、ncftp、 newaliases、nslookup passwd、quota、smb*、wget等。 /usr/sbin 放置一些用户安装的系统管理的必备程式例如:dhcpd、httpd、imap、in.*d、inetd、lpd、named、netconfig、nmbd、samba、sendmail、squid、swap、tcpd、tcpdump等。  虚拟化 https://zhuanlan.zhihu.com/p/69629212\n完全虚拟化和类虚拟化\nhttps://www.redhat.com/zh/topics/virtualization\n虚拟机监控程序(Hypervisor)可能位于操作系统的顶层（例如在便携式计算机上），或者直接安装在硬件上（例如服务器），这是大多数企业使用虚拟化的方式。虚拟机监控程序接管物理资源，并对它们进行划分，以便虚拟环境能够对其进行使用\nmakefile教程 makefile关系到了整个工程的编译规则。一个工程中的源文件不计数，其按类型、功能、模块分别放在若干个目录中，makefile定义了一系列的规则来指定，哪些文件需要先编译，哪些文件需要后编译，哪些文件需要重新编译，甚至于进行更复杂的功能操作，因为makefile就像一个Shell脚本一样，其中也可以执行操作系统的命令。makefile带来的好处就是——“自动化编译”，一旦写好，只需要一个make命令，整个工程完全自动编译，极大的提高了软件开发的效率。make是一个命令工具，是一个解释makefile中指令的命令工具，一般来说，大多数的IDE都有这个命令，比如：Delphi的make，Visual C++的nmake，Linux下GNU的make。可见，makefile都成为了一种在工程方面的编译方法。\nhttps://blog.csdn.net/weixin_38391755/article/details/80380786\nGCC 参数详解 https://www.runoob.com/w3cnote/gcc-parameter-detail.html\nC风格指南 https://zh-google-styleguide.readthedocs.io/en/latest/google-cpp-styleguide/comments/#id2\n多服务器管理工具——ClusterShell https://www.cnblogs.com/kevingrace/p/6099205.html\nVim使用大全 linux 命令行 光标移动技巧 https://blog.csdn.net/leo_618/article/details/53003111\nCtrl+a跳到本行的行首，\nCtrl+e则跳到页尾。\nCtrl+u删除当前光标前面的文字\nctrl+k-删除当前光标后面的文字\nCtrl+w和Alt+d-对于当前的单词进行删除操作，w删除光标前面的单词的字符，d则删除后面的字符\nAlt+Backsapce-删除当前光标后面的单词，\n如果删除错误，使用Ctrl+y进行恢复Ctrl+L进行清屏操作\nctrl+a:光标移到行首。\nctrl+b:光标左移一个字母\nctrl+c:杀死当前进程。\nctrl+d:退出当前 Shell。\nctrl+e:光标移到行尾。\nctrl+h:删除光标前一个字符，同 backspace 键相同。\nctrl+k:清除光标后至行尾的内容。\nctrl+l:清屏，相当于clear。\nctrl+r:搜索之前打过的命令。会有一个提示，根据你输入的关键字进行搜索bash的history\nctrl+u: 清除光标前至行首间的所有内容。\nctrl+w: 移除光标前的一个单词\nctrl+t: 交换光标位置前的两个字符\nctrl+y: 粘贴或者恢复上次的删除\nctrl+d: 删除光标所在字母;注意和backspace以及ctrl+h的区别，这2个是删除光标前的字符\nctrl+f: 光标右移\nctrl+z : 把当前进程转到后台运行，使用’ fg ‘命令恢复。比如top -d1 然后ctrl+z ，到后台，然后fg,重新恢复\nesc组合\nesc+d: 删除光标后的一个词\nesc+f: 往右跳一个词\nesc+b: 往左跳一个词\nesc+t: 交换光标位置前的两个单词。\n区别gcc中的-w -W和-Wall选项 https://blog.csdn.net/cjtstrive/article/details/85375477\n-w的意思是关闭编译时的警告，也就是编译后不显示任何warning，因为有时在编译之后编译器会显示一些例如数据转换之类的警告，这些警告是我们平时可以忽略的。\n-Wall选项意思是编译后显示所有警告。\n-W选项类似-Wall，会显示警告，但是只显示编译器认为会出现错误的警告。\n在编译一些项目的时候可以-W和-Wall选项一起使用。\n中文技术文档的写作规范 https://github.com/ruanyf/document-style-guide\n为什么选择“〜”代表主目录？ https://qastack.cn/unix/34196/why-was-chosen-to-represent-the-home-directory\n将github中的issue导出(其实是调用Github的API文档) https://www.jianshu.com/p/5180f364be18\nhttps://github.com/verygood-ops/export-pull-requests\nepr -x issues -m 7 redisread/HUGO_blog -t 0cbb300dffa5d19e30e4fffee6f23cc504252904 -p github \u0026gt; issue.csv epr redisread/HUGO_blo \u0026gt; pr.csv Bpazy blog issue https://github.com/Bpazy/blog/issues\nShell常用命令 https://www.cnblogs.com/mainz/articles/1027168.html\n将github中的issue导出(其实是调用Github的API文档) https://www.jianshu.com/p/5180f364be18\nhttps://github.com/verygood-ops/export-pull-requests\nepr -x issues -m 7 redisread/HUGO_blog -t 0cbb300dffa5d19e30e4fffee6f23cc504252904 -p github \u0026gt; issue.csv epr redisread/HUGO_blo \u0026gt; pr.csv awk命令 awk命令用法\n","description":"零零散散，最近都不怎么记录了。又开始回到之前的懒惰状态了。这里记录了近期一些零散的学习以及过程。","id":40,"section":"posts","tags":["life"],"title":"这段时间的一些记录","uri":"https://hugo.jiahongw.com/zh/posts/undefined/find-and-note/"},{"content":"什么是汉明码？ 看下面这张图，蓝色的表示需要发送的数据，我们就假设发送的数据为0101吧，外面橙色的码就是汉明码，汉明码是一种纠错码，但是只能纠正一个错误的比特。汉明码是添加到到发送数据后面的冗余码。每一个汉明码与同一个圆中的所有数据进行异或都是0.\n汉明码怎么进行纠错的？   假设原来的数据中一个比特错误了，如下面红色的字，原来的1变成了0\n此时对于每一个园，它们进行异或的值都不是0，说明错误的地方是三个圆公共的部分，这个时候我们就可以知道错误的是中间的位置：\n  假如是汉明码中的一个比特错误了，如下面红色的字，原来的0变成了1\n此时只有右上角那个圆的所有比特异或不为0，而右上角的圆与其他圆没有关系的部分就是它的汉明码部分，所以可以推断是右上角的圆的汉明码错误了\n  汉明码放置的位置在哪里呢？ 首先需要计算汉明码的校验位数。\n汉明码的校验位数 设数据有$n$位，校验码有$x$位。则校验码一共有$2^x$种取值方式。其中需要一种取值方式表示数据正确，剩下$2^x - 1$种取值方式表示有一位数据出错。因为编码后的二进制串有$n+x$位，因此x应该满足：$2^x -1 \u0026gt;= n + x$　使不等式成立的x的最小值就是校验码的位数。\n假设以1010110为例进行海明码编码。\n使不等式成立的x的最小值就是校验码的位数。在本例中，n=7，解得x=4。\n信息码和校验码的对应关系如下表：\n   信息码位数 1 2~4 5~11 12~26 27~57 58~120     校验码位数 2 3 4 5 6 7    规定在采用汉明码的一串数据中，2的i次方的位置上，我们放校验码。\n更加详细的校验码位置可看下面绿色的比特，下图为分组及校验码位置图：\n汉明码如何分组，为什么？ 按位置分组\n 凡是位置符合这种形式的，XXX1，归到P1； 凡是位置符合这种形式的，XX1X，归到P2； 凡是位置符合这种形式的，X1XX，归到P3； 凡是位置符合这种形式的，1XXX，归到P4；  ……..\n 其中的规律就是使用每个比特判断数据序列的子集，然后逐步缩小范围，从时间复杂度$O(n)$降到$O(log(n))$\n 计算校验码？ 每一行都是从对应的校验位开始校验，即从第$2^n / 2$位开始校验，校验$2^n / 2$个，然后跳过$2^n / 2$个。\n下面计算本例子(以1010110为例进行海明码编码)，将表格中的位置用二进制表示：\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 x1 x2 1 x3 0 1 0 x4 1 1 0    计算x1:\nx1是第一个校验码，位置对应栏所有最后一位为1（xxx1格式）的相异或为0，即:\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 x1 x2 1 x3 0 1 0 x4 1 1 0    $$\nx1 \\oplus 1 \\oplus 0 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x1 = 0。\n计算x2:\nx2是第二个校验码，位置对应栏所有倒数第二位为1（xx1x格式）的相异或为0，即\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 x1 x2 1 x3 0 1 0 x4 1 1 0    $$\nx2 \\oplus 1 \\oplus 1 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x2 = 1。\n计算x3:\nx3是第三个校验码，位置对应栏所有倒数第三位为1（x1xx格式）的相异或为0，即\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 x1 x2 1 x3 0 1 0 x4 1 1 0    $$\nx3 \\oplus 0 \\oplus 1 \\oplus 0 = 0\n$$\n则x3 = 1。\n计算x4:\nx4是第四个校验码，位置对应栏所有倒数第四位为1（1xxx格式）的相异或为0，即\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 x1 x2 1 x3 0 1 0 x4 1 1 0    $$\nx4 \\oplus 1 \\oplus 1 \\oplus 0 = 0\n$$\n则x4 = 0。\n所以最终的汉明码为: 01100100110,即\n   位置 0001 0010 0011 0100 0101 0110 0111 1000 1001 1010 1011     内容 0 1 1 1 0 1 0 0 1 1 0    如何进行校验？   假设位置为1011的数据传输错误，由0变成了1，则校验纠错的过程为：\n将所有位置形如xxx1, xx1x, x1xx, 1xxx的数据分别异或。\nxxx1: 0^1^0^0^1^1 = 1\nxx1x: 1^1^1^0^1^1 = 1\nx1x: 1^0^1^0 = 0\n1xxx: 0^1^1^1 = 1\n那么出错数据的位置为1011，这样便可得到出错的位置。\n  假设同时有两个位置出错，本例中假设位置为1010对应数据由1变成0,，位置为1011对应数据由0变成1，则推出校验纠错过程：\nxxx1: 0^1^0^0^1^1 = 1\nxx1x: 1^1^1^0^0^1 = 0\nx1x: 1^0^1^0 = 0\n1xxx: 0^1^0^1 = 0\n那么校算出的错误位是0001，即第一位；但实际上是倒数第二位和最后一位都有错误，说明海明码不能校验两位以上出错的数据，即海明码只能检测并纠正一位错误。\n  more 如果一条信息中包含更多用于纠错的位，且通过妥善安排这些纠错位使得不同的出错位产生不同的错误结果，那么我们就可以找出出错位了。在一个7位的信息中，单个位出错有7种可能，因此3个错误控制位就足以确定是否出错及哪一位出错了。\n汉明研究了包括五取二码在内的编码方案，并归纳了他们的想法。\nReference：\n 汉明码（海明码、hamming code）通俗易懂的解释 海明码之编码原理和校验方法 三蓝一褐 汉明码 维基百科 https://zh.wikipedia.org/wiki/%E6%B1%89%E6%98%8E%E7%A0%81  ","description":"在一个7位的信息中，单个位出错有7种可能，因此3个错误控制位就足以确定是否出错及哪一位出错了。","id":41,"section":"posts","tags":["汉明码"],"title":"汉明码","uri":"https://hugo.jiahongw.com/zh/posts/network/hamming-code/"},{"content":"求职原理三要素 1. 价值 绝⼤部分公司购买⼈才都是为了使⽤，所以他们看中的是其使⽤价值！这个使⽤价值说得更直⽩⼀点，就是⼈才如何直接或者间接的为公司挣钱。\n2. 供需 一个段子：\n 读⼩学时，⼤学不要钱；读⼤学时，⼩学不要钱；还没⼯作时，⼯作是分配的；可以⼯作时，得⾃谋职业；没挣钱时，房⼦是分配的；能挣钱时，发现⼀辈⼦的薪⽔也买不起房⼦。\n 简单的说，当企业的职位空缺远少于找⼯作的⼈数时，⼈才的价格就会下降；⽽当企业的职位空缺⽐找⼯作的⼈数更多时，⼈才的价格就会上升。\n举个例⼦，同样是管服务器，普通运维⼯程师和云计算运维⼯程师的薪资差异是⾮常⼤的。⼀个普通运维要变成云计算运维，需要补充的知识并不是特别多。所以你只要合理安排好⾃⼰的职业规划，⽐如以相对较低的薪资到类似新浪云这样的地⽅⼯作⼀到两年，你的能⼒和交换价值都会⼤幅度提升。\n3. 信息透明度 当⼈才市场很⼩的时候，信息是很透明的。因为很容易了解到各⾃的情况。\n但当信息量变⼤后，你就会发现虽然整个市场很⼤，但只有你接触到的才对你有意义。\n ⽐如北京现在有100家公司都在招聘PHP，但你只知道其中3家，这个时候，其他97家公\n司的存在对你⽽⾔是没有意义的，即使这3家给你的薪资⽐其他公司低，你也只能被迫接\n受。这就是信息透明度对我们求职的影响。\n 所以要想拿到⾜够好的薪资和获得⾜够多的机会，我们要学会和信息不对称进⾏抗争。⼀\n定要在短时间内获取到⼤量的机会，这样才能「 做选择题 」⽽不是「 做判断题 」。\n程序员职业路线图 构建个人品牌 对于技术⼈员，下边这个列表我是建议你要有的：\n Github账号，不解释。 技术博客，可以直接放到Github上，Big更⾼。 微博，最好能加V，⽤于业内交流。 技术社区账号，⽐如stackoverflow。  本文取自《程序员跳槽攻略》\n","description":"永远不要因为「现在很差」而跳槽，要因为「未来更好」而跳槽。只有这样才能保证你一直往上走。","id":42,"section":"posts","tags":["跳槽"],"title":"程序员职业路线","uri":"https://hugo.jiahongw.com/zh/posts/ideas/programer-go-go/"},{"content":"从两个层面上来说：一个是数据的访问频次层面，一个是数据分析层面。\n访问频次层面 热数据：是需要被计算节点频繁访问的在线类数据。\n冷数据：是对于离线类不经常访问的数据，比如企业备份数据、业务与操作日志数据、话单与统计数据。\n数据分析层面 独有的数据技术引擎：冷数据、温数据和热数据。\n 冷数据——性别、兴趣、常住地、职业、年龄等数据画像，表征“这是什么样的人”； 温数据——近期活跃应用、近期去过的地方等具有一定时效性的行为数据，表征“最近对什么感兴趣”； 热数据——当前地点、打开的应用等场景化明显的、稍纵即逝的营销机会，表征“正在哪里干什么”。  Reference：\n 冷数据、温数据、热数据，难道数据也是有温度的？  ","description":"温度还有数据了？我就奇怪了。","id":43,"section":"posts","tags":["冷数据","热数据"],"title":"冷数据与热数据","uri":"https://hugo.jiahongw.com/zh/posts/cloudcomputing/data-hot-ice/"},{"content":"最近在知乎专栏《高效学习法》中看到一篇比较有用的文章，主要就是讲高效人士的六个好习惯。我觉得这些习惯倒是可以好好学习，因为其实有很多时候我们不能够判断自己当前最应该做什么事情。假如我们这个时候有了一个好的习惯作为准则，一般来说我们都会做出一个比较正确的选择。至少，我们会变得更优秀！\n下面是麦肯锡思维高效工作的六个习惯：\n  做正确的事和正确的做事。 这个习惯一方面强调选择比努力更重要，另一方面又强调了选对方法解决问题很重要。\n  提高效率的起点——管理时间 对事情的重要程度和紧急程度进行排序\n  找到关键的驱动点，才能更好的解决问题。   使用逻辑树分析法解决有难度的问题 将复杂的问题分解为小而简单的问题，先从小事做起，找到成就感。\n  如何把工作简单化？  找到重点 提高技术水平 授权或外包 取消    提高效率的绝招——穿透力 集中全部力量在你要做的重要事情上。\n 摆脱事物 抗干扰 明确目标    ","description":"一个好的习惯能够让你做事情更加的轻松，也能够展示你这个人的风格；好的习惯是后天养成的，不是一蹴而就的。","id":44,"section":"posts","tags":["习惯"],"title":"高效人士的几个习惯","uri":"https://hugo.jiahongw.com/zh/posts/ideas/seven-habits/"},{"content":"如何让网络数据传输地更快？(合并一些层)\n为什么需要QUIC？   中间设备的僵化\n可能是 TCP 协议使用得太久，也非常可靠。所以我们很多中间设备，包括防火墙、NAT 网关，整流器等出现了一些约定俗成的动作。\n  依赖于操作系统的实现导致协议僵化\nTCP 是由操作系统在内核西方栈层面实现的，应用程序只能使用，不能直接修改。虽然应用程序的更新迭代非常快速和简单。但是 TCP 的迭代却非常缓慢，原因就是操作系统升级很麻烦。\n  建立连接的握手延迟大\n不管是 HTTP1.0/1.1 还是 HTTPS，HTTP2，都使用了 TCP 进行传输。HTTPS 和 HTTP2 还需要使用 TLS 协议来进行安全传输。这就出现了两个握手延迟：\n  TCP 三次握手导致的 TCP 连接建立的延迟。\n  TLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟。\n  对于很多短连接场景，这样的握手延迟影响很大，且无法消除。\n  队头阻塞\n队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。\n另外 TLS 协议层面也有一个队头阻塞，因为 TLS 协议都是按照 record 来处理数据的，如果一个 record 中丢失了数据，也会导致整个 record 无法正确处理。\n  QUIC 协议选择了 UDP，因为 UDP 本身没有连接的概念，不需要三次握手，优化了连接建立的握手延迟，同时在应用程序层面实现了 TCP 的可靠性，TLS 的安全性和 HTTP2 的并发性，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制。\nQUIC概述 QUIC 是 Quick UDP Internet Connections 的缩写，谷歌发明的新传输协议。\n 与 TCP 相比，QUIC 可以减少延迟。\n QUIC 协议可以在 1 到 2 个数据包（取决于连接的服务器是新的还是已知的）内，完成连接的创建（包括 TLS）。\nQUIC 与现有 TCP + TLS + HTTP/2 方案相比，有以下几点主要特征：\n 利用缓存，显著减少连接建立时间；(减少了 TCP 三次握手及 TLS 握手时间) 改善拥塞控制，拥塞控制从内核空间到用户空间； 没有 head of line 阻塞的多路复用； 前向纠错，减少重传； 连接平滑迁移，网络状态的变更不会影响连接断线。  拥塞控制、加密和一些HTTP/2的特性都移动到QUIC层去了\n从图上可以看出，QUIC 底层通过 UDP 协议替代了 TCP，上层只需要一层用于和远程服务器交互的 HTTP/2 API。这是因为 QUIC 协议已经包含了多路复用和连接管理，HTTP API 只需要完成 HTTP 协议的解析即可。\nQUIC也合并了TLS握手过程到它的连接过程之中\n目标 QUIC 协议的主要目的，是为了整合 TCP 协议的可靠性和 UDP 协议的速度和效率。\nQUIC连接过程 如何做到0RTT？ 首先解释一下什么是0RTT。\n所谓的0RTT就是，通信双方发起通信连接时，第一个数据包便可以携带有效的业务数据。而我们知道，这个使用传统的TCP是完全不可能的，除非你使能了TCP Fast Open特性，而这个很难，因为几乎没人愿意为了这个收益去对操作系统的网络协议栈大动手脚。未使能Fast Open的TCP传输第一笔数据前，至少要等1个RTT：\n此外，对于HTTPS这种应用而言，由于还需要额外的TLS握手，0RTT就更不可能了。\n首先声明一点，如果一对使用QUIC进行加密通信的双方此前从来没有通信过，那么0RTT是不可能的，即便是QUIC也是不可能的，所谓的0RTT是值之前连接过服务器，后面再次连接的时候就是0RTT。\n连接过程 Step1：首次连接时，客户端发送 Inchoate Client Hello 给服务端，用于请求连接；\nStep2：服务端生成 g、p、a，根据 g、p 和 a 算出 A，然后将 g、p、A 放到 Server Config 中再发送 Rejection 消息给客户端；\nStep3：客户端接收到 g、p、A 后，自己再生成 b，根据 g、p、b 算出 B，根据 A、p、b 算出初始密钥 K。B 和 K 算好后，客户端会用 K 加密 HTTP 数据，连同 B 一起发送给服务端；\nStep4：服务端接收到 B 后，根据 a、p、B 生成与客户端同样的密钥，再用这密钥解密收到的 HTTP 数据。为了进一步的安全（前向安全性），服务端会更新自己的随机数 a 和公钥，再生成新的密钥 S，然后把公钥通过 Server Hello 发送给客户端。连同 Server Hello 消息，还有 HTTP 返回数据；\nStep5：客户端收到 Server Hello 后，生成与服务端一致的新密钥 S，后面的传输都使用 S 加密。\n这样，QUIC 从请求连接到正式接发 HTTP 数据一共花了 1 RTT，这 1 个 RTT 主要是为了获取 Server Config，后面的连接如果客户端缓存了 Server Config，那么就可以直接发送 HTTP 数据，实现 0 RTT 建立连接。\n这里使用的是 DH 密钥交换算法，DH 算法的核心就是服务端生成 a、g、p 3 个随机数，a 自己持有，g 和 p 要传输给客户端，而客户端会生成 b 这 1 个随机数，通过 DH 算法客户端和服务端可以算出同样的密钥。在这过程中 a 和 b 并不参与网络传输，安全性大大提高。因为 p 和 g 是大数，所以即使在网络中传输的 p、g、A、B 都被劫持，那么靠现在的计算机算力也没法破解密钥。\n如下图：\nQUIC连接迁移  当手机从数据信号切换到WIFI信号时需要可以灵活的进行连接的切换。\n TCP 连接基于四元组（源 IP、源端口、目的 IP、目的端口），切换网络时至少会有一个因素发生变化，导致连接发生变化。当连接发生变化时，如果还使用原来的 TCP 连接，则会导致连接失败，就得等原来的连接超时后重新建立连接，所以我们有时候发现切换到一个新网络时，即使新网络状况良好，但内容还是需要加载很久。如果实现得好，当检测到网络变化时立刻建立新的 TCP 连接，即使这样，建立新的连接还是需要几百毫秒的时间。\nQUIC 的连接不受四元组的影响，当这四个元素发生变化时，原连接依然维持。那这是怎么做到的呢？道理很简单，QUIC 连接不以四元组作为标识，而是使用一个 64 位的随机数，这个随机数被称为 Connection ID，即使 IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。\n是不是很强~\nQUIC解决队头阻塞问题 HTTP 一般又允许每个主机建立 6 个 TCP 连接，这样可以更加充分地利用带宽资源，但每个连接中队头阻塞的问题还是存在。\nHTTP/2 的多路复用解决了上述的队头阻塞问题。不像 HTTP/1.1 中只有上一个请求的所有数据包被传输完毕下一个请求的数据包才可以被传输，HTTP/2 中每个请求都被拆分成多个 Frame 通过一条 TCP 连接同时被传输，这样即使一个请求被阻塞，也不会影响其他的请求。如下图所示，不同颜色代表不同的请求，相同颜色的色块代表请求被切分的 Frame。\n事情还没完，HTTP/2 虽然可以解决“请求”这个粒度的阻塞，但 HTTP/2 的基础 TCP 协议本身却也存在着队头阻塞的问题。HTTP/2 的每个请求都会被拆分成多个 Frame，不同请求的 Frame 组合成 Stream，Stream 是 TCP 上的逻辑传输单元，这样 HTTP/2 就达到了一条连接同时发送多条请求的目标，这就是多路复用的原理。我们看一个例子，在一条 TCP 连接上同时发送 4 个 Stream，其中 Stream1 已正确送达，Stream2 中的第 3 个 Frame 丢失，TCP 处理数据时有严格的前后顺序，先发送的 Frame 要先被处理，这样就会要求发送方重新发送第 3 个 Frame，Stream3 和 Stream4 虽然已到达但却不能被处理，那么这时整条连接都被阻塞。\n不仅如此，由于 HTTP/2 必须使用 HTTPS，而 HTTPS 使用的 TLS 协议也存在队头阻塞问题。TLS 基于 Record 组织数据，将一堆数据放在一起（即一个 Record）加密，加密完后又拆分成多个 TCP 包传输。一般每个 Record 16K，包含 12 个 TCP 包，这样如果 12 个 TCP 包中有任何一个包丢失，那么整个 Record 都无法解密。\n那 QUIC 是如何解决队头阻塞问题的呢？主要有两点。\n QUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、传输、解密都基于 Packet，不会跨越多个 Packet，这样就能避免 TLS 的队头阻塞问题； QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理。(Stream 之间相互独立)   当然，并不是所有的 QUIC 数据都不会受到队头阻塞的影响，比如 QUIC 当前也是使用 Hpack 压缩算法 [10]，由于算法的限制，丢失一个头部数据时，可能遇到队头阻塞。\n总体来说，QUIC 在传输大量数据时，比如视频，受到队头阻塞的影响很小。\n QUIC的拥塞控制(可插拔) 拥塞控制的目的是避免过多的数据一下子涌入网络，导致网络超出最大负荷。QUIC 的拥塞控制与 TCP 类似，并在此基础上做了改进。\nAIMD:线性增加，乘性减少反馈控制算法。\n热拔插 TCP 中如果要修改拥塞控制策略，需要在系统层面进行操作。QUIC 修改拥塞控制策略只需要在应用层操作，并且 QUIC 会根据不同的网络环境、用户来动态选择拥塞控制算法。\nQUIC前向纠错FEC QUIC 使用前向纠错(FEC，Forward Error Correction)技术增加协议的容错性。一段数据被切分为 10 个包后，依次对每个包进行异或运算，运算结果会作为 FEC 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 9 个包以及 FEC 包推算出丢失的那个包的数据，这样就大大增加了协议的容错性。\n这是符合现阶段网络技术的一种方案，现阶段带宽已经不是网络传输的瓶颈，往返时间才是，所以新的网络传输协议可以适当增加数据冗余，减少重传操作。\nQUIC重传序列号单调递增 TCP 为了保证可靠性，使用 Sequence Number 和 ACK 来确认消息是否有序到达，但这样的设计存在缺陷。\n超时发生后客户端发起重传，后来接收到了 ACK 确认消息，但因为原始请求和重传请求接收到的 ACK 消息一样，所以客户端就郁闷了，不知道这个 ACK 对应的是原始请求还是重传请求。如果客户端认为是原始请求的 ACK，但实际上是左图的情形，则计算的采样 RTT 偏大；如果客户端认为是重传请求的 ACK，但实际上是右图的情形，又会导致采样 RTT 偏小。\n 图中有几个术语，RTO 是指超时重传时间（Retransmission TimeOut），跟我们熟悉的 RTT（Round Trip Time，往返时间）很长得很像。采样 RTT 会影响 RTO 计算，超时时间的准确把握很重要，长了短了都不合适。\n QUIC 解决了上面的歧义问题。与 Sequence Number 不同的是，Packet Number 严格单调递增，如果 Packet N 丢失了，那么重传时 Packet 的标识不会是 N，而是比 N 大的数字，比如 N + M，这样发送方接收到确认消息时就能方便地知道 ACK 对应的是原始请求还是重传请求。\n如上图所示，RTO 发生后，根据重传的 Packet Number 就能确定精确的 RTT 计算。如果 Ack 的 Packet Number 是 N+M，就根据重传请求计算采样 RTT。如果 Ack 的 Pakcet Number 是 N，就根据原始请求的时间计算采样 RTT，没有歧义性。\n保证包的顺序 单纯依靠严格递增的 Packet Number 肯定是无法保证数据的顺序性和可靠性。QUIC 又引入了一个 Stream Offset 的概念。\n即一个 Stream 可以经过多个 Packet 传输，Packet Number 严格递增，没有依赖。但是 Packet 里的 Payload 如果是 Stream 的话，就需要依靠 Stream 的 Offset 来保证应用数据的顺序。如下图所示，发送端先后发送了 Pakcet N 和 Pakcet N+1，Stream 的 Offset 分别是 x 和 x+y。\n假设 Packet N 丢失了，发起重传，重传的 Packet Number 是 N+2，但是它的 Stream 的 Offset 依然是 x，这样就算 Packet N + 2 是后到的，依然可以将 Stream x 和 Stream x+y 按照顺序组织起来。\n不允许 Reneging 什么叫 Reneging 呢？就是接收方丢弃已经接收并且上报给 SACK 选项的内容。TCP 协议不鼓励这种行为，但是协议层面允许这样的行为。主要是考虑到服务器资源有限，比如 Buffer 溢出，内存不够等情况。\nReneging 对数据重传会产生很大的干扰。因为 Sack 都已经表明接收到了，但是接收端事实上丢弃了该数据。QUIC 中的 ACK 包含了与 TCP 中 SACK 等价的信息，但 QUIC 不允许任何（包括被确认接受的）数据包被丢弃。这样不仅可以简化发送端与接收端的实现难度，还可以减少发送端的内存压力。\nQUIC 在协议层面禁止 Reneging，一个 Packet 只要被 Ack，就认为它一定被正确接收，减少了这种干扰。\n更多的 ACK 块 一般来说，接收方收到发送方的消息后都应该发送一个 ACK 回复，表示收到了数据。但每收到一个数据就返回一个 ACK 回复太麻烦，所以一般不会立即回复，而是接收到多个数据后再回复，TCP SACK 最多提供 3 个 ACK block。但有些场景下，比如下载，只需要服务器返回数据就好，但按照 TCP 的设计，每收到 3 个数据包就要“礼貌性”地返回一个 ACK。而 QUIC 最多可以捎带 256 个 ACK block。在丢包率比较严重的网络下，更多的 ACK block 可以减少重传量，提升网络效率。\nACK Delay TCP 计算 RTT 时没有考虑接收方接收到数据到发送确认消息之间的延迟，如下图所示，这段延迟即 ACK Delay。QUIC 考虑了这段延迟，使得 RTT 的计算更加准确。\n 这段时间可能是解析包的时间。\n QUIC流量控制(基于 stream 和 connecton 级别) QUIC 的流量控制和 TCP 有点区别，TCP 为了保证可靠性，窗口左边沿向右滑动时的长度取决于已经确认的字节数。如果中间出现丢包，就算接收到了更大序号的 Segment，窗口也无法超过这个序列号。\n但 QUIC 不同，就算此前有些 packet 没有接收到，它的滑动只取决于接收到的最大偏移字节数。\n针对 Stream：\n$$\n可用窗口 = 最大窗口 - 接受到的最大偏移数\n$$\n针对 Connection：\n$$\n可用窗口= stream1可用窗口 + stream2可用窗口 + streamN可用窗口\n$$\n最重要的是，我们可以在内存不足或者上游处理性能出现问题时，通过流量控制来限制传输速率，保障服务可用性。\n加密认证的报文 TCP 协议头部没有经过任何加密和认证，所以在传输过程中很容易被中间网络设备篡改，注入和窃听。比如修改序列号、滑动窗口。这些行为有可能是出于性能优化，也有可能是主动攻击。\n但是 QUIC 的 packet 可以说是武装到了牙齿。除了个别报文比如 PUBLIC_RESET 和 CHLO，所有报文头部都是经过认证的，报文 Body 都是经过加密的。\n这样只要对 QUIC 报文任何修改，接收端都能够及时发现，有效地降低了安全风险。\n如下图所示，红色部分是 Stream Frame 的报文头部，有认证。绿色部分是报文内容，全部经过加密。\nReference：\n The Road to QUIC 科普：QUIC协议原理分析 Quic协议介绍和浅析 QUIC协议是如何做到0RTT加密传输的 Quic协议介绍和浅析  ","description":"新一代HTTP协议，成为HTTP/3，基于UDP，非常强大.有更快速、更灵活、更安全的特点。","id":45,"section":"posts","tags":["quic"],"title":"Quic协议为什么这么好","uri":"https://hugo.jiahongw.com/zh/posts/network/quic-protocol/"},{"content":"TCP拥塞控制算法的目的可以简单概括为：公平竞争、充分利用网络带宽、降低网络延时、优化用户体验，然而就目前而言要实现这些目标就难免有权衡和取舍。\n算法分类 基于丢包策略的传统拥塞控制算法的几个迭代版本，如图所示：\n与此同时还有一类算法是基于RTT延时策略来进行控制的，但是这类算法在发包速率上可能不够激进，竞争性能不如其他算法，因此在共享网络带宽时有失公平性，但是算法速率曲线却是很平滑\n基于链路容量的拥塞控制：实时测量网络带宽和时延，认为网络上报文总量大于带宽时延乘积时出现了拥塞，如 BBR。\n基于学习的拥塞控制：没有特定的拥塞信号，而是借助评价函数，基于训练数据，使用机器学习的方法形成一个控制策略，如 Remy。\n如何感知拥塞 基于各种拥塞策略的拥塞控制算法有不一样的拥塞判断标准：\n  基于丢包\n丢包可以由重传超时RTO和重复确认来做判断。\n  基于时延\n  基于链路容量\n  基于机器学习\n根据参数得出一个拥塞窗口值\n  拥塞控制基本策略 拥塞控制是一个动态的过程，它既要提高带宽利用率发送尽量多的数据又要避免网络拥堵丢包RTT增大等问题，基于这种高要求并不是单一策略可以搞定的，因此TCP的 拥塞控制策略实际上是分阶段分策略的综合过程：\n基于丢包的拥塞控制 Tahoe算法 如果收到三次重复确认即第四次收到相同确认号的分段确认，并且分段对应包无负载分段和无改变接收窗口的话，Tahoe算法则进入快速重传，将慢启动阈值改为当前拥塞窗口的一半，将拥塞窗口降为1个MSS，并重新进入慢启动阶段。\n拥塞控制过程大致如下：\nReno算法(我们当前理解的算法) 如果收到三次重复确认，Reno算法则进入快速重传只将拥塞窗口减半来跳过慢启动阶段，将慢启动阈值设为当前新的拥塞窗口值，进入一个称为快速恢复的新设计阶段。\n拥塞控制流程如下：\nReno 算法将收到 ACK 这一信号作为拥塞窗口增长的依据，在早期低带宽、低时延的网络中能够很好的发挥作用，但是随着网络带宽和延时的增加，Reno 的缺点就渐渐体现出来了，发送端从发送报文到收到 ACK 经历一个 RTT，在高带宽延时（High Bandwidth-Delay Product，BDP）网络中，RTT 很大，导致拥塞窗口增长很慢，传输速度需要经过很长时间才能达到最大带宽，导致带宽利用率将低。\n适用场景：\n适用于低延时、低带宽的网络。\n TCP New Reno是对TCP Reno中快速恢复阶段的重传进行改善的一种改进算法，New Reno在低错误率时运行效率和选择确认SACK相当，在高错误率仍优于Reno。\n CUBIC算法 Cubic是 Linux 内核 2.6 之后的默认 TCP 拥塞控制算法， 使用一个立方函数（cubic function）:\n$$\nW_{cubic} = C(t-K)^3 + W_{max}\n$$\n作为拥塞窗口的增长函数，其中，C 是调节因子，t 是从上一次缩小拥塞窗口经过的时间，$W_{max}$是上一次发生拥塞时的窗口大小，\n$$\nK = \\sqrt[3]{W_{max}\\beta /C}\n$$\nβ是乘法减小因子。从函数中可以看出拥塞窗口的增长不再与 RTT 有关，而仅仅取决上次发生拥塞时的最大窗口和距离上次发生拥塞的时间间隔值。\nCubic 拥塞窗口增长曲线如下，凸曲线部分为稳定增长阶段，凹曲线部分为最大带宽探测阶段。如图下图 所示，在刚开始时，拥塞窗口增长很快，在接近 $W_{max}$ 口时，增长速度变的平缓，避免流量突增而导致丢包；在 $W_{max}$ 附近，拥塞窗口不再增加；之后开始缓慢地探测网络最大吞吐量，保证稳定性（在 $W_{max}$ 附近容易出现拥塞），在远离 $W_{max}$ 后，增大窗口增长的速度，保证了带宽的利用率。\n当出现丢包时，将拥塞窗口进行乘法减小(拥塞窗口减小到当前的一半)，再继续开始上述增长过程。此方式可以使得拥塞窗口一直维持在 $W_{max}$ 附近，从而保证了带宽的利用率。Cubic 的拥塞控制过程：\nCubic 算法的优点在于只要没有出现丢包，就不会主动降低自己的发送速度，可以最大程度的利用网络剩余带宽，提高吞吐量，在高带宽、低丢包率的网络中可以发挥较好的性能。\n但是，Cubic 同之前的拥塞控制算法一样，无法区分拥塞丢包和传输错误丢包，只要发现丢包，就会减小拥塞窗口，降低发送速率，而事实上传输错误丢包时网络不一定发生了拥塞，但是传输错误丢包的概率很低，所以对 Cubic 算法的性能影响不是很大。\nCubic 算法的另一个不足之处是过于激进，在没有出现丢包时会不停地增加拥塞窗口的大小，向网络注入流量，将网络设备的缓冲区填满，出现 Bufferbloat（缓冲区膨胀）。由于缓冲区长期趋于饱和状态，新进入网络的的数据包会在缓冲区里排队，增加无谓的排队时延，缓冲区越大，时延就越高。另外 Cubic 算法在高带宽利用率的同时依然在增加拥塞窗口，间接增加了丢包率，造成网络抖动加剧。\n适用场景：\n适用于高带宽、低丢包率网络，能够有效利用带宽。\n基于链路容量的算法 BRR算法  BBR[4] 是谷歌在 2016 年提出的一种新的拥塞控制算法，已经在 Youtube 服务器和谷歌跨数据中心广域网上部署，据 Youtube 官方数据称，部署 BBR 后，在全球范围内访问 Youtube 的延迟降低了 53%，在时延较高的发展中国家，延迟降低了 80%。目前 BBR 已经集成到 Linux 4.9 以上版本的内核中。\n BBR 算法不将出现丢包或时延增加作为拥塞的信号，而是认为当网络上的数据包总量大于瓶颈链路带宽和时延的乘积时才出现了拥塞。\nBBR 算法周期性地探测网络的容量，交替测量一段时间内的带宽极大值和时延极小值，将其乘积作为作为拥塞窗口大小（交替测量的原因是极大带宽和极小时延不可能同时得到，带宽极大时网络被填满造成排队，时延必然极大，时延极小时需要数据包不被排队直接转发，带宽必然极小），使得拥塞窗口始的值始终与网络的容量保持一致。\n什么叫做BDP呢？它叫做带宽时延积，例如一条链路的带宽是100Mbps，而RTT是40ms，那么\nBDP=100Mbps*0.04s=4Mb=0.5MB 即平均每秒飞行中的报文应当是0.5MB。因此Linux的接收窗口缓存常参考此设置：\n事实上，我们的传输速度在3个阶段被不同的因素限制：\n 应用程序限制阶段，此时RTT不变，随着应用程序开始发送大文件，速率直线上升； BDP限制阶段，此时RTT开始不断上升，但吞吐量不变，因为此时瓶颈路由器已经达到上限，缓冲队列正在不断增加； 瓶颈路由器缓冲队列限制阶段，此时开始大量丢包。  如下所示：\n如CUBIC这样基于丢包的拥塞控制算法在第2条灰色竖线发生作用，这已经太晚了，更好的作用点是BDP上限开始发挥作用时，也就是第1条灰色竖线。\n而BBR通过检测RTprop和~BtlBw~来实现拥塞控制。什么是RTprop呢？这是链路的物理时延，因为RTT里含有报文在路由器队列里的排队时间、ACK的延迟确认时间等。什么叫延迟确认呢？TCP每个报文必须被确认，确认动作是通过接收端发送ACK报文实现的，但由于TCP和IP头部有40个字节，如果不携带数据只为发送ACK网络效率过低，所以会让独立的ACK报文等一等，看看有没有数据发的时候顺便带给对方，或者等等看多个ACK一起发。所以，可以用下列公式表示RTT与RTprop的差别：\n$$\nRTT_t = RT_{prop_t} + n_t\n$$\n RTT我们可以测量得出，RTprop呢，我们只需要找到瓶颈路由器队列为空时多次RTT测量的最小值即可\n 而BtlBw全称是bottleneck bandwith，即瓶颈带宽，我们可以通过测量已发送但未ACK确认的飞行中字节除以飞行时间deliveryRate来测量\n 早在1979年Leonard Kleinrock就提出了第1条竖线是最好的拥塞控制点，但被Jeffrey M. Jaffe证明不可能实现，因为没有办法判断RTT变化到底是不是因为链路变化了，从而不同的设备瓶颈导致的，还是瓶颈路由器上的其他TCP连接的流量发生了大的变化。但我们有了RTprop和BtlBw后，当RTprop升高时我们便得到了BtlBw，这便找到第1条灰色竖线最好的拥塞控制点，也有了后续发送速率的依据。\n 由于 BBR 的拥塞窗口是精确测量出来的，不会无限的增加拥塞窗口，也就不会将网络设备的缓冲区填满，避免了出现 Bufferbloat (缓冲区膨胀)问题，使得时延大大降低。\n如下图所示，网络缓冲区被填满时时延为 250ms，Cubic 算法会继续增加拥塞窗口，使得时延持续增加到 500ms 并出现丢包，整个过程 Cubic 一直处于高时延状态，而 BBR 由于不会填满网络缓冲区，时延一直处于较低状态。\n由于 BBR 算法不将丢包作为拥塞信号，所以在丢包率较高的网络中，BBR 依然有极高的吞吐量，如图 5下图所示，在 1% 丢包率的网络环境下，Cubic 的吞吐量已经降低 90% 以上，而 BBR 的吞吐量几乎没有受到影响，当丢包率大于 15% 时，BBR 的吞吐量才大幅下降。\nBBR 算法是反馈驱动的，有自主调节机制，不受 TCP 拥塞控制状态机的控制，通过测量网络容量来调整拥塞窗口，发送速率由自己掌控，而传统的拥塞控制算法只负责计算拥塞窗口，而不管发送速率（pacing rate），怎么发由 TCP 自己决定，这样会在瓶颈带宽附近因发送速率的激增导致数据包排队或出现丢包。\n经过测试，在高延时、高丢包率的环境下，BBR 相对于 Cubic 算法在传输速度上有较大的提升，具体的测试结果如下表所示：\n200ms 延时下 Cubic 与 BBR 传输速度对比 BBR 算法的不足之处在于设备队列缓存较大时，BBR 可能会竞争不过 Cubic 等比较激进算法，原因是 BBR 不主动去占据队列缓存，如果 Cubic 的流量长期占据队列缓存，会使得 BBR 在多个周期内测量的极小 RTT 增大，进而使 BBR 的带宽减小。\n适用场景：\n适用于高带宽、高时延、有一定丢包率的长肥网络，可以有效降低传输时延，并保证较高的吞吐量。\n基于学习的算法 Remy Remy 也称为计算机生成的拥塞控制算法（computer-generated congestion-control algorithm），采用机器学习的方式生成拥塞控制算法模型。\n略了吧\u0026hellip;\u0026hellip;🙃\n基于时延的算法 Vegas算法 Vegas将时延 RTT 的增加作为网络出现拥塞的信号，RTT 增加，拥塞窗口减小，RTT 减小，拥塞窗口增加。具体来说，Vegas 通过比较实际吞吐量和期望吞吐量来调节拥塞窗口的大小.\n期望吞吐量为：\n$$\nExpected = cwnd / BaseRTT\n$$\n实际吞吐量为：\n$$\nActual = cwnd / RTT\n$$\n定义一个它们之间的差距diff:\n$$\ndiff = (Expected-Actual) * BaseRTT\n$$\nBaseRTT 是所有观测来回响应时间的最小值，一般是建立连接后所发的第一个数据包的 RTT，cwnd 是目前的拥塞窗口的大小。Vegas 定义了两个阈值 a，b，当 diff \u0026gt; b 时，拥塞窗口减小，当 a \u0026lt;= diff \u0026lt;=b 时，拥塞窗口不变，当 diff \u0026lt; a 时，拥塞窗口增加。\nVegas 算法采用 RTT 的改变来判断网络的可用带宽，能精确地测量网络的可用带宽，效率比较好。但是，网络中 Vegas 与其它算法共存的情况下，基于丢包的拥塞控制算法会尝试填满网络中的缓冲区，导致 Vegas 计算的 RTT 增大，进而降低拥塞窗口，使得传输速度越来越慢，因此 Vegas 未能在 Internet 上普遍采用。\n适用场景：\n适用于网络中只存在 Vegas 一种拥塞控制算法，竞争公平的情况。\nReference：\n 万字长文|全网最强 TCP/IP 拥塞控制总结\u0026hellip; 万字详文：TCP 拥塞控制详解 浅谈 TCP 拥塞控制算法 一文解释清楚google-bbr拥塞控制算法原理  ","description":"以往的拥塞控制算法是基于TCP丢包的，随着技术的发展，也出现了基于链路容量的一些拥塞控制算法，例如BBR，使得拥塞控制也可以基于UDP，更进一步的推动了HTTP/3的发展。","id":46,"section":"posts","tags":["拥塞控制"],"title":"拥塞控制算法","uri":"https://hugo.jiahongw.com/zh/posts/network/congestion-control/"},{"content":"哈夫曼编码算法用字符在文件中出现的频率表来建立一个用0，1串表示各字符的最优表示方式。给出现频率高的字符较短的编码，出现频率较低的字符以较长的编码，可以大大缩短总码长。\nHuffman Coding两个步骤  编码(从输入的字符数据构建一颗哈夫曼树，并将字符串转化位01编码) 解码(遍历哈夫曼树将01编码转化为字符)  构建哈夫曼树的过程  计算输入数据的每一个字符的出现频率。 从最小堆中提取两个频率最小的字符。 创建一个频率等于两个节点频率之和的新内部节点。使第一个提取的节点为其左子节点，另一个提取的节点为其右子节点。将此节点添加到最小堆中。 重复step2和step3直到最小堆为空。  假如有如下几个字母及它们出现的次数(频率):\n   字符 字数     a 5   b 4   c 3   d 2   e 1    在线演示霍夫曼树的构建：https://people.ok.ubc.ca/ylucet/DS/Huffman.html\nC++使用STL实现 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110  // C++ program for Huffman Coding #include \u0026lt;bits/stdc++.h\u0026gt; using namespace std; // A Huffman tree node struct MinHeapNode { // One of the input characters \tchar data; // Frequency of the character \tunsigned freq; // Left and right child \tMinHeapNode *left, *right; MinHeapNode(char data, unsigned freq) { left = right = NULL; this-\u0026gt;data = data; this-\u0026gt;freq = freq; } }; // For comparison of // two heap nodes (needed in min heap) struct compare { bool operator()(MinHeapNode* l, MinHeapNode* r) { return (l-\u0026gt;freq \u0026gt; r-\u0026gt;freq); } }; // Prints huffman codes from // the root of Huffman Tree. void printCodes(struct MinHeapNode* root, string str) { if (!root) return; if (root-\u0026gt;data != \u0026#39;$\u0026#39;) cout \u0026lt;\u0026lt; root-\u0026gt;data \u0026lt;\u0026lt; \u0026#34;: \u0026#34; \u0026lt;\u0026lt; str \u0026lt;\u0026lt; \u0026#34;\\n\u0026#34;; printCodes(root-\u0026gt;left, str + \u0026#34;0\u0026#34;); printCodes(root-\u0026gt;right, str + \u0026#34;1\u0026#34;); } // The main function that builds a Huffman Tree and // print codes by traversing the built Huffman Tree void HuffmanCodes(char data[], int freq[], int size) { struct MinHeapNode *left, *right, *top; // Create a min heap \u0026amp; inserts all characters of data[] \tpriority_queue\u0026lt;MinHeapNode*, vector\u0026lt;MinHeapNode*\u0026gt;, compare\u0026gt; minHeap; for (int i = 0; i \u0026lt; size; ++i) minHeap.push(new MinHeapNode(data[i], freq[i])); // Iterate while size of heap doesn\u0026#39;t become 1 \twhile (minHeap.size() != 1) { // Extract the two minimum \t// freq items from min heap \tleft = minHeap.top(); minHeap.pop(); right = minHeap.top(); minHeap.pop(); // Create a new internal node with \t// frequency equal to the sum of the \t// two nodes frequencies. Make the \t// two extracted node as left and right children \t// of this new node. Add this node \t// to the min heap \u0026#39;$\u0026#39; is a special value \t// for internal nodes, not used \ttop = new MinHeapNode(\u0026#39;$\u0026#39;, left-\u0026gt;freq + right-\u0026gt;freq); top-\u0026gt;left = left; top-\u0026gt;right = right; minHeap.push(top); } // Print Huffman codes using \t// the Huffman tree built above \tprintCodes(minHeap.top(), \u0026#34;\u0026#34;); } // Driver program to test above functions int main() { char arr[] = { \u0026#39;a\u0026#39;, \u0026#39;b\u0026#39;, \u0026#39;c\u0026#39;, \u0026#39;d\u0026#39;, \u0026#39;e\u0026#39;, \u0026#39;f\u0026#39; }; int freq[] = { 5, 9, 12, 13, 16, 45 }; int size = sizeof(arr) / sizeof(arr[0]); HuffmanCodes(arr, freq, size); return 0; } // This code is contributed by Aditya Goel   Reference:\n 哈夫曼编码的理解(Huffman Coding) 哈夫曼编码 Huffman Coding | Greedy Algo-3  ","description":"哈夫曼编码算法用字符在文件中出现的频率表来建立一个用0，1串表示各字符的最优表示方式。","id":47,"section":"posts","tags":["huffman"],"title":"Huffman Tree是如何编码的？","uri":"https://hugo.jiahongw.com/zh/posts/algorithmstructure/huffman-coding/"},{"content":"参考地址：\n cloudflare.com 使用Cloudflare和Nginx来托管网站 管理 Cloudflare Origin CA 证书 已安装nginx支持https配置 nginx启动、重启、关闭 nginx配置ssl实现https访问  点击SSL/TLS，并且点击源服务器\n进入下面的页面，点击下面的创建证书，接下来按照下面链接的指导进行操作：\n使用Cloudflare和Nginx来托管网站\n同时在Nginx服务器的配置文件nginx.conf中设置相关的配置\nnginx配置ssl实现https访问\n假如Nginx提示the \u0026quot;ssl\u0026quot; parameter requires ngx_http_ssl_module,表示Nginx没有安装SSL模块，按照下面的链接指导进行操作\n已安装nginx支持https配置\n接下来在CloudFlare中设置完全严格\n最后就可以看到小锁头啦\n","description":"使用Nginx配合CloudFlare设置服务器使用Https证书。","id":48,"section":"posts","tags":["Nginx","https"],"title":"CloudFlare+Nginx配置HTTPS连接","uri":"https://hugo.jiahongw.com/zh/posts/settings/https-set/"},{"content":"🍂 HTTP报文 请求报文 HTTP 请求报文由3部分组成(请求行+请求头+请求体)\n请求行包括：请求方法、请求URL、HTTP协议及版本：\nGET和POST是最常见的HTTP方法,初次以外还包括 DELETE、HEAD、OPTIONS、PUT、TRACE，不过现在大部分的浏览器只支持GET和POST\n请求对应的URL地址,他和报文头的Host属性,组合起来是一个完整的请求URL\n报文头是一些参数信息：\n有若干个属性,形式为key:val,服务端据此获取客户端信息\n报文体是具体传输的内容。\n响应报文 响应报文与请求报文一样,由三个部分组成(响应行,响应头,响应体)\n参考：HTTP请求头和响应头详解\n🚉 HTTP状态码：  1xx：表示通知信息，如请求收到了或正在进行处理  100 Continue：继续，客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议   2xx：表示成功，如接收或知道了  200 OK: 请求成功   3xx：表示重定向，如要完成请求还必须采取进一步的行动  301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替   4xx：表示客户的差错，如请求中有错误的语法或不能完成  400 Bad Request: 客户端请求的语法错误，服务器无法理解 401 Unauthorized: 请求要求用户的身份认证 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够） 404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面 408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时   5xx：表示服务器的差错，如服务器失效无法完成请求  500 Internal Server Error: 服务器内部错误，无法完成请求 503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中 504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求    ✋ HTTP的主要方法   下面这个例子是查询HTTP服务器端支持的HTTP方法种类。\n  参考：HTTP请求头和响应头详解\n","description":"Http是定义在TCP上的一种传输协议，要传输消息就必须遵守规定，本文是使用Http的发送消息与接受消息的报文规定及方法。","id":49,"section":"posts","tags":["http"],"title":"Http报文格式及Http方法","uri":"https://hugo.jiahongw.com/zh/posts/network/http-message/"},{"content":"同步异步与阻塞非阻塞 用户空间和内核空间 操作系统为了支持多个应用同时运行，需要保证不同进程之间相对独立（一个进程的崩溃不会影响其他的进程 ， 恶意进程不能直接读取和修改其他进程运行时的代码和数据）。 因此操作系统内核需要拥有高于普通进程的权限， 以此来调度和管理用户的应用程序。\n于是内存空间被划分为两部分，一部分为内核空间，一部分为用户空间，内核空间存储的代码和数据具有更高级别的权限。内存访问的相关硬件在程序执行期间会进行访问控制（ Access Control），使得用户空间的程序不能直接读写内核空间的内存。\n进程切换 上图展示了进程切换中几个最重要的步骤：\n 当一个程序正在执行的过程中， 中断（interrupt） 或 系统调用（system call） 发生可以使得 CPU 的控制权会从当前进程转移到操作系统内核。 操作系统内核负责保存进程 i 在 CPU 中的上下文（程序计数器， 寄存器）到 PCBi （操作系统分配给进程的一个内存块）中。 从 PCBj 取出进程 j 的CPU 上下文， 将 CPU 控制权转移给进程 j ， 开始执行进程 j 的指令。   可以看出来， 操作系统在进行进切换时，需要进行一系列的内存读写操作， 这带来了一定的开销\n 进程阻塞 上图展示了一个进程的不同状态：\n New. 进程正在被创建. Running. 进程的指令正在被执行 Waiting. 进程正在等待一些事件的发生（例如 I/O 的完成或者收到某个信号） Ready. 进程在等待被操作系统调度 Terminated. 进程执行完毕（可能是被强行终止的）  我们所说的 “阻塞”是指进程在发起了一个系统调用（System Call） 后， 由于该系统调用的操作不能立即完成，需要等待一段时间，于是内核将进程挂起为**等待 （waiting）**状态， 以确保它不会被调度执行， 占用 CPU 资源。\n阻塞的原理\n阻塞的原理？\n对于Socket来说：\n当发生阻塞时候，调用阻塞程序，而阻塞程序最重要的一个操作就是将进程从工作队列移除，并且将其加到等待队列。\n当发生中断时候，调用中断程序，而中断程序最重要的一个操作就是将等待队列中的进程重新移回工作队列，继续分配系统的CPU资源。\n文件描述符 我们最熟悉的句柄是0、1、2三个，0是标准输入，1是标准输出，2是标准错误输出。0、1、2是整数表示的，对应的FILE *结构的表示就是stdin、stdout、stderr，0就是stdin，1就是stdout，2就是stderr。\n1 2 3 4 5 6 7 8 9 10 11  #include \u0026lt;stdio.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;string.h\u0026gt;int main(int argc, char **argv) { char buf[10] = \u0026#34;\u0026#34;; read(0, buf, 9);\t/* 从标准输入 0 读入字符 */ // fprintf(stdout, \u0026#34;%s\\n\u0026#34;, buf); /* 向标准输出 stdout 写字符 */ \twrite(1, buf, strlen(buf)); return 0; }   同步 同步就是一个任务的完成需要依赖另外一个任务时，只有等待被依赖的任务完成后，依赖的任务才能算完成，这是一种可靠的任务序列。也就是说，调用会等待返回结果计算完成才能继续执行。\n异步 异步是不需要等待被依赖的任务完成，只是通知被依赖的任务要完成什么工作，依赖的任务也立即执行，只要自己完成了整个任务就算完成了。也就是说，其实异步调用会直接返回，但是这个结果不是计算的结果，当结果计算出来之后，才通知被调用的程序。\n 举个通俗的例子：\n你打电话问书店老板有没有《分布式系统》这本书，如果是同步通信机制，书店老板会说，你稍等，”我查一下\u0026rdquo;，然后开始查啊查，等查好了（可能是5秒，也可能是一天）告诉你结果（返回结果）。\n而异步通信机制，书店老板直接告诉你我查一下啊，查好了打电话给你，然后直接挂电话了（不返回结果）。然后查好了，他会主动打电话给你。在这里老板通过“回电”这种方式来回调。\n 阻塞 阻塞调用是指调用结果返回之前，当前线程会被挂起，一直处于等待消息通知，不能够执行其他业务。\n非阻塞 不管可不可以读写，它都会立即返回，返回成功说明读写操作完成了，返回失败会设置相应errno状态码，根据这个errno可以进一步执行其他处理。它不会像阻塞IO那样，卡在那里不动。\n 阻塞和非阻塞关注的是程序在等待调用结果（消息，返回值）时的状态.\n 可以这么理解么？阻塞和非阻塞，应该描述的是一种状态，同步与非同步描述的是行为方式.\n多路复用 ==IO多路复用是指内核一旦发现进程指定的一个或者多个IO条件准备读取，它就通知该进程==。\n在处理 IO 的时候，阻塞和非阻塞都是同步 IO。\n只有使用了特殊的 API 才是异步 IO。\nselect、poll、epoll之间的区别：\n   \\ select poll epoll     操作方式 遍历 遍历 回调   底层实现 数组 链表 哈希表   IO效率 每次调用都进行线性遍历，时间复杂度为O(n) 每次调用都进行线性遍历，时间复杂度为O(n) 事件通知方式，每当fd就绪，系统注册的回调函数就会被调用，将就绪fd放到rdllist里面。时间复杂度O(1)   最大连接数 1024（x86）或 2048（x64） 无上限 无上限   fd拷贝 每次调用select，都需要把fd集合从用户态拷贝到内核态 每次调用poll，都需要把fd集合从用户态拷贝到内核态 调用epoll_ctl时拷贝进内核并保存，之后每次epoll_wait不拷贝    Select 基于select调用的I/O复用模型如下：\n流程 传统select/poll的另一个致命弱点就是当你拥有一个很大的socket集合，由于网络得延时，使得任一时间只有部分的socket是\u0026quot;活跃\u0026rdquo; 的，而select/poll每次调用都会线性扫描全部的集合，导致效率呈现线性下降。\n但是epoll不存在这个问题，它只会对\u0026quot;活跃\u0026quot;的socket进 行操作\u0026mdash;这是因为在内核实现中epoll是根据每个fd上面的callback函数实现的。于是，只有\u0026quot;活跃\u0026quot;的socket才会主动去调用 callback函数，其他idle状态的socket则不会，在这点上，epoll实现了一个\u0026ldquo;伪\u0026quot;AIO，因为这时候推动力在os内核。\n过程\n当进程A调用select语句的时候，会将进程A添加到多个监听socket的等待队列中\n当网卡接收到数据，然后网卡通过中断信号通知cpu有数据到达，执行中断程序，中断程序主要做了两件事：\n 将网络数据写入到对应socket的接收缓冲区里面 唤醒队列中的等待进程(A),重新将进程A放入工作队列中.  如下图，将所有等待队列的进程移除，并且添加到工作队列中。\n 上面只是一种情况，当程序调用 Select 时，内核会先遍历一遍 Socket，如果有一个以上的 Socket 接收缓冲区有数据，那么 Select 直接返回，不会阻塞。\n 问题：\n 每次调用 Select 都需要将进程加入到所有监视 Socket 的等待队列，每次唤醒都需要从每个队列中移除。这里涉及了两次遍历，而且每次都要将整个 FDS 列表传递给内核，有一定的开销。 进程被唤醒后，程序并不知道哪些 Socket 收到数据，还需要遍历一次   select和poll在内部机制方面并没有太大的差异。相比于select机制，poll只是取消了最大监控文件描述符数限制，并没有从根本上解决select存在的问题。\n Slect API 轮询所有的句柄，找到有处理状态的句柄并且进行操作。\n主要函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  /* According to POSIX.1-2001 */ #include \u0026lt;sys/select.h\u0026gt; /* According to earlier standards */ #include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;unistd.h\u0026gt; int select(int nfds, fd_set *readfds, fd_set *writefds, fd_set *exceptfds, struct timeval *timeout); /** nfds: 监控的文件描述符集里最大文件描述符加1，因为此参数会告诉内核检测前多少个文件描述符的状态 readfds： 监控有读数据到达文件描述符集合，传入传出参数 writefds： 监控写数据到达文件描述符集合，传入传出参数 exceptfds： 监控异常发生达文件描述符集合,如带外数据到达异常，传入传出参数 timeout： 定时阻塞监控时间，3种情况 1.NULL，永远等下去 2.设置timeval，等待固定时间 3.设置timeval里时间均为0，检查描述字后立即返回，轮询 struct timeval { long tv_sec; // seconds long tv_usec; // microseconds }; */ void FD_CLR(int fd, fd_set *set);\t// 把文件描述符集合里fd清0 int FD_ISSET(int fd, fd_set *set); // 测试文件描述符集合里fd是否置1 void FD_SET(int fd, fd_set *set); // 把文件描述符集合里fd位置1 void FD_ZERO(fd_set *set);\t//把文件描述符集合里所有位清0   Select例子 服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215  /************************************************************************* \u0026gt; File Name: server.cpp \u0026gt; Author: SongLee \u0026gt; E-mail: lisong.shine@qq.com \u0026gt; Created Time: 2016年04月28日 星期四 22时02分43秒 \u0026gt; Personal Blog: http://songlee24.github.io/ ************************************************************************/ #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in#include \u0026lt;sys/types.h\u0026gt; // socket#include \u0026lt;sys/socket.h\u0026gt; // socket#include \u0026lt;arpa/inet.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;sys/select.h\u0026gt; // select#include \u0026lt;sys/ioctl.h\u0026gt;#include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;cstdlib\u0026gt;#include \u0026lt;cstdio\u0026gt;#include \u0026lt;cstring\u0026gt;using namespace std; #define BUFFER_SIZE 1024 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd  int max_fd; // 最大的fd  fd_set master_set; // 所有fd集合，包括监听fd和客户端fd  fd_set working_set; // 工作集合  struct timeval timeout; public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(int nums); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen  listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; // 允许重用本地地址和端口  setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { for (int fd = 0; fd \u0026lt;= max_fd; ++fd) { if (FD_ISSET(fd, \u0026amp;master_set)) { close(fd); } } } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 将新建立的连接的fd加入master_set  FD_SET(new_fd, \u0026amp;master_set); if (new_fd \u0026gt; max_fd) { max_fd = new_fd; } } void Server::Run() { max_fd = listen_fd; // 初始化max_fd  FD_ZERO(\u0026amp;master_set); FD_SET(listen_fd, \u0026amp;master_set); // 添加监听fd  while (1) { FD_ZERO(\u0026amp;working_set); memcpy(\u0026amp;working_set, \u0026amp;master_set, sizeof(master_set)); timeout.tv_sec = 30; timeout.tv_usec = 0; int nums = select(max_fd + 1, \u0026amp;working_set, NULL, NULL, \u0026amp;timeout); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;select() error!\u0026#34;; exit(1); } if (nums == 0) { //cout \u0026lt;\u0026lt; \u0026#34;select() is timeout!\u0026#34;;  continue; } if (FD_ISSET(listen_fd, \u0026amp;working_set)) Accept(); // 有新的客户端请求  else Recv(nums); // 接收客户端的消息  } } void Server::Recv(int nums) { for (int fd = 0; fd \u0026lt;= max_fd; ++fd) { if (FD_ISSET(fd, \u0026amp;working_set)) { bool close_conn = false; // 标记当前连接是否断开了  PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度  // std::cout \u0026lt;\u0026lt; head.length \u0026lt;\u0026lt; std::endl;  char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端  { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它  { close(fd); FD_CLR(fd, \u0026amp;master_set); if (fd == max_fd) // 需要更新max_fd;  { while (FD_ISSET(max_fd, \u0026amp;master_set) == false) --max_fd; } } } } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; }   客户端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127  /************************************************************************* \u0026gt; File Name: client.cpp \u0026gt; Author: SongLee \u0026gt; E-mail: lisong.shine@qq.com \u0026gt; Created Time: 2016年04月28日 星期四 23时10分15秒 \u0026gt; Personal Blog: http://songlee24.github.io/ ************************************************************************/ #include\u0026lt;netinet/in.h\u0026gt; // sockaddr_in#include\u0026lt;sys/types.h\u0026gt; // socket#include\u0026lt;sys/socket.h\u0026gt; // socket#include\u0026lt;arpa/inet.h\u0026gt;#include\u0026lt;sys/ioctl.h\u0026gt;#include\u0026lt;unistd.h\u0026gt;#include\u0026lt;iostream\u0026gt;#include\u0026lt;string\u0026gt;#include\u0026lt;cstdlib\u0026gt;#include\u0026lt;cstdio\u0026gt;#include\u0026lt;cstring\u0026gt;using namespace std; #define BUFFER_SIZE 1024 struct PACKET_HEAD { int length; }; class Client { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int fd; public: Client(string ip, int port); ~Client(); void Connect(); void Send(string str); string Recv(); }; Client::Client(string ip, int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; if(inet_pton(AF_INET, ip.c_str(), \u0026amp;server_addr.sin_addr) == 0) { cout \u0026lt;\u0026lt; \u0026#34;Server IP Address Error!\u0026#34;; exit(1); } server_addr.sin_port = htons(port); server_addr_len = sizeof(server_addr); // create socket  fd = socket(AF_INET, SOCK_STREAM, 0); if(fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } } Client::~Client() { close(fd); } void Client::Connect() { cout \u0026lt;\u0026lt; \u0026#34;Connecting......\u0026#34; \u0026lt;\u0026lt; endl; if(connect(fd, (struct sockaddr*)\u0026amp;server_addr, server_addr_len) \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Can not Connect to Server IP!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Connect to Server successfully.\u0026#34; \u0026lt;\u0026lt; endl; } void Client::Send(string str) { PACKET_HEAD head; head.length = str.size()+1; // 注意这里需要+1  int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, str.c_str(), head.length, 0); if(ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Send Message Failed!\u0026#34;; exit(1); } } string Client::Recv() { PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); char* buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while(total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if(len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; break; } total = total + len; } string result(buffer); delete buffer; return result; } int main() { Client client(\u0026#34;127.0.0.1\u0026#34;, 15000); client.Connect(); while(1) { string msg; getline(cin, msg); if(msg == \u0026#34;exit\u0026#34;) break; client.Send(msg); cout \u0026lt;\u0026lt; client.Recv() \u0026lt;\u0026lt; endl; } return 0; }   说明：\n 监听socket也由select来轮询，不需要单独的线程； working_set每次都要重新设置，因为select调用后它所检测的集合working_set会被修改； 接收很长一段数据时，需要循环多次recv。但是recv函数会阻塞，可以通过自定义包头（保存数据长度）  Poll poll的机制与select类似，与select在本质上没有多大差别，管理多个描述符也是进行轮询，根据描述符的状态进行处理，但是poll没有最大文件描述符数量的限制。poll和select同样存在一个缺点就是，包含大量文件描述符的数组被整体复制于用户态和内核的地址空间之间，而不论这些文件描述符是否就绪，它的开销随着文件描述符数量的增加而线性增大。\n相关的函数：\n1 2  #include \u0026lt;poll.h\u0026gt;int poll(struct pollfd fds[], nfds_t nfds, int timeout)；   参数描述：\n 该poll()函数返回fds集合中就绪的读、写，或出错的描述符数量，返回0表示超时，返回-1表示出错； fds是一个struct pollfd类型的数组，用于存放需要检测其状态的socket描述符，并且调用poll函数之后fds数组不会被清空； nfds：记录数组fds中描述符的总数量； timeout：调用poll函数阻塞的超时时间，单位毫秒；  其中pollfd结构体定义如下：\n1 2 3 4 5  typedef struct pollfd { int fd; /* 需要被检测或选择的文件描述符*/ short events; /* 对文件描述符fd上感兴趣的事件 */ short revents; /* 文件描述符fd上当前实际发生的事件*/ } pollfd_t;   一个pollfd结构体表示一个被监视的文件描述符，通过传递fds[]指示 poll() 监视多个文件描述符，其中：\n 结构体的events域是监视该文件描述符的事件掩码，由用户来设置这个域。 结构体的revents域是文件描述符的操作结果事件掩码，内核在调用返回时设置这个域。  events域中请求的任何事件都可能在revents域中返回。合法的事件如下：\n   常量 说明     POLLIN 普通或优先级带数据可读   POLLRDNORM 普通数据可读   POLLRDBAND 优先级带数据可读   POLLPRI 高优先级数据可读   POLLOUT 普通数据可写   POLLWRNORM 普通数据可写   POLLWRBAND 优先级带数据可写   POLLERR 发生错误   POLLHUP 发生挂起   POLLNVAL 描述字不是一个打开的文件    当需要监听多个事件时，使用POLLIN | POLLRDNORM设置 events 域；当poll调用之后检测某事件是否就绪时，fds[i].revents \u0026amp; POLLIN进行判断。\nPoll例子 服务器\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213  #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in#include \u0026lt;sys/types.h\u0026gt; // socket#include \u0026lt;sys/socket.h\u0026gt; // socket#include \u0026lt;arpa/inet.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;poll.h\u0026gt; // poll#include \u0026lt;sys/ioctl.h\u0026gt;#include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;cstdlib\u0026gt;#include \u0026lt;cstdio\u0026gt;#include \u0026lt;cstring\u0026gt;using namespace std; #define BUFFER_SIZE 1024#define MAX_FD 1000 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd  struct pollfd fds[MAX_FD]; // fd数组，大小为1000  int nfds; public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen  listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { for (int i = 0; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026gt;= 0) { close(fds[i].fd); } } } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 将新建立的连接的fd加入fds[]  int i; for (i = 1; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026lt; 0) { fds[i].fd = new_fd; break; } } // 超过最大连接数  if (i == MAX_FD) { cout \u0026lt;\u0026lt; \u0026#34;Too many clients.\\n\u0026#34;; exit(1); } fds[i].events = POLLIN; // 设置新描述符的读事件  nfds = i \u0026gt; nfds ? i : nfds; // 更新连接数 } void Server::Run() { fds[0].fd = listen_fd; // 添加监听描述符  fds[0].events = POLLIN; nfds = 0; for (int i = 1; i \u0026lt; MAX_FD; ++i) fds[i].fd = -1; while (1) { int nums = poll(fds, nfds + 1, -1); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;poll() error!\u0026#34;; exit(1); } if (nums == 0) { continue; } if (fds[0].revents \u0026amp; POLLIN) Accept(); // 有新的客户端请求  else Recv(); } } void Server::Recv() { for (int i = 1; i \u0026lt; MAX_FD; ++i) { if (fds[i].fd \u0026lt; 0) continue; if (fds[i].revents \u0026amp; POLLIN) // 读就绪  { int fd = fds[i].fd; bool close_conn = false; // 标记当前连接是否断开了  PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度  char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端  { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它  { close(fd); fds[i].fd = -1; } } } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; }   客户端\n核Select客户端一样\nEpoll epoll可以理解为event poll(基于事件的轮询)。\n使用场合：   当客户处理多个描述符时（一般是交互式输入和网络套接口），必须使用I/O复用。\n  当一个客户同时处理多个套接口时，而这种情况是可能的，但很少出现。\n  如果一个TCP服务器既要处理监听套接口，又要处理已连接套接口，一般也要用到I/O复用。\n  如果一个服务器即要处理TCP，又要处理UDP，一般要使用I/O复用。\n  如果一个服务器要处理多个服务或多个协议，一般要使用I/O复用。\n   I/O多路复用有很多种实现。在linux上，2.4内核前主要是select和poll，自Linux 2.6内核正式引入epoll以来，epoll已经成为了目前实现高性能网络服务器的必备技术。尽管他们的使用方法不尽相同，但是本质上却没有什么区别。\n Epoll原理 不同于select/poll，Epoll正是保存了那些收到数据的Socket到一个双向链表中，这样一来，就少了一次遍历。epoll = 减少遍历 + 保存就绪Socket\n 减少遍历  将控制与阻塞分离。\n保存就绪Socket  维护一个rdlist以及rb_tree，类似于双向链表操作。\n通过 epoll_ctl 添加 Sock1、Sock2 和 Sock3 的监视，内核会将 eventpoll的引用 添加到这三个 Socket 的等待队列中。\nepoll 在 Linux 内核中申请了一个简易的文件系统，用于存储相关的对象，每一个 epoll 对象都有一个独立的 eventpoll 结构体，这个结构体会在内核空间中创造独立的内存，用于存储使用epoll_ctl 方法向 epoll 对象中添加进来的事件。这些事件都会挂到 rbr 红黑树中，这样，重复添加的事件就可以通过红黑树而高效地识别出来。\nepoll底层实现最重要的两个数据结构:epitem和eventpoll。可以简单的认为epitem是和每个用户态监控IO的fd对应的,eventpoll是用户态创建的管理所有被监控fd的结构，详细的定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  struct epitem { struct rb_node rbn; struct list_head rdllink; struct epitem *next; struct epoll_filefd ffd; int nwait; struct list_head pwqlist; struct eventpoll *ep; struct list_head fllink; struct epoll_event event; }; struct eventpoll { spin_lock_t lock; struct mutex mtx; wait_queue_head_t wq; wait_queue_head_t poll_wait; struct list_head rdllist; //就绪链表  struct rb_root rbr; //红黑树根节点  struct epitem *ovflist; };   epoll过程\n调用epoll_create，内核会创建一个eventpoll对象（也就是程序中epfd所代表的对象）。eventpoll对象也是文件系统中的一员，和socket一样，它也会有等待队列。\n通过 epoll_ctl 添加 Sock1、Sock2 和 Sock3 的监视，内核会将 eventpoll的引用 添加到这三个 Socket 的等待队列中。\n当Socket收到数据之后，中断程序会执行将Socket的引用添加到eventpoll对象的rdlist就绪列表中。\n假设计算机中正在运行进程 A 和进程 B、C，在某时刻进程 A 运行到了 epoll_wait 语句，会将进程A添加到eventpoll的等待队列中。\n当 Socket 接收到数据，中断程序一方面修改 Rdlist，另一方面唤醒 eventpoll 等待队列中的进程，进程 A 再次进入运行状态。因为Soket包含eventpoll对象的引用，因此可以直接操作eventpoll对象.\nepoll API\nepoll的api定义:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  //用户数据载体 typedef union epoll_data { void *ptr; int fd; uint32_t u32; uint64_t u64; } epoll_data_t; //fd装载入内核的载体  struct epoll_event { uint32_t events; /* Epoll events */ epoll_data_t data; /* User data variable */ }; //三板斧api int epoll_create(int size); int epoll_ctl(int epfd, int op, int fd, struct epoll_event *event); int epoll_wait(int epfd, struct epoll_event *events, int maxevents, int timeout);    poll_create是在内核区创建一个epoll相关的一些列结构，并且将一个句柄fd返回给用户态，后续的操作都是基于此fd的，参数size是告诉内核这个结构的元素的大小，类似于stl的vector动态数组，如果size不合适会涉及复制扩容，不过貌似4.1.2内核之后size已经没有太大用途了； epoll_ctl是将fd添加/删除于epoll_create返回的epfd中，其中epoll_event是用户态和内核态交互的结构，定义了用户态关心的事件类型和触发时数据的载体epoll_data； epoll_wait*是阻塞等待内核返回的可读写事件，epfd还是epoll_create的返回值，events是个结构体数组指针存储epoll_event，也就是将内核返回的待处理epoll_event结构都存储下来，maxevents告诉内核本次返回的最大fd数量，这个和events指向的数组是相关的； epoll_wait是用户态需监控fd的代言人，后续用户程序对fd的操作都是基于此结构的；  epoll例子 服务端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194  #include \u0026lt;netinet/in.h\u0026gt; // sockaddr_in#include \u0026lt;sys/types.h\u0026gt; // socket#include \u0026lt;sys/socket.h\u0026gt; // socket#include \u0026lt;arpa/inet.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;#include \u0026lt;sys/epoll.h\u0026gt; // epoll#include \u0026lt;sys/ioctl.h\u0026gt;#include \u0026lt;sys/time.h\u0026gt;#include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;string\u0026gt;#include \u0026lt;cstdlib\u0026gt;#include \u0026lt;cstdio\u0026gt;#include \u0026lt;cstring\u0026gt;using namespace std; #define BUFFER_SIZE 1024#define EPOLLSIZE 100 struct PACKET_HEAD { int length; }; class Server { private: struct sockaddr_in server_addr; socklen_t server_addr_len; int listen_fd; // 监听的fd  int epfd; // epoll fd  struct epoll_event events[EPOLLSIZE]; // epoll_wait返回的就绪事件 public: Server(int port); ~Server(); void Bind(); void Listen(int queue_len = 20); void Accept(); void Run(); void Recv(int fd); }; Server::Server(int port) { bzero(\u0026amp;server_addr, sizeof(server_addr)); server_addr.sin_family = AF_INET; server_addr.sin_addr.s_addr = htons(INADDR_ANY); server_addr.sin_port = htons(port); // create socket to listen  listen_fd = socket(PF_INET, SOCK_STREAM, 0); if (listen_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Create Socket Failed!\u0026#34;; exit(1); } int opt = 1; setsockopt(listen_fd, SOL_SOCKET, SO_REUSEADDR, \u0026amp;opt, sizeof(opt)); } Server::~Server() { close(epfd); } void Server::Bind() { if (-1 == (bind(listen_fd, (struct sockaddr *)\u0026amp;server_addr, sizeof(server_addr)))) { cout \u0026lt;\u0026lt; \u0026#34;Server Bind Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Bind Successfully.\\n\u0026#34;; } void Server::Listen(int queue_len) { if (-1 == listen(listen_fd, queue_len)) { cout \u0026lt;\u0026lt; \u0026#34;Server Listen Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;Listen Successfully.\\n\u0026#34;; } void Server::Accept() { struct sockaddr_in client_addr; socklen_t client_addr_len = sizeof(client_addr); int new_fd = accept(listen_fd, (struct sockaddr *)\u0026amp;client_addr, \u0026amp;client_addr_len); if (new_fd \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;Server Accept Failed!\u0026#34;; exit(1); } cout \u0026lt;\u0026lt; \u0026#34;new connection was accepted.\\n\u0026#34;; // 在epfd中注册新建立的连接  struct epoll_event event; event.data.fd = new_fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_ADD, new_fd, \u0026amp;event); } void Server::Run() { epfd = epoll_create(1); // 创建epoll句柄  struct epoll_event event; event.data.fd = listen_fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_ADD, listen_fd, \u0026amp;event); // 注册listen_fd  while (1) { int nums = epoll_wait(epfd, events, EPOLLSIZE, -1); if (nums \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;poll() error!\u0026#34;; exit(1); } if (nums == 0) { continue; } for (int i = 0; i \u0026lt; nums; ++i) // 遍历所有就绪事件  { int fd = events[i].data.fd; if ((fd == listen_fd) \u0026amp;\u0026amp; (events[i].events \u0026amp; EPOLLIN)) Accept(); // 有新的客户端请求  else if (events[i].events \u0026amp; EPOLLIN) Recv(fd); // 读数据  else ; } } } void Server::Recv(int fd) { bool close_conn = false; // 标记当前连接是否断开了  PACKET_HEAD head; recv(fd, \u0026amp;head, sizeof(head), 0); // 先接受包头，即数据总长度  char *buffer = new char[head.length]; bzero(buffer, head.length); int total = 0; while (total \u0026lt; head.length) { int len = recv(fd, buffer + total, head.length - total, 0); if (len \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;recv() error!\u0026#34;; close_conn = true; break; } total = total + len; } if (total == head.length) // 将收到的消息原样发回给客户端  { int ret1 = send(fd, \u0026amp;head, sizeof(head), 0); int ret2 = send(fd, buffer, head.length, 0); if (ret1 \u0026lt; 0 || ret2 \u0026lt; 0) { cout \u0026lt;\u0026lt; \u0026#34;send() error!\u0026#34;; close_conn = true; } } delete buffer; if (close_conn) // 当前这个连接有问题，关闭它  { close(fd); struct epoll_event event; event.data.fd = fd; event.events = EPOLLIN; epoll_ctl(epfd, EPOLL_CTL_DEL, fd, \u0026amp;event); // Delete一个fd  } } int main() { Server server(15000); server.Bind(); server.Listen(); server.Run(); return 0; }   总结：\n每次调用poll/select系统调用，操作系统都要把current（当前进程）挂到fd对应的所有设备的等待队列上，可以想象，fd多到上千的时候，这样“挂”法很费事；而每次调用epoll_wait则没有这么罗嗦，epoll只在epoll_ctl时把current挂一遍（这第一遍是免不了的）并给每个fd一个命令“好了就调回调函数”，如果设备有事件了，通过回调函数，会把fd放入rdllist，而每次调用epoll_wait就只是收集rdllist里的fd就可以了——epoll巧妙的利用回调函数，实现了更高效的事件驱动模型。\nepoll工作模式 LT模式 LT(level triggered)是缺省的工作方式，并且同时支持block和no-block socket。在这种做法中，内核告诉你一个文件描述符是否就绪了，然后你可以对这个就绪的fd进行IO操作。如果你不作任何操作，内核还是会继续通知你的，所以，这种模式编程出错误可能性要小一点。传统的select/poll都是这种模型的代表。\nET模式 ET (edge-triggered) 是高速工作方式，只支持no-block socket(非阻塞)。 在这种模式下，当描述符从未就绪变为就绪时，内核就通过epoll告诉你，然后它会假设你知道文件描述符已经就绪，并且不会再为那个文件描述符发送更多的 就绪通知，直到你做了某些操作而导致那个文件描述符不再是就绪状态(比如 你在发送，接收或是接受请求，或者发送接收的数据少于一定量时导致了一个EWOULDBLOCK 错误)。但是请注意，如果一直不对这个fd作IO操作(从而导致它再次变成未就绪)，内核就不会发送更多的通知(only once)。不过在TCP协议中，ET模式的加速效用仍需要更多的benchmark确认。\n参考：\n IO多路复用之select总结 IO多路复用之poll总结 IO多路复用之epoll总结 Linux IO模式及 select、poll、epoll详解 select详解 Linux下的I/O复用与epoll详解 聊聊同步、异步、阻塞与非阻塞 聊聊Linux 五种IO模型 聊聊IO多路复用之select、poll、epoll详解 Linux IO模式及 select、poll、epoll详解 彻底学会使用epoll(一)——ET模式实现分析 epoll 或者 kqueue 的原理是什么？ epoll事件处理机制详解 如果这篇文章说不清epoll的本质，那就过来掐死我吧 select、poll、epoll整理总结  ","description":"本文详细介绍了多路复用中的三种模型，它们是迭代更新的结果。现在常用的会是Epoll。","id":50,"section":"posts","tags":["Epoll","Select","Poll"],"title":"Select Poll Epoll 详解","uri":"https://hugo.jiahongw.com/zh/posts/linux/select-poll-epoll/"},{"content":"虚拟存储器作为现代操作系统中存储器管理的一项重要技术，实现了内存扩充功能。**但该功能并非是从物理上实际地扩大内存的容量，而是从逻辑上实现对内存容量的扩充，让用户所感觉到的内存容量比实际内存容量大得多。**于是便可以让比内存空间更大的程序运行，或者让更多的用户程序并发运行。这样既满足了用户的需要，又改善了系统的性能。\n虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。\n我们可以将虚拟内存看作是在磁盘上一片空间，当这片空间中的一部分访问比较频繁时，该部分数据会以页为单位被缓存到主存中以加速 CPU 访问数据的性\n能，虚拟内存利用空间较大的磁盘存储作为『内存』并使用主存储缓存进行加速，让上层认为操作系统的内存很大而且很快，然而区域很大的磁盘并不快，而很快的内存也并不大。\nLinux为什么需要虚拟内存:\n 为应用程序提供看起来容量足够大且访问足够快的存储。 通过共享代码库以减少物理内存的开销。让改动尽可能的少。 通过分配连续的虚拟内存（物理内存上不一定连续） 简化内存的连接、分配过程。 通过给各个进程分配不同的虚拟内存空间实现内存访问上的隔离，提供了一定的安全性。   拓展：\n​\t当我们在 Linux 中调用 fork 创建子进程时，实际上只复制了父进程的页表。\n 问题❓  当有一个作业很大，超过了内存的总容量，作业不能全部装入内存怎么办？ 有大量作业需要运行，但是由于内存容量不足以容纳这些所有的作业怎么办？(先执行一部分)  解决办法：\n 增加物理内存容量 逻辑上扩充内存容量(虚拟内存方法)  局部性原理🥇 程序在执行时将呈现出局部性规律，即在一较短的时间内，程序的执行仅局限于某个部分，相应地，它所访问的存储空间也局限于某个区域。\n 时间局部性：访问最近访问过的空间的可能性较大。 空间局部性：访问当前空间周围的空间的可能较大。   局部性原理使得虚拟存储技术的实现成为可能。\n 基于局部性原理可知，应用程序在运行之前没有必要将之全部装入内存，而仅须将那些当前要运行的少数页面或段先装入内存便可运行，其余部分暂留在盘上。程序在运行时，如果它所要访问的页(段)已调入内存，便可继续执行下去；但如果程序所要访问的页(段)尚未调入内存(称为缺页或缺段)，便发出缺页(段)中断请求，此时 OS 将利用请求调页(段)功能将它们调入内存，以使进程能继续执行下去。如果此时内存已满，无法再装入新的页(段)，OS 还须再利用页(段)的置换功能，将内存中暂时不用的页(段)调至盘上，腾出足够的内存空间后，再将要访问的页(段)调入内存，使程序继续执行下去。这样，便可使一个大的用户程序在较小的内存空间中运行，也可在内存中同时装入更多的进程，使它们并发执行。\n虚拟存储器📝 定义 **所谓虚拟存储器，是指具有请求调入功能和置换功能，能从逻辑上对内存容量加以扩充的一种存储器系统。**其逻辑容量由内存容量和外存容量之和所决定，其运行速度接近于内存速度，而每位的成本却又接近于外存。\n 当用户看到自己的程序能在系统中正常运行时，他会认为，该系统所具有的内存容量一定比自己的程序大，或者说，用户所感觉到的内存容量会比实际内存容量大得多。但用户所看到的大容量只是一种错觉，是虚的，故人们把这样的存储器称为虚拟存储器。\n 虚拟存储器并非可以无限大，其容量受外存大小和指令中地址长度两方面的限制。\n特征  多次性 对换性 虚拟性  实现方法 所有的虚拟存储器都是采用下述方式之一实现的：\n 请求分页系统 请求分段系统  请求分页存储管理方式 请求分页系统是建立在基本分页基础上的，为了能支持虚拟存储器功能，而增加了请求调页功能和页面置换功能。相应地，每次调入和换出的基本单位都是长度固定的页面，这使得请求分页系统在实现上要比请求分段系统简单(后者在换进和换出时是可变长度的段)。因此，请求分页便成为目前最常用的一种实现虚拟存储器的方式。\n请求页表机制(基本原理) 在请求分页系统中需要的主要数据结构是请求页表，其基本作用仍然是将用户地址空间中的逻辑地址映射为内存空间中的物理地址。为了满足页面换进换出的需要，在请求页表中又增加了四个字段。这样，在请求分页系统中的每个页表应含以下诸项(配合clock置换算法)：\n字段说明：\n 状态位(P)：用于指示该页是否已调入内存，供程序访问时参考。 访问字段(A)：记录本页在一段时间内被访问的次数，或者记录本页最近已有多久时间未被访问，供置换算法在选择换出页面时参考。 修改位(M)：表示该页在调入内存之后有没有被修改。供置换页面时参考。未修改则无需写入外存。 外存地址：用于指出该页在外存上的地址，通常是物理块号地址，供调入该页时参考。  缺页中断机构 在请求分页系统中，每当所要访问的页面不在内存时，便产生一缺页中断，请求 OS将缺的页调入内存。\n**缺页中断作为中断，它们同样需要经历诸如保护 CPU 环境、分析中断原因、转入缺页中断处理程序进行处理，以及在中断处理完成后再恢复 CPU 环境等几个步骤。**但缺页中断又是一种特殊的中断，它与一般的中断相比有着明显的区别，主要表现在下面两个方面：\n 在指令执行期间产生和处理中断信号。 一条指令在执行期间可能产生多次缺页中断。  地址变换机构 请求分页系统中的地址变换机构是在分页系统地址变换机构的基础上，为实现虚拟存储器，再增加了某些功能所形成的，如产生和处理缺页中断，以及从内存中换出一页的功能等等。下图示出了请求分页系统中的地址变换过程：\n在进行地址变换时，首先检索快表，试图从中找出所要访问的页。若找到，便修改页表项中的访问位，供置换算法选换出页面时参考。对于写指令，还须将修改位置成“1”,表示该页在调入内存后已被修改。然后利用页表项中给出的物理块号和页内地址形成物理地址。地址变换过程到此结束。\n如果在快表中未找到该页的页表项，则应到内存中去查找页表，再从找到的页表项中的状态位 P 来了解该页是否已调入内存。若该页已调入内存，这时应将该页的页表项写入快表。当快表已满时，则应先调出按某种算法所确定的页的页表项，然后再写入该页的页表项；若该页尚未调入内存，这时应产生缺页中断，请求 OS 从外存把该页调入内存。\n请求分页的内存分配 三个问题：\n  最小物理块数的确定。先分配给进程多少物理空间它才能先正常运行。\n  内存分配策略。\n  固定分配局部置换\n所谓固定分配，是指为每个进程分配一组固定数目的物理块，在进程运行期间不再改变。所谓局部置换，是指如果进程在运行中发现缺页，则只能从分配给该进程的 n 个页而中选出一页换出，然后再调入一页，以保证分配给该进程的内存空间不变。\n  可变分配全局置换\n所谓可变分配，是指先为每个进程分配一定数目的物理块，在进程运行期间，可根据情况做适当的增加或减少。所谓全局置换，是指如果进程在运行中发现缺页，则将 OS 所保留的空闲物理块(一般组织为一个空闲物理块队列)取出一块分配给该进程，或者以所有进程的全部物理块为标的，选择一块换出，然后将所缺之页调入。这样，分配给该进程的内存空间就随之增加。\n  可变分配局部置换\n该策略同样是基于进程的类型或根据程序员的要求，为每个进程分配一定数目的物理块，但当某进程发现缺页时，只允许从该进程在内存的页面中选择一页换出，这样就不会影响其它进程的运行。如果进程在运行中频繁地发生缺页中断，则系统须再为该进程分配若干附加的物理块，直至该进程的缺页率减少到适当程度为止。反之，若一个进程在运行过程中的缺页率特别低，则此时可适当减少分配给该进程的物理块数，但不应引起其缺页率的明显增加。\n    物理块分配算法\n 平均分配算法 比例分配算法 考虑优先权的分配算法    页面调入策略 问题：\n  何时调入页面\n 预调页策略，一次调入若干个相邻的页面。 请求调页机制，当请求的页面不存在内存，由OS将所需页面调入内存。    何处调入页面\n将请求分页系统中的外存分为两部分：用于存放文件的文件区和用于存放对换页而的对换区。通常，由于对换区是采用连续分配方式，而文件区是采用离散分配方式，所以对换区的数据存取(磁盘 I/O)速度比文件区的高。\n 系统拥有足够的对换区空间，这时可以全部从对换区调入所需页面，以提高调页速度。为此，在进程运行前，便须将与该进程有关的文件从文件区拷贝到对换区。 系统缺少足够的对换区空间，这时凡是不会被修改的文件，都直接从文件区调入；而当换出这些页面时，由于它们未被修改，则不必再将它们重写到磁盘(换出)，以后再调入时，仍从文件区直接调入。但对于那些可能被修改的部分，在将它们换出时便须调到对换区，以后需要时再从对换区调入。 UNIX 方式。由于与进程有关的文件都放在文件区，故凡是未运行过的页面，都应从文件区调入。而对于曾经运行过但又被换出的页面，由于是被放在对换区，因此在下次调入时应从对换区调入。由于 UNIX 系统允许页面共享，因此，某进程所请求的页面有可能已被其它进程调入内存，此时也就无需再从对换区调入。    页面调入过程\n每当程序所要访问的页面未在内存时(存在位为“0”)，便向 CPU 发出一缺页中断，中断处理程序首先保留 CPU 环境，分析中断原因后转入缺页中断处理程序。该程序通过杳找页表得到该页在外存的物理块后，如果此时内存能容纳新页，则启动磁盘 I/O，将所缺之页调入内存，然后修改页表。如果内存已满，则须先按照某种置换算法，从内存中选出一页准备换出；如果该页未被修改过(修改位为“0”)，可不必将该页写回磁盘；但如果此页已被修改(修改位为“1”)，则必须将它写回磁盘，然后再把所缺的页调入内存，并修改页表中的相应表项，置其存在位为“1”，并将此页表项写入快表中。在缺页调入内存后，利用修改后的页表形成所要访问数据的物理地址，再去访问内存数据。整个页面的调入过程对用户是透明的。\n  页面置换算法 不适当的算法可能会导致进程发生“抖动”(Thrashing)，即刚被换出的页很快又要被访问，需要将它重新调入，此时又需要再选一页调出；而此刚被调出的页很快又被访问,又需将它调入，如此频繁地更换页面，以致一个进程在运行中把大部分时间都花费在页面置换工作上，我们称该进程发生了“抖动”。\n假定系统为某进程分配了三个物理块，并考虑有以下的页面号引用串：\n7,0,1,2,0,3,0,4,2,3,0,3,2,1,2,0,1,7,0,1 最佳置换算法 是一种理想化的算法，具有最好的性能，但是实际上是实现不了的，但是可以作为评估其他算法的优劣。采用这种算法可以获取最低的缺页率。\n先进先出置换算法 该算法总是淘汰最先进入内存的页面，即选择在内存中驻留时间最久的页面予以淘汰。用链表就能够很容易的实现。\n最近最久未使用置换算法(LRU) FIFO 置换算法的性能之所以较差，是因为它所依据的条件是各个页面调入内存的时间，而页面调入的先后并不能反映页面的使用情况。最近最久未使用(LRU)的页面置换算法是根据页面调入内存后的使用情况做出决策的。由于无法预测各页面将来的使用情况，只能利用“最近的过去”作为“最近的将来”的近似，因此，LRU 置换算法是选择最近最久未使用的页面予以淘汰。该算法赋予每个页面一个访问字段，用来记录一个页而自上次被访问以来所经历的时间 t。当需淘汰一个页面时，选择现有页面中其 t 值最大的，即最近最久未使用的页面予以淘汰。\n算法实现(硬件支持)：\n  寄存器\n为了记录某进程在内存中各页的使用情况，须为每个在内存中的页面配置一个移位寄存器，可表示为：\n$$\nR = R_{n-1}R_{n-2}R_{n-3} … R_2R_1R_0\n$$\n当进程访问某物理块时，要将相应寄存器的 $R_{n-1}$位置成 1。此时，定时信号将每隔一定时间(例如 100 ms)将寄存器右移一位。如果我们把 n 位寄存器的数看作是一个整数，那么，具有最小数值的寄存器所对应的页面，就是最近最久未使用的页面。下图中第三个内存页面的R值最小，缺页时因该被换出：\n  特殊的栈\n可利用一个特殊的栈保存当前使用的各个页面的页面号。每当进程访问某页而时，便将该页面的页面号从栈中移出，将它压入栈顶。因此，栈顶始终是最新被访问页面的编号,而栈底则是最近最久未使用页面的页面号。\n  map + 双向链表实现LRU算法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75  struct MyNode { int k, v; MyNode(int tk = 0, int tv = 0) { k = tk; v = tv; } }; // @lc code=start class LRUCache { private: map\u0026lt;int, int\u0026gt; hashtable; list\u0026lt;MyNode *\u0026gt; cache; unsigned int capacity; public: LRUCache(int capacity) { this-\u0026gt;capacity = capacity; } int get(int key) { if (hashtable.find(key) != hashtable.end()) { MyNode *node = new MyNode(key, hashtable[key]); for (list\u0026lt;MyNode *\u0026gt;::iterator it = cache.begin(); it != cache.end(); it++) { if ((*it)-\u0026gt;k == key) { cache.erase(it); break; } } cache.push_front(node); return hashtable[key]; } return -1; } void put(int key, int value) { MyNode *node = new MyNode(key, value); if (hashtable.find(key) == hashtable.end()) { // 不存在这个Key  if (hashtable.size() \u0026gt;= capacity) { // 超过容量，移除队尾元素  MyNode *rnode = cache.back(); cache.pop_back(); hashtable.erase(rnode-\u0026gt;k); } hashtable[key] = value; cache.push_front(node); } else { // 存在这个key  // 移除  for (list\u0026lt;MyNode *\u0026gt;::iterator it = cache.begin(); it != cache.end(); it++) { if ((*it)-\u0026gt;k == key) { cache.erase(it); break; } } cache.push_front(node); hashtable[key] = value; } } };     最少使用置换算法(LFU) LFU（Least Frequently Used）最近最少使用算法。它是基于“如果一个数据在最近一段时间内使用次数很少，那么在将来一段时间内被使用的可能性也很小”的思路。\n注意LFU和LRU算法的不同之处，LRU的淘汰规则是基于访问时间，而LFU是基于访问次数的。举个简单的例子：\n为了能够淘汰最少使用的数据，因此LFU算法最简单的一种设计思路就是 利用一个数组存储 数据项，用hashmap存储每个数据项在数组中对应的位置，然后为每个数据项设计一个访问频次，当数据项被命中时，访问频次自增，在淘汰的时候淘汰访问频次最少的数据。这样一来的话，在插入数据和访问数据的时候都能达到O(1)的时间复杂度，在淘汰数据的时候，通过选择算法得到应该淘汰的数据项在数组中的索引，并将该索引位置的内容替换为新来的数据内容即可，这样的话，淘汰数据的操作时间复杂度为O(n)。\nClock置换算法 简单Clock置换算法 每页设置一个访问位，取值为0和1，当该页被访问时，访问位置为1。\n当利用简单 Clock 算法时，只需为每页设置一位访问位，再将内存中的所有页面都通过链接指针链接成一个循环队列。当某页被访问时，其访问位被置 1。置换算法在选择一页淘汰时，只需检查页的访问位。如果是 O，就选择该页换出；若为 1，则重新将它置 O，暂不换出，给予该页第二次驻留内存的机会，再按照 FIFO 算法检查下一个页面。当检查到队列中的最后一个页面时，若其访问位仍为 1，则再返回到队首去检查第一个页面。\n改进Clock置换算法 设置两个关键位，一个为访问位，一个为修改位。\n页面。由访问位 A 和修改位 M 可以组合成下面四种类型的页面：\n1 类(A=0，M=0)：表示该页最近既未被访问，又未被修改，是最佳淘汰页。\n2 类(A=0，M=1）：表示该页最近未被访问，但已被修改，并不是很好的淘汰页。\n3 类(A=1，M=O)：表示最近已被访问，但未被修改，该页有可能再被访问。\n4 类(A=1，M=1)：表示最近已被访问且被修改，该页可能再被访问。\n面中的哪一种。其执行过程可分成以下三步:\n 从指针所指示的当前位置开始，扫描循环队列，寻找 A=0 且 M=0 的第一类页面，将所遇到的第一个页面作为所选中的淘汰页。在第一次扫描期间不改变访问位 A。 如果第一步失败，即查找一轮后未遇到第一类页面，则开始第二轮扫描，寻找且 M=1 的第二类页面，将所遇到的第一个这类页面作为淘汰页。在第二轮扫描期间，将所有扫描过的页面的访问位都置 0。 如果第二步也失败，亦即未找到第二类页面，则将指针返回到开始的位置，并将所有的访问位复 0。然后重复第一步，即寻找 A=O 且 M=O 的第一类页面，如果仍失败，必要时再重复第二步，寻找 A=0 且 M=1 的第二类页面，此时就一定能找到被淘汰的页。  该算法与简单 Clock 算法比较，可减少磁盘的 I/O 操作次数。但为了找到一个可置换的页，可能须经过几轮扫描。换言之，实现该算法本身的开销将有所增加。\n参考链接：\n 为什么 Linux 需要虚拟内存 《操作系统》- 第四版  ","description":"虚拟内存是操作系统物理内存和进程之间的中间层，它为进程隐藏了物理内存这一概念，为进程提供了更加简洁和易用的接口以及更加复杂的功能。","id":51,"section":"posts","tags":["虚拟内存"],"title":"Linux虚拟内存与分页存储管理","uri":"https://hugo.jiahongw.com/zh/posts/linux/virtual-memory/"},{"content":"从今天开始，准备记录以下自己平时的想法。因为有趣的想法可能一瞬间就消失了。如果没有将这些想法及过程记录下来，后面可能被什么事情给耽搁了，很快就会忘记。这样前面的想法就只能进行到一半，没有后续了。我希望以后能够经常记录自己的想法，因为自己的记忆力其实不太好，这也许是一种方法能够让我坚持下去做某一件事情吧\n并且我还想到的一件事情就是，其实多写关于自己的想法还有一个好处，就是能够拓宽自己的思维。因为我在写东西的时候也喜欢和自己进行对话，这样能够得出很多不一样的idea. 🤠\n","description":"把有趣的东西记录下来，才能记住当下自己在做什么！","id":52,"section":"posts","tags":["life"],"title":"博客小记","uri":"https://hugo.jiahongw.com/zh/posts/ideas/first-thoughts/"},{"content":"数据库事务 事务（Transaction）是由一系列对系统中数据进行访问与更新的操作所组成的一个程序执行逻辑单元。事务是DBMS中最基础的单位，事务不可分割。\n数据库事务四大特性(ACID)  原子性：不可分割，要么全部完成提交，要么全部回滚 一致性：一致性是指事务必须使数据库从一个一致性状态变换到另一个一致性状态，也就是说一个事务执行之前和执行之后都必须处于一致性状态。 隔离性：多用户一起进行事务操作互不影响，相互隔离。 持久性：一个事务一旦被提交了，那么对数据库中的数据的改变就是永久性的，即便是在数据库系统遇到故障的情况下也不会丢失提交事务的操作。  数据库事务隔离级别 读取的问题\nusers    id name age     1 Joe 20   2 Jill 25      脏读\n当一个事务允许读取另外一个事务修改但未提交的数据时，就可能发生脏读。\n例子中，事务2修改了一行，但是没有提交，事务1读了这个没有提交的数据。现在如果事务2回滚了刚才的修改或者做了另外的修改的话，事务1中查到的数据就是不正确的了。\n  不可重复读\n在一次事务中，当一行数据获取两遍得到不同的结果表示发生了“不可重复读”.\n在基于锁的并发控制中“不可重复读”现象发生在当执行SELECT 操作时没有获得读锁或者SELECT操作执行完后马上释放了读锁； 多版本并发控制中当没有要求一个提交冲突(commit conflict)的事务回滚也会发生“不可重复读”现象。\n这个例子中，事务2提交成功，因此他对id为1的行的修改就对其他事务可见了。但是事务1在此前已经从这行读到了另外一个“age”的值。在可序列化（SERIALIZABLE）和可重复读的隔离级别，数据库在第二次SELECT请求的时候应该返回事务2更新之前的值。在提交读和未提交读，返回的是更新之后的值，这个现象就是不可重复读。\n 解决不可重复读：\n 要求事务2延迟到事务1提交或者回滚之后再执行。这种方式实现了T1, T2 的串行化调度。串行化调度可以支持可重复读。 另一种策略是多版本并发控制。为了得到更好的并发性能，允许事务2先提交。但因为事务1在事务2之前开始，事务1必须在其开始执行时间点的数据库的快照上面操作。当事务1最终提交时候，数据库会检查其结果是否等价于T1, T2串行调度。如果等价，则允许事务1提交，如果不等价，事务1需要回滚并抛出个串行化失败的错误     幻读\n在事务执行过程中，当两个完全相同的查询语句执行得到不同的结果集。这种现象称为“幻影读（phantom read）”\n当事务没有获取*范围锁*的情况下执行*SELECT \u0026hellip; WHERE*操作可能会发生“幻影读”。\n“幻影读”是不可重复读的一种特殊场景：当事务1两次执行SELECT \u0026hellip; WHERE检索一定范围内数据的操作中间，事务2在这个表中创建了(如INSERT)了一行新数据，这条新数据正好满足事务1的“WHERE”子句。\n需要指出的是事务1执行了两遍同样的查询语句。如果设了最高的隔离级别，两次会得到同样的结果集，这也正是数据库在可序列化（SERIALIZABLE）隔离级别上需要满足的。但是在较低的隔离级别上，第二次查询可能会得到不同的结果集。\n   事务隔离其实就是为了解决上面提到的脏读、不可重复读、幻读这几个问题\n 隔离级别\n  读未提交（READ UNCOMMITTED）\n未提交读（READ UNCOMMITTED）是最低的隔离级别。允许“脏读”（dirty reads），事务可以看到其他事务“尚未提交”的修改。\n  读提交 （READ COMMITTED）\n在提交读（READ COMMITTED）级别中，基于锁机制并发控制的DBMS需要对选定对象的写锁一直保持到事务结束，但是读锁在SELECT操作完成后马上释放。\n  可重复读 （REPEATABLE READ）\n在可重复读（REPEATABLE READS）隔离级别中，基于锁机制并发控制的DBMS需要对选定对象的读锁（read locks）和写锁（write locks）一直保持到事务结束。\n 为了解决不可重复读，或者为了实现可重复读，MySQL 采用了 MVVC (多版本并发控制) 的方式。\n 我们在数据库表中看到的一行记录可能实际上有多个版本，每个版本的记录除了有数据本身外，还要有一个表示版本的字段，记为 row trx_id，而这个字段就是使其产生的事务的 id，事务 ID 记为 transaction id，它在事务开始的时候向事务系统申请，按时间先后顺序递增。\n按照上面这张图理解，一行记录现在有 3 个版本，每一个版本都记录这使其产生的事务 ID，比如事务A的transaction id 是100，那么版本1的row trx_id 就是 100，同理版本2和版本3。\n读提交和可重复读的时候都提到了一个词，叫做快照，学名叫做一致性视图，这也是可重复读和不可重复读的关键。可重复读是在事务开始的时候生成一个当前事务全局性的快照，而读提交则是每次执行语句的时候都重新生成一次快照。\n  串行化 （SERIALIZABLE）\n串行化是4种事务隔离级别中隔离效果最好的，解决了脏读、可重复读、幻读的问题，但是效果最差，它将事务的执行变为顺序执行，与其他三个隔离级别相比，它就相当于单线程，后一个事务的执行必须等待前一个事务结束。读的时候加共享锁，也就是其他事务可以并发读，但是不能写。写的时候加排它锁，其他事务不能并发写也不能并发读。\n 在基于锁机制并发控制的DBMS实现可串行化，要求在选定对象上的读锁和写锁保持直到事务结束后才能释放。在SELECT 的查询中使用一个“WHERE”子句来描述一个范围时应该获得一个“范围锁”（range-locks）。这种机制可以避免“幻读”（phantom reads）现象\n   并发写问题\n存在这的情况，两个事务，对同一条数据做修改。最后结果应该是哪个事务的结果呢，肯定要是时间靠后的那个。\n假设事务A执行 update 操作， update 的时候要对所修改的行加行锁，这个行锁会在提交之后才释放。而在事务A提交之前，事务B也想 update 这行数据，于是申请行锁，但是由于已经被事务A占有，事务B是申请不到的，此时，事务B就会一直处于等待状态，直到事务A提交，事务B才能继续执行，如果事务A的时间太长，那么事务B很有可能出现超时异常。如下图所示。\n需要注意的是，加入查询的字段设置了索引，那么数据库系统可以很方便的给该行数据加上一个行锁；加入没有设置索引的话，数据库系统会直接将该表的所有行加上行锁，然后再遍历一遍，释放掉没用的行锁。\n解决幻读\n并发写问题的解决方式就是行锁，而解决幻读用的也是锁，叫做间隙锁，MySQL 把行锁和间隙锁合并在一起，解决了并发写和幻读的问题，这个锁叫做 Next-Key锁。\n在数据库中会为索引维护一套B+树，用来快速定位行记录。B+索引树是有序的，所以会把这张表的索引分割成几个区间。可能会有如下的B+树：\n如图所示，分成了3 个区间，(负无穷,10]、(10,30]、(30,正无穷]，在这3个区间是可以加间隙锁的。\n在事务A提交之前，事务B的插入操作只能等待，这就是间隙锁起得作用。当事务A执行update user set name='风筝2号’ where age = 10; 的时候，由于条件 where age = 10 ，数据库不仅在 age =10 的行上添加了行锁，而且在这条记录的两边，也就是(负无穷,10]、(10,30]这两个区间加了间隙锁，从而导致事务B插入操作无法完成，只能等待事务A提交。不仅插入 age = 10 的记录需要等待事务A提交，age\u0026lt;10、10\u0026lt;age\u0026lt;30 的记录页无法完成，而大于等于30的记录则不受影响，这足以解决幻读问题了。\n 这是有索引的情况，如果 age 不是索引列，那么数据库会为整个表加上间隙锁。所以，如果是没有索引的话，不管 age 是否大于等于30，都要等待事务A提交才可以成功插入。\n 隔离级别vs读现象\n   隔离级别 脏读 不可重复读 幻影读     未提交读 可能发生 可能发生 可能发生   提交读 - 可能发生 可能发生   可重复读 - - 可能发生   可序列化 - - -    可序列化（Serializable）隔离级别不等同于可串行化（Serializable）。可串行化调度是避免以上三种现象的必要条件，但不是充分条件。\n “可能发生”表示这个隔离级别会发生对应的现象，“-”表示不会发生。采用哪种隔离级别要根据系统需求权衡决定，其中，可重复读是 MySQL 的默认级别。\n 隔离级别vs 锁持续时间\n在基于锁的并发控制中，隔离级别决定了锁的持有时间。\u0026ldquo;C\u0026rdquo;-表示锁会持续到事务提交。 \u0026ldquo;S\u0026rdquo; –表示锁持续到当前语句执行完毕。如果锁在语句执行完毕就释放则另外一个事务就可以在这个事务提交前修改锁定的数据，从而造成混乱\n   隔离级别 写操作 读操作 范围操作 (\u0026hellip;where\u0026hellip;)     未提交读 S S S   提交读 C S S   可重复读 C C S   可序列化 C C C    MySQL隔离操作：\n 查看Mysql默认的隔离级别：  1 2 3 4 5 6 7  mysql\u0026gt; show variables like \u0026#39;transaction_isolation\u0026#39;; +-----------------------+-----------------+ | Variable_name | Value | +-----------------------+-----------------+ | transaction_isolation | REPEATABLE-READ | +-----------------------+-----------------+ 1 row in set, 1 warning (0.11 sec)   可以发现Mysql默认的隔离级别为可重复读\n修改改数据库的隔离级别：set [作用域] transaction isolation level [事务隔离级别]，具体如下：\n1  SET [SESSION | GLOBAL] TRANSACTION ISOLATION LEVEL {READ UNCOMMITTED | READ COMMITTED | REPEATABLE READ | SERIALIZABLE}。   数据库索引(INDEX) 数据库索引是为了增加查询速度而对表字段附加的一种标识，是对数据库表中一列或多列的值进行排序的一种结构。\nMysql创建索引：\n1  CREATE INDEX INDEX_NAME ON TABLE_NAME (COLUMN_LIST)   数据库的三大范式 第一范式\n当关系模式R的所有属性都不能再分解为更基本的数据单位时，称R是满足第一范式，即属性不可分\n第二范式\n如果关系模式R满足第一范式，并且R得所有非主属性都完全依赖于R的每一个候选关键属性，称R满足第二范式\n第三范式\n设R是一个满足第一范式条件的关系模式，X是R的任意属性集，如果X非传递依赖于R的任意一个候选关键字，称R满足第三范式，即非主属性不传递依赖于键码\n参考链接：\n https://www.cnblogs.com/fengzheng/p/12557762.html https://zh.wikipedia.org/wiki/%E4%BA%8B%E5%8B%99%E9%9A%94%E9%9B%A2#%E8%84%8F%E8%AF%BB  mysql的MVCC机制 MVCC的维基百科解释：多版本并发控制(Multiversion concurrency control， MCC 或 MVCC)，是数据库管理系统常用的一种并发控制，也用于程序设计语言实现事务内存。\n MVCC是一种多版本并发控制机制，是MySQL的InnoDB存储引擎实现隔离级别的一种具体方式，用于实现提交读和可重复读这两种隔离级别\n MVCC作用\nMVCC意图解决读写锁造成的多个、长时间的读操作饿死写操作问题。所以MVCC通过保存某个时间点的快照来实现该机制，每个事务读到的数据项都是一个历史快照（snapshot)并依赖于实现的隔离级别。写操作不覆盖已有数据项，而是创建一个新的版本，直至所在操作提交时才变为可见。快照隔离使得事物看到它启动时的数据状态。\n MVCC可以无锁实现。\n 常见的数据库优化方法  或者索引相关的点你全部都知道么？聚簇索引，非聚簇索引，普通索引，唯一索引，change buffer，表锁、行锁、间隙锁以及行锁并发情况下的最大TPS是多少？还有索引为啥会选择错误？这些大家知道嘛？\n 数据库的组成结构图：\n我们所谓的调优也就是在，执行器执行之前的分析器，优化器阶段完成的。\n  先跑sql explain\nMySQL 提供了一个 EXPLAIN 命令, 它可以对 SELECT 语句进行分析, 并输出 SELECT 执行的详细信息, 以供开发人员针对性优化.\nEXPLAIN 命令用法十分简单, 在 SELECT 语句前加上 Explain 就可以了, 例如:\n1  EXPLAIN SELECT * from user_info WHERE id \u0026lt; 300;   EXPLAIN 命令的输出内容大致如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  mysql\u0026gt; explain select * from user_info where id = 2\\G *************************** 1. row *************************** id: 1 select_type: SIMPLE table: user_info partitions: NULL type: const possible_keys: PRIMARY key: PRIMARY key_len: 8 ref: const rows: 1 filtered: 100.00 Extra: NULL 1 row in set, 1 warning (0.00 sec)   各列的含义如下:\n  id: SELECT 查询的标识符. 每个 SELECT 都会自动分配一个唯一的标识符.\n  select_type: SELECT 查询的类型.\n它的常用取值有:\n SIMPLE, 表示此查询不包含 UNION 查询或子查询 PRIMARY, 表示此查询是最外层的查询 UNION, 表示此查询是 UNION 的第二或随后的查询 DEPENDENT UNION, UNION 中的第二个或后面的查询语句, 取决于外面的查询 UNION RESULT, UNION 的结果 SUBQUERY, 子查询中的第一个 SELECT DEPENDENT SUBQUERY: 子查询中的第一个 SELECT, 取决于外面的查询. 即子查询依赖于外层查询的结果.    table: 查询的是哪个表\n  partitions: 匹配的分区\n  type: join 类型\ntype 字段比较重要, 它提供了判断查询是否高效的重要依据依据. 通过 type 字段, 我们判断此次查询是 全表扫描 还是 索引扫描 等.\ntype 常用的取值有:\n system: 表中只有一条数据. 这个类型是特殊的 const 类型. const: 针对主键或唯一索引的等值查询扫描, 最多只返回一行数据. const 查询速度非常快, 因为它仅仅读取一次即可.    possible_keys: 此次查询中可能选用的索引\npossible_keys 表示 MySQL 在查询时, 能够使用到的索引. 注意, 即使有些索引在 possible_keys 中出现, 但是并不表示此索引会真正地被 MySQL 使用到. MySQL 在查询时具体使用了哪些索引, 由 key 字段决定.\n  key: 此次查询中确切使用到的索引.\n  ref: 哪个字段或常数与 key 一起被使用\n  rows: 显示此查询一共扫描了多少行. 这个是一个估计值.\nrows 也是一个重要的字段. MySQL 查询优化器根据统计信息, 估算 SQL 要查找到结果集需要扫描读取的数据行数.\n这个值非常直观显示 SQL 的效率好坏, 原则上 rows 越少越好.\n  filtered: 表示此查询条件所过滤的数据的百分比\n  extra: 额外的信息\n    排除缓存干扰(Mysql8.0之前需要需要排除)\n我们在执行SQL的时候，记得加上SQL NoCache去跑SQL，这样跑出来的时间就是真实的查询时间了。\n 为什么缓存会失效，而且是经常失效？\n缓存失效比较频繁的原因就是，只要我们一对表进行更新，那这个表所有的缓存都会被清空，其实我们很少存在不更新的表。\n   覆盖索引\n我们在数据库查询的操作中，可能有回表的操作，我们希望不进行回表操作，在自己的索引上就查到自己想要的，不进行主键索引查找。\n如果在我们建立的索引上就已经有我们需要的字段，就不需要回表了，在电商里面也是很常见的，我们需要去商品表通过各种信息查询到商品id，id一般都是主键，可能sql类似这样：\n1  select itemId from itemCenter where size between 1 and 6   因为商品id itemId一般都是主键，在size索引上肯定会有我们这个值，这个时候就不需要回主键表去查询id信息了。\n由于覆盖索引可以减少树的搜索次数，显著提升查询性能，所以使用覆盖索引是一个常用的性能优化手段。\n  联合索引——构建两个属性之间的快速查询\n还是商品表举例，我们需要根据他的名称，去查他的库存，假设这是一个很高频的查询请求，你会怎么建立索引呢？\n 思考回表的消耗对SQL进行优化。\n 建立一个，名称和库存的联合索引，这样名称查出来就可以看到库存了，不需要查出id之后去回表再查询库存了，联合索引在我们开发过程中也是常见的，但是并不是可以一直建立的，大家要思考索引占据的空间。\n  最左匹配原则\n如果利用一个模糊查询 itemname like ’敖丙%‘，这样还是能利用到这个索引的，而且如果有这样的联合索引，大家也没必要去新建一个商品名称单独的索引了。\n 很多时候我们索引可能没建对，那你调整一下顺序，可能就可以优化到整个SQL了。\n   索引下推\n知道了前缀索引规则，那我就说一个官方帮我们优化的东西，索引下推。\n1  select * from itemcenter where name like \u0026#39;敖%\u0026#39; and size=22 and age = 20;   所以这个语句在搜索索引树的时候，只能用 “敖”，找到第一个满足条件的记录ID1，当然，这还不错，总比全表扫描要好。\n然后我们还可以使用索引下推进行优化：\n在MySQL 5.6之前，只能从ID1开始一个个回表，到主键索引上找出数据行，再对比字段值。\n而MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。\n  唯一索引普通索引选择\n当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InooDB会将这些更新操作缓存在change buffer中，这样就不需要从磁盘中读入这个数据页了。\n在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行change buffer中与这个页有关的操作，通过这种方式就能保证这个数据逻辑的正确性。\n 将change buffer中的操作应用到原数据页，得到最新结果的过程称为merge。除了访问这个数据页会触发merge外，系统有后台线程会定期merge。在数据库正常关闭（shutdown）的过程中，也会执行merge操作。\n 那么，什么条件下可以使用change buffer呢？\n对于唯一索引来说，所有的更新操作都要先判断这个操作是否违反唯一性约束。\n要判断表中是否存在这个数据，而这必须要将数据页读入内存才能判断，如果都已经读入到内存了，那直接更新内存会更快，就没必要使用change buffer了。\n因此，唯一索引的更新就不能使用change buffer，实际上也只有普通索引可以使用。\nchange buffer用的是buffer pool里的内存，因此不能无限增大，change buffer的大小，可以通过参数innodb_change_buffer_max_size来动态设置，这个参数设置为50的时候，表示change buffer的大小最多只能占用buffer pool的50%。\n将数据从磁盘读入内存涉及随机IO的访问，是数据库里面成本最高的操作之一，change buffer因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。\n  前缀索引\n我们存在邮箱作为用户名的情况，每个人的邮箱都是不一样的，那我们是不是可以在邮箱上建立索引，但是邮箱这么长，我们怎么去建立索引呢？\nMySQL是支持前缀索引的，也就是说，你可以定义字符串的一部分作为索引。默认地，如果你创建索引的语句不指定前缀长度，那么索引就会包含整个字符串。\n  Mysql各种引擎和区别  MySQL中的数据用各种不同的技术存储在文件（或者内存）中。这些技术中的每一种技术都使用不同的存储机制、索引技巧、锁定水平并且最终提供广泛的不同的功能和能力。通过选择不同的技术，你能够获得额外的速度或者功能，从而改善你的应用的整体功能。\n MySQL存储引擎主要有： MyIsam、InnoDB、Memory、Blackhole、CSV、Performance_Schema、Archive、Federated、Mrg_Myisam。\n但是最常用的是InnoDB和Mylsam。\nInnoDB\nInnoDB是一个事务型的存储引擎，有行级锁定和外键约束。\nInnodb引擎提供了对数据库ACID事务的支持，并且实现了SQL标准的四种隔离级别，关于数据库事务与其隔离级别的内容请见数据库事务与其隔离级别这类型的文章。该引擎还提供了行级锁和外键约束，它的设计目标是处理大容量数据库系统，它本身其实就是基于MySQL后台的完整数据库系统，MySQL运行时Innodb会在内存中建立缓冲池，用于缓冲数据和索引。但是该引擎不支持FULLTEXT类型的索引，而且它没有保存表的行数，当SELECT COUNT(*) FROM TABLE时需要扫描全表。当需要使用数据库事务时，该引擎当然是首选。由于锁的粒度更小，写操作不会锁定全表，所以在并发较高时，使用Innodb引擎会提升效率。但是使用行级锁也不是绝对的，如果在执行一个SQL语句时MySQL不能确定要扫描的范围，InnoDB表同样会锁全表。\n 适用场景：\n经常更新的表，适合处理多重并发的更新请求。\n 索引结构：InnoDB是B+Treee索引结构。并且Innodb的索引文件本身就是数据文件，即B+Tree的数据域存储的就是实际的数据，这种索引就是聚集索引。\n InnoDB的辅助索引数据域存储的也是相应记录主键的值而不是地址，所以当以辅助索引查找时，会先根据辅助索引找到主键，再根据主键索引找到实际的数据。所以Innodb不建议使用过长的主键，否则会使辅助索引变得过大。建议使用自增的字段作为主键，这样B+Tree的每一个结点都会被顺序的填满，而不会频繁的分裂调整，会有效的提升插入数据的效率。\n Mylsam\nMyIASM是MySQL默认的引擎，但是它没有提供对数据库事务的支持，也不支持行级锁和外键，因此当INSERT或UPDATE数据时即写操作需要锁定整个表，效率便会低一些。MyIsam 存储引擎独立于操作系统，也就是可以在windows上使用，也可以比较简单的将数据转移到linux操作系统上去。\n 适用场景：\n不支持事务的设计，但是并不代表着有事务操作的项目不能用MyIsam存储引擎，可以在service层进行根据自己的业务需求进行相应的控制。\n不支持外键的表设计。\n查询速度很快，如果数据库insert和update的操作比较多的话比较适用。\n整天对表进行加锁的场景。\nMyISAM极度强调快速读取操作。\n 索引结构：MyISAM索引用的B+ tree来储存数据，MyISAM索引的指针指向的是键值的地址，地址存储的是数据。B+Tree的数据域存储的内容为实际数据的地址，也就是说它的索引和实际的数据是分开的，只不过是用索引指向了实际的数据，这种索引就是所谓的非聚集索引。\nInnoDB和MyISAM的区别\n  事务：MyISAM类型不支持事务处理等高级处理，而InnoDB类型支持，提供事务支持已经外部键等高级数据库功能\n  性能：MyISAM类型的表强调的是性能，其执行数度比InnoDB类型更快。\n  行数保存：InnoDB 中不保存表的具体行数，也就是说，执行select count() fromtable时，InnoDB要扫描一遍整个表来计算有多少行，但是MyISAM只要简单的读出保存好的行数即可。注意的是，当count()语句包含where条件时，两种表的操作是一样的。\n  索引存储：对于AUTO_INCREMENT类型的字段，InnoDB中必须包含只有该字段的索引，但是在MyISAM表中，可以和其他字段一起建立联合索引。MyISAM支持全文索引（FULLTEXT）、压缩索引，InnoDB不支持。\nMyISAM的索引和数据是分开的，并且索引是有压缩的，内存使用率就对应提高了不少。能加载更多索引，而Innodb是索引和数据是紧密捆绑的，没有使用压缩从而会造成Innodb比MyISAM体积庞大不小。\nInnoDB存储引擎被完全与MySQL服务器整合，InnoDB存储引擎为在主内存中缓存数据和索引而维持它自己的缓冲池。InnoDB存储它的表＆索引在一个表空间中，表空间可以包含数个文件（或原始磁盘分区）。这与MyISAM表不同，比如在MyISAM表中每个表被存在分离的文件中。InnoDB 表可以是任何尺寸，即使在文件尺寸被限制为2GB的操作系统上。\n  服务器数据备份：InnoDB必须导出SQL来备份，LOAD TABLE FROM MASTER操作对InnoDB是不起作用的，解决方法是首先把InnoDB表改成MyISAM表，导入数据后再改成InnoDB表，但是对于使用的额外的InnoDB特性(例如外键)的表不适用。\nMyISAM应对错误编码导致的数据恢复速度快。MyISAM的数据是以文件的形式存储，所以在跨平台的数据转移中会很方便。在备份和恢复时可单独针对某个表进行操作。\nInnoDB是拷贝数据文件、备份 binlog，或者用 mysqldump，在数据量达到几十G的时候就相对痛苦了。\n  锁的支持：MyISAM只支持表锁。InnoDB支持表锁、行锁 行锁大幅度提高了多用户并发操作的新能。但是InnoDB的行锁，只是在WHERE的主键是有效的，非主键的WHERE都会锁全表的。\n  参考链接：\n 有哪些常见的数据库优化方法？ MySQL 性能优化神器 Explain 使用分析  ","description":"","id":53,"section":"talks","tags":[""],"title":"Database Talk","uri":"https://hugo.jiahongw.com/zh/talks/database-talk/"},{"content":"546. 移除盒子 给出一些不同颜色的盒子，盒子的颜色由数字表示，即不同的数字表示不同的颜色。\n你将经过若干轮操作去去掉盒子，直到所有的盒子都去掉为止。每一轮你可以移除具有相同颜色的连续 k 个盒子（k \u0026gt;= 1），这样一轮之后你将得到 k*k 个积分。\n当你将所有盒子都去掉之后，求你能获得的最大积分和。\n示例：\n输入：boxes = [1,3,2,2,2,3,4,3,1] 输出：23 解释： [1, 3, 2, 2, 2, 3, 4, 3, 1] ----\u0026gt; [1, 3, 3, 4, 3, 1] (3*3=9 分) ----\u0026gt; [1, 3, 3, 3, 1] (1*1=1 分) ----\u0026gt; [1, 1] (3*3=9 分) ----\u0026gt; [] (2*2=4 分) 提示：\n 1 \u0026lt;= boxes.length \u0026lt;= 100 1 \u0026lt;= boxes[i] \u0026lt;= 100  分析 一般来说，求最值的问题几乎和动态规划有关系，那么这题也是从动态规划的角度去思考解决方案。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Solution { int len; int removeBoxes(vector\u0026lt;int\u0026gt;\u0026amp; boxes,int i,int j,int k,vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026gt;\u0026amp; dp) { if(i \u0026gt; j) return 0; if(dp[i][j][k] \u0026gt; 0) return dp[i][j][k]; for(;i+1 \u0026lt;= j \u0026amp;\u0026amp; boxes[i+1] == boxes[i];++i,++k); int res = (k+1) * (k+1) + removeBoxes(boxes,i+1,j,0,dp); for(int m = i + 1;m \u0026lt;= j;++m) if(boxes[m] == boxes[i]) res = max(res,removeBoxes(boxes,i+1,m-1,0,dp) + removeBoxes(boxes,m,j,k+1,dp)); return dp[i][j][k] = res; } public: int removeBoxes(vector\u0026lt;int\u0026gt;\u0026amp; boxes) { len = boxes.size(); // dp[i][j][k] 表示从i到j的范围有k个相同颜色的数字在i的前面，并且下标i的颜色也与它们相同  vector\u0026lt;vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026gt; dp(len+1,vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;(len+1,vector\u0026lt;int\u0026gt;(len+1,0))); return removeBoxes(boxes,0,len-1,0,dp); } };   5490. 吃掉 N 个橘子的最少天数 厨房里总共有 n 个橘子，你决定每一天选择如下方式之一吃这些橘子：\n 吃掉一个橘子。 如果剩余橘子数 n 能被 2 整除，那么你可以吃掉 n/2 个橘子。 如果剩余橘子数 n 能被 3 整除，那么你可以吃掉 2*(n/3) 个橘子。  每天你只能从以上 3 种方案中选择一种方案。\n请你返回吃掉所有 n 个橘子的最少天数。\n示例 1：\n输入：n = 10 输出：4 解释：你总共有 10 个橘子。 第 1 天：吃 1 个橘子，剩余橘子数 10 - 1 = 9。 第 2 天：吃 6 个橘子，剩余橘子数 9 - 2*(9/3) = 9 - 6 = 3。（9 可以被 3 整除） 第 3 天：吃 2 个橘子，剩余橘子数 3 - 2*(3/3) = 3 - 2 = 1。 第 4 天：吃掉最后 1 个橘子，剩余橘子数 1 - 1 = 0。 你需要至少 4 天吃掉 10 个橘子。 示例 2：\n输入：n = 6 输出：3 解释：你总共有 6 个橘子。 第 1 天：吃 3 个橘子，剩余橘子数 6 - 6/2 = 6 - 3 = 3。（6 可以被 2 整除） 第 2 天：吃 2 个橘子，剩余橘子数 3 - 2*(3/3) = 3 - 2 = 1。（3 可以被 3 整除） 第 3 天：吃掉剩余 1 个橘子，剩余橘子数 1 - 1 = 0。 你至少需要 3 天吃掉 6 个橘子。 示例 3：\n输入：n = 1 输出：1 示例 4：\n输入：n = 56 输出：6 提示：\n 1 \u0026lt;= n \u0026lt;= 2*10^9  分析 整个问题就是一个求最值的问题，可以使用递归进行深度优先判断，也可以使用动态规划建立一个dp数组进行求解：\n代码 递归求解(超时)：\n1 2 3 4 5 6 7 8 9  int solve(int n) { if(n == 0) return 0; if(n == 1) return 1; int r1 = minDays(n - 1); int r2 = n%2==0? minDays(n - n/2):INT_MAX; int r3 = n%3==0? minDays(n -2*(n/3)):INT_MAX; return min(min(r1,r2),r3) + 1; }   加上哈希表(堆栈溢出)：\n1 2 3 4 5 6 7 8 9 10 11  unordered_map\u0026lt;int,int\u0026gt; table; int solve(int n) { if(n == 0) return 0; if(n == 1) return 1; if(table.find(n) != table.end()) return table[n]; int r1 = minDays(n - 1); int r2 = n%2==0? minDays(n - n/2):INT_MAX; int r3 = n%3==0? minDays(n -2*(n/3)):INT_MAX; return table[n] = min(min(r1,r2),r3) + 1; }   动态规划(超出时间限制)：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  int minDays(int n) { vector\u0026lt;int\u0026gt; dp(n+1,0); for(int i = 1;i \u0026lt;= n;++i) { if(i % 6 == 0) { dp[i] = min(min(dp[i - 2*(i/3)],dp[i-1]),dp[i - i/2]) + 1; } else if(i % 2 == 0) dp[i] = min(dp[i - i/2],dp[i-1]) + 1; else if(i % 3 == 0) dp[i] = min(dp[i - 2*(i/3)],dp[i-1]) + 1; else dp[i] = dp[i-1] + 1; } return dp[n]; }   离散化递归：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  class Solution { unordered_map\u0026lt;int,int\u0026gt; table; int solve(int n) { if(n == 0 || n == 1) return n; if(table.find(n) != table.end()) return table[n]; table[n] = min((n\u0026amp;1) + solve(n/2),(n%3) + solve(n/3))+1; return table[n]; } public: int minDays(int n) { return solve(n); } };   743. 网络延迟时间 有 N 个网络节点，标记为 1 到 N。\n给定一个列表 times，表示信号经过有向边的传递时间。 times[i] = (u, v, w)，其中 u 是源节点，v 是目标节点， w 是一个信号从源节点传递到目标节点的时间。\n现在，我们从某个节点 K 发出一个信号。需要多久才能使所有节点都收到信号？如果不能使所有节点收到信号，返回 -1。\n示例：\n输入：times = [[2,1,1],[2,3,1],[3,4,1]], N = 4, K = 2 输出：2 注意:\n N 的范围在 [1, 100] 之间。 K 的范围在 [1, N] 之间。 times 的长度在 [1, 6000] 之间。 所有的边 times[i] = (u, v, w) 都有 1 \u0026lt;= u, v \u0026lt;= N 且 0 \u0026lt;= w \u0026lt;= 100。  分析 本题为一个图算法题，两点之间的时间可以抽象成路程，那么本题相当于求某一点到其他各点的最短路径，然后求出各点最短路径的最大值。\n常见的最短路问题分为两类：单源最短路和多源最短路。前者只需要求一个固定的起点到各个顶点的最短路径，后者则要求得出任意两个顶点之间的最短路径。\nDijkstra算法 Dijkstra(迪杰斯特拉)算法是典型的单源最短路径算法，用于计算一个节点到其他所有节点的最短路径。主要特点是以起始点为中心向外层层扩展，直到扩展到终点为止。算法主要的思想是贪心法。\n适用范围\n 1、不能处理负权边或环 2、可以处理正权边 3、可以处理无向图和有向图  使用步骤\n 初始化邻接矩阵 初始化还未确定最短路径的节点列表 双重循环：\n最外层为除源点之外的其他节点的遍历\n里面为遍历和更新未确定距离的节点列表的遍历\n3.1、从还未确定最短路径的节点列表中找出距离源点最近的节点\n3.2、更新还未确定最短路径的节点列表\n3.3、根据找到的这个最短路径节点，更新每一个还未确定最短路径的节点到源点的距离 根据题目要求计算结果  Floyd算法 Floyd算法是一个经典的动态规划算法。是解决任意两点间的最短路径(称为多源最短路径问题)的一种算法，可以正确处理有向图或负权的最短路径问题。\n其核心思想就是从任意节点u到任意节点v的最短路径有2种：\n 是直接从u到v 是从u经过若干个节点k到v  所以，我们假设graph(u,v)为节点u到节点v的最短路径的距离(当然，不同的题目代表的不一样，比如有的可能是花费，需要灵活变通)，对于每一个节点k(1~N个节点)，我们检查graph(u,k) + graph(k,v) \u0026lt; graph(u,v)是否成立，如果成立，证明从u到k再到v的路径比u直接到v的路径短，我们便设置graph(u,v) = graph(u,k) + graph(k,v)，当我们遍历完所有节点k，graph(u,v)中记录的便是u到v的最短路径的距离。\n适用范围\n 1、可以处理负权边 2、不能处理负权环 3、可以处理无向图和有向图  使用步骤\n  初始化邻接矩阵\n  三重循环：\n 最外层为中间节点k的遍历\n里面两层分别为节点u和节点v的遍历\n 2.1、根据k为中间跳节点更新(u, v)的最短距离\n  根据题目要求计算结果\n  代码 Dijkstra算法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  class Solution { public: int networkDelayTime(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; times, int N, int K) { const int INF = 102; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; graph(N+1,vector\u0026lt;int\u0026gt;(N+1,INF)); for(auto\u0026amp; v:times) graph[v[0]][v[1]] = v[2]; vector\u0026lt;int\u0026gt; dist(N + 1,INF); vector\u0026lt;bool\u0026gt; st(N + 1,false); // 设置起始点  dist[K] = 0; for(int i = 1;i \u0026lt; N;++i) // 外层循环N-1次  { int t = -1; int tmin = INF; for(int j = 1;j \u0026lt;= N;++j) { // 从还未确定最短路径的节点列表中找出距离源点最近的节点  if(!st[j] \u0026amp;\u0026amp; (dist[j] \u0026lt; tmin)) { t = j; tmin = dist[j]; } } st[t] = true; // 标记确定最短路径  // 用t更新其他点的距离  for(int j = 1;j \u0026lt;= N;++j) dist[j] = min(dist[j],dist[t] + graph[t][j]); } int r = *max_element(dist.begin() + 1,dist.end()); return r == INF ? -1:r; } };   Floyd算法(十分暴力)\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  int Floyd(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; times, int N, int K) { const int INF = 102; vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt; dist(N+1,vector\u0026lt;int\u0026gt;(N+1,INF)); for(int i = 1;i \u0026lt;= N;++i) dist[i][i] = 0; for(auto\u0026amp; v:times) dist[v[0]][v[1]] = min(dist[v[0]][v[1]],v[2]); for(int k = 1;k \u0026lt;= N;++k) for(int i = 1;i \u0026lt;= N;++i) for(int j = 1;j \u0026lt;= N;++j) if(i != j) dist[i][j] = min(dist[i][j],dist[i][k]+dist[k][j]); int r = 0; for(int i = 1;i \u0026lt;= N;++i) r = max(r,dist[K][i]); return r == INF?-1:r; }   堆优化版的Dijkstra算法\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  class Solution { public: int networkDelayTime(vector\u0026lt;vector\u0026lt;int\u0026gt;\u0026gt;\u0026amp; times, int N, int K) { const int INF = 0x3f3f3f3f; typedef pair\u0026lt;int, int\u0026gt; PII; // first:距离; second: 几号点  vector\u0026lt;bool\u0026gt; st(N+1, false); // 是否已得到最短距离  vector\u0026lt;int\u0026gt; dist(N+1, INF); // 距离起始点的最短距离  unordered_map\u0026lt;int, vector\u0026lt;PII\u0026gt;\u0026gt; graph; // 邻接表；u-\u0026gt;v,权重w  priority_queue\u0026lt;PII, vector\u0026lt;PII\u0026gt;, greater\u0026lt;PII\u0026gt;\u0026gt; heap; // 小顶堆；维护到起始点的最短距离和点  for (auto \u0026amp;t: times){ // 初始化邻接表  graph[t[0]].push_back({t[2],t[1]}); } heap.push({0, K}); dist[K] = 0; while(heap.size()){ auto t = heap.top(); heap.pop(); int ver = t.second, distance = t.first; if (st[ver]) continue; // 之前更新过，是冗余备份  st[ver] = true; for (auto \u0026amp;p: graph[ver]){ if (dist[p.second] \u0026gt; distance + p.first){ // 用t去更新其他点到起始点的最短距离  dist[p.second] = distance + p.first; heap.push({dist[p.second], p.second}); } } } int ans = *max_element(dist.begin()+1, dist.end()); return ans == INF ? -1: ans; } };   参考链接：\n 学图论，你真的了解最短路吗？ https://leetcode-cn.com/problems/network-delay-time/solution/csetban-dui-you-hua-dijkstra-by-ray-152/  109. 有序链表转换二叉搜索树 给定一个单链表，其中的元素按升序排序，将其转换为高度平衡的二叉搜索树。\n本题中，一个高度平衡二叉树是指一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1。\n示例:\n给定的有序链表： [-10, -3, 0, 5, 9], 一个可能的答案是：[0, -3, 9, -10, null, 5], 它可以表示下面这个高度平衡二叉搜索树： 0 / \\ -3 9 / / -10 5 分析 构建一个平衡二叉树的关键就是左右子树的高度差不超过1，那么我们可以每次取链表中间的节点作为当前子树的根节点，然后递归链表左边的子链表和右边的子链表进行递归求解。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  class Solution { public: TreeNode* sortedListToBST(ListNode* head) { if(head == nullptr) return nullptr; // 空链表情况  if(head-\u0026gt;next == nullptr) // 链表长度为1  { TreeNode *tt = new TreeNode(head-\u0026gt;val); return tt; } ListNode *slow = head; ListNode * fast = head; ListNode *slow_pre = nullptr; // 下面快慢指针找到链表的中间节点  while(fast-\u0026gt;next \u0026amp;\u0026amp; fast-\u0026gt;next-\u0026gt;next) { slow_pre = slow; slow = slow-\u0026gt;next; fast = fast-\u0026gt;next-\u0026gt;next; } TreeNode *t; // 判断并且递归求解  if(slow_pre == nullptr) { t = new TreeNode(slow-\u0026gt;next-\u0026gt;val); slow-\u0026gt;next = nullptr; t-\u0026gt;left = sortedListToBST(head); t-\u0026gt;right = nullptr; } else { t = new TreeNode(slow-\u0026gt;val); slow_pre-\u0026gt;next = nullptr; t-\u0026gt;left = sortedListToBST(head); t-\u0026gt;right = sortedListToBST(slow-\u0026gt;next); } return t; } };   647. 回文子串 给定一个字符串，你的任务是计算这个字符串中有多少个回文子串。\n具有不同开始位置或结束位置的子串，即使是由相同的字符组成，也会被视作不同的子串。\n示例 1：\n输入：\u0026quot;abc\u0026quot; 输出：3 解释：三个回文子串: \u0026quot;a\u0026quot;, \u0026quot;b\u0026quot;, \u0026quot;c\u0026quot; 示例 2：\n输入：\u0026quot;aaa\u0026quot; 输出：6 解释：6个回文子串: \u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;a\u0026quot;, \u0026quot;aa\u0026quot;, \u0026quot;aa\u0026quot;, \u0026quot;aaa\u0026quot; 提示：\n 输入的字符串长度不会超过 1000 。  分析 中心拓展法。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30  class Solution { public: int countSubstrings(string s) { int r = 0; int len = s.length(); // 奇数类型  for(int i = 0;i \u0026lt; len;++i) { ++r; int left = i - 1; int right = i + 1; while(left \u0026gt;= 0 \u0026amp;\u0026amp; right \u0026lt; len \u0026amp;\u0026amp; s[left] == s[right]) { ++r; --left; ++right; } left = i; right = i + 1; // 偶数类型  while(left \u0026gt;= 0 \u0026amp;\u0026amp; right \u0026lt; len \u0026amp;\u0026amp; s[left] == s[right]) { ++r; --left; ++right; } } return r; } };   28. 实现 strStr() 实现 strStr() 函数。\n给定一个 haystack 字符串和一个 needle 字符串，在 haystack 字符串中找出 needle 字符串出现的第一个位置 (从0开始)。如果不存在，则返回 -1。\n示例 1:\n输入: haystack = \u0026quot;hello\u0026quot;, needle = \u0026quot;ll\u0026quot; 输出: 2 示例 2:\n输入: haystack = \u0026quot;aaaaa\u0026quot;, needle = \u0026quot;bba\u0026quot; 输出: -1 说明:\n当 needle 是空字符串时，我们应当返回什么值呢？这是一个在面试中很好的问题。\n对于本题而言，当 needle 是空字符串时我们应当返回 0 。这与C语言的 strstr() 以及 Java的 indexOf() 定义相符。\n分析 使用KMP算法。\nKMP算法\nKMP 是一种模式匹配算法，要解决的问题可以形式化为：给定模式串 T 与目标串 S，我们要在目标串 S 中寻找 T 的所有出现。\n使用KMP算法最关键的一步是构建next数组。next[i]储存的是string中前i+1位字符串前缀和后缀的最长长度。如abadefg，next[2]存的是aba这个字符串前缀和后缀的最长长度。但是这里为了和代码相对应，将next数组的大小设置为字符串的长度加1。\n假如我们现在求字符串\u0026quot;abababac\u0026quot;的next数组:\n在下标为0的时候设置next[0] = -1;并且i = 0，j = -1\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1            一个字符的字符串的最长相同前缀和后缀的长度为0，此时i = 1,j = 0\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0           接下来str[j] != str[i]，j的值又变为next[j] = next[0] = -1；然后继续执行得到next[++i] = ++j，即next[2] = 0,此时i = 2,j = 0;\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0          接下来str[j] == str[i] ,next[++i] = ++j，即next[30] = 1，此时i = 3,j = 1\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1         接下来str[i] == str[j]，则next[++i] = ++j，即next[4] = 2，此时i = 4,j = 2\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1 2        接下来str[i] == str[j]，则next[++i] = ++j，即next[5] = 3，此时i = 5,j = 3\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1 2 3       接下来str[i] == str[j]，则next[++i] = ++j，即next[6] = 4，此时i = 6,j = 4\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1 2 3 4      接下来str[i] == str[j]，则next[++i] = ++j，即next[7] = 5，此时i = 7,j = 5\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1 2 3 4 5     接下来str[i] != str[j]，j = next[j] = next[5] = 3;i = 7;此时str[3] != str[7],j = next[j] = next[3] = 1;此时str[1] != str[7],j = next[j] = next[1] = 0;此时str[0] != str[7],j = next[j] = next[0] = -1;接下来next[++i] = next[8] = ++j = 0\n   index 0 1 2 3 4 5 6 7 8     str NULL a b a b a b a c   next -1 0 0 1 2 3 4 5 0    匹配字符串的思路与构建next数组的思路类似。\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  class Solution { public: int strStr(string haystack, string needle) { if(needle == \u0026#34;\u0026#34;) return 0; int n = haystack.length(); // 构建next数组  int m = needle.length(); vector\u0026lt;int\u0026gt; next(m + 1,0); for(int i = 0,j = next[0] = -1;i \u0026lt; m;next[++i] = ++j) while(~j \u0026amp;\u0026amp; needle[j] != needle[i]) j = next[j]; // 搜索  for(int i = 0,j = 0;i \u0026lt; n;++i) { while(j \u0026gt; 0 \u0026amp;\u0026amp; haystack[i] != needle[j]) j = next[j]; if(haystack[i] == needle[j]) ++j; if(j == m) return (i - m + 1); } return -1; } };   参考链接：\n 【算法ABC】KMP 算法 动态规划之KMP字符匹配算法 从头到尾彻底理解KMP  459. 重复的子字符串 给定一个非空的字符串，判断它是否可以由它的一个子串重复多次构成。给定的字符串只含有小写英文字母，并且长度不超过10000。\n示例 1:\n输入: \u0026quot;abab\u0026quot; 输出: True 解释: 可由子字符串 \u0026quot;ab\u0026quot; 重复两次构成。 示例 2:\n输入: \u0026quot;aba\u0026quot; 输出: False 示例 3:\n输入: \u0026quot;abcabcabcabc\u0026quot; 输出: True 解释: 可由子字符串 \u0026quot;abc\u0026quot; 重复四次构成。 (或者子字符串 \u0026quot;abcabc\u0026quot; 重复两次构成。) 分析 假如有重复，那么至少重复两个相同的字符串，假如A是相同的字符串，AA是一个最小重复的字符串，即s = AA，当我们执行s + s的时候，得到AAAA，我们在中间也可以找到与原来字符串相等的子串AA，那么也就证明了s中存在重复的子串，其中子串匹配的方法可以使用KMP算法。参考\n代码 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  class Solution { public: bool repeatedSubstringPattern(string s) { string str = s.substr(1) + s.substr(0,s.length()-1); string pattern = s; int n = str.length(); int m = pattern.length(); vector\u0026lt;int\u0026gt; next(m+1); for(int i = 0,j = next[0] = -1;i \u0026lt; m;next[++i] = ++j) { while(~j \u0026amp;\u0026amp; pattern[i] != pattern[j]) j = next[j]; } for(int i = 0,j = 0;i \u0026lt; n;++i) { while(j \u0026gt; 0 \u0026amp;\u0026amp; str[i] != pattern[j]) j = next[j]; if(str[i] == pattern[j]) ++j; if(j == m) return true; } return false; } };   ","description":"","id":54,"section":"talks","tags":[""],"title":"Leetcode Problem Solve","uri":"https://hugo.jiahongw.com/zh/talks/leetcode/"},{"content":"哈希表 什么是哈希表？\n哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。也就是说，它通过把关键码值映射到表中一个位置来访问记录，以加快查找的速度。这个映射函数叫做散列函数，存放记录的数组叫做散列表。\n 哈希表hashtable(key，value) 就是把Key通过一个固定的算法函数既所谓的哈希函数转换成一个整型数字，然后就将该数字对数组长度进行取余，取余结果就当作数组的下标，将value存储在以该数字为下标的数组空间里。（或者：把任意长度的输入（又叫做预映射， pre-image），通过散列算法，变换成固定长度的输出，该输出就是散列值。这种转换是一种压缩映射，也就是，散列值的空间通常远小于输入的空间，不同的输入可能会散列成相同的输出，而不可能从散列值来唯一的确定输入值。简单的说就是一种将任意长度的消息压缩到某一固定长度的消息摘要的函数。）\n 其中，记录的位置 = H(关键字)，H称为哈希函数。\n哈希构造方法   直接定址法\n例如如果我们现在要对0-100岁的人口数字统计表，那么我们对年龄这个关键字就可以直接用年龄的数字作为地址。此时f(key) = key。\n 这个时候，我们可以得出这么个哈希函数：f(0) = 0，f(1) = 1，……，f(20) = 20。这个是根据我们自己设定的直接定址来的。人数我们可以不管，我们关心的是如何通过关键字找到地址。\n   除留余数法\n除留余数法此方法为最常用的构造散列函数方法。对于散列表长为m的散列函数公式为：\n$$\nf( key ) = key \\mod p ( p ≤ m )\n$$\n mod是取模（求余数）的意思。事实上，这方法不仅可以对关键字直接取模，也可在折叠、平方取中后再取模。\n   数字分析法\n如下图所示，有80个记录，每一行为一个记录中的键，假设表长为100，则可取两位十进制数组成哈希地址。\n  折叠法\n将关键字分成位数相同的几部分（最后一位可以不同），然后取叠加和作为哈希地址，这一方法被称为折叠法。当表的键位数很多，而且每一位上数字分布比较均匀的时候， 可以考虑采用这一方法。 折叠法有移位叠加和间位叠加两种方法例如国际标准图书编号0-442-20586-4的哈希地址可以用这两种方法表示为\n  平方取中法\n取关键字平方后的中间几位为哈希地址，这种方法叫做平方取中法。它弥补了数字分析法的一些缺陷，因为我们有时并不能知道键的全部情况，取其中几位也不一定合适，而一个数平方后的中间几个数和原数的每一位都相关，由此我们就能得到随机性更强的哈希地址取的位数由表长决定。\n  哈希表处理冲突的方法   链地址法\n冲突的关键字存储在一个链表中，查找的时候可能需要遍历链表。例如下面：\n  开放地址法\n开放定址法是指可存放新表项的空闲地址，既向它的同义词表项开放，又向它的非同义词表项开放。\n一般有一个递推公式:l\n$$H_i = (H(key) + d_i) % m$$\n式中，i = 1，2，…，k，m为散列表表长，$d_i$为增量序列。$d_i$通常有以下几种取法：\n 当$d_i = 1，2，…，m - 1$时，称为**线性探测法。**其特点是，冲突发生时顺序查看表中下一个单元，直到找出一个空单元或查遍全表。 当$d_i = 1^2，-1^2，2^2，-2^2，…，k^2，-k2$时，又称为二次探测法。 当$d_i$ = 伪随机数序列时，称为伪随机探测法。    再散列法\n当发生冲突时，再利用一个新的哈希函数计算得到一个新的地址，直到不发生冲突时进行存放。\n  公共溢出区\n所有发生冲突的关键字都存储在这个公共溢出区，当查找不到的时候来这里查找。\n  哈希表的优缺点 优点：不论哈希表中有多少数据，查找、插入、删除（有时包括删除）只需要接近常量的时间即0(1）的时间级。实际上，这只需要几条机器指令。\n哈希表运算得非常快，在计算机程序中，如果需要在一秒种内查找上千条记录通常使用哈希表（例如拼写检查器)哈希表的速度明显比树快，树的操作通常需要O(N)的时间级。哈希表不仅速度快，编程实现也相对容易。\n如果不需要有序遍历数据，并且可以提前预测数据量的大小。那么哈希表在速度和易用性方面是无与伦比的。\n缺点：它是基于数组的，数组创建后难于扩展，某些哈希表被基本填满时，性能下降得非常严重，所以程序员必须要清楚表中将要存储多少数据（或者准备好定期地把数据转移到更大的哈希表中，这是个费时的过程）。\n数据结构及图示 线性探测的哈希表数据结构和图片\n1 2 3 4 5 6 7 8 9 10 11 12  typedef char KeyType; typedef struct { KeyType key; }RcdType; typedef struct { RcdType *rcd; int size; int count; bool *tag; }HashTable;   哈希表实现： 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177  #include\u0026lt;stdio.h\u0026gt;#include\u0026lt;stdlib.h\u0026gt; #define SUCCESS 1#define UNSUCCESS 0#define OVERFLOW -1#define OK 1#define ERROR -1#define MAXNUM 9999\t// 用于初始化哈希表的记录 key  typedef int Status; typedef int KeyType; // 哈希表中的记录类型 typedef struct { KeyType key; }RcdType; // 哈希表类型 typedef struct { RcdType *rcd; int size; int count; int *tag; }HashTable; // 哈希表每次重建增长后的大小 int hashsize[] = { 11, 31, 61, 127, 251, 503 }; int index = 0; // 初始哈希表 Status InitHashTable(HashTable \u0026amp;H, int size) { int i; H.rcd = (RcdType *)malloc(sizeof(RcdType)*size); H.tag = (int *)malloc(sizeof(int)*size); if (NULL == H.rcd || NULL == H.tag) return OVERFLOW; KeyType maxNum = MAXNUM; for (i = 0; i \u0026lt; size; i++) { H.tag[i] = 0; H.rcd[i].key = maxNum; } H.size = size; H.count = 0; return OK; } // 哈希函数：除留余数法 int Hash(KeyType key, int m) { return (3 * key) % m; } // 处理哈希冲突：线性探测 void collision(int \u0026amp;p, int m) { p = (p + 1) % m; } // 在哈希表中查询 Status SearchHash(HashTable H, KeyType key, int \u0026amp;p, int \u0026amp;c) { p = Hash(key, H.size); int h = p; c = 0; while ((1 == H.tag[p] \u0026amp;\u0026amp; H.rcd[p].key != key) || -1 == H.tag[p]) { collision(p, H.size); c++; } if (1 == H.tag[p] \u0026amp;\u0026amp; key == H.rcd[p].key) return SUCCESS; else return UNSUCCESS; } //打印哈希表 void printHash(HashTable H) { int i; printf(\u0026#34;key : \u0026#34;); for (i = 0; i \u0026lt; H.size; i++) printf(\u0026#34;%3d \u0026#34;, H.rcd[i].key); printf(\u0026#34;\\n\u0026#34;); printf(\u0026#34;tag : \u0026#34;); for (i = 0; i \u0026lt; H.size; i++) printf(\u0026#34;%3d \u0026#34;, H.tag[i]); printf(\u0026#34;\\n\\n\u0026#34;); } // 函数声明：插入哈希表 Status InsertHash(HashTable \u0026amp;H, KeyType key); // 重建哈希表 Status recreateHash(HashTable \u0026amp;H) { RcdType *orcd; int *otag, osize, i; orcd = H.rcd; otag = H.tag; osize = H.size; InitHashTable(H, hashsize[index++]); //把所有元素，按照新哈希函数放到新表中 \tfor (i = 0; i \u0026lt; osize; i++) { if (1 == otag[i]) { InsertHash(H, orcd[i].key); } } return OK; } // 插入哈希表 Status InsertHash(HashTable \u0026amp;H, KeyType key) { int p, c; if (UNSUCCESS == SearchHash(H, key, p, c)) { //没有相同key \tif (c*1.0 / H.size \u0026lt; 0.5) { //冲突次数未达到上线 \t//插入代码 \tH.rcd[p].key = key; H.tag[p] = 1; H.count++; return SUCCESS; } else recreateHash(H); //重构哈希表 \t} return UNSUCCESS; } // 删除哈希表 Status DeleteHash(HashTable \u0026amp;H, KeyType key) { int p, c; if (SUCCESS == SearchHash(H, key, p, c)) { //删除代码 \tH.tag[p] = -1; H.count--; return SUCCESS; } else return UNSUCCESS; } int main() { printf(\u0026#34;-----哈希表-----\\n\u0026#34;); HashTable H; int i; int size = 11; KeyType array[8] = { 22, 41, 53, 46, 30, 13, 12, 67 }; KeyType key; //初始化哈希表 \tprintf(\u0026#34;初始化哈希表\\n\u0026#34;); if (SUCCESS == InitHashTable(H, hashsize[index++])) printf(\u0026#34;初始化成功\\n\u0026#34;); //插入哈希表 \tprintf(\u0026#34;插入哈希表\\n\u0026#34;); for (i = 0; i \u0026lt;= 7; i++) { key = array[i]; InsertHash(H, key); printHash(H); } //删除哈希表 \tprintf(\u0026#34;删除哈希表中key为12的元素\\n\u0026#34;); int p, c; if (SUCCESS == DeleteHash(H, 12)) { printf(\u0026#34;删除成功，此时哈希表为：\\n\u0026#34;); printHash(H); } //查询哈希表 \tprintf(\u0026#34;查询哈希表中key为67的元素\\n\u0026#34;); if (SUCCESS == SearchHash(H, 67, p, c)) printf(\u0026#34;查询成功\\n\u0026#34;); //再次插入，测试哈希表的重建 \tprintf(\u0026#34;再次插入，测试哈希表的重建：\\n\u0026#34;); KeyType array1[8] = { 27, 47, 57, 47, 37, 17, 93, 67 }; for (i = 0; i \u0026lt;= 7; i++) { key = array1[i]; InsertHash(H, key); printHash(H); } getchar(); return 0; }   参考链接：\n 哈希表（散列表）原理详解 【算法】哈希表的诞生  ","description":"哈希表（Hash table，也叫散列表），是根据关键码值(Key value)而直接进行访问的数据结构。。","id":55,"section":"posts","tags":["数据结构","哈希表"],"title":"哈希表","uri":"https://hugo.jiahongw.com/zh/posts/algorithmstructure/hash/"},{"content":"关于程序的装入   绝对装入：绝对映射，程序中逻辑地址与内存物理地址完全相同 （单片机)\n  可重定位装入：静态映射，在装入时对逻辑地址进行修改\n  动态运行时装入：逻辑地址到物理地址的映射在程序运行时才执行 (现代PC机)\n  而动态重定位如下：\n 静态重定位的特点是在一个作业装入内存时，必须分配其要求的全部内存空间，如果没有足够的内存，就不能装入该作业。此外，作业一旦进入内存后，在整个运行期间不能在内存中移动，也不能再申请内存空间。\n 关于程序的链接   静态链接方式(Static Linking)\n在程序运行之前，先将各目标模块及它们所需的库函数链接成一个完整的可执行程序，以后不再拆开。\n  装入时动态链接(Load time Dynamic Linking)\n将用户源程序编译后所得到的一组目标模块，在装入内存时，釆用边装入边链接的链接方式。\n  运行时动态链接(Run-time Dynamic Linking）\n对某些目标模块的链接，是在程序执行中需要该目标模块时，才对它进行的链接。其优点是便于修改和更新，便于实现对目标模块的共享。\n  连续分配方式 单一连续分配 只能用于单用户、单任务的操作系统中。采用这种存储管理方式时，可把内存分为系统区和用户区两部分，系统区仅提供给 OS 使用，通常是放在内存的低址部分；用户区是指除系统区以外的全部内存空间，提供给用户使用。\n固定分区连续分配 将内存用户空间划分为若干个固定大小的区域，在每个分区中只装入一道作业，这样，把用户空间划分为几个分区，便允许有几道作业并发运行。当有一空闲分区时，便可以再从外存的后备作业队列中选择一个适当大小的作业装入该分区，当该作业结束时，又可再从后备作业队列中找出另一作业调入该分区。\n划分分区的方法：\n 分区大小相等 分区大小不相等  另外可以设置分区大小不等的一些分区，如下：\n固定分区分配的缺点：\n 造成存储空间的浪费 拓展性差  动态分区分配 动态分区分配数据结构：\n  空闲分区表\n在系统中设置一张空闲分区表，用于记录每个空闲分区的情况。每个空闲分区占一个表目，表目中包括分区序号、分区始址及分区的大小等数据项。\n  空闲分区链\n为了实现对空闲分区的分配和链接，在每个分区的起始部分，设置一些用于控制分区分配的信息，以及用于链接各分区所用的前向指针；在分区尾部则设置一后向指针，通过前、后向链接指针，可将所有的空闲分区链接成一个双向链，如下图所示：\n  内存分配分配算法 基于顺序搜索：(适合不太大的系统)   首次适应算法(FF)\n在分配内存时，从链首开始顺序查找，直到找到一个大小能满足的空闲分区即可。然后再再按照作业的大小，从空间分区中划分出与作业大小相同的空间给作业使用，余下的空间留在空闲分区链中。\n 首次适应算法要求空闲分区链以地址递增的次序链接。\n 缺点：空闲分区链的低地址部分不断被划分，会有许多细小的碎片空间难以利用。每次都是从低地址开始找空闲分区，查找的效率低。\n  循环首次适应算法(NF)\n循环首次适应算法在为进程分配内存空间时，不再是每次都从链首开始查找，而是从上次找到的空闲分区的下一个空闲分区开始查找，直到找到一个能够满足进程的空闲分区为止，最后从空闲分区划分出与请求大小相等的空间给作业。\n 循环到链表末尾又从新从链首开始查找。\n 缺点：缺少可用的大空间空闲分区。\n  最佳适应算法(BF)\n最佳适应算法在分配内存的时候，把满足要求并且又是最小的空闲分区给作业。为了加速寻找，该算法需要对空闲分区链按照空闲分区大小进行从小到大排序。\n缺点：会产生许多细小的碎片\n  最差适应算法(WF)\n最差适应算法每次分配内存的时候，把满足要求的最大的空闲分区给作业，将与作业申请大小的空间划分出来，剩余的空间留在空闲分区中，并且更新空闲分区链。该算法需要对空闲分区链按照空闲分区大小进行从大到小排序。\n优点：查找效率块，产生碎片少。\n缺点：缺少大的空闲分区\n  例子：\n假设有新程序F装入，大小为32K，当前已有程序B和D，最近一次空间分配是D：\n基于索引搜索：(适合比较大的系统)   快速适应算法(QF)\n该算法又叫做分类搜索法，是将空闲分区根据其容量大小进行分类，对于每一类具有相同容量的所有空闲分区，单独设置一个空闲分区链，这样系统存在多个空闲分区链。同时，还需要在内存中设立一张管理索引表，其中的每一个索引表项对应了一种空闲分区类型，并记录了该类型空闲分区链表表头指针。\n 空闲分区的分类是根据进程常用的空闲大小进行划分的，如2KB、4KB、8KB等，对于其他大小的空闲分区像7KB的空闲分区，既可以放在8KB的链表中，也可以放在一个特殊的空闲链表中。\n   伙伴系统\n该算法规定，无论是分配分区还是空闲分区，其大小均为2的k次幂(k为整数且1\u0026lt;=k\u0026lt;=m)。通常$2^m$是整个可分配内存的大小。\n  哈希算法\n哈希算法是利用哈希快速查找的优点，以及空闲分区在可利用空闲分区表中的分布规律，建立哈希函数，构造一张以空闲分区大小为关键字的哈希表，该表的每一个表项记录了一个对应的空闲分区链表表头指针。\n  动态重定位分区分配 紧凑\n对内存中正在使用的分区进行搬迁，使多个小的空闲分区（碎片）合并为一个大的空闲分区\n动态重定位\n算法：\n什么是内存碎片？\n内部碎片是指已经分配给作业但不能被利用的内存空间，外部碎片是指系统中还没有分配给作业，但由于碎片太小而无法分配给申请内存空间的新进程的存储块。通俗点的理解就是，某个作业所占用的内存区域如果没有装满，就是内部碎片，而作业与作业之间，如果有内存区域没有分配给某个作业，但又不能分配给任何作业，就是外部碎片。\n 连续分配: 为用户进程分配的必须是一个连续的内存空间。\n非连续分配: 为用户进程分配的可以是一些分散的内存空间。\n 非连续分配方式(离散分配方式) 思想\n假设进程A大小为23MB,但是每个分区大小只有10MB,如果进程只能占用一个分区,那显然放不下。\n解决思路:\n如果允许进程占用多个分区,那么可以把进程拆分成10MB+10MB+3MB三个部外,再把这三个部分分别放到三个分区中(这些分区不要求连续)\u0026hellip;\n进程A的最后一个部分是3MB,放入分区后会产生7MB的内部碎片，如果每个分区大小为2MB,那么进程A可以拆分成11*2MB +1MB共12个部分,只有最后一部分1MB占不满分区,共产生1MB的内部碎片.\n显然,如果把外区大小设置的更小一些,内部碎片会更小,内学利用率会更高.\n具有快表的地址变换机构：（时间局部性与空间局部性原理）\n快表,又称联想寄存器(TLB) ,是一种访问速度比内存快很多的高速缓冲存储器,用来存放当\u0026quot;前访间的若干页表项,以加速地址变换的过程。与此对应,内存中的页表常称为慢表。\n多级页表\n问题\n加载一个大的页表需要占用很大的内存\n解决\n将大表分为几个小表。类似CIDR。\n可将长长的页表进行分组,使每个内存块刚好可以放入一个分组(比如上个侧子中,页面大小4KB,每个页表项48,每个页面可存放1K个页表项,因此每1K个连续的页表项为一组,每组刚好占一个内存块,再讲各组离散地放到各个内存块中)另外,要为离散分配的页表再建立一张页表,称为页目录表,或称外层页表,或称顶层页表\n存储管理方式  本质上是一种内存的划分方法\n 分页存储管理 这种方式中，将用户程序的地址空间，注意，是用户程序的地址空间分为若干个固定大小的区域，成为“页”或“页面”。我们可以知道，这也页其实是不存在的，只是一种划分内存空间的方法。也就是说，这种方式将用户的程序**“肢解”**了，分成很多个小的部分，每个部分称为一个“页”。\n逻辑地址 将逻辑地址的前n位作为页号，后面32-n位作为页内偏移量。\n页内碎片 由于进程的最后一页经常装不满一个块，从而形成了不可利用的碎片，称之为**“页内碎片”**。\n页表 作用：实现页号到物理号的地址映射。\n页表是记录逻辑空间（虚拟内存）中每一页在内存中对应的物理块号。但并非每一页逻辑空间都会实际对应着一个物理块，只有实际驻留在物理内存空间中的页才会对应着物理块。\n系统会为每一个进程建立一张页表，页表是需要一直驻留在物理内存中的（多级页表除外），另外页表的起址和长度存放在 PCB（Process Control Block）进程控制结构体中。\n可以在页表的表项中设置相关的权限控制字段，例如设置存取控制字段，用于保护该存储块的读写；若存取控制字段为2位，则可以设置读/写、只读和只执行等存取方式。\n物理块 物理块是实实在在存在于内存中的：\n地址变换机构 由于执行频率高，要求效率比较高，需要使用硬件实现。\n在系统中设置一个页表寄存器(PTR),其中存放页表在内存的起始地址和页表的长度。平时进程未执行的时候，页表的起始地址和页表长度放在本进程的PCB中。当调度程序调度到某个进程的时候，才将这两个数据装入页表寄存器。\n 注意，当创建一个进程的时候，它的页表也同时创建了，只不过只在PCB存储了页表的起始地址和长度。\n 变换过程：\n 进程访问某个逻辑地址时，分页地址机构自动将逻辑地址分为页号和页内地址 页号大于页表长度，越界错误;否则继续下面的步骤 页表项的地址 p = 页表起始地址 F + 页号 P * 表项大小 S，从而得到对应的物理块号 B 页和物理块的大小是一致的，所以 页内地址=块内地址 然后 物理地址 = 物理块号 B * 页大小 L + 页内地址 根据物理地址读取数据  快表的变换机构\n 基础的地址变换机构的缺点：\n由于页表是存放在内存中的，这使得CPU在每存取一个数据时，都需要两次访问内存。第一次时访问内存中的页表，获取物理块号，于偏移值拼接得到物理地址，第二次是从第一次所得物理地址获取所需数据(或者向该地址写入数据)。这样计算机的处理速度几乎降低了1/2；\n 为了提高地址变换速度，可在地址变换机构中增设一个具有并行查询能力的特殊高速缓冲寄存器，又称为\u0026quot;联想寄存器\u0026quot;或者“快表”。俗称TLB。\n快表与页表的功能类似，其实就是将一部分页表存到 CPU 内部的高速缓冲存储器 Cache。CPU 寻址时先到快表查询相应的页表项形成物理地址，如果查询不到，则到内存中查询，并将对应页表项调入到快表中。但，如果快表的存储空间已满，则需要通过算法找到一个暂时不再需要的页表项，将它换出内存。\n由于成本的关系，快表不可能做得很大，通常只存放 16~512 个页表项，这对中、小型作业来说，已有可能把全部页表项放在快表中；但对于大型作业而言，则只能将其一部分页表项放入其中。由于对程序和数据的访问往往带有局限性，因此，据统计，从快表中能找到所需页表项的概率可达 90% 以上。这样，由于增加了地址变换机构而造成的速度损失可减少到 10% 以下，达到了可接受的程度。\n两级页表  一级页表的缺陷：由于页表必须连续存放，并且需要常驻物理内存，当逻辑地址空间很大时，导致页表占用内存空间很大。\n 我们可以采用这样两个方法来解决这一问题：\n① 对于页表所需的内存空间，可采用离散分配方式，以解决难以找到一块连续的大内存空间的问题；\n② 只将当前需要的部分页表项调入内存，其余的页表项仍驻留在磁盘上，需要时再调入。\n二级页表的页表项：\n过程：\n 外层页表寄存器中保存了外层页表的始址，根据外层页号查找到内层页号。 找到指定页表分页的始址，根据内层页号找到物理块号。 物理块号P和页内地址d组装成一个实际的物理地址。  在采用两级页表结构的情况下，对于正在运行的进程，必须将其外层页表调入内存，而对于内页表则只需调入一页或几页。为了表征某页的页表是否已经调入内存，还应在外层页表项中增设一个状态位 S，其值若为 0，表示该页表分页不在内存中，否则说明其分页已调入内存。进程运行时，地址变换机构根据逻辑地址中的 P1去查找外层页表；若所找到的页表项中的状态位为 0，则产生一个中断信号，请求 OS 将该页表分页调入内存。\n多级页表 多级页表和二级页表类似。多级页表和二级页表是为了节省物理内存空间。使得页表可以在内存中离散存储。（单级页表为了随机访问必须连续存储，如果虚拟内存空间很大，就需要很多页表项，就需要很大的连续内存空间，但是多级页表不需要。）\n 分页式管理很好的避免了外部碎片，但是还是存在内部碎片，因为程序大小不可能总是2的n次幂。多级页表使得页表数据可以不需要连续存储，即实现了页表的离散式存储。并且在当对应程序运行才将内页表数据调入内存也减少了页表所占用的内存空间。本质上是提高内存利用率。\n 分段存储管理  为了满足用户要求的一种存储管理的方式\n 为什么引入分段存储管理？\n 通常的程序都可以分为若干个段，如主程序段、子程序段A、子程序段B、\u0026hellip;、数据段和栈段等等。 实现和满足信息共享、信息保护、动态链接以及信息的动态增长  引入效果：\n  方便编程\n使用符号作为段地址进行使用。(每个段都是从 0 开始的独立逻辑地址空间；)\n  信息共享\n在实现对程序和数据的共享时，是以信息的逻辑单位为基础的。比如，为了共享某个过程、函数或文件。分页系统中的“页”只是存放信息的物理单位(块)，并无完整的逻辑意义，这样，一个可被共享的过程往往可能需要占用数十个页面，这为实现共享增加了困难。段可以是信息的逻辑单位，因此，我们可以为该被共享过程建立一个独立的段，这就极大地简化了共享的实现。\n  信息保护\n信息保护同样是以信息的逻辑单位为基础的，而且经常是以一个过程、函数或文件为基本单位进行保护的。例如，我们希望函数 A 仅允许进程执行，而不允许读，更不允许写，那么，我们只须在包含了函数 A 的这个段上标上只执行标志即可。但是在分页系统中，函数 A 可能要占用若干个页面，而且其中的第一个和最后一个页面还会装有其它程序段的数据，它们可能有着不同的保护属性，如可以允许进程读写，这样就很难对这些页面实施统一的保护，因此，分段管理方式能更有效和方便地实现对信息的保护功能。\n  动态增长\n在实际应用中，往往存在着一些段，尤其是数据段，在它们的使用过程中，由于数据量的不断增加，而使数据段动态增长，相应地它所需要的存储空间也会动态增加。然而，对于数据段究竟会增长到多大，事先又很难确切地知道。对此，很难采取预先多分配的方法进行解决。前述的其它几种存储管理方式都难以应付这种动态增长的情况，而分段存储管理方式却能较好地解决这一问题。\n  动态链接\n动态链接在作业运行之前，并不是把所有的目标程序段都链接起来。当程序要运行时，首先将主程序和它立即需要用到的目标程序装入内存，即启动运行。而在程序运行过程中，当需要调用某个目标程序时，才将该段(目标程序)调入内存并进行链接。可见，动态链接要求的是以目标程序(即段)作为链接的基本单位,因此，分段存储管理方式非常适合于动态链接。\n  它将用户程序的地址空间分为若干个大小不同的的段，每个段可以定义一组完整的信息。\n分段地址 段号表示段名，每个段都从0开始编址，并且采用一段连续的地址空间。\n在该地址结构中，允许一个作业最长有64K个段，每个段的最大长度为64KB。\n在分段式存储管理系统中，为每一个分段分配一个连续的分区。进程的各个段，可以离散地装入内存中不同的分区中。\n段表 作用：实现从逻辑地址到物理内存区的映射。\n为了保证程序能够正常运行，就必须能够从物理内存中找出每个逻辑段所对应的位置。为此在系统中会为每一个进程建立一张段表。每个段在表中有一个表项，其中记录了该段在内存中的起始地址和段的长度。一般将段表保存在内存中。\n在配置了段表之后，执行的过程可以通过查找段表，找到每一个段所对应的内存区。\n地址变换机构 为了实现进程从逻辑地址到物理地址的变换功能，在系统设置了段表寄存器，用于存放段表的起始地址和段表长度TL。\n在进行地址变换时，系统将逻辑地址中的段号与段表长度TL 进行比较。若 S \u0026gt; TL，表示段号太大，是访问越界，于是产生越界中断信号。若未越界，则根据段表的始址和该段的段号，计算出该段对应段表项的位置，从中读出该段在内存的起始地址。然后，再检查段内地址 d 是否超过该段的段长 SL。若超过，即 d\u0026gt;SL，同样发出越界中断信号。若未越界，则将该段的基址 d 与段内地址相加，即可得到要访问的内存。\n 像分页系统一样，当段表放在内存中时，每要访问一个数据，都须访问两次内存，从而成倍地降低了计算机的速率。解决的方法和分页系统类似，也增设一个联相存储器，用于保存最近常用的段表项。一般情况下，由于是段比页大，因而段表项的数目比页表项的数目少，其所需的联想存储器也相对较小，所以可以显著地减少存取数据的时间，与没有地址变换的常规存储器相比而言，其存取速度约慢 10%~15%。\n 段页式存储管理 分页和分段的区别 分页和分段系统相似之处：两者都采用离散分配方式，且都是通过地址映射机构实现地址变换。\n但在概念上两者完全不同，主要表现在下述三个方面：\n 页是信息的物理单位，段是信息的逻辑单位。 页的大小确定且又系统决定；段的长度不固定，决定于用户所编写的程序。 分页的用户程序地址空间是一维的，只需要一个记忆符就能够表示一个地址；分段的用户程序地址空间是二维的，既需要段名，又需要段内地址。  段页式 分页系统以页面作为内存分配的基本单位，能有效地提高内存利用率，而分段系统以段作为内存分配的基本单位，它能够更好地满足用户多方面的需要。\n段页式地址结构 段页式地址结构由段号、段内页号及页内地址三部分所组成\n段页式系统的基本原理是分段和分页原理的结合，即先将用户程序分成若干个段，再把每个段分成若干个页，并为每一个段赋予一个段名。如下图展示了一个作业地址空间的结构。该作业有三个段：主程序段、子程序段和数据段；页面大小为 4 KB：\n在段页式系统中，为了实现从逻辑地址到物理地址的变换，系统中需要同时配置段表和页表。段表的内容与分段系统略有不同，它不再是内存始址和段长，而是页表始址和页表长度。下图展示出了利用段表和页表进行从用户地址空间到物理(内存)空间的映射。\n地址变换过程 在段页式系统中，为了便于实现地址变换，须配置一个段表寄存器，其中存放段表始址和段长 TL。进行地址变换时，首先利用段号 S，将它与段长 TL 进行比较。若 S \u0026lt; TL，表示未越界，于是利用段表始址和段号来求出该段所对应的段表项在段表中的位置，从中得到该段的页表始址，并利用逻辑地址中的段内页号 P 来获得对应页的页表项位置，从中读出该贝所在的物理块号 b，再利用块号 b 和页内地址来构成物理地址。\n在段页式系统中，为了获得一条指令或数据，须三次访问内存。第一次访问是访问内存中的段表，从中取得页表始址；第二次访问是访问内存中的页表，从中取出该页所在的物理块号，并将该块号与页内地址一起形成指令或数据的物理地址；第三次访问才是真正从第二次访问所得的地址中取出指令或数据。\n显然，这使访问内存的次数增加了近两倍。为了提高执行速度，在地址变换机构中增设一个高速缓冲寄存器。每次访问它时，都须同时利用段号和页号去检索高速缓存，若找到匹配的表项，便可从中得到相应页的物理块号，用来与页内地址一起形成物理地址：若未找到匹配表项，则仍需第三次访问内存。\n参考链接：\n 【操作系统 - 4】动态分区分配算法 程序的链接的三种方式 连续分配管理方式 深入理解操作系统之——分页式存储管理 《计算机操作系统》(第四版)  ","description":"","id":57,"section":"posts","tags":["Linux"],"title":"Linux内存管理","uri":"https://hugo.jiahongw.com/zh/posts/linux/memory-control/"},{"content":"网络层 网际协议IP是TCP/IP体系中两个最主要的协议之一[STEV94][COME06][FORO10]，也是最重要的因特网标准协议之一。\n与IP协议配套使用的还有三个协议：\n 地址解析协议ARP (Address Resolution Protocol) 网际控制报文协议ICMP (Internet Control Message Protocol) 网际组管理协议IGMP (Internet Group Management Protocol)  在这一层中，ARP画在最下面，因为IP经常要使用这个协议。ICMP和IGMP画在这一层的上部，因为它们要使用IP协议。由于网际协议IP是用来使互连起来的许多计算机网络能够进行通信，因此TCP/IP体系中的网络层常常称为网际层(internet layer)，或IP层。\n虚拟互连网络  从一般的概念来讲，将网络互相连接起来要使用一些中间设备。根据中间设备所在的层次，可以有以下四种不同的中间设备：\n(1) 物理层使用的中间设备叫做转发器(repeater)。\n(2) 数据链路层使用的中间设备叫做网桥或桥接器(bridge)。\n(3) 网络层使用的中间设备叫做路由器(router)[插图]。\n(4) 在网络层以上使用的中间设备叫做网关(gateway)。\n用网关连接两个不兼容的系统需要在高层进行协议的转换。\n IP网：\n异构的互联网链路\nH1→R1→R2→R3→R4→R5→H2\nARP协议  已经知道了一个机器（主机或路由器）的IP地址，需要找出其相应的硬件地址\n ARP协议工作原理：\n当主机A要向本局域网上的某个主机B发送IP数据报时，就先在其ARP高速缓存中查看有无主机B的IP地址。如有，就在ARP高速缓存中查出其对应的硬件地址，再把这个硬件地址写入MAC帧，然后通过局域网把该MAC帧发往此硬件地址。\n当找不到时，执行下面的操作：\n ARP进程在本局域网上广播发送一个ARP请求分组 在本局域网上的所有主机上运行的ARP进程都收到此ARP请求分组 主机B的IP地址与ARP请求分组中要查询的IP地址一致，就收下这个ARP请求分组，并向主机A发送ARP响应分组，并在这个ARP响应分组中写入自己的硬件地址。  在网络链路上传送的帧最终是按照硬件地址找到目的主机的，那么为什么我们不直接使用硬件地址进行通信，而是要使用抽象的IP地址并调用ARP来寻找出相应的硬件地址呢？\n由于全世界存在着各式各样的网络，它们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转换工作，因此由用户或用户主机来完成这项工作几乎是不可能的事。但统一的IP地址把这个复杂问题解决了。连接到因特网的主机只需拥有统一的IP地址，它们之间的通信就像连接在同一个网络上那样简单方便，因为上述的调用ARP的复杂过程都是由计算机软件自动进行的，对用户来说是看不见这种调用过程的。\nIP数据报 IP报文格式：\n片偏移的列子：\n一数据报的总长度为3 820字节，其数据部分为3 800字节长（使用固定首部），需要分片为长度不超过1 420字节的数据报片。因固定首部长度为20字节，因此每个数据报片的数据部分长度不能超过1 400字节。于是分为3个数据报片，其数据部分的长度分别为1 400，1 400和1000字节。原始数据报首部被复制为各数据报片的首部，但必须修改有关字段的值。下如给出分片后得出的结果（请注意片偏移的数值）\n下面是数据报首部与分片有关的字段中的数值，其中标识字段的值是任意给定的（12345）。具有相同标识的数据报片在目的站就可无误地重装成原来的数据报。\n首部检验和 占16位。这个字段只检验数据报的首部，但不包括数据部分\n这是因为数据报每经过一个路由器，路由器都要重新计算一下首部检验和（一些字段，如生存时间、标志、片偏移等都可能发生变化）。不检验数据部分可减少计算的工作量。为了进一步减小计算检验和的工作量，IP首部的检验和不采用复杂的CRC检验码而采用下面的简单计算方法：在发送方，先把IP数据报首部划分为许多16位字的序列，并把检验和字段置零。用反码算术运算[插图]把所有16位字相加后，将得到的和的反码写入检验和字段。接收方收到数据报后，将首部的所有16位字再使用反码算术运算相加一次。将得到的和取反码，即得出接收方检验和的计算结果。若首部未发生任何变化，则此结果必为0，于是就保留这个数据报。否则即认为出差错，并将此数据报丢弃。\nIP层转发分组 网络拓扑图：\n在简化图中，网络变成了一条链路，但每一个路由器旁边都注明其IP地址。使用这样的简化图，可以使我们不用关心某个网络内部的具体拓扑以及连接在该网络上有多少台计算机，因为这些对于研究分组转发问题并没有什么关系。这样的简化图强调了在互联网上转发分组时，是从一个路由器转发到下一个路由器。\n总之，在路由表中，对每一条路由最主要的是以下两个信息：\n（目的网络地址，下一跳地址）\n于是，我们就根据目的网络地址来确定下一跳路由器，这样做得出以下的结果。\n(1) IP数据报最终一定可以找到目的主机所在目的网络上的路由器（可能要通过多次的间接交付）。\n(2) 只有到达最后一个路由器时，才试图向目的主机进行直接交付。\n网际控制报文协议ICMP 为了更有效地转发IP数据报和提高交付成功的机会，在网际层使用了网际控制报文协议ICMP。\n ICMP允许主机或路由器报告差错情况和提供有关异常情况的报告.一个新搭建好的网络，往往需要先进行一个简单的测试，来验证网络是否畅通；但是IP协议并不提供可靠传输。如果丢包了，IP协议并不能通知传输层是否丢包以及丢包的原因。所以我们就需要一种协议来完成这样的功能–ICMP协议。\n ICMP报文格式\nICMP报文的种类有两种，即ICMP差错报告报文和ICMP询问报文。\n几种常用的ICMP报文类型\nICMP报文的代码字段是为了进一步区分某种类型中的几种不同的情况。检验和字段用来检验整个ICMP报文。我们应当还记得，IP数据报首部的检验和并不检验IP数据报的内容，因此不能保证经过传输的ICMP报文不产生差错。\nICMP差错报告 ICMP差错报文共有五种，即：\n  终点不可达 当路由器或主机不能交付数据报时就向源点发送终点不可达报文。\n  源点抑制 当路由器或主机由于拥塞而丢弃数据报时，就向源点发送源点抑制报文，使源点知道应当把数据报的发送速率放慢。\n  时间超过 当路由器收到生存时间为零的数据报时，除丢弃该数据报外，还要向源点发送时间超过报文。当终点在预先规定的时间内不能收到一个数据报的全部数据报片时，就把已收到的数据报片都丢弃，并向源点发送时间超过报文。\n  参数问题 当路由器或目的主机收到的数据报的首部中有的字段的值不正确时，就丢弃该数据报，并向源点发送参数问题报文。\n  改变路由（重定向） 路由器把改变路由报文发送给主机，让主机知道下次应将数据报发送给另外的路由器（可通过更好的路由）。\n如果默认路由器发现主机发往某个目的地址的数据报的最佳路由不应当经过默认路由器而是应当经过网络上的另一个路由器R时，就用改变路由报文把这情况告诉主机。于是，该主机就在其路由表中增加一个项目：到某某目的地址应经过路由器R （而不是默认路由器）。\n  所有的ICMP差错报告报文中的数据字段都具有同样的格式：\n下面是不应发送ICMP差错报告报文的几种情况。\n● 对ICMP差错报告报文不再发送ICMP差错报告报文。\n● 对第一个分片的数据报片的所有后续数据报片都不发送ICMP差错报告报文。\n● 对具有多播地址的数据报都不发送ICMP差错报告报文。\n● 对具有特殊地址（如127.0.0.0或0.0.0.0）的数据报不发送ICMP差错报告报文。\nICMP询问报文 常用的ICMP询问报文有两种，即:\n 回送请求和回答 ICMP回送请求报文是由主机或路由器向一个特定的目的主机发出的询问。收到此报文的主机必须给源主机或路由器发送ICMP回送回答报文。这种询问报文用来测试目的站是否可达以及了解其有关状态。 时间戳请求和回答 ICMP时间戳请求报文是请某个主机或路由器回答当前的日期和时间。在ICMP时间戳回答报文中有一个32位的字段，其中写入的整数代表从1900年1月1日起到当前时刻一共有多少秒。时间戳请求与回答可用来进行时钟同步和测量时间。  应用 ping ICMP报文的一个最大用途就是ping命令，用来测试两个主机之间的连通性：\ntracert Traceroute从源主机向目的主机发送一连串的IP数据报，数据报中封装的是无法交付的UDP用户数据报[插图]。第一个数据报P1的生存时间TTL设置为1。当P1到达路径上的第一个路由器R1时，路由器R1先收下它，接着把TTL的值减1。由于TTL等于零了，R1就把P1丢弃了，并向源主机发送一个ICMP时间超过差错报告报文。源主机接着发送第二个数据报P2，并把TTL设置为2。P2先到达路由器R1，R1收下后把TTL减1再转发给路由器R2。R2收到P2时TTL为1，但减1后TTL变为零了。R2就丢弃P2，并向源主机发送一个ICMP时间超过差错报告报文。这样一直继续下去。当最后一个数据报刚刚到达目的主机时，数据报的TTL是1。主机不转发数据报，也不把TTL值减1。但因IP数据报中封装的是无法交付的运输层的UDP用户数据报，因此目的主机要向源主机发送ICMP终点不可达差错报告报文。\n这样，源主机达到了自己的目的，因为这些路由器和最后目的主机发来的ICMP报文正好给出了源主机想知道的路由信息——到达目的主机所经过的路由器的IP地址，以及到达其中的每一个路由器的往返时间\n","description":"网络层浅析","id":58,"section":"posts","tags":["计算机网络","网络层"],"title":"网络层","uri":"https://hugo.jiahongw.com/zh/posts/network/net-level/"},{"content":" 公司\t岗位\t题目\t帖子时间\n==字节跳动\tjava\t剑指 Offer 53 - II. 0～n-1中缺失的数字\t2020.07.18== （双指针）\n==字节跳动\tjava\t如何判断一个单链表是不是有环\t2020.07.18== （快慢指针）\n==字节跳动\tjava\t给你一个数组，求三个数字之和为100.\t2020.07.18== （调用两数之和，哈希）\n==字节跳动\t客户端\t算法题（合并链表\t2020.07.18==\n==字节跳动\t客户端\t求岛屿个数\t2020.07.18==\n==字节跳动\t客户端\t树找两节点最长距离\t2020.07.18==\n字节跳动\tjava\t1243534543634交换各位的数字，找出大于目前这个数的最小的一个数。\t2020.07.18\n字节跳动\t后端\t对一个奇数位升序，偶数位降序的链表，进行排序，例如 1-\u0026gt;100-\u0026gt;20-\u0026gt;80-\u0026gt;40-\u0026gt;30\t2020.07.18\n字节跳动\t后端\t算法题：(1)设计sqtr(x)\t2020.07.18\n字节跳动\t后端\t2、算法题：(1)判断回文链表\t2020.07.18\n字节跳动\t后端\t(2)对于给定的数据，找出比这个数大的最小回文数（正反读都一样的数），如 12310 -\u0026gt; 12321\t2020.07.18\n字节跳动\t后端\t第一道代码：数组只交换一次求最大\t2020.07.18\n字节跳动\t后端\t第二道代码： 单链表判断是否有环\t2020.07.18\n字节跳动\t客户端\tleetcode原题 从一个数 l 一直 与 操作到 r ，怎么做最快，复杂度最小\t2020.07.18\n字节跳动\t客户端\tk个一组反转链表\t2020.07.18\n字节跳动\t客户端\t二叉树的非递归后序遍历\t2020.07.18\n字节跳动\t后端\t括号匹配\t2020.07.17\n字节跳动\t客户端\t按字典序全排列输出\t2020.07.17\n字节跳动\t客户端\t跳台阶\t2020.07.17\n字节跳动\t图形/图像岗\t一棵完全二叉树的最底层的最右节点\t2020.07.17\n字节跳动\t测试\t求子集\t2020.07.17\n字节跳动\t测试\t二维有序数组（从左到右递增，从上到下也递增），找目标数（我写的二分法）\t2020.07.17\n字节跳动\t算法\t1.判断左右括号是否合理\t2020.07.16\n字节跳动\t算法\t2.朴素贝叶斯的算法实现\t2020.07.16\n字节跳动\t算法\t3.两个很大的数据集存着url 找到两个数据集共有的url\t2020.07.16\n字节跳动\t算法\t4.一个二维矩阵由小到大排列 找target数字\t2020.07.16\n字节跳动\t算法\t5.二叉树按行输出\t2020.07.16\n字节跳动\t算法\t1.给二叉树前序遍历和中序遍历 输出这个树\t2020.07.16\n字节跳动\t算法\t2.翻转链表\t2020.07.16\n字节跳动\t算法\t3. 把只包含质因子2、3和5的数称作丑数。例如6、8都是丑数，但14不是，因为它包含质因子7。 习惯上我们把1当做是第一个丑数。求按从小到大的顺序的第N个丑数。\t2020.07.16\n字节跳动\t算法\t给一个类似树的结构，每个节点都可以有多个节点（不止两个树）然后每个根节点和字节点间的路径不一样，求叶子结点到叶子结点的最大路径\t2020.07.16\n字节跳动\t后端\t链表每k个翻转\t2020.07.16\n字节跳动\t后端\t判断单链表有没有环，有的话找入口\t2020.07.16\n字节跳动\t安卓\t. 算法题：根据前中序重构二叉树\t2020.07.16\n字节跳动\t安卓\t算法：螺旋矩阵\t2020.07.16\n字节跳动\t后台\t给定m和n，输出从1~n中任意多个数字，且和为mu的组合(数字不能重复使用)\t2020.07.16\n字节跳动\t后台\t算法题(求第n个丑数,leetcode原题,难度mid)\t2020.07.16\n字节跳动\t后台\t第一题是求开根号n的值\t2020.07.16\n字节跳动\t后台\t第二题是输出交错后的链表(比如链表a-b-c-d-e,交错后输出为a-e-b-d-c)\t2020.07.16\n字节跳动\t后台\t反转链表\t2020.07.16\n字节跳动\t后台\t找峰值\t2020.07.16\n字节跳动\t客户端\t1. 有两个单链表，其有交叉节点，求交叉节点。\t2020.07.16\n字节跳动\t客户端\t2. LRU算法，给一个整数数组，若LRU的窗口大小是4，求下一个元素进来后剔除哪个元素。\t2020.07.15\n字节跳动\t客户端\t3. 求最小子数组，leetcode209题。\t2020.07.15\n字节跳动\t后端\t2N的格子 12的格子填满它有多少种方法， 给个数组，找出右边第一个比它大的元素， 链表两两反转\t2020.07.15\n字节跳动\t前端\t删除链表的倒数第n个\t2020.07.15\n字节跳动\t大数据\t算法题1: 请对3个有序数组进行归并排序\t2020.07.15\n字节跳动\t大数据\t算法题2: 求一个字符串中最长不重复子串的长度\t2020.07.15\n字节跳动\t服务端\t给定一个int数组A，数组中元素互不重复，给定一个数x，求所有求和能得到x的数字组合，组合中的元素来自A，可重复使用。\t2020.07.15\n字节跳动\t后端\t手撕代码:Z字型遍历二叉树（剑指offer原题，LeetCode第1553题）\t2020.07.15\n字节跳动\t算法\ttopk\t2020.07.15\n字节跳动\tjava\t手撕平方根\t2020.07.15\n字节跳动\t测试\t反转链表？\t2020.07.15\n字节跳动\t前端\t给定一个整数数组 nums 和一个目标值 target，请你在该数组中找出和为目标值的那 两个 整数，并返回他们的数组下标。\t2020.07.15\n字节跳动\t后端\t算法题1：很大量的int型数，输出前100最大的数（中等）\t2020.07.15\n字节跳动\t后端\t算法题2：单向链表，头尾奇偶交替输出（中等）\t2020.07.15\n字节跳动\t后端\t单链表反转\t2020.07.15\n字节跳动\t后端\t平衡二叉搜索树插入算法\t2020.07.15\n字节跳动\t客户端\t2. 一个二叉树， 求路径之和。。。。\t2020.07.15\n字节跳动\t后台\t算法：掷骰子走路，1～6，给定的输入n，走到第n个格子有多少种走法\t2020.07.15\n字节跳动\t后台\t算法：青蛙跳格子，数组里元素表示该位置石头个数，每次跳3-5格，问跳出数组最少踩多少石头。\t2020.07.15\n字节跳动\t后台\t算法：给定链表和k，要求每k个元素翻转一次\t2020.07.15\n字节跳动\t计算机视觉工程师\t做道题吧，LeetCode4：两个有序数组的中位数\t2020.07.15\n字节跳动\t后端\t算法：找出数组里出现次数大于n/k的数\t2020.07.14\n字节跳动\t后端\t算法判断树是否对称，用bfs做了\t2020.07.14\n字节跳动\t客户端\t11.手撕代码：1）给定数组，求连续子串的最大和\t2020.07.14\n字节跳动\t客户端\t2）用两个栈实现队列\t2020.07.14\n字节跳动\t客户端\t10.手撕代码：1）给定一个二维数组，从左到右，从上到下都是递增的，查找某个元素\t2020.07.14\n字节跳动\t客户端\t2）给定一个矩阵，每次只能向右或向下走，从左上角开始到右下角一共有多少种走法\t2020.07.14\n字节跳动\t客户端\t，第一题就是给一个矩阵，从右上角往左下角一层一层斜着遍历，类似于这样：\t2020.07.14\n字节跳动\t客户端\t层次遍历二叉树\t2020.07.14\n字节跳动\t客户端\tleetcode 236\t2020.07.14\n字节跳动\t客户端\tleetcode 62，\t2020.07.14\n字节跳动\t服务端\t1.给一个正整数，表示成一个或多个不同的正整数的和，输出所有的解决方案（深搜，但是我实现的时候写的不好）\t2020.07.14\n字节跳动\t服务端\t2.给一个n*n的方阵，螺旋填入数字\t2020.07.14\n字节跳动\tandroid\t（手撕）1：[2,3] 表示 孩子和父母。输入一组这样的数据， 给两个数，问是否有共同祖先。\t2020.07.14\n字节跳动\t后端\t力扣 124.\t2020.07.14\n字节跳动\t后端\t第二题：二叉树的左视图\t2020.07.14\n字节跳动\t后台\t第一题，一个int数组，找出两个异或最大的数字，时间要求O(n)\t2020.07.14\n字节跳动\t后台\t第二题，四个int数组，从每个数组里边挑一个数，加起来等于指定数，要求打印出所有非重复的组合，要求最大n2。\t2020.07.14\n字节跳动\tjava\t代码题：不含重复字符的最长子串（leetcode原题）\t2020.07.14\n字节跳动\t后端\t2.最长上升子序列的状态转移,时间复杂度\t2020.07.14\n字节跳动\t后端\t给出前序和中序数组,生成后序数组\t2020.07.14\n字节跳动\t后端\t11.算法题：给一棵二叉树和一个整数，要求输出二叉树中路径和等于这个整数的路径，如\t2020.07.14\n字节跳动\t后端\t1。算法题，两个链表了类型的整数求和，如1-\u0026gt;2-\u0026gt;5与3-\u0026gt;6求和得到1-\u0026gt;4-\u0026gt;1。用栈或者反转链表\t2020.07.13\n字节跳动\t后端\t算法题：找波谷数；\t2020.07.13\n字节跳动\t后端\t算法题：复制带随机指针的单向链表；\t2020.07.13\n字节跳动\t后端\t14. 算法题：找到两个链表的公共节点\t2020.07.13\n字节跳动\t后端\t1. 给定两个单链表，判断是否有公共节点\t2020.07.13\n字节跳动\t后端\t3. 求字符数组的全排列（用的交换的方式，但是面试官问思路却有点紧张，没回答好，然后他问我leetcode刷了多少道题，八成认为我是直接背的题了，难受）\t2020.07.13\n字节跳动\t后端\t查找有序数组中一个目标值出现的第一次位置，没有找到返回 -1\t2020.07.13\n字节跳动\t后端\t5. 算法：滑动窗口寻找满足的字符串\t2020.07.13\n字节跳动\t后端\t爬楼梯\t2020.07.13\n字节跳动\t前端\tleetcode 93 没写出来。。面试官说我思绪混乱 导致后面脑子空白\t2020.07.13\n字节跳动\t前端\t二叉树层序遍历\t2020.07.13\n字节跳动\t后端\t说思路：实现一个栈，o(1)时间找最大值\t2020.07.13\n字节跳动\t后端\t写代码：矩阵从左上到右下找最小路径\t2020.07.13\n字节跳动\t后端\t说思路：删除单链表的倒数第k个节点\t2020.07.13\n字节跳动\t客户端\t编程：判断两个链表是否相交并返回交点；\t2020.07.13\n字节跳动\t测试\t代码：无重复最长字串\t2020.07.13\n字节跳动\t测试\t10、算法：求数组中升序的子序列\t2020.07.13\n字节跳动\t测试\t11、算法：两个链表找公共节点\t2020.07.13\n字节跳动\t前端\tMerge 两个有序的链表\t2020.07.13\n字节跳动\tios\t1. 如何用两个栈实现一个队列？如何优化前面说的那种思路？\t2020.07.13\n字节跳动\tios\t2. 编程题：上台阶(那个简单的fabonacci)然后就又来了一道\t2020.07.13\n字节跳动\tios\t3. 编程题：区间合并求并集\t2020.07.13\n字节跳动\tios\t算法题：连续子数组的最大和\t2020.07.13\n字节跳动\tios\t1. 二分查找在升序数组中找出绝对值最小的那个数\t2020.07.13\n字节跳动\tios\t2. 8个桶(每个桶只能放一个球)，5个球，三个连续的情况有几种。一般情况下呢\t2020.07.13\n字节跳动\t后端\tmerge k list\t2020.07.13\n字节跳动\t客户端\tLeetCode 25. K个一组反转链表\t2020.07.13\n字节跳动\t客户端\tLeetCode 53.最大子序和\t2020.07.13\n字节跳动\t客户端\t给定一个包含大写英文字母和数字的句子，找出这个句子所包含的最大的十六进制整数，返回这个整数的值。数据保证该整数在int表示范围内。\t2020.07.13\n字节跳动\t后端\t01矩阵最大正方形,经典题了,dp选左上最小+1,随便写了一下,没让跑test.\t2020.07.13\n字节跳动\t后端\t二叉树找target路径\t2020.07.13\n字节跳动\t后端\t二叉树转单链表,常规题,递归一下完事了.\t2020.07.13\n字节跳动\t后端\t算法题：从左上角走到右下角有多少种不同的路线\t2020.07.13\n字节跳动\tC++客户端\t10.leetcode 奇偶链表\t2020.07.12\n字节跳动\tC++客户端\t二进制中1的个数\t2020.07.12\n字节跳动\tC++客户端\t反转字符串\t2020.07.12\n字节跳动\t游戏客户端\t字符串数组两个字符串的最小距离（easy）\t2020.07.12\n字节跳动\t游戏客户端\t做题，数组中和最大的连续子数组（mid）\t2020.07.12\n字节跳动\t客户端\t189. 旋转数组\t2020.07.12\n字节跳动\t游戏客户端\t手撕 无序数组两数之和\t2020.07.12\n字节跳动\t游戏客户端\t手撕代码 两个栈实现队列\t2020.07.12\n字节跳动\t游戏客户端\t手撕代码 实现洗牌算法\t2020.07.12\n字节跳动\t算法\t二叉树子路径和为k的路径个数\t2020.07.12\n字节跳动\t算法\t1. 求和为k的子数组个数\t2020.07.12\n字节跳动\t算法\t2. 判断是否存在个数超过数组长度一半的数\t2020.07.12\n字节跳动\t客户端\t10、简化路径（算法提）\t2020.07.12\n字节跳动\t客户端\t11、二叉树的右视图（算法题）\t2020.07.12\n字节跳动\tandriod\t代码题：旋转数组\t2020.07.12\n字节跳动\tandriod\t代码题：两数相加（链表，要求原地实现，空间复杂度O(1)，这个犯蠢撕了好久结果还是靠强行打印发现的问题）\t2020.07.12\n字节跳动\tandriod\t代码题：a) 螺旋遍历矩阵\t2020.07.12\n字节跳动\tandriod\t；b)（变种）原地旋转图像\t2020.07.12\n字节跳动\t服务端\t算法题 反转链表（白给）\t2020.07.12\n字节跳动\t后端\t两个有序链表合并\t2020.07.12\n字节跳动\t后端\t给定2D矩阵，求里面1构成的正方形的最大面积。\t2020.07.12\n字节跳动\t后端\t算法题：接雨水\t2020.07.12\n字节跳动\t前端\t14.找出两个链表的交叉点（\t2020.07.12\n字节跳动\t客户端\t10.手撕代码：从无序数组中找到右边第一个大的数（与leetcode 739 每日体温类似）\t2020.07.12\n字节跳动\t后端\t22.抛硬币（一个0.3 一个0.7 如何保证公平）\t2020.07.12\n字节跳动\t后端\t23 z字形打印二叉树\t2020.07.12\n字节跳动\t后端\t- 一颗搜索二叉树有两个节点是颠倒的，恢复成正确的\t2020.07.12\n字节跳动\t后端\t- 单链表高位在前、低位在后，大数计算\t2020.07.12\n字节跳动\t后端\t- 阶乘\t2020.07.12\n字节跳动\t后端\t- 一个有序、有重复元素数组找到有多少满足 a + b = target的\t2020.07.12\n字节跳动\t前端\t1.斐波那契 递归实现/dp实现/空间优化\t2020.07.11\n字节跳动\t前端\t. 算法题 找出sum大于等于target的最短连续数组的长度 要通过所有测试数据 （找bug找半天，面试官一直温柔的说别着急哈哈）\t2020.07.11\n字节跳动\t测试\t10.代码:链表的逆序输出\t2020.07.11\n字节跳动\t测试\t11.代码:判断回文\t2020.07.11\n字节跳动\tC++客户端\t两两反转链表\t2020.07.10\n字节跳动\tC++客户端\t算法：判断两个链表是否相交\t2020.07.10\n字节跳动\tC++客户端\t算法：查找二叉树中两个节点的最近公共祖先\t2020.07.10\n字节跳动\t前端\t7.算法：合并有序数组\t2020.07.10\n字节跳动\t前端\t12 算法：逆序输出数字。\t2020.07.10\n字节跳动\t后端\t手撕：层序遍历\t2020.07.10\n字节跳动\t后端\t二叉树中序遍历\t2020.07.10\n字节跳动\t后端\t手撕 lru\t2020.07.10\n字节跳动\t算法\t第K大个数\t2020.07.10\n字节跳动\t算法\t链表找环\t2020.07.10\n字节跳动\t算法\t合并数组\t2020.07.10\n字节跳动\t后端\t编程题：字符串转换为整数，leetcode第67题\t2020.07.10\n字节跳动\t后端\t3 sum\t2020.07.10\n字节跳动\t客户端\t字符串反转\t2020.07.10\n字节跳动\t后端\t先问两个无序数组怎么找交集。\t2020.07.10\n字节跳动\t客户端\t手撕数组A-数组B\t2020.07.10\n字节跳动\t客户端\t手撕旋转矩阵90度\t2020.07.10\n字节跳动\tc++、\t手撕代码 求m个数中最大的n个数\t2020.07.10\n字节跳动\t服务端\t7.手撕代码，一道旋转链表的题目，leetcode easy水平\t2020.07.10\n字节跳动\t服务端\t8.手撕代码，一道矩阵相乘，也很简单。\t2020.07.10\n字节跳动\t算法\t给定一个数组，求连续子序列乘积为完全平方数的最大长度\t2020.07.10\n字节跳动\t算法\t判断给定序列是否为二叉搜索树的前序遍历\t2020.07.10\n字节跳动\t前端\t算法题：数组去重\t2020.07.10\n字节跳动\t前端\t爬楼梯\t2020.07.10\n字节跳动\t后端\t算法题，最长连续相同字符的子串\t2020.07.10\n字节跳动\t后端\t写个题，每K个节点翻转链表\t2020.07.10\n字节跳动\t后端\t1.原题，字符串全排列\t2020.07.09\n字节跳动\t后端\t2.原题，二叉树的最大路径和\t2020.07.09\n字节跳动\t后端\t1、类似于并查集的问题，最终求连通分量的数量\t2020.07.09\n字节跳动\t客户端\t算法题 镜像二叉树\t2020.07.09\n字节跳动\t测试\t算法题： leetcode1636\t2020.07.09\n字节跳动\t测试\t我一道leetcode 32\t2020.07.09\n字节跳动\t测试\t我一道leetcode 1\t2020.07.09\n字节跳动\t测试\tLeetCode 20 有效的括号\t2020.07.09\n字节跳动\t测试\t平衡二叉树\t2020.07.09\n字节跳动\t测试\t，二叉树遍历\t2020.07.09\n字节跳动\t后台\t回文串判断\t2020.07.09\n字节跳动\t后台\t二叉搜索树转链表\t2020.07.09\n字节跳动\t后台\t二叉树求和leetcode129-讲一下时间复杂度\t2020.07.09\n字节跳动\t后台\t1）求链表的倒数第k个节点\t2020.07.09\n字节跳动\t后台\t（2）序列化和反序列化二叉树\t2020.07.09\n字节跳动\t后台\t（3）求数组的极值点，找出一个满足的就行（二分查找）\t2020.07.09\n字节跳动\t后台\t前序遍历和中序遍历重构二叉树 （不给用HashMap 好在做出来了）\t2020.07.09\n字节跳动\t后台\t算法题：判断回文链表（中间拆分两条链表 后面的反转链表 对比数值是否相等）\t2020.07.09\n字节跳动\t后台\t算法题：奇数位升序偶数位降序的链表要求时间O(n)空间O(1)的排序？（奇偶拆分 偶链反转 归并merge）\t2020.07.09\n字节跳动\t测试\t手撕代码：求一个数组的所有子集\t2020.07.09\n字节跳动\t测试\t手撕代码：驼峰数组最大值\t2020.07.09\n字节跳动\t客户端\t问了一道链表反转；\t2020.07.09\n字节跳动\t客户端\t1、力扣原题113 路径综合\t2020.07.09\n字节跳动\t客户端\t2、给定一个升序数组，可能会有重复的数字，将数组里的数平方后，有多少不同的数。\t2020.07.09\n字节跳动\t前端\t二叉树所有根到叶子节点路径上所有节点，组成的数字之和\t2020.07.08\n字节跳动\t后端\t手撕代码：链表加法\t2020.07.08\n字节跳动\t客户端\t手写算法：链表合并\t2020.07.08\n字节跳动\t客户端\t手写算法：判断一棵树是否是镜像树\t2020.07.08\n字节跳动\t前端\t8、 算法题：判断给定的一颗树是否是 二叉查找树\t2020.07.08\n字节跳动\t前端\t9、算法题：给定一个数字数组，及数字出现次数，\t2020.07.08\n字节跳动\t客户端\t如何判断一颗树是否是完全二叉树\t2020.07.08\n字节跳动\t客户端\tlru\t2020.07.08\n字节跳动\tios\t算法题：求k大数\t2020.07.08\n字节跳动\tios\tleetcode1 两数之和\t2020.07.08\n字节跳动\tios\t剑指offer 62 圆圈中剩下的数字（约瑟夫环问题）\t2020.07.08\n字节跳动\tios\tleetcode 41 缺失的第一个正数\t2020.07.08\n字节跳动\t前端\t输出数组第k大元素\t2020.07.08\n字节跳动\t服务端\t括号匹配\t2020.07.08\n字节跳动\t后端\t链表的两两翻转\t2020.07.08\n字节跳动\t后端\tLRu\t2020.07.08\n字节跳动\t测试\t算法：返回一棵树的最大叶节点距离\t2020.07.07\n字节跳动\t测试\t对含有重复数字的数组去重并排序，手撕快排\t2020.07.07\n字节跳动\t测试\t算法:两个大数字符串求和输出字符串\t2020.07.07\n字节跳动\t测试\tlru\t2020.07.07\n字节跳动\t后端\t一面：最大连续子序列和和回文链表\t2020.07.07\n字节跳动\t后端\t二面：一个奇数位升序、偶数位降序的单向无环链表，排成一个有序链表\t2020.07.07\n字节跳动\t后端\t三面：S型打印二叉树，两条单向链表的相交节点，任意数组中的第一个缺失的正整数\t2020.07.07\n字节跳动\t客户端\t字符串反转\t2020.07.07\n字节跳动\t测试\t来个简单的—第一题：求二叉树最大长度\t2020.07.07\n字节跳动\t测试\t第二题：用String存两个很长的数，求和\t2020.07.07\n字节跳动\t后端\t1. 第一题 判断是否回文链表\t2020.07.07\n字节跳动\t后端\t2. 第二题 求逆数对\t2020.07.07\n字节跳动\t后端\t3.第三题 动态规划\t2020.07.07\n字节跳动\t后端\t1.第一题 最大化股票交易\t2020.07.07\n字节跳动\t后端\t2.第二题 最大化股票交易（有限交易）\t2020.07.07\n字节跳动\t客户端\t手撕代码 反转链表。\t2020.07.07\n字节跳动\t测试\t7.代码：驼峰字符串问题\t2020.07.07\n字节跳动\t后台\t算法题：滑动窗口匹配字符串\t2020.07.07\n字节跳动\t前端\t1. 实现斐波纳西数列（\t2020.07.07\n字节跳动\t算法\t用两个栈实现一个队列\t2020.07.07\n字节跳动\t算法\t一个list，一个target，求list中两数之和等于target的所有组合，list中有重复的，算medium吧。\t2020.07.07\n字节跳动\t算法\t1. Leetcode124\t2020.07.07\n字节跳动\t后端\t补充：8. 大数问题中的topK问题\t2020.07.07\n字节跳动\t后端\t补充：9. 给整数数组做数字次数统计，答unordered_map，让我再想其他方法，不会。\t2020.07.07\n字节跳动\t后端\t1.给你一个数组和一个target，找出和是target整数倍的连续子串\t2020.07.07\n字节跳动\t后端\t2.一个括号字符串，找出最长合法长度（写完了，优化一下，优化了）\t2020.07.07\n字节跳动\t算法\t子序最大和（要求子序列长度大于等于k）\t2020.07.07\n字节跳动\t后端\tLC128\t2020.07.07\n字节跳动\t客户端\t找链表交点，\t2020.07.07\n字节跳动\t客户端\t1. 判断二叉树是否镜像\t2020.07.07\n字节跳动\t客户端\t2. 给一个分数n/m，如果这个分数是无线循环小数，找出循环位。\t2020.07.07\n字节跳动\t客户端\t3. I am student 返回 student am I\t2020.07.07\n字节跳动\t客户端\t6.先升后降数组，找峰值的坐标，二分法\t2020.07.07\n字节跳动\t测试\t5. 撕代码环节：题目为leetcode第三题，求最长连续不含重复字符子串\t2020.07.07\n","description":"","id":59,"section":"talks","tags":[""],"title":"Leetcode高频","uri":"https://hugo.jiahongw.com/zh/talks/leetcode-hot/"},{"content":"描述符的就绪状态有两种判断方法: 边沿触发和水平触发。\n水平触发\n我认为这是“拉”模式或“民意调查”模式。为了确定描述符是否就绪，进程尝试执行非阻塞 I/O 操作。一个进程可以多次执行这样的操作。这允许在处理任何后续 I/O 操作方面有更大的灵活性ー例如，如果描述符已经准备好，进程可以选择读取所有可用的数据或者根本不执行任何 I/O 操作，或者选择不读取缓冲区中所有可用的输入数据。让我们通过一个例子来看看它是如何工作的。\n在 t0时，进程可以在非阻塞描述符上尝试 I/O 操作。如果 I/O 操作阻塞，系统调用将返回一个错误。\n然后在 t1时，进程可以再次尝试在描述符上进行 I/O。假设调用再次阻塞，并返回一个错误。\n然后在时间 t2，进程再次尝试描述符上的 I/O。假设调用再次阻塞，并返回一个错误。\n假设在 t3时，进程轮询描述符的状态，描述符就绪。然后进程可以选择实际执行整个 I/O 操作(例如，读取套接字上的所有可用数据)。\n让我们假设在 t4时进程轮询描述符的状态，而描述符没有准备好。调用再次阻塞，并且 I/O 操作返回一个错误。\n假设在 t5时，进程轮询描述符的状态，描述符就绪。进程随后可以选择只执行部分 I/O 操作(例如，只读取所有可用数据的一半)。\n​\t假设在 t6时，进程轮询描述符的状态，描述符就绪。这一次，进程可以选择根本不执行后续的 I/O。\n边缘触发 流程只有在文件描述符“就绪”时才会收到通知(通常是在文件描述符上有任何新活动时，因为它是上次被监视的)。我认为这就是“推送”模型，因为通知被推送到进程中，说明文件描述符的准备就绪情况。此外，对于 push 模型，只通知进程说描述符已经为 I/O 准备好了，而不提供其他信息，例如到达 socket 缓冲区的字节数。\n因此，当一个进程试图执行任何后续 I/O 操作时，它只配备了不完整的数据。为了解决这个问题，进程可以在每次获得描述符准备就绪通知时，尝试执行尽可能大的 I/O，因为如果不这样做，就意味着进程必须等待下一个通知到来，即使在下一个通知到来之前，在描述符上可以进行 I/O。\n开始：\n在 t2时，进程得到一个关于描述符已经准备好的通知。\n可用于 I/O 的字节流存储在缓冲区中。假设当进程在时间 t2获得通知时，有1024个字节可供读取。\n假设该进程只读取1024个字节中的500个字节。\n这意味着在 t3、 t4和 t5时，缓冲区中仍然有524个字节可供进程读取而不会阻塞。但是，由于进程只能在获得下一个通知后执行 I/O，因此在这段时间内，这524个字节将保留在缓冲区中。\n假设进程在时间 t6获得下一个通知，当额外的1024个字节到达缓冲区时。缓冲区上可用的数据总量现在是1548字节ー524字节，以前没有读过，1024字节是新到的。\n假设进程现在读取1024个字节。\n这意味着在第二次 I/O 操作结束时，524个字节仍然保留在缓冲区中，在下一个通知到达之前，进程将无法读取这个缓冲区。\n虽然在通知到达后立即执行所有 I/O 可能是临时的，但这样做会产生一些后果。单个描述符上的大型 I/O 操作可能会饿死其他描述符。此外，即使在级别触发通知的情况下，一个非常大的写或发送调用也有可能阻塞。\nMultiplexing I/O on descriptors 有几种在描述符上多路 I/O 的方法:\n— non-blocking I/O (the descriptor itself is marked as non-blocking, operations may finish partially)\n— signal driven I/O (the process owning the descriptor is notified when the I/O state of the descriptor changes)\n— polling I/O (with *select* or *poll* system calls, both of which provide level triggered notifications about the readiness of descriptors)\n— BSD specific kernel event polling (with the *kevent* system call).\n参考：\n https://medium.com/@copyconstruct/the-method-to-epolls-madness-d9d2d6378642  ","description":"","id":60,"section":"posts","tags":["Linux","epoll"],"title":"epoll的水平触发与边缘触发","uri":"https://hugo.jiahongw.com/zh/posts/linux/epoll-lt-et/"},{"content":"HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。\nHTTP/0.9 HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。\n 协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。\n HTTP/1.x  在早期，HTTP 使用一个简单的模型来处理这样的连接。这些连接的生命周期是短暂的：每发起一个请求时都会创建一个新的连接，并在收到应答时立即关闭。连接的成本较高。\n 当请求发起时，网络延迟和带宽都会对性能造成影响。现代浏览器往往要发起很多次请求(十几个或者更多)才能拿到所需的完整信息，证明了这个早期模型的效率低下。\n在 HTTP/1.x 里有多种模型：短连接, 长连接, 和 HTTP 流水线。\n短链接模型 HTTP/1.0 的默认模型。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。\n 在 HTTP/1.1 中，只有当 Connection 被设置为 close 时才会用到这个模型\n 长连接模型 保持连接去完成多次连续的请求，减少了不断重新打开连接的时间。在 HTTP/1.1 里，默认就是长连接的。\n 短连接有两个比较大的问题：创建新连接耗费的时间尤为明显，另外 TCP 连接的性能只有在该连接被使用一段时间后(热连接)才能得到改善。另外我们知道，TCP协议有个滑动窗口，有慢启动这回事，就是说每次建立新连接后，数据先是慢慢地传，然后滑动窗口慢慢变大，才能较高速度地传。\n 具体流程：\n一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：连接在空闲一段时间后会被关闭(服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间)。\n缺点：\n就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS attacks 攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。\n 长连接一个优化的方法就是设置一个超时时间，但是具体这个时间是多少，应该通过测试之后得出一个较为均衡的时间。\n 流水线模型(管线化) 多个连续的请求甚至都不用等待立即返回就可以被发送。HTTP 流水线在现代浏览器中并不是默认被启用的。\n默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n**流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟。理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。**就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的 MSS(Maximum Segment Size) 选项，仍然足够包含一系列简单的请求。\n 比如，当请求一个包含10张图片的HTML Web页面，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n 队头阻塞 在一般情况下，HTTP遵守“请求-响应”的模式，也就是客户端每次发送一个请求到服务端，服务端返回响应，这种模式很简单，但是有一个致命缺陷那就是页面中有多个请求，每个请求必须等到前一个请求响应之后才能发送，并且当前请求的响应返回之后，当前请求的下一个请求才能发送，流程如下图\n在TCP链接中，http请求必须等待前一个请求响应之后，才能发送，后面的依次类推，由此可以看出，如果在一个tcp通道中如果某个http请求的响应因为某个原因没有及时返回，后面的响应会被阻塞，这就是队头阻塞。\n 注意这里说的是响应之后，并不是请之后!\n 为了提高速度和效率，在持久连接的基础上，HTTP1.1进一步地支持在持久连接上使用管道化（pipelining）特性。管道化允许客户端在已发送的请求收到服务端的响应之前发送下一个请求，借此来减少等待时间提高吞吐，如果多个请求能在同一个TCP分节发送的话，还能提高网络利用率，流程如图：\n同一个tcp连接中可以同时发送多个http请求，也就是并发，但是在响应的时候，必须排队响应，谁先到达的谁先响应，相比不支持管道化的http请求确实提高了效率，但是还是有局限性，假如其中某个响应因为某种原因延迟了几秒，后面的响应都会被阻塞。上面箭头所指的响应如果阻塞了，那么这个也是队头阻塞。\n并且使用HTTP管道化还有一些限制:\n1、管道化要求服务端按照请求发送的顺序返回响应（FIFO），原因很简单，HTTP请求和响应并没有序号标识，无法将乱序的响应与请求关联起来。\n2、当客户端在支持管道化时需要保持未收到响应的请求，当连接意外中断时，需要重新发送这部分请求。如果这个请求只是从服务器获取数据，那么并不会对资源造成任何影响，而如果是一个提交信息的请求如post请求，那么可能会造成资源多次提交从而改变资源，这是不允许的。而不会对服务器资源产生影响的请求有个专业名词叫做幂等请求。客户端在使用管道化的时候请求方式必须是幂等请求。\n比较：\n上面的管线化的模型就是加速了请求的过程，但是响应的过程还是存在队头阻塞。\n 因为HTTP管道化本身可能会导致队头阻塞的问题，以及上面提到的一些限制，现代浏览器默认都关闭了管道化，并且大部分服务器也是默认不支持管道化的。\n 如何解决队头阻塞？\n客户端使用并发长连接，注意这个并发指的是tcp并发连接。\n 并发长连接虽然在一定程度上解决了http的队头阻塞，但是会对服务器的性能有较高的要求\n HTTP/2  HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为\u0026quot;帧\u0026rdquo;（frame）：头信息帧和数据帧。\n 😆 HTTP/2 没有改动 HTTP 的应用语义。 HTTP 方法、状态代码、URI 和标头字段等核心概念一如往常。 不过，HTTP/2 修改了数据格式化（分帧）以及在客户端与服务器间传输的方式。这两点统帅全局，通过新的分帧层向我们的应用隐藏了所有复杂性。 因此，所有现有的应用都可以不必修改而在新协议下运行。\n 为什么不是 HTTP/1.2？\n为了实现 HTTP 工作组设定的性能目标，HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端向后兼容，因此协议的主版本提升到 HTTP/2。\n 二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。\n这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。\n数据流、消息和帧  数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。  关系：\n 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。(多工) 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。  简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。\nHTTP/2 帧结构如下：\n实际的传输过程可能是下面这样(吞吐量增大)：\n请求与响应复用 HTTP/2 中新的二进制分帧层实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。\n数据流优先级 我们来看一下上图中的几个操作示例。 从左到右依次为：\n 数据流 A 和数据流 B 都没有指定父依赖项，依赖于隐式“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 依赖于根数据流；C 依赖于 D。 因此，D 应先于 C 获得完整资源分配。 权重不重要，因为 C 的依赖关系拥有更高的优先级。 数据流 D 应先于 C 获得完整资源分配；C 应先于 A 和 B 获得完整资源分配；数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 应先于 E 和 C 获得完整资源分配；E 和 C 应先于 A 和 B 获得相同的资源分配；A 和 B 应基于其权重获得比例分配。  流控制 流控制是一种阻止发送方向接收方发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常繁忙、处于较高的负载之下，也可能仅仅希望为特定数据流分配固定量的资源。 例如，客户端可能请求了一个具有较高优先级的大型视频流，但是用户已经暂停视频，客户端现在希望暂停或限制从服务器的传输，以免提取和缓冲不必要的数据。 再比如，一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接的速度来控制其资源利用率；等等。类似TCP流量控制。\n服务器推送 HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源（图 12-5），而无需客户端明确地请求。\n标头压缩 每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。为了减少此开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：\n 这种格式支持通过静态霍夫曼代码对传输的标头字段进行编码，从而减小了各个传输的大小。 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输的值进行有效编码。  利用霍夫曼编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。\n哈夫曼树如何压缩 文件压缩的主要思想是利用哈夫曼编码来实现的，但是得到编码之前我们需要构建这棵树。那么利用什么来构建树呢？！这里，我们需要统计每个字符出现的次数，用次数来构建HuffmanTree。假设我们现在有一个.txt的小文件，内容是\u0026quot;aaaabbbccd\u0026quot;。字符存在计算机中时以字节为单位的，因此我们需要将这些字符压缩成0、1表示的编码，0和1表示字节中的“位”，这样能大大降低文件的大小。\n体验HTTP2 https://http2.akamai.com/demo\n参考链接：\n HTTP 连接管理进化论 https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn 白话http队头阻塞  ","description":"http协议迭代了好几个版本，从一开始的短链接模型到长连接模型，最后还衍生出二进制帧层......","id":61,"section":"posts","tags":["network","http","https"],"title":"Http协议浅析","uri":"https://hugo.jiahongw.com/zh/posts/network/http/"},{"content":"C/C++ ⭕面向对象与面向过程 Leetcode对面向对象的理解：面向对象的编程方式使得每一个类都只做一件事。面向过程会让一个类越来越全能，就像一个管家一样做了所有的事。而面向对象像是雇佣了一群职员，每个人做一件小事，各司其职，最终合作共赢！\n面向对象的特点是可维护、可复用、可扩展、灵活性好，它真正强大的地方在于：随着业务变得越来越复杂，面向对象依然能够使得程序结构良好，而面向过程却会导致程序越来越臃肿。\n让面向对象保持结构良好的秘诀就是 设计模式。\n➕C++程序设计模型 程序模型(procedural model)\n抽象数据模型(abstract data type model)\n例如std::string\n面向对象模型(object-oriented model)\n✖多态 多态如何实现？\n要实现C++中OO程序设计的多态性质，只有通过point或者reference的间接处理。\n多态用途？\n经由一个共同的接口来影响类型的封装，这个接口通常被定义在一个抽象的base class中。\n虚函数与纯虚函数\n引入虚函数是为了动态绑定,引入虚函数是为了动态绑定。\n基类需要虚析构函数的原因\n当derived class经由一个base class指针被删除而该base class的析构函数为non-virtual时，将发生未定义行为。通常将发生资源泄漏。\n解决方法即为：为多态基类声明一个virtual 析构函数。\n🖐 C++11新特性  自动类型推断 auto 匿名函数 Lambda 智能指针 显示重写(覆盖)override和final  📇const 关键字const出现在星号左边，表示被指物是常量；如果出现在星号右边，表示指针本身是常量；如果出现在两边，表示被指物和指针都是常量。\n作用：\n 修饰变量，说明该变量不可以被改变； 修饰指针，分为指向常量的指针（pointer to const）和自身是常量的指针（常量指针，const pointer）； 修饰引用，指向常量的引用（reference to const），用于形参类型，即避免了拷贝，又避免了函数对值的修改； 修饰成员函数，说明该成员函数内不能修改成员变量。  🗽Static   静态常量整数成员可以在类内进行初始化，其他需要在类外面进行初始化\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #include \u0026lt;iostream\u0026gt;using namespace std; class A{ public: static const int val = 5; static int GG; }; int A::GG = 6; int main() { cout \u0026lt;\u0026lt; A::val \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; A::GG \u0026lt;\u0026lt; endl; return 0; }   5 6   C++支持重载，C不支持重载\n📤 extern \u0026ldquo;C\u0026quot;作用 extern \u0026ldquo;C\u0026quot;的主要作用就是为了能够正确实现C++代码调用其他C语言代码。加上extern \u0026ldquo;C\u0026quot;后，会指示编译器这部分代码按C语言（而不是C++）的方式进行编译。由于C++支持函数重载，因此编译器编译函数的过程中会将函数的参数类型也加到编译后的代码中，而不仅仅是函数名；而C语言并不支持函数重载，因此编译C语言代码的函数时不会带上函数的参数类型，一般只包括函数名。\n这个功能十分有用处，因为在C++出现以前，很多代码都是C语言写的，而且很底层的库也是C语言写的，为了更好的支持原来的C代码和已经写好的C语言库，需要在C++中尽可能的支持C，而extern \u0026ldquo;C\u0026quot;就是其中的一个策略。\n 如果C++调用一个C语言编写的.DLL时，当包括.DLL的头文件或声明接口函数时，应加extern \u0026ldquo;C\u0026rdquo; {　}。  📌inline内联函数 static静态函数 普通函数区别 面试时候一般只会问你区别，所有本文只说区别。\n内联函数和普通函数的区别：\n内联函数和普通函数最大的区别在于内部的实现方面，当普通函数在被调用时，系统首先跳跃到该函数的入口地址，执行函数体，执行完成后，再返回到函数调用的地方，函数始终只有一个拷贝； 而内联函数则不需要进行一个寻址的过程，当执行到内联函数时，此函数展开（很类似宏的使用），如果在 N处调用了此内联函数，则此函数就会有N个代码段的拷贝。\n静态函数和普通函数的区别：\nstatic函数和普通函数的最大的区别在于作用域方面，static函数限定在本源码文件中，不能被本源码文件以外的代码文件调用。而普通的函数，默认是extern的，也就是说，可以被其它代码文件调用该函数。同时static函数在内存中只有一份，普通函数在每个被调用中维持一份拷贝。\ninline与define的区别：\n内联函数和宏的区别在于，宏是由预处理器对宏进行替代，而内联函数是通过编译器控制来实现的。而且内联函数是真正的函数，只是在需要用到的时候，内联函数像宏一样的展开，所以取消了函数的参数压栈，减少了调用的开销。你可以象调用函数一样来调用内联函数，而不必担心会产生于处理宏的一些问题。内联函数与带参数的宏定义进行下比较，它们的代码效率是一样，但是内联欢函数要优于宏定义，因为内联函数遵循的类型和作用域规则，它与一般函数更相近，在一些编译器中，一旦关上内联扩展，将与一般函数一样进行调用，比较方便。\ninline使用：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  // 声明1（加 inline，建议使用） inline int functionName(int first, int second,...); // 声明2（不加 inline） int functionName(int first, int second,...); // 定义 inline int functionName(int first, int second,...) {/****/}; // 类内定义，隐式内联 class A { int doA() { return 0; } // 隐式内联 } // 类外定义，需要显式内联 class A { int doA(); } inline int A::doA() { return 0; } // 需要显式内联   优缺点：\n优点\n 内联函数同宏函数一样将在被调用处进行代码展开，省去了参数压栈、栈帧开辟与回收，结果返回等，从而提高程序运行速度。 内联函数相比宏函数来说，在代码展开时，会做安全检查或自动类型转换（同普通函数），而宏定义则不会。 在类中声明同时定义的成员函数，自动转化为内联函数，因此内联函数可以访问类的成员变量，宏定义则不能。 内联函数在运行时可调试，而宏定义不可以。  缺点\n 代码膨胀。内联是以代码膨胀（复制）为代价，消除函数调用带来的开销。如果执行函数体内代码的时间，相比于函数调用的开销较大，那么效率的收获会很少。另一方面，每一处内联函数的调用都要复制代码，将使程序的总代码量增大，消耗更多的内存空间。 inline 函数无法随着函数库升级而升级。inline函数的改变需要重新编译，不像 non-inline 可以直接链接。 是否内联，程序员不可控。内联函数只是对编译器的建议，是否对函数内联，决定权在于编译器。  参考：\n inline内联函数 static静态函数 普通函数区别 C++ inline和#define宏的区别  💟C++内存布局   内核空间\n  栈\n1、stack存放函数的临时变量、局部变量、函数参数和返回值\n2、由编译器自动分配和释放。\n  动态链接库(共享映射区)\n调用的库文件，位于堆和栈之间\n  堆\nheap用来动态分配内存，由程序员控制，交由程序自身决定开辟和释放。\n  全局数据区\n.bss\nbss段用来存放没有被初始化和已经被初始化为0的全局变量\n.data\ndata段用来存放已经被初始化为非0的全局变量\n  常量区\n.rodata\nrodata段用来存放常量数据、被编译器自动存放来的字符串和加const关键字的常量数据。\n  代码区\n.text\ntext段用来存放代码和部分整数常量，该段是可执行的。\n  💱 C++空类产生哪些成员函数 构造、拷贝构造、赋值、析构、取地址、取地址const，\nC++ 空类默认产生的类成员函数\n✈ 指针常见错误 面试题Getmemory\n🚙 C的内存结构 C语言内存布局\n🗡程序运行时内存分配 变量和函数占用的内存是系统在程序运行时为程序分配的，但并不是所有的变量和函数都被分配在同一块内存区域中。对于一个C++程序来说，系统一般采用3种方式为程序分配内存，下面将分别介绍这3种方式。\n  从静态存储区域分配\n**这部分内存在程序编译的时候就已经分配好，并且这块内存在程序的整个运行期间都存在。例如在函数外定义的全局变量，以及在创建时使用static修饰符的变量。**在该区域存储的内容一般是全局变量，其中存储在数据段中的全局变量通常已经被初始化。\n  在栈上进行内存分配\n这部分区域被称为堆栈，但这只是一种习惯性说法，并不是堆和栈的统称。该部分存储的变量一般是在函数体中定义的局部变量（不包括static声明的变量，static意味着变量存放在数据段中），除此之外，经常在栈区出现的还有传递给函数的参数和函数的返回值等。栈区变量的生存周期是在入栈前（函数开始被调用）获得内存空间，而在出栈时（函数结束调用）释放内存空间。因此尽量不要将函数中的局部变量作为函数的返回值，因为在函数调用结束后，局部变量就不存在了，再使用此变量的值作为返回值，会使程序获取的返回值有可能为随机数。在执行函数时，函数体内的局部变量在栈上被自动创建，而在函数执行结束时，这些存储单元自动被释放。栈内存分配由操作系统完成而不需要程序员手动参与。因此其执行效率非常高。但是整个栈区可以被分配的内存容量有限。因此定义过多的未使用的局部变量会使程序执行变慢。\n  从堆上分配\n通常称为动态分配的内存，该部分内存区域的大小并不固定，当程序运行时有程序员用 malloc() 函数等内存分配函数来分配，或使用 new 操作符等系统提供的函数来分配。该内存的大小可以根据程序中的实际需要来指定。该部分内存空间不会随着函数运行的结束而被自动回收，也不会被自动释放，需要程序员自己用 free() 函数或 delete 操作符进行内存的回收。动态内存的生存期由程序员自行决定，但如果分配了空间，就必须对其回收，否则运行的程序会出现内存泄漏，并且频繁地分配和释放不同大小的堆空间将会产生堆内碎块，间接降低内存空间的使用率，严重时会产生大量内存碎片。\n  　（内存碎片是一些分散的内存区域，大量内存碎片的存在会降低内存的使用率。）\n👽struct字节对齐问题 1 2 3 4 5 6 7  typedef struct { char c1; short s; char c2; int i; } T_FOO;   上面的结构体使用sizeof输出大小为12。（假设这个结构体的成员在内存中是紧凑排列的，且c1的起始地址是0，则s的地址就是1，c2的地址是3，i的地址是4）\n字节对齐\n现代计算机中，内存空间按照字节划分，理论上可以从任何起始地址访问任意类型的变量。但实际中在访问特定类型变量时经常在特定的内存地址访问，这就需要各种类型数据按照一定的规则在空间上排列，而不是顺序一个接一个地存放，这就是对齐。\n对齐的原因和作用\n  不同硬件平台对存储空间的处理上存在很大的不同。某些平台对特定类型的数据只能从特定地址开始存取，而不允许其在内存中任意存放。例如Motorola 68000 处理器不允许16位的字存放在奇地址，否则会触发异常，因此在这种架构下编程必须保证字节对齐。\n  但最常见的情况是，如果不按照平台要求对数据存放进行对齐，会带来存取效率上的损失。比如32位的Intel处理器通过总线访问(包括读和写)内存数据。每个总线周期从偶地址开始访问32位内存数据，内存数据以字节为单位存放。如果一个32位的数据没有存放在4字节整除的内存地址处，那么处理器就需要2个总线周期对其进行访问，显然访问效率下降很多。\n因此，通过合理的内存对齐可以提高访问效率。为使CPU能够对数据进行快速访问，数据的起始地址应具有“对齐”特性。比如4字节数据的起始地址应位于4字节边界上，即起始地址能够被4整除\n  此外，合理利用字节对齐还可以有效地节省存储空间。但要注意，在32位机中使用1字节或2字节对齐，反而会降低变量访问速度。因此需要考虑处理器类型。还应考虑编译器的类型。在VC/C++和GNU GCC中都是默认是4字节对齐。\n  对齐准则\n  sizeof的最终结果必然是结构内部最大成员的整数倍，不够补齐。\n  结构内部各个成员的首地址必然是自身大小的整数倍。\n如果定义了#pragma pack(n)，则上述俩条规则可定义为：\n1、整个sizeof的最终结果必然是 min[n,结构内部最大成员] 的整数倍，不够补齐。\n2、结构内部各个成员的首地址必然是min[n,自身大小]的整数倍。\n 由上述原则可知，在写结构体时，成员先后不要随意写哦，应遵循从大到小的原则，这样有助于节省空间。\n   使用四字节对齐：\n1 2 3 4 5 6 7 8 9 10  #pragma pack(push)#pragma pack(4)typedef struct { char c1; short s; char c2; int i; } T_FOO; #pragma pack(pop)  对其使用sizeof得到的大小为12\n不使用字节对齐，即使用1字节对齐：\n1 2 3 4 5 6 7 8 9 10  #pragma pack(push)#pragma pack(1)typedef struct { char c1; short s; char c2; int i; } T_FOO; #pragma pack(pop)  大小为8\n参考：C语言字节对齐问题详解\nⓜmalloc一次性最大能申请多大内存空间？ 具体情况分析\n🔶字节序了解吗？讲一下大端对齐和小端对齐 主机字节序又叫 CPU 字节序，其不是由操作系统决定的，而是由 CPU 指令集架构决定的。主机字节序分为两种：\n 大端字节序（Big Endian）：高序字节存储在低位地址，低序字节存储在高位地址 小端字节序（Little Endian）：高序字节存储在高位地址，低序字节存储在低位地址  32 位整数 0x12345678 是从起始位置为 0x00 的地址开始存放，则：\n   内存地址 0x00 0x01 0x02 0x03     大端 12 34 56 78   小端 78 56 34 12    判断大端小端\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #include \u0026lt;iostream\u0026gt;using namespace std; int main() { int i = 0x12345678; if (*((char*)\u0026amp;i) == 0x12) cout \u0026lt;\u0026lt; \u0026#34;大端\u0026#34; \u0026lt;\u0026lt; endl; else cout \u0026lt;\u0026lt; \u0026#34;小端\u0026#34; \u0026lt;\u0026lt; endl; return 0; }   网络字节顺序是 TCP/IP 中规定好的一种数据表示格式，它与具体的 CPU 类型、操作系统等无关，从而可以保证数据在不同主机之间传输时能够被正确解释。\n网络字节顺序采用：大端（Big Endian）排列方式。\n📏字符串与字符串指针的大小  sizeof 对数组，得到整个数组所占空间大小。 sizeof 对指针，得到指针本身所占空间大小。  可以看看下面的例子：\n1 2 3 4 5 6 7 8 9  char *a = \u0026#34;abcd\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;sizeof a = \u0026#34; \u0026lt;\u0026lt; sizeof(a) \u0026lt;\u0026lt; \u0026#34;\u0026#34; \u0026lt;\u0026lt; \u0026#34;strlen(a) = \u0026#34; \u0026lt;\u0026lt; strlen(a) \u0026lt;\u0026lt; endl; char b[] = \u0026#34;abcd\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;sizeof b = \u0026#34; \u0026lt;\u0026lt; sizeof(b) \u0026lt;\u0026lt; \u0026#34;\u0026#34; \u0026lt;\u0026lt; \u0026#34;strlen(b) = \u0026#34; \u0026lt;\u0026lt; strlen(b) \u0026lt;\u0026lt; endl; char c[10] = \u0026#34;abcd\u0026#34;; cout \u0026lt;\u0026lt; \u0026#34;sizeof c = \u0026#34; \u0026lt;\u0026lt; sizeof(c) \u0026lt;\u0026lt; \u0026#34;\u0026#34; \u0026lt;\u0026lt; \u0026#34;strlen(c) = \u0026#34; \u0026lt;\u0026lt; strlen(c) \u0026lt;\u0026lt; endl;   输出为：\nsizeof a = 8 strlen(a) = 4 sizeof b = 5 strlen(b) = 4 sizeof c = 10 strlen(c) = 4 strlen()的结果都一样，返回的是字符串的长度(不计\\0);但是sizeof()是返回类型的大小，假如是指针，返回当前操作系统地址指针的大小；假如是显示数组初始化的数组，就返回数组实际大小的字节数。\n💃动态链接和静态链接的区别 https://www.cnblogs.com/tracylee/archive/2012/10/15/2723816.html\n静态链接方式：在程序执行之前完成所有的组装工作，生成一个可执行的目标文件（EXE文件）。\n动态链接方式：在程序已经为了执行被装入内存之后完成链接工作，并且在内存中一般只保留该编译单元的一份拷贝。\n🛩智能指针的多线程问题 🎪 关于template的三个问题  template的声明。 如何“实例化（instantiates）”class object、inline nonmember以及 member templatefunctions。这些是“每一个编译单位都会拥有一份实例”的东西。 如何“实例化（instantiates）”nonmember、member template functions以及 static template class members。这些都是“每一个可执行文件中只需要一份实例”的东西。这也就是一般而言 template所带来的问题。  代码样例：\n首先，当编译器看到template class 声明时，它会做出什么反应？在实际程序中，什么反应也没有！\n静态成员变量\n对于模板类里面的静态成员变量，当初始化它的时候，我们使用下面一条语句才能使用：\n1  Point\u0026lt; float \u0026gt;::freeList;   不能使用Point::freeList;，此时会使其一份实例与 Point class 的 float instantiation在程序中产生关联。\n当我们再调用下面的语句时：\n1  Point\u0026lt; double \u0026gt;::freeList;   就会出现第二个freeList实例，与Point class的double instantiation产生关联。\n类对象实例\n所以，一个class object 的定义，不论是由编译器暗中地做（像稍早程序代码中出现过的temporary），或是由程序员像下面这样显式地做：\n1  const Point\u0026lt; float \u0026gt; origin;   都会导致template class的“实例化”，也就是说，float instantiation的真正对象布局会被产生出来。\n 回顾先前的 template 声明，我们看到 Point 有三个 nonstatic members，每一个的类型都是Type。Type现在被绑定为float，所以origin的配置空间必须足够容纳三个float成员。\n 成员函数\n然而，member functions（至少对于那些未被使用过的）不应该被“实例化”。只有在memberfunctions被使用的时候，C++Standard才要求它们被“实例化”。\n这些函数在什么时候“实例化”？目前流行两种策略：\n 在编译的时候。那么函数将“实例化”于 origin和 p存在的那个文件中。 在链接的时候。那么编译器会被一些辅助工具重新激活。template 函数实例可能被放在这一文件中、别的文件中或一个分离的存储位置。  模板错误报告：\ncfront对template的处理是完全解析（parse）但不做类型检验；只有在每一个实例化操作（instantiation）发生时才做类型检验。所以在一个parsing策略之下，所有语汇（lexing）错误和解析（parsing）错误都会在处理template声明的过程中被标示出来。\n❗c++的异常处理机制 欲支持exception handling，编译器的主要工作就是找出catch子句，以处理被抛出来的exception。\n一般而言，exception handling机制需要与编译器所产生的数据结构以及执行期的一个exception library紧密合作。在程序大小和执行速度之间，编译器必须有所抉择：\n 为了维护执行速度，编译器可以在编译时期建立起用于支持的数据结构。这会使程序的大小发生膨胀，但编译器可以几乎忽略这些结构，直到有个 exception被抛出来。 为了维护程序大小，编译器可以在执行期建立起用于支持的数据结构。这会影响程序的执行速度，但意味着编译器只有在必要的时候才建立那些数据结构（并且可以抛弃之）。  C++的exception handling由三个主要的语汇组件构成：\n 一个 throw 子句。它在程序某处发出一个 exception。被抛出去的exception可以是内建类型，也可以是使用者自定类型。 一个或多个 catch子句。每一个 catch子句都是一个 exception handler。它用来表示说，这个子句准备处理某种类型的 exception，并且在封闭的大括号区段中提供实际的处理程序。 一个 try区段。它被围绕以一系列的叙述句（statements），这些叙述句可能会引发 catch子句起作用。  当一个exception 被抛出去时，控制权会从函数调用中被释放出来，并寻找一个吻合的catch子句。如果都没有吻合者，那么默认的处理例程terminate（）会被调用。当控制权被放弃后，堆栈中的每一个函数调用也就被推离（popped up）。这个程序称为unwinding the stack。在每一个函数被推离堆栈之前，函数的local class objects的destructor会被调用。\n🏃执行期类型识别（Runtime Type Identification，RTTI）  类型安全的向下转型，一个安全的向下转型需要在执行期可以对指针进行查询，确定可以正确且安全的向下转型。因为需要支持查询，则需要在转型时的空间和执行时间上的额外负担。额外负担有：  　1) 额外空间以存储类型信息，通常为一个指向某类型信息节点的指针；\n　2) 额外时间以决定执行期的类型。\n　C++利用虚表，将类相关的RTTI对象地址(即type_info对象地址)放在虚表中(一般为第一个slot)，此时编译器在编译的时候设定vtpr和虚表即可，当需要向下转型时利用RTTI决定执行期类型等信息。\n 类型安全的动态转换dynamic_cast可以确保转化合适的类型对象，若失败则返回空指针(当转化为指针类型时)或者抛出异常(当转化为引用类型时)。dynamic_cast的成本在于运行期的类型识别判断。\n  使用typeid运算符获取对象的类型，即type_info，当然也可以通过typeid来确定是否满足某个类型，然后调用static_cast转化即可。即if(typeid(someObj) == typeid(someType) ) {someType \u0026amp;rf = static_cast\u0026lt;someType\u0026amp;\u0026gt;(someObj);}。此外RTTI不仅可用于多态类，也可以用于内置类型和非多态的用户自定义类型。\n  🚧C++构造函数  四种情况，造成“编译器会为未声明的constructor的classes合成一个default constructor\n   带有Default Constructor 的Member Class Object\n如果一个class没有任何constructor，但它内含一个member object，而后者 有default constructor，那么这个class的implicit default constructor 就是 “nontrivial”,编译器需要为此class合成出一个default constructor。不过这个 合成操作只有在constructor真正需要被调用时才会发生。\n例子：Bar会生成一个默认的构造函数\n 提示：被合成的默认构造函数只是满足编译器的需要，而不是程序的需要。\n   “带有 Default Constructor”的 Base Class\n如果一个没有任何constructors的class派生自一个“带有default constructor”的base class,那么这个derived class的default constructor会被视为nontrivial，并因此需要被合成出来。它将调用上一层base classes的default constructor(根据它们的声明次序）。对一个后继派生的class而言，这个合成的constructor和一个“被明确提供的default constructor”没有什么差异。\n  “带有一个 Virtual Function”的Class\n构造函数的构建主要是为了初始化或者更新虚函数指针\n例子\n  “带有一个Virtual Base Class”的Class\n例子：\n  在合成的default constructor中，只有base class subobjects和member classobjects会被初始化。所有其它的 nonstatic data member，如整数、整数指针、整数数组等等都不会被初始化。这些初始化操作对程序而言或许有需要，但对编译器则并非必要。如果程序需要一个“把某指针设为0”的default constructor,那么提供它的人应该是程序员。\n👮C++拷贝构造函数 有三种情况，会以一个object的内容作为另一个class object的初值:\n  对一个object做明确的初始化操作，像这样：\n1 2 3 4  class X{...}; X x; //明确地以一个object的内容作为另一个class object的初值 X xx = x;     当object 被当作参数交给某个函数时,例如：\n1 2 3 4 5 6  extern void foo(X x); void test(){ X xx; foo(xx);\t//以xx作为foo（）第一个参数的初值（不明显的初始化操作） }     当函数传回一个class object时，例如：\n1 2 3 4  X foo_bar(){ X xx; return xx; }     Default Memberwise Initialization 如果函数并没有提供一个explicit copy constructor，那么其拷贝同类型对象的操作由default memberwise initialization完成，其执行策略为：对每一个内建或派生的data member的值，从某一个object拷贝到另一个object。不过它不会拷贝其中的member class object，而是实施递归式的memberwise initialization(对每一个对象依次执行default memberwise initialization）。\n Default constructors 和 copy constructors在必要的时候才由编译器产生出来。\n Bitwise Copy Semantics(位逐次拷贝） 看看下面的程序段：\n1 2 3 4 5 6  #include\u0026#34;Word.h\u0026#34;Word noun(\u0026#34;book\u0026#34;); void foo() { Word verb = noun; //... }   我们不可能预测这个初始化操作的程序行为。如果class Word的设计者定义了一个copy constructor，verb的初始化操作会调用它。但如果该class 没有定义explicit copy constructor,那么是否会有一个编译器合成的实体被调用呢？这就得视该class 是否展现\u0026quot;bitwise copy semantics”而定。\n举个例子，已知下面的class Word 声明：\n1 2 3 4 5 6 7 8 9  //以下声明展现了bitwise copy semantics class Word{ public: Word(const char*); ~Word(){ delete []str;} //.. private: int cnt; char *str; }；   这种情况下并不需要合成出一个default copy constructor，因为上述声明展现了“default copy semantics”。\n再如下面的例子：\n1 2 3 4 5 6 7 8 9  //以下声明并未展现出bitwise copy semantics class Word{ public: Word(const String\u0026amp;); ~Word(){ delete []str;} //.. private: int cnt; String str; }；   其中String声明了一个显示的拷贝构造函数\n1 2 3 4 5 6  class String{ public: String(const char*); ~String(); //... };   在这个情况下，编译器必须合成出一个copy constructor 以便调用member class String object的 copy constructor:\n什么时候一个class不展现出“bitwise copy semantics”呢?有四种情况：\n 当class内含一个member object而后者的class声明有一个copy constructor时（不论是被class 设计者明确地声明，就像前面的String那样；或是被编译器合成，像class Word那样）。 当class继承自一个base class而后者存在有一个copy constructor时（再次强调，不论是被明确声明或是被合成而得）。 当class声明了一个或多个virtual functions时。 当class派生自一个继承串链，其中有一个或多个virtual base classes时。  前两神情况中，编译器必须将member或base class的“copy constructors调用操作”安插到被合成的copy constructor中。\n虚函数指针\n编译时期有两个程序的扩张操作：\n■ 增加一个virtual function table（vtbl)，内含每一个有作用的 virtual function的地址。\n■ 将一个指向virtual function table的指针（vptr)，安插在每一个class object内。\n很显然，如果编译器对于每一个新产生的class object的vptr不能成功而正确地设好其初值，将导致可怕的后果。因此，当编译器导入一个vptr到class之中时，该class就不再展现bitwise semantics了。现在，编译器需要合成出一个copy constructor，以求将vptr适当地初始化，下面是个例子。\n以一个派生类对象作为其父类对象的初始值，编译器需要**”判断“**\n程序转化语义 下面的程序：\n1 2 3 4 5 6 7  #include \u0026lt;iostream\u0026gt; X foo(){ X xx; // ... \treturn xx; }   可能会做出以下假设：\n 每次foo0被调用，就传回xx的值。 如果class X定义了一个copy constructor，那么当foo0被调用时，保证该copy constructor 也会被调用。   第一个假设的真实性，必须视class X如何定义而定。第二个假设的真实性，虽然也有部分必须视class X如何定义而定，但最主要还是视你的C++编译器所提供的进取性优化程度（degree of aggressive optimization)而定。你甚至可以假设在一个高品质的C++编译器中，上述两点对于class X的nontrivial definitions都不正确。\n 显式初始化操作(Explicit Initialization)\n下面的例子是三种显示的拷贝构造操作：\n1 2 3 4 5 6  void test() { X x0; X x1(x0); // 第一种显示拷贝构造  X x2 = x0; // 第二种显示拷贝构造  X x3 = X(x0); // 第三种显示拷贝构造 }   上面的程序转化可能会有两个阶段：\n 重写每一个定义，其中的初始化操作会被剥除。 class的copy constructor 调用操作会被安插进去。  可能会变成下面这样\n1 2 3 4 5 6 7 8 9 10  void test_Cpp() { // ... x0的构造函数  // 三个声明  X x1,x2,x3; // 三个定义  x1.X::X(x0); x2.X::X(x0); x3.X::X(x0); }   参数的初始化（Argument Initialization)\nC++标准说，把一个class object 当做参数传给一个函数，相当于一下形式的初始化操作：\n(定义一个类X，作为test函数的参数)\n1 2  X xx; test(xx);   其中test函数的声明如下：\n1  void test(X x0);   上面的参数xx这个变量作为参数传到函数test中，会产生一个临时对象，并且会调用拷贝构造函数将这个临时对象初始化，经过这些步骤这个参数才真正传入函数中进行使用。\n所以上面的代码可能会转换为：\n1 2 3  X __temp;\t// 临时对象产生 __temp.X::X(xx);\t//编译器对拷贝构造函数的调用 test(__temp);\t//重新改写函数的调用操作   然而上面的做法只完成了一般，因为函数xx的声明还是一个传值的参数，test的声明也也须被转化，形式参数必须从原先的一个class X object改变为一个class X reference,像这样：\n1  void test(X\u0026amp; x0)；   返回值的初始化（Return Value Initialization)\n例如下面的例子：\n1 2 3 4 5  X test() { X xx; return xx; }   编译器可能会做如下NRV优化：\n1 2 3 4 5 6  X __result; void test(X\u0026amp; __result) { __result.X::X()； return; }   当类显示Bitwise的情况下，应该不去定义一个拷贝构造函数，使用编译器合成就非常高效和安全！\nData语义学\n💽C++——data语义 每一个class object 因此必须有足够的大小以容纳它所有的 nonstatic datamembers。有时候其值可能令你吃惊（正如那位法国来信者），因为它可能比你想象的还大，原因是：\n 由编译器自动加上的额外data members，用以支持某些语言特性（主要是各种virtual特性）. 因为alignment（边界调整）的需要。  Data Member的绑定\n看看下面这个例子：\n1 2 3 4 5 6 7 8 9 10 11 12  //某个foo.h头文件，从某处含入 extern float x; //程序员的Point3d.h文件 class Point3d{ public: Point3d(float,float,float); //问题：被传回和被设定的x是哪一个x呢  float X() const { return x;} void X( float new x) const{x=new_x;} //..… private: float x,y,z; };   如果我问你Point3d::X()传回哪一个x？是class内部的那个x，还是外部（extern)的那个x？今天每个人都会回答我是内部那一个。这个答案是正确的，但并不是从过去以来一直都正确！\n早期C++的两种防御性程序设计风格：\n 把所有的data members放在class声明起头处，以确保正确的绑定： 把所有的inline functions，不管大小都放在class声明之外：  这个语言规则被称为“member rewriting rule”，大意是“一个inline函数实体，在整个 class声明未被完全看见之前，是不会被评估求值（evaluated）的”。C++Standard 以“member scope resolution rules”来精炼这个“rewriting rule”，其效果是，如果一个inline函数在class声明之后立刻被定义的话，那么就还是对其评估求值（evaluate)。\n然而，这对于member function的argument list 并不为真。Argument list中的名称还是会在它们第一次遭遇时被适当地决议（resolved）完成。因此在extern和nested type names之间的非直觉绑定操作还是会发生。例如在下面的程序片段中，length的类型在两个member function signatures中都决议（resolve)为global typedef,也就是int.当后续再有length的nested typedef 声明出现时，C+Standard 就把稍早的绑定标示为非法：\n1 2 3 4 5 6 7 8 9 10 11  typedef int length; class Point3D{ public: // 1ength 被决议(resolved）为global  void mumble(length val){_val = val;} length mumble() {return _val;} private: typedef float length; // 1ength 被决议(resolved）为local  length _val; };   上述这种语言状况，仍然需要某种防御性程序风格：请始终把“nested type声明”放在class的起始处。在上述例子中，如果把length的nested typedef定义于“在class中被参考”之前，就可以确保非直觉绑定的正确性。\nData Member的布局（Data Member Layout)\nData Member的存取\n我用它们来存取data members，像这样：\n1 2  origin.x=0.0; pt-\u0026gt;x=0.0;   通过origin存取和通过pt存取，有什么重大差异吗？\n“从origin存取”和“从pt存取”有什么重大的差异？答案是“当Point3d是一个derived class，而在其继承结构中有一个virtual base class，并且被存取的member(如本例的x）是一个从该virtual base class继承而来的member时，就会有重大的差异”。这时候我们不能够说pt必然指向哪一种 class type（因此我们也就不知道编译时期这个member真正的offset位置），所以这个存取操作必须延迟至执行期，经由一个额外的间接导引，才能够解决。但如果使用origin，就不会有这些问题，其类型无疑是Point3d class，而即使它继承自 virtual baseclass，members的offset位置也在编译时期就固定了。一个积极进取的编译器甚至可以静态地经由 origin就解决掉对x的存取。“从origin存取”和“从pt存取”有什么重大的差异？答案是“当Point3d是一个derived class，而在其继承结构中有一个virtual base class，并且被存取的member(如本例的x）是一个从该virtual base class继承而来的member时，就会有重大的差异”。这时候我们不能够说pt必然指向哪一种 class type（因此我们也就不知道编译时期这个member真正的offset位置），所以这个存取操作必须延迟至执行期，经由一个额外的间接导引，才能够解决。但如果使用origin，就不会有这些问题，其类型无疑是Point3d class，而即使它继承自 virtual baseclass，members的offset位置也在编译时期就固定了。一个积极进取的编译器甚至可以静态地经由 origin就解决掉对x的存取。\n静态数据成员\n。。。\n非静态数据成员\n。。。\n继承与数据成员\n指向Data Members的指针（Pointer to Data Members）\n如果vptr放在对象的尾端，三个坐标值在对象布局中的offset分别是0，4，8。如果vptr放在对象的起头，三个坐标值在对象布局中的offset分别是4，8，12。然而你若去取data members的地址，传回的值总是多1，也就是1，5，9或5，9，13等等。你知道为什么Bjarne决定要这么做吗？\n为了区分第一个数据成员与指向类对象的地址。\n🖕 Function语义学\n如果我有一个Point3d的指针和对象：\n1 2  Point3d obj; Point3d *ptr = \u0026amp;obj;   当我这样做：\n1 2  obj.normalize(); ptr-\u0026gt;normalize();   时，会发生什么事？其中的Point3d：：normalize（）定义如下：\nMember的各种调用方式\n非静态成员函数\nC++的设计准则之一就是：nonstatic member function 至少必须和一般的nonmember function有相同的效率。\n例如下面的两个函数：\n1 2  float magnitude(const Point3d *_this){...} float Point3d::magnitude(){...}   选择member function不应该带来什么额外负担。这是因为编译器内部已将“member函数实例”转换为对等的“nonmember函数实例”。\n下面是转化步骤：\n  改写函数的 signature（译注：意指函数原型）以安插一个额外的参数到member function中，用以提供一个存取管道，使 class object得以将此函数调用。该额外参数被称为 this指针：\n1 2  //non-const nonstatic member的扩张过程 Point3d Point3d::magnitude(Point3d *const this)   如果member function是const，则变成\n1 2  //non-const nonstatic member的扩张过程 Point3d Point3d::magnitude(const Point3d *const this)     将每一个“对 nonstatic data member 的存取操作”改为经由 this指针来存取：\n1 2 3 4 5 6  { return sqrt( this-\u0026gt;_x * this-\u0026gt;_x + this-\u0026gt;_y * this-\u0026gt;_y + this-\u0026gt;_z * this-\u0026gt;_z); }     将 member function重新写成一个外部函数。将函数名称经过“mangling”处理，使它在程序中成为独一无二的语汇：\n1  extern magnitude_7Point3dFv( register Point3d *const this );     名称的特殊处理\n一般而言，member的名称前面会被加上class名称，形成独一无二的命名。例如下面的声明：\n1  class Bar {public:int ival;...};   其中的ival有可能变成这样：\n1 2  //member 经过name-mangling之后的可能结果之一 ival__3Bar   静态成员函数\n关于typedef的用法总结 https://www.cnblogs.com/csyisong/archive/2009/01/09/1372363.html\n✒ 智能指针 unique_ptr std::unique_ptr 是通过指针占有并管理另一对象，并在 unique_ptr 离开作用域时释放该对象的智能指针。在下列两者之一发生时用关联的删除器释放对象：\n 销毁了管理的 unique_ptr 对象 通过 operator= 或 reset() 赋值另一指针给管理的 unique_ptr 对象。  shared_ptr std::shared_ptr 是通过指针保持对象共享所有权的智能指针。多个 shared_ptr 对象可占有同一对象。下列情况之一出现时销毁对象并解分配其内存：\n 最后剩下的占有对象的 shared_ptr 被销毁； 最后剩下的占有对象的 shared_ptr 被通过 operator= 或 reset() 赋值为另一指针。  每次创建类的新对象时，初始化指针并将引用计数置为1；当对象作为另一对象的副本而创建时，引用计数加1；对一个对象进行赋值时，赋值操作符减少左操作数所指对象的引用计数（如果引用计数为减至0，则删除对象），并增加右操作数所指对象的引用计数；调用析构函数时，构造函数减少引用计数（如果引用计数减至0，则删除基础对象）。\nshared_ptr的内存模型：\n下面是用类模板简单实现shared_ptr.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62  #include \u0026lt;iostream\u0026gt;using namespace std; template\u0026lt;typename T\u0026gt; class SmartPointer { private: T* p_; size_t* count_; public: SmartPointer(T* ptr = nullptr) : p_(ptr) { if (p_) { count_ = new size_t(1); } else { count_ = new size_t(0); } } SmartPointer(const SmartPointer\u0026amp; ptr) { p_ = ptr.p_; count_ = ptr.count_; (*count_)++; } SmartPointer\u0026amp; operator=(const SmartPointer\u0026amp; ptr) { if (p_ == ptr.p_) { return *this; } if (p_) { if (--(*count_) == 0) { delete p_; delete count_; } } p_ = ptr.p_; count_ = ptr.count_; (*count_)++; return *this; } ~SmartPointer() { if (--(*count_) == 0) { delete p_; delete count_; } } size_t use_count() { return *count_; } }; int main() { SmartPointer\u0026lt;int\u0026gt; sp1(new int(10)); SmartPointer\u0026lt;int\u0026gt; sp2(sp1); SmartPointer\u0026lt;int\u0026gt; sp3(new int(20)); sp2 = sp3; std::cout \u0026lt;\u0026lt; sp1.use_count() \u0026lt;\u0026lt; std::endl; std::cout \u0026lt;\u0026lt; sp3.use_count() \u0026lt;\u0026lt; std::endl; }   智能指针带来的性能影响:\n1）shared_ptr的尺寸是裸指针的两倍。\n2）会带来控制块的开销。\n3）引用计数的递增和递减是原子操作，原子操作一般都比非原子操作慢。\nweak_ptr weak_ptr 是一种不控制对象生命周期的智能指针, 它指向一个 shared_ptr 管理的对象. 进行该对象的内存管理的是那个强引用的 shared_ptr. weak_ptr只是提供了对管理对象的一个访问手段。weak_ptr 设计的目的是为配合 shared_ptr 而引入的一种智能指针来协助 shared_ptr 工作, 它只可以从一个 shared_ptr 或另一个 weak_ptr 对象构造, 它的构造和析构不会引起引用记数的增加或减少。weak_ptr是用来解决shared_ptr相互引用时的死锁问题,如果说两个shared_ptr相互引用,那么这两个指针的引用计数永远不可能下降为0,资源永远不会释放。它是对对象的一种弱引用，不会增加对象的引用计数，和shared_ptr之间可以相互转化，shared_ptr可以直接赋值给它，它可以通过调用lock函数来获得shared_ptr。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  #include \u0026lt;iostream\u0026gt;#include \u0026lt;vector\u0026gt;#include \u0026lt;memory\u0026gt;using namespace std; class B; class A { public: weak_ptr\u0026lt;B\u0026gt; pb_; ~A() { cout \u0026lt;\u0026lt; \u0026#34;A delete\\n\u0026#34;; } }; class B { public: shared_ptr\u0026lt;A\u0026gt; pa_; ~B() { cout \u0026lt;\u0026lt; \u0026#34;B delete\\n\u0026#34;; } }; void fun() { shared_ptr\u0026lt;B\u0026gt; pb(new B()); shared_ptr\u0026lt;A\u0026gt; pa(new A()); pb-\u0026gt;pa_ = pa; pa-\u0026gt;pb_ = pb; cout \u0026lt;\u0026lt; pb.use_count() \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; pa.use_count() \u0026lt;\u0026lt; endl; } int main() { fun(); return 0; }    注意的是我们不能通过weak_ptr直接访问对象的方法，比如B对象中有一个方法print(),我们不能这样访问，pa-\u0026gt;pb_-\u0026gt;print(); 英文pb_是一个weak_ptr，应该先把它转化为shared_ptr,如：shared_ptr p = pa-\u0026gt;pb_.lock(); p-\u0026gt;print();\n 多线程读写shared_ptr需要加锁 在现代C++中，通过使用shared_ptr这样的智能指针能够很好的降低内存泄漏的可能性，但是在多线程中无保护的读写shared_ptr则有可能带来race condition的情况。\n 竞争危害 (race hazard) 又名竞态条件 (race condition)。旨在描述一个系统或者进程的输出展现无法预测的、对事件间相对时间的排列顺序的致命相依性。\n 参考：\n C++11\u0026ndash;智能指针详解及实现 多线程读写shared_ptr需要加锁  野指针\n野指针就是指向一个已删除的对象或者未申请访问受限内存区域的指针\nC++内存管理与程序内存分区 C++内存分区 C++存在如下的内存分区\n1）栈区（stack）：由编译器自动分配释放 ，存放函数的 参数值，局部变量的值等。其操作方式类似于数据结 构中的栈。\n2）堆区（heap）：一般由程序员分配释放，若程序员不 释放，程序结束时可能由OS回收。注意它与数据结构 中的堆是两回事，分配方式倒是类似于链表。\n3）全局/静态区(static）：全局变量和静态变量的存储是 放在一块的，在程序编译时分配\n4）文字常量区：存放常量字符串\n5）程序代码区：存放函数体（类的成员函数、全局函数） 的二进制代码\nC语言中，内存分配有三种：\n 静态区域分配：由编译器自动分配与释放，内存在编译的时候已经分配好，这块内存在整个程序的运行期间都存在直到程序结束时才被释放，如全局变量与static变量。 栈分配：由编译器在程序运行时从栈上分配，函数栈退出时自动释放。栈分配的运算在处理器的指令集中，所以它的运行效率很高，但能分配的内容是有限的。 堆分配：有程序员主动调用内存分配函数来申请内存，且使用完毕后由程序员自己释放，其使用非常灵活，但其分配方式是通过调用函数来实现，效率没栈高。malloc,alloc等  程序在内存中的分布 中文版\n  内核空间\n  栈\n1、stack存放函数的临时变量、局部变量、函数参数和返回值\n2、由编译器自动分配和释放。\n  动态链接库(共享映射区)\n调用的库文件，位于堆和栈之间\n  堆\nheap用来动态分配内存，由程序员控制，交由程序自身决定开辟和释放。\n  全局数据区\n.bss\nbss段用来存放没有被初始化和已经被初始化为0的全局变量\n.data\ndata段用来存放已经被初始化为非0的全局变量\n  常量区\n.rodata\nrodata段用来存放常量数据、被编译器自动存放来的字符串和加const关键字的常量数据。\n  代码区\n.text\ntext段用来存放代码和部分整数常量，该段是可执行的。\n  堆与栈 栈是一种的“先进后出”的存储结构。\n堆是一种完全二叉树。节点从左到右填满，最后一层的树叶都在最左边。（即如果一个节点没有左边儿子，那么它一定没有右边儿子），每个节点的值都小于（或者大于）其子节点的值（大顶堆、小顶堆）。它的特点是可以使用一维数组来表示。堆的操作也可通过数据元素交换的形式解决，非常适合内存空间线性的特点。\n参考地址\n 程序在内存中的分布 http://baijiahao.baidu.com/s?id=1664957369973450228\u0026amp;wfr=spider\u0026amp;for=pc  C++内存泄漏  系统资源泄露（Resource Leak）。主要指程序使用系统分配的资源比如 Bitmap,handle ,SOCKET等没有使用相应的函数释放掉，导致系统资源的浪费，严重可导致系统效能降低，系统运行不稳定。\n 内存泄漏 内存泄漏指由于疏忽或错误造成程序未能释放已经不再使用的内存的情况\n检测内存泄漏的原理 主要还是运用二进制插桩，记录资源的申请和释放操作，然后对记录进行匹配剔除，最后就是剩下的泄漏的了。\n检测方法 最简单的 在每一处申请/释放内存的地方进行打点，然后匹对一下就知道哪里内存泄露了。\nWindows平台下的内存泄漏检测 Windows平台下面Visual Studio 调试器和 C 运行时 (CRT) 库为我们提供了检测和识别内存泄漏的有效方法，原理大致如下：内存分配要通过CRT在运行时实现，只要在分配内存和释放内存时分别做好记录，程序结束时对比分配内存和释放内存的记录就可以确定是不是有内存泄漏。在vs中启用内存检测的方法如下：\n  在程序中包括以下语句： （#include 语句必须采用上文所示顺序。 如果更改了顺序，所使用的函数可能无法正常工作。）\n1 2 3  #define _CRTDBG_MAP_ALLOC#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;crtdbg.h\u0026gt;   通过包括 crtdbg.h，将 malloc 和 free 函数映射到它们的调试版本，即 _malloc_dbg 和 _free_dbg，这两个函数将跟踪内存分配和释放。 此映射只在调试版本（在其中定义了**_DEBUG**）中发生。 发布版本使用普通的 **malloc** 和 **free** 函数。\n #define 语句将 CRT 堆函数的基版本映射到对应的“Debug”版本。 并非绝对需要该语句；但如果没有该语句，内存泄漏转储包含的有用信息将较少。\n  在添加了上述语句之后，可以通过在程序中包括以下语句（通常应恰好放在程序退出位置之前）来转储内存泄漏信息：\n1  _CrtDumpMemoryLeaks();   如果没有使用 #define _CRTDBG_MAP_ALLOC 语句，内存泄漏转储将如下所示\n 未定义 _CRTDBG_MAP_ALLOC 时，所显示的会是：\n 内存分配编号（在大括号内）。 块类型（普通、客户端或 CRT）。     定位到具体的位置\n  最终定位代码\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  #define _CRTDBG_MAP_ALLOC#include \u0026lt;stdlib.h\u0026gt;#include \u0026lt;crtdbg.h\u0026gt; #include \u0026lt;iostream\u0026gt;using namespace std; _CrtMemState s1, s2, s3; void GetMemory(char *p, int num) { p = (char*)malloc(sizeof(char) * num); } int main(int argc,char** argv) { _CrtMemCheckpoint( \u0026amp;s1 ); char *str = NULL; GetMemory(str, 100); _CrtMemCheckpoint( \u0026amp;s2 ); if ( _CrtMemDifference( \u0026amp;s3, \u0026amp;s1, \u0026amp;s2) ) _CrtMemDumpStatistics( \u0026amp;s3 ); cout\u0026lt;\u0026lt;\u0026#34;Memory leak test!\u0026#34;\u0026lt;\u0026lt;endl; _CrtDumpMemoryLeaks(); return 0; }   Linux平台下的内存泄漏检测 Valgrind是一套Linux下，开放源代码（GPL V2）的仿真调试工具的集合。Valgrind由内核（core）以及基于内核的其他调试工具组成。内核类似于一个框架（framework），它模拟了一个CPU环境，并提供服务给其他工具；而其他工具则类似于插件 (plug-in)，利用内核提供的服务完成各种特定的内存调试任务。Valgrind的体系结构如下图所示：\n参考链接：\n C/C++内存泄漏及检测   C++函数指针 函数指针是指向函数的指针变量。\n指向函数的指针变量的一般定义形式为： 数据类型 (*指针变量名)(参数表);\n参考：C++函数指针详解\nmalloc的原理 Malloc函数用于动态分配内存。为了减少内存碎片和系统调用的开销，malloc其采用内存池的方式，先申请大块内存作为堆区，然后将堆区分为多个内存块，以块作为内存管理的基本单位。当用户申请内存时，直接从堆区分配一块合适的空闲块。Malloc采用隐式链表结构将堆区分成连续的、大小不一的块，包含已分配块和未分配块；同时malloc采用显示链表结构来管理所有的空闲块，即使用一个双向链表将空闲块连接起来，每一个空闲块记录了一个连续的、未分配的地址。当进行内存分配时，Malloc会通过隐式链表遍历所有的空闲块，选择满足要求的块进行分配；当进行内存合并时，malloc采用边界标记法，根据每个块的前后块是否已经分配来决定是否进行块合并。\nMalloc在申请内存时，一般会通过brk或者mmap系统调用进行申请。其中当申请内存小于128K时，会使用系统函数brk在堆区中分配；而当申请内存大于128K时，会使用系统函数mmap在映射区分配。\nC++模板 https://www.cnblogs.com/gw811/archive/2012/10/25/2738929.html\n模板是一种对类型进行参数化的工具；通常有两种形式：函数模板和类模板；函数模板针对仅参数类型不同的函数；类模板针对仅数据成员和成员函数类型不同的类。\n函数模板 函数模板格式 1 2 3 4  template \u0026lt;class 形参名，class 形参名，......\u0026gt; 返回类型 函数名(参数列表) { 函数体 }    其中template和class是关见字，class可以用typename 关见字代替，在这里typename 和class没区别\n 类模板 类模板格式 1 2  template\u0026lt;class 形参名，class 形参名，…\u0026gt; class 类名 { ... };   类模板对象的创建\n比如一个模板类A，则使用类模板创建对象的方法为A m;在类A后面跟上一个\u0026lt;\u0026gt;尖括号并在里面填上相应的类型，这样的话类A中凡是用到模板形参的地方都会被int 所代替。当类模板有两个模板形参时创建对象的方法为A\u0026lt;int, double\u0026gt; m;类型之间用逗号隔开。\n在类模板外部定义成员函数的方法为：\n1  template\u0026lt;模板形参列表\u0026gt; 函数返回类型 类名\u0026lt;模板形参名\u0026gt;::函数名(参数列表){函数体}，   例如：\n1  template\u0026lt;class T1,class T2\u0026gt; void A\u0026lt;T1,T2\u0026gt;::h(){}。   C++引用 引用限定符： \u0026amp; 与 \u0026amp;\u0026amp; ，有const的话两个限定符均需要在const后面\n移动\nstd::move()\n转发\nstd::forward()\n保持实参的源类型以及值\n栈或者堆上面创建类 在堆上创建类对象 设置析构函数为私有：\n1 2 3 4 5 6 7  class HeapClass{ public: HeapClass(){} private: ~HeapClass(){} };   在栈上创建类对象 重载new和delete运算符为私有\n1 2 3 4 5 6 7 8 9  class StackClass{ public: StackClass(){} ~StackClass(){} private: void* operator new(size_t t){} void operator delete(void *ptr){} };   不使用第三个数交换两个数 加法 1 2 3 4 5 6  void swap1(int \u0026amp;x,int \u0026amp;y) { x = x + y; y = x - y; x = x - y; }   异或 1 2 3 4 5 6  void swap2(int \u0026amp;x,int \u0026amp;y) { x = x ^ y; y = y ^ x; x = x ^ y; }   回调函数与仿函数 为什么使用仿函数？\n 迭代和计算逻辑分离 参数可设置 有状态 性能(编译时期就能够确定调用的函数)  函数指针有缺点,最重要的是它无法持有自己的状态(所谓局部状态,localstates），也无法达到组件技术中的可适配性（adaptability）——也就是无法再将某些修饰条件加诸于其上而改变其状态。\n为此，STL 算法的特殊版本所接受的所谓“条件”或 “策略”或 “一整组操作”，都以仿函数形式呈现。所谓仿函数（functor）就是使用起来像函数一样的东西。如果你针对某个 class 进行 operator(）重载，它就成为一个仿函数。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;using namespace std; //回调函数 void call_back(char elem) { cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; endl; } //仿函数 struct Functor { void operator() (char elem) { cout \u0026lt;\u0026lt; elem \u0026lt;\u0026lt; endl; } }; int main() { string strA = \u0026#34;hello\u0026#34;; string strB = \u0026#34;world\u0026#34;; for_each(strA.begin(),strA.end(),Functor()); cout\u0026lt;\u0026lt;\u0026#34;===========GAP===============\u0026#34;\u0026lt;\u0026lt;endl; for_each(strB.begin(),strB.end(),call_back); getchar(); return 0; }    仿函数需要经过3次的构造和析构。\n 仿函数和回调函数区别在于:\n 使用仿函数可以声明在业务相关的类内部 缩小作用域 使用仿函数可以使用类的成员属性和成员函数 仿函数是一个类 可以使用面向对象的各种机制(封装 继承 多态) 若使用回调函数 那么只能声明为某个类的静态成员函数或全局函数，使用类内部的资源需要用一些手段传参,没有直接使用成员函数便捷  参考：\nhttps://my.oschina.net/mlgb/blog/290350\nC++仿函数（functor）\nC++析构函数为什么是虚函数 原因：基类对象的指针操作派生类对象时，防止析构函数只调用基类的，而不调用派生类的\n参考：\n https://blog.csdn.net/zkangaroo/article/details/57000397  +++++++++++++++++\n实现memcpy📝 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  void *my_memcpy(void *dst, void *src, int n) { char *d = (char *)(dst); char *s = (char *)(src); if (d \u0026gt; s \u0026amp;\u0026amp; d \u0026lt; s + n) { for(int i = n-1;i \u0026gt;= 0;--i) *(d + i) = *(s + i); } else { for(int i = 0;i \u0026lt; n;++i) *(d + i) = *(s + i); } return dst; }   memmove与memcpy的区别？ strcpy与mencpy的区别? 快速排序⏲ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  int partition(vector\u0026lt;int\u0026gt; \u0026amp;nums, int start, int end) { int p = nums[start]; while (start \u0026lt; end) { while (nums[end] \u0026gt;= p \u0026amp;\u0026amp; start \u0026lt; end) --end; nums[start] = nums[end]; while (nums[start] \u0026lt;= p \u0026amp;\u0026amp; start \u0026lt; end) ++start; nums[end] = nums[start]; } nums[start] = p; return start; } void quick_sort(vector\u0026lt;int\u0026gt; \u0026amp;nums, int left, int right) { if (left \u0026lt; right) { int p = partition(nums, left, right); quick_sort(nums, left, p - 1); quick_sort(nums, p + 1, right); } }   堆排序🎳 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void heap_sort(vector\u0026lt;int\u0026gt; \u0026amp;nums, int n) { if (n == 1) return; for (int i = n / 2 - 1; i \u0026gt;= 0; --i) { int left = 2 * i + 1, right = 2 * i + 2; int imax = i; if (left \u0026lt; n \u0026amp;\u0026amp; nums[left] \u0026gt; nums[imax]) imax = left; if (right \u0026lt; n \u0026amp;\u0026amp; nums[right] \u0026gt; nums[imax]) imax = right; if (imax != i) swap(nums[i], nums[imax]); } swap(nums[0], nums[n - 1]); heap_sort(nums, n - 1); }   👠堆TopK C++实现最大堆和最小堆\n最小堆 构建、插入、删除的过程图解\n#Network\n参考：\n 搞定计算机网络面试，看这篇就够了（补充版）  多问为什么！ 🎚 网络分层 OSI与TCP/IP分层模型\n为什么网络需要分层？\n  大部分软件系统都是分层架构的，为了工程上实现/调试/维护方便。网络系统分得更明显一点，因为其系统设计写成了协议。\n  把TCP/IP层次化是有好处的。比如，如果互联网只由一个协议统筹，某个地方需要改变设计时，就必须把所有部分整体替换掉。而分层之后只需把变动的层替换掉即可。把各层之间的接口部分规划好之后，每个层次内部的设计就能够自由改动了。\n  分层模型传输过程\n发送端在层与层之间传输数据时，每经过一层时必定会被打上一个该层所属的首部信息。反之，接收端在层与层传输数据时，每经过一层时会把对应的首部消去。\n参考：为什么网络协议选择分层设计？这样做有什么好处？\n🥉 为什么需要三次握手 为什么TCP客户端最后还要发送一次确认呢？\n  为了防止 已失效的链接请求报文突然又传送到了服务端，因而产生错误。\n客户端发出的连接请求报文并未丢失，而是在某个网络节点长时间滞留了，以致延误到链接释放以后的某个时间才到达Server。这是，Server误以为这是Client发出的一个新的链接请求，于是就向客户端发送确认数据包，同意建立链接。若不采用“三次握手”，那么只要Server发出确认数据包，新的链接就建立了。由于client此时并未发出建立链接的请求，所以其不会理睬Server的确认，也不与Server通信；而这时Server一直在等待Client的请求，这样Server就白白浪费了一定的资源。若采用“三次握手”，在这种情况下，由于Server端没有收到来自客户端的确认，则就会知道Client并没有要求建立请求，就不会建立链接。\n如果采用的是三次握手，就算是那一次失效的报文传送过来了，服务端接受到了那条失效报文并且回复了确认报文，但是客户端不会再次发出确认。由于服务器收不到确认，就知道客户端并没有请求连接。\n  因为双方都需要确认对方收到了自己发送的序列号，确认过程最少要进行三次通信。\n参考：知乎 . TCP 为什么是三次握手，而不是两次或四次？\n  因为信道不可靠，而 TCP 想在不可靠信道上建立可靠地传输，那么三次通信是理论上的最小值。（而 UDP 则不需建立可靠传输，因此 UDP不需要三次握手。）\n参考：Google Groups . TCP 建立连接为什么是三次握手？{技术}{网络通信}\n   TCP传了 SYN,为啥还要传 ACK？\n双方通信无误必须是两者互相发送信息都无误。传了 SYN，证明发送方到接收方的通道没有问题，但是接收方到发送方的通道还需要 ACK 信号来进行验证。\n ✋ 为什么是四次挥手？   这个是一个全双工的连接，两边都需要断开，每次的断开都需要两次的握手。\n建立连接的时候， 服务器在LISTEN状态下，收到建立连接请求的SYN报文后，把ACK和SYN放在一个报文里发送给客户端。\n而关闭连接时，服务器收到对方的FIN报文时，仅仅表示对方不再发送数据了但是还能接收数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN一般都会分开发送，从而导致多了一次。即另一方并不需要也急着断开，还可以继续发送消息。\n  服务器可能还有数据需要传输给客户端\n因为客户端请求释放时，服务器可能还有数据需要传输给客户端，因此服务端要先响应客户端 FIN 请求（服务端发送 ACK），然后数据传输，传输完成后，服务端再提出 FIN 请求（服务端发送 FIN）；而连接时则没有中间的数据传输，因此连接时可以 ACK 和 SYN 一起发送。\n  为什么客户端最后还要等待2MSL？\nMSL（Maximum Segment Lifetime），TCP允许不同的实现可以设置不同的MSL值。\n第一，保证客户端发送的最后一个ACK报文能够到达服务器，因为这个ACK报文可能丢失，站在服务器的角度看来，我已经发送了FIN+ACK报文请求断开了，客户端还没有给我回应，应该是我发送的请求断开报文它没有收到，于是服务器又会重新发送一次，而客户端就能在这个2MSL时间段内收到这个重传的报文，接着给出回应报文，并且会重启2MSL计时器。\n第二，防止类似与“三次握手”中提到了的“已经失效的连接请求报文段”出现在本连接中。客户端发送完最后一个确认报文后，在这个2MSL时间中，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样新的连接中不会出现旧连接的请求报文。\n参考：\n 两张动图-彻底明白TCP的三次握手与四次挥手  🏑 如果已经建立了连接，但是客户端突然出现故障了怎么办？ TCP还设有一个保活计时器，显然，客户端如果出现故障，服务器不能一直等下去，白白浪费资源。服务器每收到一次客户端的请求后都会重新复位这个计时器，时间通常是设置为2小时，若两小时还没有收到客户端的任何数据，服务器就会发送一个探测报文段，以后每隔75秒发送一次。若一连发送10个探测报文仍然没反应，服务器就认为客户端出了故障，接着就关闭连接。\n📉 ​GET 和 POST的区别  GET用来获取数据，POST用来提交数据 GET请求通过URL（请求行）提交数据，在URL中可以看到所传参数。POST通过“请求体”传递数据，参数不会在url中显示 GET请求提交的数据有长度限制，POST请求没有限制。 GET请求返回的内容可以被浏览器缓存起来。而每次提交的POST，浏览器在你按下F5的时候会跳出确认框，浏览器不会缓存POST请求返回的内容。 GET对数据进行查询，POST主要对数据进行增删改！简单说，GET是只读，POST是写。 get 请求的url是在服务器上有日志记录，在浏览器也能查到历史记录，但是post请求的参数都在body里面，浏览器历史记录不到   如果是指网络安全，那两者一样。\n如果考虑到某些服务端和客户端的默认配置和默认使用方式，那么POST在很多时候比GET安全。\n而在HTTP的定义中，GET被称为安全方法，POST却不是.\n 感觉对于服务器更安全的是Get，对于客户端更安全的是Post。\n本质上：\n首先get和post在本质上都是tcp链接，但由于http协议和浏览器或者服务器的限制，从而使它们在应用过程中产生了差别，但是它们中还有一个较大的区别：get在请求时发送一个数据包，会将header和data一起发送过去，而post会产生两个数据包先发送header，服务器返回100，然后在发送data，服务器返回200\n 所以当你一层一层的把get和post剖析到底，你会发现他们的本质就是tcp连接，没有啥区别，只是由于http协议规定和浏览器或者服务器的限制，导致他们在应用过程中体现形式不同。\n RFC：\n1.safe（安全）\n 这里的安全和通常所理解的安全意义不同，就好比如果一个请求的语义本质上就是获取数据（只读），那么这个请求就是安全的。客户端向服务器发起的请求如果没有引起服务器端任何的状态变化，那么他就是安全的而post请求来提交数据必然会是服务器发生相应的变化。从这个维度来看，get请求相对服务器而言，是安全的，post则不安全的。\n ldempotend（幂等）\n **幂等通俗的来讲就是指同一个请求执行多次和仅执行一次的效果完全相等。**这里来扯出幂等主要是为了处理同一个请求重复发送的情况，假如在请求响应之前失去连接，如果这个请求时幂等的，那么就可以放心的重发一次请求。所以可以得出get请求时幂等的，可以重复发送请求，post请求时不幂等的，重复请求可能会发生无法预知的后果。\n cacheable（可缓存性）\n 顾名思义，就是一个请求是否可以被缓存，绝大多数部分，post都是不可缓存的（某些浏览器可能支持post缓存），但get是可以缓存的。\n 勉强理解一下大概就是：\n get是请求获取指定资源，get方法时安全、幂等、可缓存的，get方法的报文主体没有任何语义。\n  post是根据报文主体来对指定资源做出处理，post不安全，不幂等，不可缓存（大部分情况下）。\n 参考：\n 都 2019 年了，还问 GET 和 POST 的区别 POST 方法比 GET 方法更安全吗? 为什么? get和post的区别？  🍂 HTTP报文 请求报文 HTTP 请求报文由3部分组成(请求行+请求头+请求体)\n请求行包括：请求方法、请求URL、HTTP协议及版本：\nGET和POST是最常见的HTTP方法,初次以外还包括 DELETE、HEAD、OPTIONS、PUT、TRACE，不过现在大部分的浏览器只支持GET和POST\n请求对应的URL地址,他和报文头的Host属性,组合起来是一个完整的请求URL\n报文头是一些参数信息：\n有若干个属性,形式为key:val,服务端据此获取客户端信息\n报文体是具体传输的内容。\n响应报文 响应报文与请求报文一样,由三个部分组成(响应行,响应头,响应体)\n参考：HTTP请求头和响应头详解\n🚉 HTTP状态码：  1xx：表示通知信息，如请求收到了或正在进行处理  100 Continue：继续，客户端应继续其请求 101 Switching Protocols 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到 HTTP 的新版本协议   2xx：表示成功，如接收或知道了  200 OK: 请求成功   3xx：表示重定向，如要完成请求还必须采取进一步的行动  301 Moved Permanently: 永久移动。请求的资源已被永久的移动到新 URL，返回信息会包括新的 URL，浏览器会自动定向到新 URL。今后任何新的请求都应使用新的 URL 代替   4xx：表示客户的差错，如请求中有错误的语法或不能完成  400 Bad Request: 客户端请求的语法错误，服务器无法理解 401 Unauthorized: 请求要求用户的身份认证 403 Forbidden: 服务器理解请求客户端的请求，但是拒绝执行此请求（权限不够） 404 Not Found: 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置 “您所请求的资源无法找到” 的个性页面 408 Request Timeout: 服务器等待客户端发送的请求时间过长，超时   5xx：表示服务器的差错，如服务器失效无法完成请求  500 Internal Server Error: 服务器内部错误，无法完成请求 503 Service Unavailable: 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的 Retry-After 头信息中 504 Gateway Timeout: 充当网关或代理的服务器，未及时从远端服务器获取请求    ✋ HTTP的主要方法    方法 意义     OPTIONS 请求一些选项信息，允许客户端查看服务器的性能   GET 请求指定的页面信息，并返回实体主体   HEAD 类似于 get 请求，只不过返回的响应中没有具体的内容，用于获取报头   POST 向指定资源提交数据进行处理请求（例如提交表单或者上传文件）。数据被包含在请求体中。POST请求可能会导致新的资源的建立和/或已有资源的修改   PUT 从客户端向服务器传送的数据取代指定的文档的内容   DELETE 请求服务器删除指定的页面   TRACE 回显服务器收到的请求，主要用于测试或诊断      下面这个例子是查询HTTP服务器端支持的HTTP方法种类。\n  💫 HTTP2.0与HTTP1.0的区别 📥 什么是SQL注入？ SQL注入就是通过把SQL命令插入到Web表单提交或输入域名或页面请求的查询字符串，最终达到欺骗服务器执行恶意的SQL命令。\nSQL注入的思路：\n SQL注入的位置 判断服务器类型和后台数据类型 针对不通的服务器和数据库特点进行SQL注入攻击  应对的方法：\n 参数绑定使用预编译手段，绑定参数是最好的防SQL注入的方法。目前许多的ORM框架及JDBC等都实现了SQL预编译和参数绑定功能，攻击者的恶意SQL会被当做SQL的参数而不是SQL命令被执行。在mybatis的mapper文件中，对于传递的参数我们一般是使用#和$来获取参数值。当使用#时，变量是占位符，就是一般我们使用javajdbc的PrepareStatement时的占位符，所有可以防止sql注入；当使用​$时，变量就是直接追加在sql中，一般会有sql注入问题。 使用正则表达式过滤传入的参数  🍪 Cookie技术 Cookie 通过在请求和响应报文中写入 Cookie 信息来控制客户端的状态。\n相当于，在客户端第一次请求后，服务器会下发一个装有客户信息的「小贴纸」，后续客户端请求服务器的时候，带上「小贴纸」，服务器就能认得了了。\n  没有Cookie信息状态下的请求\n  第2次以后（存有Cookie信息状态）的请求\n  底层原理\n  WEB服务器通过在HTTP响应消息中增加Set-Cookie响应头字段将Cookie信息发送给浏览器，\n  浏览器则通过在HTTP请求消息中增加Cookie请求头字段将Cookie回传给WEB服务器。\n  Cookie的传送过程示意图\nCookie的缺陷\n(1) cookie会被附加在每个HTTP请求中，所以无形中增加了流量。\n(2) 由于在HTTP请求中的cookie是明文传递的，所以安全性成问题。（除非用HTTPS)\n(3) Cookie的大小限制在4KB左右。对于复杂的存储需求来说是不够用的。\n参考：\n 会话技术——Cookies和Session详解  💬 Session技术 什么是会话？\n会话是浏览器和服务器之间的多次请求和响应。也就是说，从浏览器访问服务器开始，到访问服务器结束，浏览器关闭为止的这段时间内容产生的多次请求和响应，合起来叫做浏览器和服务器之间的一次会话。\n为什么使用会话技术？\n实际上会话问题解决的还是客户端与服务器之间的通信问题，通过一些会话技术，可以将每个用户的数据以例如cookie/session的形式存储，方便以后用户访问web资源的时候使用\n 假定场景：A和B两人在某个网上购物商场登陆账号后，A买了一个HHKB的键盘，而B则购买了一把民谣吉他，这些信息都会被保存下来\n用途是：保存账户信息，登录时询问日后是否自动登录，或者根据之前浏览，购买过的商品，分析用户喜欢什么类型的商品，做出精准推送\n 服务器使用session把用户的信息临时保存在了服务器上，用户离开网站后session会被销毁。这种用户信息存储方式相对cookie来说更安全，可是session有一个缺陷：如果web服务器做了负载均衡，那么下一个操作请求到了另一台服务器的时候session会丢失。\n参考：\n 会话技术——Cookies和Session详解 彻底理解cookie，session，token 认识HTTP\u0026mdash;-Cookie和Session篇  📸 Session和Cookie的区别 从存储方式上比较\nCookie只能存储字符串，如果要存储非ASCII字符串还要对其编码。\nSession可以存储任何类型的数据，可以把Session看成是一个容器\n从隐私安全上比较\nCookie存储在浏览器中，对客户端是可见的。信息容易泄露出去。如果使用Cookie，最好将Cookie加密\nSession存储在服务器上，对客户端是透明的。不存在敏感信息泄露问题。\n从有效期上比较\nCookie保存在硬盘中，只需要设置maxAge属性为比较大的正整数，即使关闭浏览器，Cookie还是存在的\nSession的保存在服务器中，设置maxInactiveInterval属性值来确定Session的有效期。并且Session依赖于名为JSESSIONID的Cookie，该Cookie默认的maxAge属性为-1。如果关闭了浏览器，该Session虽然没有从服务器中消亡，但也就失效了。\n从对服务器的负担比较\nSession是保存在服务器的，每个用户都会产生一个Session，如果是并发访问的用户非常多，是不能使用Session的，Session会消耗大量的内存。\nCookie是保存在客户端的。不占用服务器的资源。像baidu、Sina这样的大型网站，一般都是使用Cookie来进行会话跟踪。\n从浏览器的支持上比较\n如果浏览器禁用了Cookie，那么Cookie是无用的了！\n如果浏览器禁用了Cookie，Session可以通过URL地址重写来进行会话跟踪。\n从跨域名上比较\nCookie可以设置domain属性来实现跨域名\nSession只在当前的域名内有效，不可跨域名\n© IP协议 IP协议的作用是把各种数据包传送给对方。而要保证确实传送到对方那里，则需要满足各类条件。其中两个重要的条件是IP地址和MAC地址（Media Access Control Address）。IP地址指明了节点被分配到的地址，MAC地址是指网卡所属的固定地址。IP地址可以和MAC地址进行配对。IP地址可变换，但MAC地址基本上不会更改。\n什么是MAC地址？\nMAC地址也叫物理地址、硬件地址，由网络设备制造商生产时烧录在网卡的EPROM(一种闪存芯片，通常可以通过程序擦写)。IP地址与MAC地址在计算机里都是以二进制表示的，IP地址是32位的，而MAC地址则是48位的 。\n有了 IP 地址，为什么还要用 MAC 地址 IP地址属于网络层，而MAC地址属于数据链路层。 网络层协议使数据可以从一个网络传递到另一个网络上（ARP根据目的IP地址，找到中间节点的MAC地址，通过中间节点传送，从而最终到达目的网络）；数据链路层协议可以使数据从一个节点传递到相同链路的另一个节点上（通过MAC地址）。\n  MAC地址寻址的时间复杂度太大\n如果只有MAC地址，是无法支撑起这么大的网络的，你觉得直接访问到MAC地址就行了，问题是你让路由器怎么给你找到路线呢？\n  没有统一的硬件地址\n由于全世界存在着各式各样的网络，他们使用不同的硬件地址。要使这些异构网络能够互相通信就必须进行非常复杂的硬件地址转化工作，因此由用户或用户主机来完成这项工作几乎是不可能的的事。但IP编址就把这个复杂的问题解决了。连接到互联网的主机只需要各自拥有一个唯一的IP地址，他们之间的通信就像连接在同一个网络那么简单方便。因为ARP是由计算机软件自动进行的，对用户来说是看不见这种调用过程的。\n   IP地址是逻辑地址，需要映射到物理地址MAC地址才能将数据写入对方的网卡。\n 参考：\n 有了 IP 地址，为什么还要用 MAC 地址 为什么有了Mac地址，还要IP地址  🛰 DNS协议 DNS（Domain Name System）服务是和HTTP协议一样位于应用层的协议。它提供域名到IP地址之间的解析服务。\n简单的过程：\n复杂解析过程：\n当一个应用进程需要把主机名解析为ip地址时，该应用进程就调用解析程序，并成为dns的一个客户，把待解析的域名在dns请求报文中，以udp用户数据报方式发送给本地域名服务器。本地域名服务器在查找域名后，把对应的ip地址放在回答报文中返回。应用进程获得目的主机的ip地址后即可进行通信。\n若本地域名服务器不能回答该请求，则此域名服务器就暂时成为了dns中的另一个客户，并向其它域名服务器发送查询请求。这种过程直至找到能够回答该请求的域名服务器为止。\n域名服务解析的两种方式：\n客户端发出的查询都是递归查询，DNS服务器向外发出的查询一般都是迭代查询\n 🗃 FTP协议 文件传输协议FTP(File Transfer Protocol)是因特网中使用最广泛的文件传输协议。FTP使用交互式的访问，允许客户指定文件的类型和格式(如指明是否使用ASCII码)，并允许文件具有存取权限(如访问文件的用户必须经过授权，并输入有效的口令)。\n文件传输协议有基于TCP的FTP和基于UDP的简单文件传输协议TFTP，它们都是文件共享协议中的一大类，即复制整个文件，其特点是：若要存取一个文件，就必须先获得一个本地的文件副本。如果要修改文件，只能对文件的副本进行修改，然后再将修改后的文件传回到原节点。\n与Telnet类似，FTP最早的设计是用于两台不同的主机，这两个主机可能运行在不同的操作系统下、使用不同的文件结构、并可能使用不同字符集。但不同的是，Telnet获得异构性是强制两端都采用同一个标准：使用7比特ASCII码的NVT。而FTP是采用另一种方法来处理不同系统间的差异。FTP支持有限数量的文件类型（ASCII，二进制，等等）和文件结构（面向字节流或记录）\nFTP与我们已描述的另一种应用不同，它采用两个TCP连接来传输一个文件。\n 控制连接以通常的客户服务器方式建立。服务器以被动方式打开众所周知的用于FTP的端口（21），等待客户的连接。客户则以主动方式打开TCP端口21，来建立连接。控制连接始终等待客户与服务器之间的通信。该连接将命令从客户传给服务器，并传回服务器的应答。\n由于命令通常是由用户键入的，所以IP对控制连接的服务类型就是“最大限度地减小迟延”。 每当一个文件在客户与服务器之间传输时，就创建一个数据连接。（其他时间也可以创建，后面我们将说到）。\n由于该连接用于传输目的，所以IP对数据连接的服务特点就是“最大限度提高吞吐量”。  连接情况：\n从图中可以看出，交互式用户通常不处理在控制连接中转换的命令和应答。这些细节均由两个协议解释器来完成。标有“用户接口”的方框功能是按用户所需提供各种交互界面（全屏幕菜单选择，逐行输入命令，等等），并把它们转换成在控制连接上发送的FTP命令。类似地，从控制连接上传回的服务器应答也被转换成用户所需的交互格式。\n参考：\n 深入理解FTP协议 第27章 FTP:文件传送协议  X.509 数字证书 简单来说，数字证书就是一张附带了数字签名的信息表。\n数字证书的签署 总的来说，就是对公钥和信息进行hash得到摘要，然后使用私钥对摘要进行加密得到加密后的摘要。加加密后的摘要和公钥以及信息包装成一个证书。\n根认证机构的构建 简要流程\n 根认证机构「CA」生成公钥 ca_KeyPub 和私钥 ca_KeyPri，以及基本信息表 ca_Info。ca_Info 中一般包含了「CA」的名称、证书的有效期等信息。 根认证机构「CA」对（ca_KeyPub + ca_Info）进行散列运算，得到散列值 ca_Hash。 根认证机构「CA」使用其私钥 ca_KeyPri 对 ca_Hash 进行非对称加密，得到加密的散列值 enc_ca_Hash。 根认证机构「CA」将（ca_KeyPub + ca_Info + enc_ca_Hash）组合生成自签名的数字证书**「ca_Cert」**。这张证书称之为根证书。  根证书**「ca_Cert」**包含的内容：ca_KeyPub + ca_Info + enc_ca_Hash。\n**「ca_Cert」**可用于签署下一级的证书。\n单级认证机构的证书签署 简要流程\n 服务器「S」生成公钥 s_KeyPub 和私钥 s_KeyPri，以及基本信息表 s_Info。s_Info 中一般包含了「S」的名称、证书要求的有效期等信息。 服务器「S」将 s_KeyPub、s_Info 送给根认证机构「CA」。 根认证机构「CA」通过某种方式验证「S」的身份之后，再加上根认证机构自己的一些信息 ca_Info，然后对它们（s_KeyPub + s_Info + ca_Info）进行散列运算，得到散列值 s_Hash。 根认证机构「CA」使用其私钥 ca_KeyPri 对 s_Hash 进行非对称加密，得到加密的散列值 enc_s_Hash。 根认证机构「CA」将（s_KeyPub + s_Info + ca_Info + enc_s_Hash）组合签署成数字证书**「s_Cert」**并回送给「S」。  服务器证书**「s_Cert」**包含的内容：s_KeyPub + s_Info + ca_Info + enc_s_Hash。\n**「s_Cert」**不可用于签署下一级的证书。\n二级（或以上）认证机构的构建  在现实中，仅仅靠一个认证机构是满足不了海量证书签署需求的，因此需要构建分支认证机构。\n 简要流程\n 二级认证机构「CA2」生成公钥 ca2_KeyPub 和私钥 ca2_KeyPri，以及基本信息表 ca2_Info。ca2_Info 中一般包含了「CA2」的名称、证书要求的有效期等信息。 二级认证机构「CA2」将 ca2_KeyPub、ca2_Info 送给根认证机构「CA」。 根认证机构「CA」通过某种方式验证「CA2」的身份之后，再加上根认证机构自己的一些信息 ca_Info，然后对它们（ca2_KeyPub + ca2_Info + ca_Info）进行散列运算，得到散列值 ca2_Hash。 根认证机构「CA」使用其私钥 ca_KeyPri 对 ca2_Hash 进行非对称加密，得到加密的散列值 enc_ca2_Hash。 根认证机构「CA」将（ca2_KeyPub + ca2_Info + ca_Info + enc_ca2_Hash）组合签署成数字证书**「ca2_Cert」**并回送给「CA2」。  二级认证机构证书**「ca2_Cert」**包含的内容：ca2_KeyPub + ca2_Info + ca_Info + enc_ca2_Hash。\n**「ca2_Cert」**可用于签署下一级的证书。\n三级或更多级认证机构的构建流程跟这个流程差不多，这里就不再赘述了。\n二级（或以上）认证机构的证书签署 简要流程\n 服务器「S2」生成公钥 s2_KeyPub 和私钥 s2_KeyPri，以及基本信息表 s2_Info。s2_Info 中一般包含了「S2」的名称、证书要求的有效期等信息。 服务器「S2」将 s2_KeyPub、s2_Info 送给二级认证机构「CA2」。 二级认证机构「CA2」通过某种方式验证「S2」的身份之后，再加上根认证机构自己的一些信息 ca2_Info，然后对它们（s2_KeyPub + s2_Info + ca2_Info）进行散列运算，得到散列值 s2_Hash。 二级认证机构「CA2」使用其私钥 ca2_KeyPri 对 s2_Hash 进行非对称加密，得到加密的散列值 enc_s2_Hash。 二级认证机构「CA2」将（s2_KeyPub + s2_Info + ca2_Info + enc_s2_Hash）组合签署成数字证书**「s2_Cert」**并回送给「S2」。  服务器证书**「s2_Cert」**包含的内容：s2_KeyPub + s2_Info + ca2_Info + enc_s2_Hash。\n**「s2_Cert」**不可用于签署下一级的证书。\n三级或更多级认证机构证书签署流程跟这个流程差不多，也不再赘述了。\n从上面可以看出，证书签署的流程是：「ca_Cert」-\u0026gt; 「ca2_Cert」-\u0026gt;**「s2_Cert」**。它是一条完整的链条，我们把它称之为「证书链」。\n现实中的证书签署 现实中的证书大多数是由二级认证机构签署的。\n并且，以某种方式（如 DNS）对服务器的身份进行验证之后，一般无需让服务器提供任何信息（CSR 文件）。\n认证机构会提供证书、证书链以及私钥，服务器直接使用就好了。\n服务器的配置 如果服务器「S」使用的证书是由根认证机构「CA」直接签署的，那么只需要向客户端提供**「s_Cert」**，然后自己使用私钥 s_KeyPri 即可实现非对称加密。\n如果服务器「S2」使用的证书不是由根认证机构「CA」直接签署的，则不仅需要向客户端提供**「s2_Cert」**，而且还要提供除根认证机构「CA」之外所有认证机构的证书（这里还要提供**「ca2_Cert」**），否则客户端可能会提示证书链不完整而无法通过验证。服务器自己使用私钥 s2_KeyPri 即可实现非对称加密。\n客户端验证服务器的身份 单级认证机构的验证 简要流程\n（假设根认证机构「CA」的根证书**「ca_Cert」**已经安装到操作系统中且被信任。下同。）\n 服务器「S」下发证书**「s_Cert」**给客户端「C」。 客户端「C」检查到**「s_Cert」**中的 ca_Info，发现它是由「CA」签署的。 客户端「C」取出**「ca_Cert」**中的 ca_KeyPub，对**「s_Cert」**中的 enc_s_Hash 进行解密得到 s_Hash。 客户端「C」对**「s_Cert」**中的（s_KeyPub + s_Info + ca_Info）进行散列运算，得到散列值 s_Hash_tmp。 客户端「C」判断 s_Hash 和 s_Hash_tmp 是否相等。如果两者相等，则证明**「s_Cert」**是由**「ca_Cert」**签署的。 客户端「C」检查**「ca_Cert」**，发现该证书是根证书，且已经被系统信任，身份验证通过。   如果**「ca_Cert」**没有安装到系统中，那么将无法对 enc_s_Hash 进行解密，也就无法验证**「s_Cert」**的真实性了。下同。\n 二级（或以上）认证机构的验证 简要流程\n 服务器「S2」下发证书**「s2_Cert」**、**「ca2_Cert」**给客户端「C」。 客户端「C」检查到**「s2_Cert」**中的 ca2_Info，发现它是由「CA2」签署的。 客户端「C」取出**「ca2_Cert」**中的 ca2_KeyPub，对**「s2_Cert」**中的 enc_s2_Hash 进行解密得到 s2_Hash。 客户端「C」对**「s2_Cert」**中的（s2_KeyPub + s2_Info + ca2_Info）进行散列运算，得到散列值 s2_Hash_tmp。 客户端「C」判断 s2_Hash 和 s2_Hash_tmp 是否相等。如果两者相等，则证明**「s2_Cert」**是由**「ca2_Cert」**签署的。 客户端「C」检查到**「ca2_Cert」**中的 ca_Info，发现它是由「CA」签署的。 客户端「C」取出**「ca_Cert」**中的 ca_KeyPub，对**「ca2_Cert」**中的 enc_ca2_Hash 进行解密得到 ca2_Hash。 客户端「C」对**「ca2_Cert」**中的（ca2_KeyPub + ca2_Info + ca_Info）进行散列运算，得到散列值 ca2_Hash_tmp。 客户端「C」判断 ca2_Hash 和 ca2_Hash_tmp 是否相等。如果两者相等，证明**「ca2_Cert」**是由**「ca_Cert」**签署的。 客户端「C」检查**「ca_Cert」**，发现该证书是根证书，且已经被系统信任，身份验证通过。  三级或更多级认证机构证书验证流程跟这个流程差不多，就是一环扣一环地验证下去。\n加密传输的数据 服务器「S」的身份得到客户端「C」的认可之后，服务器「S」可以使用 s_KeyPri 对传出的数据进行加密或者对传入的数据进行解密。\n反过来，客户端「C」可以使用 s_KeyPub 对传出的数据进行加密或者对传入的数据进行解密。\n由于非对称加密的效率较低，所以一般使用非对称加密协商并交换一个临时的会话密钥之后，使用会话密钥进行对称加密。\n现实中的证书验证 现实中，一些众所周知且被信任证书认证机构的根证书都被内置到了操作系统中。\n而客户端在检查服务器证书的时候，一般还会检查它的有效期以及该证书是否在认证机构的证书吊销列表中。证书吊销列表一般是在线检查的。\n参考：\n X.509数字证书的结构与解析 X.509 数字证书的基本原理及应用  HTTP概述 HTTP是一个属于应用层的面向对象的协议，由于其简捷、快速的方式，适用于分布式超媒体信息系统。\nHTTP/0.9 HTTP 是基于 TCP/IP 协议的应用层协议。它不涉及数据包（packet）传输，主要规定了客户端和服务器之间的通信格式，默认使用80端口。\n 协议规定，服务器只能回应HTML格式的字符串，不能回应别的格式。\n HTTP/1.x  在早期，HTTP 使用一个简单的模型来处理这样的连接。这些连接的生命周期是短暂的：每发起一个请求时都会创建一个新的连接，并在收到应答时立即关闭。连接的成本较高。\n 当请求发起时，网络延迟和带宽都会对性能造成影响。现代浏览器往往要发起很多次请求(十几个或者更多)才能拿到所需的完整信息，证明了这个早期模型的效率低下。\n在 HTTP/1.x 里有多种模型：短连接, 长连接, 和 HTTP 流水线。\n短链接模型 HTTP/1.0 的默认模型。每一个 HTTP 请求都由它自己独立的连接完成；这意味着发起每一个 HTTP 请求之前都会有一次 TCP 握手，而且是连续不断的。\n 在 HTTP/1.1 中，只有当 Connection 被设置为 close 时才会用到这个模型\n 长连接模型 保持连接去完成多次连续的请求，减少了不断重新打开连接的时间。在 HTTP/1.1 里，默认就是长连接的。\n 短连接有两个比较大的问题：创建新连接耗费的时间尤为明显，另外 TCP 连接的性能只有在该连接被使用一段时间后(热连接)才能得到改善。另外我们知道，TCP协议有个滑动窗口，有慢启动这回事，就是说每次建立新连接后，数据先是慢慢地传，然后滑动窗口慢慢变大，才能较高速度地传。\n 具体流程：\n一个长连接会保持一段时间，重复用于发送一系列请求，节省了新建 TCP 连接握手的时间，还可以利用 TCP 的性能增强能力。当然这个连接也不会一直保留着：连接在空闲一段时间后会被关闭(服务器可以使用 Keep-Alive 协议头来指定一个最小的连接保持时间)。\n缺点：\n就算是在空闲状态，它还是会消耗服务器资源，而且在重负载时，还有可能遭受 DoS attacks 攻击。这种场景下，可以使用非长连接，即尽快关闭那些空闲的连接，也能对性能有所提升。\n 长连接一个优化的方法就是设置一个超时时间，但是具体这个时间是多少，应该通过测试之后得出一个较为均衡的时间。\n 流水线模型(管线化) 多个连续的请求甚至都不用等待立即返回就可以被发送。HTTP 流水线在现代浏览器中并不是默认被启用的。\n默认情况下，HTTP 请求是按顺序发出的。下一个请求只有在当前请求收到应答过后才会被发出。由于会受到网络延迟和带宽的限制，在下一个请求被发送到服务器之前，可能需要等待很长时间。\n**流水线是在同一条长连接上发出连续的请求，而不用等待应答返回。这样可以避免连接延迟。理论上讲，性能还会因为两个 HTTP 请求有可能被打包到一个 TCP 消息包中而得到提升。**就算 HTTP 请求不断的继续，尺寸会增加，但设置 TCP 的 MSS(Maximum Segment Size) 选项，仍然足够包含一系列简单的请求。\n 比如，当请求一个包含10张图片的HTML Web页面，与挨个连接相比，用持久连接可以让请求更快结束。而管线化技术则比持久连接还要快。请求数越多，时间差就越明显。\n 队头阻塞 在一般情况下，HTTP遵守“请求-响应”的模式，也就是客户端每次发送一个请求到服务端，服务端返回响应，这种模式很简单，但是有一个致命缺陷那就是页面中有多个请求，每个请求必须等到前一个请求响应之后才能发送，并且当前请求的响应返回之后，当前请求的下一个请求才能发送，流程如下图\n在TCP链接中，http请求必须等待前一个请求响应之后，才能发送，后面的依次类推，由此可以看出，如果在一个tcp通道中如果某个http请求的响应因为某个原因没有及时返回，后面的响应会被阻塞，这就是队头阻塞。\n 注意这里说的是响应之后，并不是请之后!\n 为了提高速度和效率，在持久连接的基础上，HTTP1.1进一步地支持在持久连接上使用管道化（pipelining）特性。管道化允许客户端在已发送的请求收到服务端的响应之前发送下一个请求，借此来减少等待时间提高吞吐，如果多个请求能在同一个TCP分节发送的话，还能提高网络利用率，流程如图：\n同一个tcp连接中可以同时发送多个http请求，也就是并发，但是在响应的时候，必须排队响应，谁先到达的谁先响应，相比不支持管道化的http请求确实提高了效率，但是还是有局限性，假如其中某个响应因为某种原因延迟了几秒，后面的响应都会被阻塞。上面箭头所指的响应如果阻塞了，那么这个也是队头阻塞。\n并且使用HTTP管道化还有一些限制:\n1、管道化要求服务端按照请求发送的顺序返回响应（FIFO），原因很简单，HTTP请求和响应并没有序号标识，无法将乱序的响应与请求关联起来。\n2、当客户端在支持管道化时需要保持未收到响应的请求，当连接意外中断时，需要重新发送这部分请求。如果这个请求只是从服务器获取数据，那么并不会对资源造成任何影响，而如果是一个提交信息的请求如post请求，那么可能会造成资源多次提交从而改变资源，这是不允许的。而不会对服务器资源产生影响的请求有个专业名词叫做幂等请求。客户端在使用管道化的时候请求方式必须是幂等请求。\n比较：\n上面的管线化的模型就是加速了请求的过程，但是响应的过程还是存在队头阻塞。\n 因为HTTP管道化本身可能会导致队头阻塞的问题，以及上面提到的一些限制，现代浏览器默认都关闭了管道化，并且大部分服务器也是默认不支持管道化的。\n 如何解决队头阻塞？\n客户端使用并发长连接，注意这个并发指的是tcp并发连接。\n 并发长连接虽然在一定程度上解决了http的队头阻塞，但是会对服务器的性能有较高的要求\n HTTP/2  HTTP/1.1 版的头信息肯定是文本（ASCII编码），数据体可以是文本，也可以是二进制。HTTP/2 则是一个彻底的二进制协议，头信息和数据体都是二进制，并且统称为\u0026quot;帧\u0026rdquo;（frame）：头信息帧和数据帧。\n 😆 HTTP/2 没有改动 HTTP 的应用语义。 HTTP 方法、状态代码、URI 和标头字段等核心概念一如往常。 不过，HTTP/2 修改了数据格式化（分帧）以及在客户端与服务器间传输的方式。这两点统帅全局，通过新的分帧层向我们的应用隐藏了所有复杂性。 因此，所有现有的应用都可以不必修改而在新协议下运行。\n 为什么不是 HTTP/1.2？\n为了实现 HTTP 工作组设定的性能目标，HTTP/2 引入了一个新的二进制分帧层，该层无法与之前的 HTTP/1.x 服务器和客户端向后兼容，因此协议的主版本提升到 HTTP/2。\n 二进制分帧层 HTTP/2 所有性能增强的核心在于新的二进制分帧层，它定义了如何封装 HTTP 消息并在客户端与服务器之间传输。\n这里所谓的“层”，指的是位于套接字接口与应用可见的高级 HTTP API 之间一个经过优化的新编码机制：HTTP 的语义（包括各种动词、方法、标头）都不受影响，不同的是传输期间对它们的编码方式变了。 HTTP/1.x 协议以换行符作为纯文本的分隔符，而 HTTP/2 将所有传输的信息分割为更小的消息和帧，并采用二进制格式对它们编码。\n数据流、消息和帧  数据流：已建立的连接内的双向字节流，可以承载一条或多条消息。 消息：与逻辑请求或响应消息对应的完整的一系列帧。 帧：HTTP/2 通信的最小单位，每个帧都包含帧头，至少也会标识出当前帧所属的数据流。  关系：\n 所有通信都在一个 TCP 连接上完成，此连接可以承载任意数量的双向数据流。(多工) 每个数据流都有一个唯一的标识符和可选的优先级信息，用于承载双向消息。 每条消息都是一条逻辑 HTTP 消息（例如请求或响应），包含一个或多个帧。 帧是最小的通信单位，承载着特定类型的数据，例如 HTTP 标头、消息负载等等。 来自不同数据流的帧可以交错发送，然后再根据每个帧头的数据流标识符重新组装。  简言之，HTTP/2 将 HTTP 协议通信分解为二进制编码帧的交换，这些帧对应着特定数据流中的消息。所有这些都在一个 TCP 连接内复用。 这是 HTTP/2 协议所有其他功能和性能优化的基础。\nHTTP/2 帧结构如下：\n实际的传输过程可能是下面这样(吞吐量增大)：\n请求与响应复用 HTTP/2 中新的二进制分帧层实现了完整的请求和响应复用：客户端和服务器可以将 HTTP 消息分解为互不依赖的帧，然后交错发送，最后再在另一端把它们重新组装起来。\n数据流优先级 我们来看一下上图中的几个操作示例。 从左到右依次为：\n 数据流 A 和数据流 B 都没有指定父依赖项，依赖于隐式“根数据流”；A 的权重为 12，B 的权重为 4。因此，根据比例权重：数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 依赖于根数据流；C 依赖于 D。 因此，D 应先于 C 获得完整资源分配。 权重不重要，因为 C 的依赖关系拥有更高的优先级。 数据流 D 应先于 C 获得完整资源分配；C 应先于 A 和 B 获得完整资源分配；数据流 B 获得的资源是 A 所获资源的三分之一。 数据流 D 应先于 E 和 C 获得完整资源分配；E 和 C 应先于 A 和 B 获得相同的资源分配；A 和 B 应基于其权重获得比例分配。  流控制 流控制是一种阻止发送方向接收方发送大量数据的机制，以免超出后者的需求或处理能力：发送方可能非常繁忙、处于较高的负载之下，也可能仅仅希望为特定数据流分配固定量的资源。 例如，客户端可能请求了一个具有较高优先级的大型视频流，但是用户已经暂停视频，客户端现在希望暂停或限制从服务器的传输，以免提取和缓冲不必要的数据。 再比如，一个代理服务器可能具有较快的下游连接和较慢的上游连接，并且也希望调节下游连接传输数据的速度以匹配上游连接的速度来控制其资源利用率；等等。类似TCP流量控制。\n服务器推送 HTTP/2 新增的另一个强大的新功能是，服务器可以对一个客户端请求发送多个响应。 换句话说，除了对最初请求的响应外，服务器还可以向客户端推送额外资源（图 12-5），而无需客户端明确地请求。\n标头压缩 每个 HTTP 传输都承载一组标头，这些标头说明了传输的资源及其属性。 在 HTTP/1.x 中，此元数据始终以纯文本形式，通常会给每个传输增加 500–800 字节的开销。如果使用 HTTP Cookie，增加的开销有时会达到上千字节。为了减少此开销和提升性能，HTTP/2 使用 HPACK 压缩格式压缩请求和响应标头元数据，这种格式采用两种简单但是强大的技术：\n 这种格式支持通过静态霍夫曼代码对传输的标头字段进行编码，从而减小了各个传输的大小。 这种格式要求客户端和服务器同时维护和更新一个包含之前见过的标头字段的索引列表（换句话说，它可以建立一个共享的压缩上下文），此列表随后会用作参考，对之前传输的值进行有效编码。  利用霍夫曼编码，可以在传输时对各个值进行压缩，而利用之前传输值的索引列表，我们可以通过传输索引值的方式对重复值进行编码，索引值可用于有效查询和重构完整的标头键值对。\n哈夫曼树如何压缩 文件压缩的主要思想是利用哈夫曼编码来实现的，但是得到编码之前我们需要构建这棵树。那么利用什么来构建树呢？！这里，我们需要统计每个字符出现的次数，用次数来构建HuffmanTree。假设我们现在有一个.txt的小文件，内容是\u0026quot;aaaabbbccd\u0026rdquo;。字符存在计算机中时以字节为单位的，因此我们需要将这些字符压缩成0、1表示的编码，0和1表示字节中的“位”，这样能大大降低文件的大小。\n体验HTTP2 https://http2.akamai.com/demo\n参考链接：\n HTTP 连接管理进化论 https://developers.google.com/web/fundamentals/performance/http2?hl=zh-cn 白话http队头阻塞  HTTPS详解 什么是HTTPS？ HTTPS是在HTTP上建立SSL加密层，并对传输数据进行加密，是HTTP协议的安全版。现在它被广泛用于万维网上安全敏感的通讯，例如交易支付方面。\nHTTP协议存在的问题？  通信使用明文（不加密），内容可能被窃听 无法证明报文的完整性，所以可能遭篡改 不验证通信方的身份，因此有可能遭遇伪装  HTTPS的优势？  数据隐私性：内容经过对称加密，每个连接生成一个唯一的加密密钥 数据完整性：内容传输经过完整性校验 身份认证：第三方无法伪造服务端（客户端）身份  HTTPS协议 HTTPS并非是应用层的一种新协议。只是HTTP通信接口部分用SSL和TLS协议代替而已。\n通常，HTTP直接和TCP通信。当使用SSL时，则演变成先和SSL通信，再由SSL和TCP通信了。简言之，所谓HTTPS，其实就是身披SSL协议这层外壳的HTTP。\n在采用SSL后，HTTP就拥有了HTTPS的加密、证书和完整性保护这些功能。也就是说HTTP加上加密处理和认证以及完整性保护后即是HTTPS。\nHTTPS 协议的主要功能基本都依赖于 TLS/SSL 协议，TLS/SSL 的功能实现主要依赖于三类基本算法：散列函数 、对称加密和非对称加密，其利用非对称加密实现身份认证和密钥协商，对称加密算法采用协商的密钥对数据加密，基于散列函数验证信息的完整性。\n数字证书 数字证书认证机构处于客户端与服务器双方都可信赖的第三方机构的立场上。\n数字证书认证机构的业务流程：\n 服务器的运营人员向第三方机构CA提交公钥、组织信息、个人信息(域名)等信息并申请认证; CA通过线上、线下等多种手段验证申请者提供信息的真实性，如组织是否存在、企业是否合法，是否拥有域名的所有权等; 如信息审核通过，CA会向申请者签发认证文件-证书。证书包含以下信息：申请者公钥、申请者的组织信息和个人信息、签发机构 CA的信息、有效时间、证书序列号等信息的明文，同时包含一个签名。 其中签名的产生算法：首先，使用散列函数计算公开的明文信息的信息摘要，然后，采用 CA的私钥对信息摘要进行加密，密文即签名; 客户端 Client 向服务器 Server 发出请求时，Server 返回证书文件; 客户端 Client 读取证书中的相关的明文信息，采用相同的散列函数计算得到信息摘要，然后，利用对应 CA的公钥解密签名数据，对比证书的信息摘要，如果一致，则可以确认证书的合法性，即服务器的公开密钥是值得信赖的。 客户端还会验证证书相关的域名信息、有效时间等信息; 客户端会内置信任CA的证书信息(包含公钥)，如果CA不被信任，则找不到对应 CA的证书，证书也会被判定非法。  HTTPS工作流程   Client发起一个HTTPS（比如https://juejin.im/user/5a9a9cdcf265da238b7d771c）的请求，根据RFC2818的规定，Client知道需要连接Server的443（默认）端口。\n  Server把事先配置好的公钥证书（public key certificate）返回给客户端。\n  Client验证公钥证书：比如是否在有效期内，证书的用途是不是匹配Client请求的站点，是不是在CRL吊销列表里面，它的上一级证书是否有效，这是一个递归的过程，直到验证到根证书（操作系统内置的Root证书或者Client内置的Root证书）。如果验证通过则继续，不通过则显示警告信息。\n  Client使用伪随机数生成器生成加密所使用的对称密钥，然后用证书的公钥加密这个对称密钥，发给Server。\n  Server使用自己的私钥（private key）解密这个消息，得到对称密钥。至此，Client和Server双方都持有了相同的对称密钥。\n  Server使用对称密钥加密“明文内容A”，发送给Client。\n  Client使用对称密钥解密响应的密文，得到“明文内容A”。\n  Client再次发起HTTPS的请求，使用对称密钥加密请求的“明文内容B”，然后Server使用对称密钥解密密文，得到“明文内容B”。\n  参考：\n HTTPS的安全原理  虚拟IP原理 虚拟IP技术。虚拟IP，就是一个未分配给真实主机的IP，也就是说对外提供数据库服务器的主机除了有一个真实IP外还有一个虚IP，使用这两个IP中的任意一个都可以连接到这台主机，所有项目中数据库链接一项配置的都是这个虚IP，当服务器发生故障无法对外提供服务时，动态将这个虚IP切换到备用主机。\n其实现原理主要是靠 TCP/IP 的 ARP 协议。因为IP地址只是一个逻辑地址，在以太网中 MAC 地址才是真正用来进行数据传输的物理地址，每台主机中都有一个 ARP 高速缓存，存储同一个网络内的 IP 地址与 MAC 地址的对应关系，以太网中的主机发送数据时会先从这个缓存中查询目标 IP 对应的 MAC 地址，会向这个 MAC 地址发送数据。操作系统会自动维护这个缓存。这就是整个实现的关键。\n参考：\n 虚拟IP技术  传输层🚙 TCP〰 TCP中流的解释 TCP中的“流”(stream)指的是流入到进程或从进程流出的字节序列。“面向字节流”的含义是：虽然应用程序和TCP的交互是一次一个数据块（大小不等），但TCP把应用程序交下来的数据看成仅仅是一连串的无结构的字节流。TCP并不知道所传送的字节流的含义。TCP不保证接收方应用程序所收到的数据块和发送方应用程序所发出的数据块具有对应大小的关系（例如，发送方应用程序交给发送方的TCP共10个数据块，但接收方的TCP可能只用了4个数据块就把收到的字节流交付上层的应用程序）。但接收方应用程序收到的字节流必须和发送方应用程序发出的字节流完全一样。当然，接收方的应用程序必须有能力识别收到的字节流，把它还原成有意义的应用层数据。\n一个简单的示意图如下：\n TCP和UDP在发送报文时所采用的方式完全不同。TCP并不关心应用进程一次把多长的报文发送到TCP的缓存中，而是根据对方给出的窗口值和当前网络拥塞的程度来决定一个报文段应包含多少个字节（UDP发送的报文长度是应用进程给出的）。如果应用进程传送到TCP缓存的数据块太长，TCP就可以把它划分短一些再传送。如果应用进程一次只发来一个字节，TCP也可以等待积累有足够多的字节后再构成报文段发送出去\n TCP报文格式 英文版：\nTCP的固定包头为20个字节，下面是几个参数：\n 序号：即SEQ序号。TCP连接中传送的数据流中的每一个字节都编上一个序号。序号字段的值则指的是本报文段所发送的数据的第一个字节的序号。 确认号：即确认序号，也叫ACK序号。是期望收到对方的下一个报文段的数据的第一个字节的序号。只有ACK标志位为1时，确认序号字段才有效，ACK=SEQ+1。 数据偏移：它指出TCP报文段的数据起始处距离TCP报文段的起始处有多远。该字段长 4 位，单位为 4 字节。表示为 TCP 首部的长度。所以 TCP 首部长度最多为 60 字节。 标志位：共6个，即URG(紧急比特)、ACK(确认比特)、PSH(推送比特)、RST(复位比特)、SYN(同步比特)、FIN(结束比特)等。 窗口大小：窗口字段用来控制对方发送的数据量，单位为字节。TCP连接的一端根据设置的缓存空间大小确定自己的接收窗口大小，然后通知对方以确定对方的发送窗口的上。 校验和：检验和字段检验的范围包括首部和数据这两部分。在计算检验和时，要在TCP报文段的前面加上12字节的伪首部。 紧急指针：紧急指针指出在本报文段中的紧急数据的最后一个字节的序号。 选项：TCP只规定了一种选项，即最大报文段长度MSS（MaximumSegment Size）。MSS告诉对方TCP：“我的缓存所能接收的报文段的数据字段的最大长度是MSS 个字节。”  几个控制位：\n1 2 3 4 5 6 7 8  CWR：用于 IP 首部的 ECN 字段。ECE 为 1 时，则通知对方已将拥塞窗口缩小。 ECE：在收到数据包的 IP 首部中 ECN 为 1 时将 TCP 首部中的 ECE 设置为 1，表示从对方到这边的网络有拥塞。 URG：紧急模式 ACK：确认 PSH：推送，接收方应尽快给应用程序传送这个数据。没用到 RST：该位为 1 表示 TCP 连接中出现异常必须强制断开连接。 SYN：初始化一个连接的同步序列号 FIN：该位为 1 表示今后不会有数据发送，希望断开连接   选项（Options）：\n受 Data Offset 控制，长度最大为 40 字节。一般 Option 的格式为 TLV 结构：\n常见的 TCP Options 有，SACK 字段就位于该选项中:\nSACK 的工作原理\n如下图所示， 接收方收到 500-699 的数据包，但没有收到 300-499 的数据包就会回 SACK(500-700) 给发送端，表示收到 500-699 的数据。\n三次握手：  三次握手是必须的——TCP 需要 seq 序列号来做可靠重传或接收，而避免连接复用时无法分辨出 seq 是延迟或者是旧链接的 seq，因此需要三次握手来约定确定双方的 ISN（初始 seq 序列号）。\n 四次挥手 其中A发送的X为前面已传送过的数据的最后一个字节的序号加1。\n第一次A到B方向结束，第二次B到A方向结束。\n第二次B发送的SEQ=Z(在半关闭状态B可能又发送了一些数据),B还必须重复上次已发送过的确认号ACK = X+1。\n 请注意，TCP规定，FIN报文段即使不携带数据，它也消耗掉一个序号。\n请注意，现在TCP连接还没有释放掉。必须经过时间等待计时器(TIME-WAIT timer)设置的时间2MSL后，A才进入到CLOSED状态。时间MSL叫做最长报文段寿命(Maximum Segment Lifetime)，RFC 793建议设为2分钟。但这完全是从工程上来考虑，对于现在的网络，MSL = 2分钟可能太长了一些。因此TCP允许不同的实现可根据具体情况使用更小的MSL值。因此，从A进入到TIME-WAIT状态后，要经过4分钟才能进入到CLOSED状态，才能开始建立下一个新的连接。当A撤销相应的传输控制块TCB后，就结束了这次的TCP连接。\n 为什么A在TIME-WAIT状态(发送最后一个数据包之后)必须等待2MSL的时间呢？这有两个理由。\n  第一，为了保证A发送的最后一个ACK报文段能够到达B。这个ACK报文段有可能丢失，因而使处在LAST-ACK状态的B收不到对已发送的FIN + ACK报文段的确认。B会超时重传这个FIN + ACK报文段，而A就能在2MSL时间内收到这个重传的FIN + ACK报文段。接着A重传一次确认，重新启动2MSL计时器。最后，A和B都正常进入到CLOSED状态。如果A在TIME-WAIT状态不等待一段时间，而是在发送完ACK报文段后立即释放连接，那么就无法收到B重传的FIN + ACK报文段，因而也不会再发送一次确认报文段。这样，B就无法按照正常步骤进入CLOSED状态。\n  第二，防止上一节提到的“已失效的连接请求报文段”出现在本连接中。A在发送完最后一个ACK报文段后，再经过时间2MSL，就可以使本连接持续的时间内所产生的所有报文段都从网络中消失。这样就可以使下一个新的连接中不会出现这种旧的连接请求报文段。B只要收到了A发出的确认，就进入CLOSED状态。同样，B在撤销相应的传输控制块TCB后，就结束了这次的TCP连接。我们注意到，B结束TCP连接的时间要比A早一些。\n  TCP的4个定时器  重传定时器、坚持定时器、保持定时器、时间等待定时器\n 重传计时器：\n当TCP发送报文段时，就创建该特定报文段的重传计时器。\n 若在计时器截止时间到(通常60秒)之前收到了对此特定报文段的确认，则撤销此计时器。 若在计时器截止时间之前没有收到对此特定报文的确认，则就认为该报文丢失，需要重传此报文段，并将计时器复位。  坚持计时器-防止收不到非0窗口大小的报文\n 假设TCP收到了一个窗口大小为0报文段，发送TCP就停止传送报文段，直到接收TCP发送一个非零的窗口大小。但是这个确认有可能丢失，若确认丢了，接收TCP并不会知道，而是认为他已经完成任务了。但是发送TCP由于没有收到确认，就会一直等待接收方发送确认来通知窗口的大小。双方的TCP这时就会造成死锁，所以要使用一个计时器来避免死锁的发送。\n  当TCP收到一个窗口大小为0的确认时，就要启动坚持计时器。当坚持计时器期限到时，发送TCP就发送一个特殊的探测报文，这个探测报文段只有一个字节数据，它有一个序号，但是它的序号永远不需要确认。探测报文段提醒对端，确认已丢失，必须重传。 坚持计时器的值设置为重传时间的数值。若没有收到从接收端来的响应，需要发送一个探测报文，并将坚持计时器的值加倍和复位，直到这个值增大到门限值(通常60秒)为止。在这以后，发送端每隔60秒发送一个探测报文，直到窗口重新打开。  保活计时器\n保活计时器用来防止两个TCP之间的连续出现长时间的空闲。\n 假定客户已主动与服务器建立了TCP链接。然后这个客户端出现故障。在这种情况下，这个链接就会永远的处于打开状态。而服务器维护一个链接，也是要耗费一定的资源的，所以必须采取措施，使服务器不能白白等下去。 要解决这种问题，就要对服务器设置保活计时器。每当服务器收到客户的信息，就将计时器复位，保活时间通常设置为2小时。若服务器过了两小时还没有收到客户的信息，他就发送一个探测报文，以后每隔75秒就发一次，连续发送10个探测报文后客户端仍然没有响应，服务器就认为客户端出现了故障，接着就关闭这个链接。  时间等待计时器\n当客户端进入TIME-WAIT状态的时候，链接还没有释放掉，必须等待2倍的MSL(最长报文段寿命)后，客户端才能关闭连接。在时间等待期间，链接还处于一种过渡状态。这就可以使重复的FIN报文段(若果有的话)可以到达目的站因而可将其丢弃。\n保证传输可靠 理想的传输条件有以下两个特点：\n 传输信道不产生差错。 不管发送方以多快的速度发送数据，接收方总是来得及处理收到的数据。   我们可以使用一些可靠传输协议，当出现差错时让发送方重传出现差错的数据，同时在接收方来不及处理收到的数据时，及时告诉发送方适当降低发送数据的速度。这样一来，本来是不可靠的传输信道就能够实现可靠传输了。\n 序号与确认号\n有一个问题：这条连接突然断开重连后，TCP 怎么样识别之前旧链接重发的包？——这就需要独一无二的 ISN（初始序列号）机制。\n超时重传\n超时重传：可靠传输协议是这样设计的：A只要超过了一段时间仍然没有收到确认，就认为刚才发送的分组丢失了，因而重传前面发送过的分组。这就叫做超时重传。\n 要实现超时重传，就要在每发送完一个分组设置一个超时计时器。如果在超时计时器到期之前收到了对方的确认，就撤销已设置的超时计时器\n 确认丢失与确认迟到：\n停止等待协议 - 简单的保证传输的可靠性- ARQ协议\n停止等待协议：“停止等待”就是每发送完一个分组就停止发送，等待对方的确认。在收到确认后再发送下一个分组。(信道利用率低)\n连续ARQ协议\n连续ARQ协议：发送方每收到一个确认，就\t把发送窗口向前滑动一个分组的位置。\n接收方一般都是采用累积确认的方式。这就是说，接收方不必对收到的分组逐个发送确认，而是在收到几个分组后，对按序到达的最后一个分组发送确认，这就表示：到这个分组为止的所有分组都已正确收到了。\n滑动窗口\n发送窗口表示：在没有收到B的确认的情况下，A可以连续把窗口内的数据都发送出去。凡是已经发送过的数据，在未收到确认之前都必须暂时保留，以便在超时重传时使用\n从以上所述可以看出，要描述一个发送窗口的状态需要三个指针：P1，P2和P3。指针都指向字节的序号。这三个指针指向的几个部分的意义如下：小于P1的是已发送并已收到确认的部分，而大于P3的是不允许发送的部分。P3 - P1 = A的发送窗口（又称为通知窗口）P2 - P1 = 已发送但尚未收到确认的字节数P3 - P2 = 允许发送但尚未发送的字节数（又称为可用窗口或有效窗口）\n发送方的应用进程把字节流写入TCP的发送缓存，接收方的应用进程从TCP的接收缓存中读取字节流。下图表示了发送方维持的发送缓存和发送窗口，以及接收方维持的接收缓存和接收窗口。\n总结：\n发送缓存用来暂时存放：\n 发送应用程序传送给发送方TCP准备发送的数据 TCP已发送出但尚未收到确认的数据。   发送窗口通常只是发送缓存的一部分。已被确认的数据应当从发送缓存中删除，因此发送缓存和发送窗口的后沿是重合的。发送应用程序最后写入发送缓存的字节减去最后被确认的字节，就是还保留在发送缓存中的被写入的字节数。发送应用程序必须控制写入缓存的速率，不能太快，否则发送缓存就会没有存放数据的空间。\n 接收缓存用来暂时存放：\n 按序到达的、但尚未被接收应用程序读取的数据 未按序到达的数据。   如果收到的分组被检测出有差错，则要丢弃。如果接收应用程序来不及读取收到的数据，接收缓存最终就会被填满，使接收窗口减小到零。反之，如果接收应用程序能够及时从接收缓存中读取收到的数据，接收窗口就可以增大，但最大不能超过接收缓存的大小。\n 超时重传的选择\nTCP采用了一种自适应算法，它记录一个报文段发出的时间，以及收到相应的确认的时间。这两个时间之差就是报文段的往返时间RTT。TCP保留了RTT的一个加权平均往返时间 $RTT_S$（这又称为平滑的往返时间，S表示Smoothed。因为进行的是加权平均，因此得出的结果更加平滑）。每当第一次测量到RTT样本时，RTTS值就取为所测量到的RTT样本值。但以后每测量到一个新的RTT样本，就按下式重新计算一次$RTT_S$\n RFC2988推荐的α值为1/8，即0.125。用这种方法得出的加权平均往返时间RTTS就比测量出的RTT值更加平滑\n 超时计时器设置的超时重传时间 RTO (RetransmissionTime-Out)应略大于上面得出的加权平均往返时间$RTT_S$。RFC 2988建议使用下式计算RTO：\n$$\nRTO = RTT_{S} + 4 \\times RTT_{D}\n$$\n而$RTT_D$是RTT的偏差的加权平均值，它与$RTT_S$和新的RTT样本之差有关。当第一次测量时，RTTD值取为测量到的RTT样本值的一半。在以后的测量中，则使用下式计算加权平均的RTTD：\n 这里 β 是个小于1的系数，它的推荐值是1/4，即0.25。\n 接受方有一个判断接受的报文时之前发送的还是之后重传的报文的问题，这里接受方如何判断给哪一个报文发送确认？\n选择确认SACK\n这就是若收到的报文段无差错，只是未按序号，中间还缺少一些序号的数据，那么能否设法只传送缺少的数据而不重传已经正确到达接收方的数据？\n流量控制  所谓流量控制(flow control)就是让发送方的发送速率不要太快，要让接收方来得及接收\n 滑动窗口流量控制：\n现在我们考虑一种情况。、B向A发送了零窗口的报文段后不久，B的接收缓存又有了一些存储空间。于是B向A发送了rwnd = 400的报文段。然而这个报文段在传送过程中丢失了。A一直等待收到B发送的非零窗口的通知，而B也一直等待A发送的数据。如果没有其他措施，这种互相等待的死锁局面将一直延续下去。这个时候就需要坚持计时器来保证了。\n控制TCP发送报文段的时机 有三种发送报文段的方法：\n 第一种机制是TCP维持一个变量，它等于最大报文段长度MSS。只要缓存中存放的数据达到MSS字节时，就组装成一个TCP报文段发送出去。 第二种机制是由发送方的应用进程指明要求发送报文段，即TCP支持的推送(push)操作 第三种机制是发送方的一个计时器期限到了，这时就把当前已有的缓存数据装入报文段（但长度不能超过MSS）发送出去。  在TCP的实现中广泛使用Nagle算法。算法如下：若发送应用进程把要发送的数据逐个字节地送到TCP的发送缓存，则发送方就把第一个数据字节先发送出去，把后面到达的数据字节都缓存起来。当发送方收到对第一个数据字符的确认后，再把发送缓存中的所有数据组装成一个报文段发送出去，同时继续对随后到达的数据进行缓存。只有在收到对前一个报文段的确认后才继续发送下一个报文段。当数据到达较快而网络速率较慢时，用这样的方法可明显地减少所用的网络带宽。Nagle算法还规定，当到达的数据已达到发送窗口大小的一半或已达到报文段的最大长度时，就立即发送一个报文段。这样做，就可以有效地提高网络的吞吐量。\n另一个问题叫做糊涂窗口综合症。要解决这个问题，可以让接收方等待一段时间，使得或者接收缓存已有足够空间容纳一个最长的报文段，或者等到接收缓存已有一半空闲的空间。只要出现这两种情况之一，接收方就发出确认报文，并向发送方通知当前的窗口大小。此外，发送方也不要发送太小的报文段，而是把数据积累成足够大的报文段，或达到接收方缓存的空间的一半大小。\n拥塞控制  流量控制与拥塞控制的区别：\n拥塞控制与流量控制的关系密切，它们之间也存在着一些差别。所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。\n相反，流量控制往往指点对点通信量的控制，是个端到端的问题（接收端控制发送端）。流量控制所要做的就是抑制发送端发送数据的速率，以便使接收端来得及接收。\n 什么是网络拥塞？\n在计算机网络中的链路容量（即带宽）、交换结点中的缓存和处理机等，都是网络的资源。在某段时间，若对网络中某一资源的需求超过了该资源所能提供的可用部分，网络的性能就要变坏。这种情况就叫做拥塞(congestion)。\n 所谓拥塞控制就是防止过多的数据注入到网络中，这样可以使网络中的路由器或链路不致过载。\n 拥塞控制所要做的都有一个前提，就是网络能够承受现有的网络负荷。拥塞控制是一个全局性的过程，涉及到所有的主机、所有的路由器，以及与降低网络传输性能有关的所有因素。但TCP连接的端点只要迟迟不能收到对方的确认信息，就猜想在当前网络中的某处很可能发生了拥塞，但这时却无法知道拥塞到底发生在网络的何处，也无法知道发生拥塞的具体原因（是访问某个服务器的通信量过大？还是在某个地区出现了自然灾害）。\n拥塞控制所起的作用如下：\n图中随着提供的负载的增大，网络吞吐量的增长速率逐渐减小。也就是说，在网络吞吐量还未达到饱和时，就已经有一部分的输入分组被丢弃了。当网络的吞吐量明显地小于理想的吞吐量时，网络就进入了轻度拥塞的状态。更值得注意的是，当提供的负载达到某一数值时，网络的吞吐量反而随提供的负载的增大而下降，这时网络就进入了拥塞状态。当提供的负载继续增大到某一数值时，网络的吞吐量就下降到零，网络已无法工作。这就是所谓的死锁(deadlock)。\n由于计算机网络是一个很复杂的系统，因此可以从控制理论的角度来看拥塞控制这个问题。这样，从大的方面看，可以分为开环控制和闭环控制两种方法。开环控制方法就是在设计网络时事先将有关发生拥塞的因素考虑周到，力求网络在工作时不产生拥塞。但一旦整个系统运行起来，就不再中途进行改正了。\n闭环控制是基于反馈环路的概念。属于闭环控制的有以下几种措施：\n 监测网络系统以便检测到拥塞在何时、何处发生。 把拥塞发生的信息传送到可采取行动的地方。 调整网络系统的运行以解决出现的问题。  几种方法  1999年公布的因特网建议标准RFC 2581定义了进行拥塞控制的四种算法，即慢开始(slow-start)、拥塞避免(congestion avoidance)、快重传(fast retransmit)和快恢复(fast recovery)。\n   慢开始和拥塞避免\n发送方维持一个叫做拥塞窗口 cwnd (congestion window)的状态变量。拥塞窗口的大小取决于网络的拥塞程度，并且动态地在变化。发送方让自己的发送窗口等于拥塞窗口。\n送方控制拥塞窗口的原则是：只要网络没有出现拥塞，拥塞窗口就再增大一些，以便把更多的分组发送出去。但只要网络出现拥塞，拥塞窗口就减小一些，以减少注入到网络中的分组数。\n 发送方又是如何知道网络发生了拥塞呢？我们知道，当网络发生拥塞时，路由器就要丢弃分组。因此只要发送方没有按时收到应当到达的确认报文，就可以猜想网络可能出现了拥塞。现在通信线路的传输质量一般都很好，因传输出差错而丢弃分组的概率是很小的（远小于1 %）。\n 慢开始算法的思路是这样的。当主机开始发送数据时，如果立即把大量数据字节注入到网络，那么就有可能引起网络拥塞，因为现在并不清楚网络的负荷情况。\n经验证明，较好的方法是先探测一下，即由小到大逐渐增大发送窗口，也就是说，由小到大逐渐增大拥塞窗口数值。通常在刚刚开始发送报文段时，先把拥塞窗口cwnd设置为一个最大报文段MSS的数值[插图]。而在每收到一个对新的报文段的确认后，把拥塞窗口增加至多一个MSS的数值。用这样的方法逐步增大发送方的拥塞窗口cwnd，可以使分组注入到网络的速率更加合理。\n慢开始拥塞窗口变化：\n图解：\n拥塞避免算法就是指拥塞窗口按线性规律增长。\n在TCP拥塞控制的文献中经常可看见“乘法减小”(Multiplicative Decrease)和“加法增大”(Additive Increase)这样的提法。“乘法减小”是指不论在慢开始阶段还是拥塞避免阶段，只要出现超时（即很可能出现了网络拥塞），就把慢开始门限值ssthresh减半，即设置为当前的拥塞窗口的一半（与此同时，执行慢开始算法）。当网络频繁出现拥塞时，ssthresh值就下降得很快，以大大减少注入到网络中的分组数。而“加法增大”是指执行拥塞避免算法后，使拥塞窗口缓慢增大，以防止网络过早出现拥塞。上面两种算法合起来常称为AIMD算法（加法增大乘法减小）。对这种算法进行适当修改后，又出现了其他一些改进的算法。但使用最广泛的还是AIMD算法。\n  快重传和快恢复\n快重传算法规定，发送方只要一连收到三个重复确认就应当立即重传对方尚未收到的报文段M3，而不必继续等待为M3设置的重传计时器到期。由于发送方能尽早重传未被确认的报文段，因此采用快重传后可以使整个网络的吞吐量提高约20%。\n示意图：\n快重传配合使用的还有快恢复算法，其过程有以下两个要点：\n 当发送方连续收到三个重复确认时，就执行“乘法减小”算法，把慢开始门限ssthresh减半。这是为了预防网络发生拥塞。请注意，接下去不执行慢开始算法。 由于发送方现在认为网络很可能没有发生拥塞（如果网络发生了严重的拥塞，就不会一连有好几个报文段连续到达接收方，也就不会导致接收方连续发送重复确认），因此与慢开始不同之处是现在不执行慢开始算法（即拥塞窗口cwnd现在不设置为1），而是把cwnd值设置为慢开始门限ssthresh减半后的数值，然后开始执行拥塞避免算法（“加法增大”），使拥塞窗口缓慢地线性增大。  示意图：\n  如果把拥塞控制和接收方对发送方的流量控制一起考虑，那么很显然，发送方的窗口的上限值应当取为接收方窗口rwnd和拥塞窗口cwnd这两个变量中较小的一个，也就是说：\n流量控制 滑动窗口\n拥塞控制 快重传、快恢复、超时重传，拥塞避免\nUDP📦 UDP一次交付一个完整的报文，不会对报文进行拆分。因此，应用程序必须选择合适大小的报文。若报文太长，UDP把它交给IP层后，IP层在传送时可能要进行分片，这会降低IP层的效率。反之，若报文太短，UDP把它交给IP层后，会使IP数据报的首部的相对长度太大，这也降低了IP层的效率。\nUDP数据报格式：(首部8字节)\n伪报头格式：\n **校验和计算：**伪报头+UDP数据报\n 伪报头的作用是验证UDP数据报是否正确传送到目的进程。\n计算校验和：\n在发送方，首先是先把全零放入检验和字段。再把伪首部以及UDP用户数据报看成是由许多16位的字串接起来。若UDP用户数据报的数据部分不是偶数个字节，则要填入一个全零字节（但此字节不发送）。然后按二进制反码计算出这些16位字的和。将此和的二进制反码写入检验和字段后，就发送这样的UDP用户数据报。在接收方，把收到的UDP用户数据报连同伪首部（以及可能的填充全零字节）一起，按二进制反码求这些16位字的和。当无差错时其结果应为全1。\n 二进制反码求和：0和0相加是0，但要产生一个进位1，0和1相加是1，1和1相加是0。若最高位相加后产生进位，则最后得到的结果要加1。\n（0）反 + （0）反 = 1 + 1 = 10\n（1）反 +（0）反=0+ 1 =1\n（1）反 + （1）反 = 0 + 0 = 0\n\u0026ldquo;二进制反码求和\u0026rdquo; 等价于 \u0026ldquo;二进制求和再取反\u0026rdquo;\n二进制求出的和如果大于16位时所做的操作,用和值中高16位加上低16位的值作为最终的和值,然后再做取反运算.\n 下面是计算校验和的一个例子：\n 这样的检验和，既检查了UDP用户数据报的源端口号和目的端口号以及UDP用户数据报的数据部分，又检查了IP数据报的源IP地址和目的地址。\n  网卡收到一条数据到进程处理数据,这之间经历了什么(中断的上半部下半部,网络层协议拆包)？\n拥塞控制算法 TCP拥塞控制算法的目的可以简单概括为：公平竞争、充分利用网络带宽、降低网络延时、优化用户体验，然而就目前而言要实现这些目标就难免有权衡和取舍。\n算法分类 基于丢包策略的传统拥塞控制算法的几个迭代版本，如图所示：\n与此同时还有一类算法是基于RTT延时策略来进行控制的，但是这类算法在发包速率上可能不够激进，竞争性能不如其他算法，因此在共享网络带宽时有失公平性，但是算法速率曲线却是很平滑\n如何感知拥塞 在TCP连接的发送方一般是基于丢包来判断当前网络是否发生拥塞，丢包可以由重传超时RTO和重复确认来做判断。\n拥塞控制基本策略 拥塞控制是一个动态的过程，它既要提高带宽利用率发送尽量多的数据又要避免网络拥堵丢包RTT增大等问题，基于这种高要求并不是单一策略可以搞定的，因此TCP的 拥塞控制策略实际上是分阶段分策略的综合过程：\nTCP Tahoe 和TCP Reno\n这两个算法代号取自太浩湖Lake和Tahoe里诺市，两者算法大致一致，对于丢包事件判断都是以重传超时retransmission timeout和重复确认为条件，但是对于重复确认的处理两者有所不同，对于超时重传RTO情况两个算法都是将拥塞窗口降为1个MSS，然后进入慢启动阶段。\nTCP Tahoe算法：如果收到三次重复确认即第四次收到相同确认号的分段确认，并且分段对应包无负载分段和无改变接收窗口的话，Tahoe算法则进入快速重传，将慢启动阈值改为当前拥塞窗口的一半，将拥塞窗口降为1个MSS，并重新进入慢启动阶段。\nTCP Reno算法：如果收到三次重复确认，Reno算法则进入快速重传只将拥塞窗口减半来跳过慢启动阶段，将慢启动阈值设为当前新的拥塞窗口值，进入一个称为快速恢复的新设计阶段。TCP New Reno\nTCP New Reno是对TCP Reno中快速恢复阶段的重传进行改善的一种改进算法，New Reno在低错误率时运行效率和选择确认SACK相当，在高错误率仍优于Reno。\nTCP BIC 和TCP CUBIC\nTCP BIC旨在优化高速高延迟网络的拥塞控制，其拥塞窗口算法使用二分搜索算法尝试找到能长时间保持拥塞窗口最大值，Linux内核在2.6.8至2.6.18使用该算法作为默认TCP拥塞算法。\nCUBIC则是比BIC更温和和系统化的分支版本，其使用三次函数代替二分算法作为其拥塞窗口算法，并且使用函数拐点作为拥塞窗口的设置值，Linux内核在2.6.19后使用该算法作为默认TCP拥塞算法。\nTCP PRR\nTCP PRR是旨在恢复期间提高发送数据的准确性，该算法确保恢复后的拥塞窗口大小尽可能接近慢启动阈值。在Google进行的测试中，能将平均延迟降低3~10%恢复超时减少5%，PRR算法后作为Linux内核3.2版本默认拥塞算法。\nTCP BBR是由Google设计于2016年发布的拥塞算法，该算法认为随着网络接口控制器逐渐进入千兆速度时，分组丢失不应该被认为是识别拥塞的主要决定因素，所以基于模型的拥塞控制算法能有更高的吞吐量和更低的延迟，可以用BBR来替代其他流行的拥塞算法。\nGoogle在YouTube上应用该算法，将全球平均的YouTube网络吞吐量提高了4%，BBR之后移植入Linux内核4.9版本。\n其中比较有名的Vegas算法是大约在1995年由亚利桑那大学的研究人员拉里·彼得森和劳伦斯·布拉科夫提出，这个新的TCP拥塞算法以内华达州最大的城市拉斯维加斯命名，后成为TCP Vegas算法。\n关于基于RTT的TCP Vegas算法的详细介绍可以查阅文档：\n http://www.cs.cmu.edu/~srini/15-744/F02/readings/BP95.pdf\n 文档对Vegas算法和New Reno做了一些对比，我们从直观图形上可以看到Vegas算法更加平滑，相反New Reno则表现除了较大的波动呈锯齿状，如图所示：\n实际上还有更细粒度的分类，由于不是今天的重点，就不再深入展开了，当前使用的拥塞控制算法还是基于丢包Loss-Based作为主流。\n参考：\n 万字长文|全网最强 TCP/IP 拥塞控制总结\u0026hellip; 万字详文：TCP 拥塞控制详解  一泡尿的时间，快速读懂QUIC协议 如何让网络数据传输地更快？(合并一些层)\n为什么需要QUIC？   中间设备的僵化\n可能是 TCP 协议使用得太久，也非常可靠。所以我们很多中间设备，包括防火墙、NAT 网关，整流器等出现了一些约定俗成的动作。\n  依赖于操作系统的实现导致协议僵化\nTCP 是由操作系统在内核西方栈层面实现的，应用程序只能使用，不能直接修改。虽然应用程序的更新迭代非常快速和简单。但是 TCP 的迭代却非常缓慢，原因就是操作系统升级很麻烦。\n  建立连接的握手延迟大\n不管是 HTTP1.0/1.1 还是 HTTPS，HTTP2，都使用了 TCP 进行传输。HTTPS 和 HTTP2 还需要使用 TLS 协议来进行安全传输。这就出现了两个握手延迟：\n  TCP 三次握手导致的 TCP 连接建立的延迟。\n  TLS 完全握手需要至少 2 个 RTT 才能建立，简化握手需要 1 个 RTT 的握手延迟。\n  对于很多短连接场景，这样的握手延迟影响很大，且无法消除。\n  队头阻塞\n队头阻塞主要是 TCP 协议的可靠性机制引入的。TCP 使用序列号来标识数据的顺序，数据必须按照顺序处理，如果前面的数据丢失，后面的数据就算到达了也不会通知应用层来处理。\n另外 TLS 协议层面也有一个队头阻塞，因为 TLS 协议都是按照 record 来处理数据的，如果一个 record 中丢失了数据，也会导致整个 record 无法正确处理。\n  QUIC 协议选择了 UDP，因为 UDP 本身没有连接的概念，不需要三次握手，优化了连接建立的握手延迟，同时在应用程序层面实现了 TCP 的可靠性，TLS 的安全性和 HTTP2 的并发性，只需要用户端和服务端的应用程序支持 QUIC 协议，完全避开了操作系统和中间设备的限制。\nQUIC 是 Quick UDP Internet Connections 的缩写，谷歌发明的新传输协议。\n 与 TCP 相比，QUIC 可以减少延迟。\n QUIC 协议可以在 1 到 2 个数据包（取决于连接的服务器是新的还是已知的）内，完成连接的创建（包括 TLS）。\nQUIC 与现有 TCP + TLS + HTTP/2 方案相比，有以下几点主要特征：\n 利用缓存，显著减少连接建立时间；(减少了 TCP 三次握手及 TLS 握手时间) 改善拥塞控制，拥塞控制从内核空间到用户空间； 没有 head of line 阻塞的多路复用； 前向纠错，减少重传； 连接平滑迁移，网络状态的变更不会影响连接断线。  拥塞控制、加密和一些HTTP/2的特性都移动到QUIC层去了\n从图上可以看出，QUIC 底层通过 UDP 协议替代了 TCP，上层只需要一层用于和远程服务器交互的 HTTP/2 API。这是因为 QUIC 协议已经包含了多路复用和连接管理，HTTP API 只需要完成 HTTP 协议的解析即可。\nQUIC也合并了TLS握手过程到它的连接过程之中\n目标 QUIC 协议的主要目的，是为了整合 TCP 协议的可靠性和 UDP 协议的速度和效率。\nQUIC连接过程 Step1：首次连接时，客户端发送 Inchoate Client Hello 给服务端，用于请求连接；\nStep2：服务端生成 g、p、a，根据 g、p 和 a 算出 A，然后将 g、p、A 放到 Server Config 中再发送 Rejection 消息给客户端；\nStep3：客户端接收到 g、p、A 后，自己再生成 b，根据 g、p、b 算出 B，根据 A、p、b 算出初始密钥 K。B 和 K 算好后，客户端会用 K 加密 HTTP 数据，连同 B 一起发送给服务端；\nStep4：服务端接收到 B 后，根据 a、p、B 生成与客户端同样的密钥，再用这密钥解密收到的 HTTP 数据。为了进一步的安全（前向安全性），服务端会更新自己的随机数 a 和公钥，再生成新的密钥 S，然后把公钥通过 Server Hello 发送给客户端。连同 Server Hello 消息，还有 HTTP 返回数据；\nStep5：客户端收到 Server Hello 后，生成与服务端一致的新密钥 S，后面的传输都使用 S 加密。\n这样，QUIC 从请求连接到正式接发 HTTP 数据一共花了 1 RTT，这 1 个 RTT 主要是为了获取 Server Config，后面的连接如果客户端缓存了 Server Config，那么就可以直接发送 HTTP 数据，实现 0 RTT 建立连接。\n这里使用的是 DH 密钥交换算法，DH 算法的核心就是服务端生成 a、g、p 3 个随机数，a 自己持有，g 和 p 要传输给客户端，而客户端会生成 b 这 1 个随机数，通过 DH 算法客户端和服务端可以算出同样的密钥。在这过程中 a 和 b 并不参与网络传输，安全性大大提高。因为 p 和 g 是大数，所以即使在网络中传输的 p、g、A、B 都被劫持，那么靠现在的计算机算力也没法破解密钥。\nQUIC连接迁移  当手机从数据信号切换到WIFI信号时需要可以灵活的进行连接的切换。\n TCP 连接基于四元组（源 IP、源端口、目的 IP、目的端口），切换网络时至少会有一个因素发生变化，导致连接发生变化。当连接发生变化时，如果还使用原来的 TCP 连接，则会导致连接失败，就得等原来的连接超时后重新建立连接，所以我们有时候发现切换到一个新网络时，即使新网络状况良好，但内容还是需要加载很久。如果实现得好，当检测到网络变化时立刻建立新的 TCP 连接，即使这样，建立新的连接还是需要几百毫秒的时间。\nQUIC 的连接不受四元组的影响，当这四个元素发生变化时，原连接依然维持。那这是怎么做到的呢？道理很简单，QUIC 连接不以四元组作为标识，而是使用一个 64 位的随机数，这个随机数被称为 Connection ID，即使 IP 或者端口发生变化，只要 Connection ID 没有变化，那么连接依然可以维持。\n是不是很强~\nQUIC解决队头阻塞问题 HTTP 一般又允许每个主机建立 6 个 TCP 连接，这样可以更加充分地利用带宽资源，但每个连接中队头阻塞的问题还是存在。\nHTTP/2 的多路复用解决了上述的队头阻塞问题。不像 HTTP/1.1 中只有上一个请求的所有数据包被传输完毕下一个请求的数据包才可以被传输，HTTP/2 中每个请求都被拆分成多个 Frame 通过一条 TCP 连接同时被传输，这样即使一个请求被阻塞，也不会影响其他的请求。如下图所示，不同颜色代表不同的请求，相同颜色的色块代表请求被切分的 Frame。\n事情还没完，HTTP/2 虽然可以解决“请求”这个粒度的阻塞，但 HTTP/2 的基础 TCP 协议本身却也存在着队头阻塞的问题。HTTP/2 的每个请求都会被拆分成多个 Frame，不同请求的 Frame 组合成 Stream，Stream 是 TCP 上的逻辑传输单元，这样 HTTP/2 就达到了一条连接同时发送多条请求的目标，这就是多路复用的原理。我们看一个例子，在一条 TCP 连接上同时发送 4 个 Stream，其中 Stream1 已正确送达，Stream2 中的第 3 个 Frame 丢失，TCP 处理数据时有严格的前后顺序，先发送的 Frame 要先被处理，这样就会要求发送方重新发送第 3 个 Frame，Stream3 和 Stream4 虽然已到达但却不能被处理，那么这时整条连接都被阻塞。\n不仅如此，由于 HTTP/2 必须使用 HTTPS，而 HTTPS 使用的 TLS 协议也存在队头阻塞问题。TLS 基于 Record 组织数据，将一堆数据放在一起（即一个 Record）加密，加密完后又拆分成多个 TCP 包传输。一般每个 Record 16K，包含 12 个 TCP 包，这样如果 12 个 TCP 包中有任何一个包丢失，那么整个 Record 都无法解密。\n那 QUIC 是如何解决队头阻塞问题的呢？主要有两点。\n QUIC 的传输单元是 Packet，加密单元也是 Packet，整个加密、传输、解密都基于 Packet，这样就能避免 TLS 的队头阻塞问题； QUIC 基于 UDP，UDP 的数据包在接收端没有处理顺序，即使中间丢失一个包，也不会阻塞整条连接，其他的资源会被正常处理。  QUIC的拥塞控制 拥塞控制的目的是避免过多的数据一下子涌入网络，导致网络超出最大负荷。QUIC 的拥塞控制与 TCP 类似，并在此基础上做了改进。\nQUIC 重新实现了 TCP 协议的 Cubic 算法进行拥塞控制，并在此基础上做了不少改进。\n热拔插\nTCP 中如果要修改拥塞控制策略，需要在系统层面进行操作。QUIC 修改拥塞控制策略只需要在应用层操作，并且 QUIC 会根据不同的网络环境、用户来动态选择拥塞控制算法。\nQUIC前向纠错FEC QUIC 使用前向纠错(FEC，Forward Error Correction)技术增加协议的容错性。一段数据被切分为 10 个包后，依次对每个包进行异或运算，运算结果会作为 FEC 包与数据包一起被传输，如果不幸在传输过程中有一个数据包丢失，那么就可以根据剩余 9 个包以及 FEC 包推算出丢失的那个包的数据，这样就大大增加了协议的容错性。\n这是符合现阶段网络技术的一种方案，现阶段带宽已经不是网络传输的瓶颈，往返时间才是，所以新的网络传输协议可以适当增加数据冗余，减少重传操作。\nQUIC重传序列号单调递增 TCP 为了保证可靠性，使用 Sequence Number 和 ACK 来确认消息是否有序到达，但这样的设计存在缺陷。\n超时发生后客户端发起重传，后来接收到了 ACK 确认消息，但因为原始请求和重传请求接收到的 ACK 消息一样，所以客户端就郁闷了，不知道这个 ACK 对应的是原始请求还是重传请求。如果客户端认为是原始请求的 ACK，但实际上是左图的情形，则计算的采样 RTT 偏大；如果客户端认为是重传请求的 ACK，但实际上是右图的情形，又会导致采样 RTT 偏小。图中有几个术语，RTO 是指超时重传时间（Retransmission TimeOut），跟我们熟悉的 RTT（Round Trip Time，往返时间）很长得很像。采样 RTT 会影响 RTO 计算，超时时间的准确把握很重要，长了短了都不合适。\nQUIC 解决了上面的歧义问题。与 Sequence Number 不同的是，Packet Number 严格单调递增，如果 Packet N 丢失了，那么重传时 Packet 的标识不会是 N，而是比 N 大的数字，比如 N + M，这样发送方接收到确认消息时就能方便地知道 ACK 对应的是原始请求还是重传请求。\nACK Delay TCP 计算 RTT 时没有考虑接收方接收到数据到发送确认消息之间的延迟，如下图所示，这段延迟即 ACK Delay。QUIC 考虑了这段延迟，使得 RTT 的计算更加准确。\n更多的 ACK 块 一般来说，接收方收到发送方的消息后都应该发送一个 ACK 回复，表示收到了数据。但每收到一个数据就返回一个 ACK 回复太麻烦，所以一般不会立即回复，而是接收到多个数据后再回复，TCP SACK 最多提供 3 个 ACK block。但有些场景下，比如下载，只需要服务器返回数据就好，但按照 TCP 的设计，每收到 3 个数据包就要“礼貌性”地返回一个 ACK。而 QUIC 最多可以捎带 256 个 ACK block。在丢包率比较严重的网络下，更多的 ACK block 可以减少重传量，提升网络效率。\nQUIC流量控制 似乎一样。\n参考：\n The Road to QUIC 科普：QUIC协议原理分析 Quic协议介绍和浅析  参考与更多➕  计算机网络面试总结      Interview OS 高频知识——操作系统面试问题整理\n小白如何学习操作系统？\n进程、线程、协程区别💠 进程与线程的来由☄ 进程的作用与定义：是为了提高CPU的执行效率，为了避免因等待而造成CPU空转以及其他计算机硬件资源的浪费而提出来的。\n线程的引入：例如，有一个Web服务器要进程的方式并发地处理来自不同用户的网页访问请求的话，可以创建父进程和多个子进程的方式来进行处理，但是创建一个进程要花费较大的系统开销和占用较多的资源。除外，这些不同的用户子进程在执行的时候涉及到进程上下文切换，上下文切换是一个复杂的过程。所以，为了减少进程切换和创建的开销，提高执行效率和节省资源，人们在操作系统中引入了\u0026quot;线程（thread）\u0026ldquo;的概念。\n(进程的消耗太大，所以引入线程)\n进程与线程的数据🗡 进程是系统资源分配的最小单位, 系统由一个个进程(程序)组成 一般情况下，包括文本区域（text region）、数据区域（data region）和堆栈（stack region）。\n 文本区域存储处理器执行的代码 数据区域存储变量和进程执行期间使用的动态分配的内存； 堆栈区域存储着活动过程调用的指令和本地变量。   与进程的控制表PCB相似，线程也有自己的控制表TCB，但是TCB中所保存的线程状态比PCB表少得多。\n 线程属于进程，并且共享进程的内存地址空间\n线程几乎不占有系统资源通信问题: 进程相当于一个容器,而线程而是运行在容器里面的,因此对于容器内的东西,线程是共同享有的,因此线程间的通信可以直接通过全局变量进行通信,但是由此带来的例如多个线程读写同一个地址变量的时候则将带来不可预期的后果,因此这时候引入了各种锁的作用,例如互斥锁等。\n 同时多线程是不安全的,当一个线程崩溃了,会导致整个进程也崩溃了,即其他线程也挂了, 但多进程而不会,一个进程挂了,另一个进程依然照样运行。\n 上下文切换📊 进程切换分3步:\n 切换页目录以使用新的地址空间 切换内核栈 切换硬件上下文  而线程切换只需要第2、3步,因此进程的切换代价比较大\n**协程，英文Coroutines，是一种比线程更加轻量级的存在。**正如一个进程可以拥有多个线程一样，一个线程也可以拥有多个协程。\n协程是属于线程的。协程程序是在线程里面跑的，因此协程又称微线程和纤程等\n协没有线程的上下文切换消耗。协程的调度切换是用户(程序员)手动切换的,因此更加灵活,因此又叫用户空间线程.\n原子操作性。由于协程是用户调度的，所以不会出现执行一半的代码片段被强制中断了，因此无需原子操作锁。\n 协程不是被操作系统内核所管理，而完全是由程序所控制（也就是在用户态执行）。协程的暂停完全由程序控制，线程的阻塞状态是由操作系统内核来进行切换。\n好处：\n​\t性能得到了很大的提升，不会像线程切换那样消耗资源。\n 如果说操作系统引入进程的目的是为了提高程序并发执行，以提高资源利用率和系统吞吐量。那么操作系统中引入线程的目的，则是为了减少进程并发执行过程中所付出的时空开销，使操作系统能很好的并发执行。\n　进程process定义了一个执行环境，包括它自己私有的地址空间、一个句柄表，以及一个安全环境；线程则是一个控制流，有他自己的调用栈call stack，记录了它的执行历史。\n　线程由两个部分组成：1）线程的内核对象，操作系统用它来对线程实施管理。内核对象也是系统用来存放线程统计信息的地方。2）线程堆栈，它用于维护线程在执行代码时需要的所有参数和局部变量。当创建线程时，系统创建一个线程内核对象。该线程内核对象不是线程本身，而是操作系统用来管理线程的较小的数据结构。可以将线程内核对象视为由关于线程的统计信息组成的一个小型数据结构。\n参考链接：\n 线程，进程，协程详细解释 进程、线程和协程的概念  进程的几种状态   就绪(Ready)状态\n当进程已分配到除CPU以外的所有必要资源后，只要再获得CPU，便可立即执行，进程这时的状态称为就绪状态。在一个系统中处于就绪状态的进程可能有多个，通常将它们排成一个队列，称为就绪队列。\n  执行状态\n进程已获得CPU，其程序正在执行。在单处理机系统中，只有一个进程处于执行状态； 在多处理机系统中，则有多个进程处于执行状态。\n  阻塞状态\n正在执行的进程由于发生某事件而暂时无法继续执行时，便放弃处理机而处于暂停状态，亦即进程的执行受到阻塞，把这种暂停状态称为阻塞状态，有时也称为等待状态或封锁状态。致使进程阻塞的典型事件有：请求I/O，申请缓冲空间等。通常将这种处于阻塞状态的进程也排成一个队列。有的系统则根据阻塞原因的不同而把处于阻塞状态的进程排成多个队列。\n  死锁，活锁和饥饿🔐 死锁🔐：是指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。\n死锁的条件:\n 互斥 请求和保持 不剥夺原则 环路等待  如何避免死锁？🏃\n预防\n 打破互斥条件：改造独占性资源为虚拟资源，大部分资源已无法改造。 打破不可抢占条件：当一进程占有一独占性资源后又申请一独占性资源而无法满足，则退出原占有的资源。 打破占有且申请条件：采用资源预先分配策略，即进程运行前申请全部资源，满足则运行，不然就等待，这样就不会占有且申请。 打破循环等待条件：实现资源有序分配策略，对所有设备实现分类编号，所有进程只能采用按序号递增的形式申请资源。 有序资源分配法 银行家算法  活锁🚛：**是指线程1可以使用资源，但它很礼貌，让其他线程先使用资源，线程2也可以使用资源，但它很绅士，也让其他线程先使用资源。**这样你让我，我让你，最后两个线程都无法使用资源。\n饥饿🇭🇺 :是指如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求\u0026hellip;\u0026hellip;，T2可能永远等待。\n如何检测死锁 一般来说，由于操作系统有并发，共享以及随机性等特点，通过预防和避免的手段达到排除死锁的目的是很困难的。这需要较大的系统开销，而且不能充分利用资源。为此，一种简便的方法是系统为进程分配资源时，不采取任何限制性措施，但是提供了检测和解脱死锁的手段：能发现死锁并从死锁状态中恢复出来。因此，在实际的操作系统中往往采用死锁的检测与恢复方法来排除死锁。常利用资源分配图、进程等待图来协助这种检测。\n核心是：不试图阻止死锁，而是当检测到死锁发生时，采取措施进行恢复。\n可以对进程 - 资源分配图进行检测(按周期进行检测)：\n 如果进程 - 资源分配图中无环路，此时系统没有发生死锁。 如果进程 - 资源分配图中有环路，则可分为以下两种情况：  每种资源类中仅有一个资源，则系统发生了死锁。此时，环路是系统发生死锁的充分必要条件，环路中的进程就是死锁进程 每种资源类中有多个资源，则环路的存在只是产生死锁的必要不充分条件，系统未必会发生死锁。    死锁恢复   资源剥夺法\n剥夺陷于死锁的进程所占用的资源，但并不撤销此进程，直至死锁解除。\n  进程回退法\n根据系统保存的检查点让所有的进程回退，直到足以解除死锁，这种措施要求系统建立保存检查点、回退及重启机制。\n  进程撤销法\n   撤销陷入死锁的所有进程，解除死锁，继续运行。 逐个撤销陷入死锁的进程，回收其资源并重新分配，直至死锁解除。    可选择符合下面条件之一的先撤销： 1.CPU消耗时间最少者 2.产生的输出量最小者\n3.预计剩余执行时间最长者 4.分得的资源数量最少者后优先级最低者\n 系统重启法\n结束所有进程的执行并重新启动操作系统。这种方法很简单，但先前的工作全部作废，损失很大。  参考：\n 操作系统中的死锁检测方法 死锁的产生、防止、避免、检测和解除  什么是守护进程？ 守护进程就是在后台运行,不与任何终端关联的进程,通常情况下守护进程在系统启动时就在运行,它们以root用户或者其他特殊用户(apache和postfix)运行,并能处理一些系统级的任务.习惯上守护进程的名字通常以d结尾(sshd),但这些不是必须的.\n参考：\n 什么是守护进程  Linux运行内存分区🚩 虚拟内存是一个抽象概念 ，它为 每个进程提供了一个假象， 即每个进程都在独占地使用主存 。\n虚拟地址空间(和C程序空间一致)如下：\n在 Linux中 ，地址空间最上面的区域是保留给操作系统中的代码和数据的 ，这对所有进程来说都是一样 。地址空间的底部区域存放用户进程定义的代码和数据 。\n进程间通信🦅   管道(PIPE) / FIFO(有名管道)\n管道可用于具有亲缘关系进程间的通信，有名管道克服了管道没有名字的限制，因此，除具有管道所具有的功能外，它还允许无亲缘关系进程间的通信；无名管道使用fork实现。\n  消息队列\n消息队列是消息的链接表，包括Posix消息队列system V消息队列。有足够权限的进程可以向队列中添加消息，被赋予读权限的进程则可以读走队列中的消息。消息队列克服了信号承载信息量少，管道只能承载无格式字节流以及缓冲区大小受限等缺点。\n  信号量\n要作为进程间以及同一进程不同线程之间的同步手段。\n  共享内存\n使得多个进程可以访问同一块内存空间，是最快的可用IPC形式。是针对其他通信机制运行效率较低而设计的。往往与其它通信机制，如信号量结合使用，来达到进程间的同步及互斥。\n 优点：无须复制，快捷，信息量大 缺点：  通信是通过将共享空间缓冲区直接附加到进程的虚拟地址空间中来实现的，因此进程间的读写操作的同步问题 利用内存缓冲区直接交换信息，内存的实体存在于计算机中，只能同一个计算机系统中的诸多进程共享，不方便网络通信      域套接字(Domain Socket)\n更为一般的进程间通信机制，可用于不同机器之间的进程间通信。起初是由Unix系统的BSD分支开发出来的，但现在一般可以移植到其它类Unix系统上：Linux和System V的变种都支持套接字。\n  信号(Signal)\n信号是比较复杂的通信方式，用于通知接受进程有某种事件发生，除了用于进程间通信外，进程还可以发送信号给进程本身；Linux除了支持Unix早期信号语义函数sigal外，还支持语义符合Posix.1标准的信号函数sigaction（实际上，该函数是基于BSD的，BSD为了实现可靠信号机制，又能够统一对外接口，用sigaction函数重新实现了signal函数）；\n 一般来说，signal是对“中断\u0026quot;这种概念在软件层面上的模拟，也称”软中断“，其中信号的发送者相当于中断源，而接收者相当于处理器，所以必须是一个进程。\n   如果说“命名管道”把“管道”这种原来只适用近亲的手段推广到了同一台计算机中的任意进程之间，则Socket又进一步将其推广至计算机网络中的任意进程之间。从这个意义上讲，Socket成了最一般、最普遍适用的进程间通信手段和机制。事实上，现在有些Unix系统中的管道机制也反过来改成通过Socket来实现。\n为什么共享内存更快？ 拷贝4次(一般进程通信方式)\n1，由用户空间缓冲区中将数据拷贝到内核空间缓冲区中\n2，内核空间缓冲区将数据拷贝到内存中\n3，内存将数据拷贝到到内核缓冲区\n4，内核空间缓冲区到用户空间缓冲区.\n拷贝2次(共享内存通信)\n1，用户空间到内存。\n2，内存到用户空间。\n线程间通信👂  锁机制：包括互斥锁/量（mutex）、读写锁（reader-writer lock）、自旋锁（spin lock）、条件变量（condition）  互斥锁/量（mutex）：提供了以排他方式防止数据结构被并发修改的方法。 读写锁（reader-writer lock）：允许多个线程同时读共享数据，而对写操作是互斥的。 自旋锁（spin lock）与互斥锁类似，都是为了保护共享资源。互斥锁是当资源被占用，申请者进入睡眠状态；而自旋锁则循环检测保持者是否已经释放锁。 条件变量（condition）：可以以原子的方式阻塞进程，直到某个特定条件为真为止。对条件的测试是在互斥锁的保护下进行的。条件变量始终与互斥锁一起使用。   信号量机制(Semaphore)  无名线程信号量 命名线程信号量   信号机制(Signal)：类似进程间的信号处理 屏障（barrier）：屏障允许每个线程等待，直到所有的合作线程都达到某一点，然后从该点继续执行。  线程间的通信目的主要是用于线程同步，所以线程没有像进程通信中的用于数据交换的通信机制\n什么是孤儿进程、僵尸进程？ 在unix/linux中，正常情况下，子进程是通过父进程创建的，子进程在创建新的进程。子进程的结束和父进程的运行是一个异步过程,即父进程永远无法预测子进程 到底什么时候结束。 当一个 进程完成它的工作终止之后，它的父进程需要调用wait()或者waitpid()系统调用取得子进程的终止状态。\n孤儿进程:\n一个父进程退出，而它的一个或多个子进程还在运行，那么那些子进程将成为孤儿进程。孤儿进程将被init进程(进程号为1)所收养，并由init进程对它们完成状态收集工作。\n僵尸进程：\n一个进程使用fork创建子进程，如果子进程退出，而父进程并没有调用wait或waitpid获取子进程的状态信息，那么子进程的进程描述符仍然保存在系统中。这种进程称之为僵死进程。\n处理僵尸进程：\n  干掉父进程﻿\n干掉父进程后，让剩下的子进程成为孤儿进程，成为孤儿进程后就和我们上面说的一样了，由init进程来领养这些进程，并且来处理这些进程的资源释放等工作。\n  父进程调用wait或waitpid\n等函数等待子进程结束，这会导致父进程挂起。\n执行wait（）或 waitpid（）系统调用，则子进程在终止后会立即把它在进程表中的数据返回给父进程，此时系统会立即删除该进入点。在这种情形下就不会产生defunct进程。\n  fork两次\n第一次 fork : 父进程fork一个子进程\n第二次 fork : 子进程fork一个孙进程后退出\n那么孙进程被init接管，当孙进程结束后，init会回收。\n但子进程的回收还要自己做。\n  signal函数\n父进程来处理：用signal函数为SIGCHLD安装handler，在子进程结束后，父进程会收到该信号，可以在handler中调用wait回收。\n内核来处理:\n如果父进程不关心子进程什么时候结束，可以通过以下两个函数通知内核自己不感兴趣子进程的结束，此时，子进程结束后，内核会回收并不再给你父进程发信号。\n signal（SIGCLD, SIG_IGN） signal（SIGCHLD, SIG_IGN）    ﻿\n参考：孤儿进程与僵尸进程总结\n内核态和用户态🏒 为了安全，用户进程是受限的，它不能随意访问资源、获取资源。所以，由内核进程负责管理和分配资源，它具有最高权限，而用户进程使用被分配的资源。用户态的程序不能 随意操作内核地址空间，具有一定的安全保护作用。\n而且，操作系统必须能够在有需要的时候能立即切换回内核进程(通过中断)，只有这样，操作系统才能有安全感。\n用户态切换到内核态的3种方式   系统调用\n这是用户态进程主动要求切换到内核态的一种方式，用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作，比如fork()实际上就是执行了一个创建新进程的系统调用。而系统调用的机制其核心还是使用了操作系统为用户特别开放的一个中断来实现，例如Linux的int 80h中断。\n  中断\n当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令转而去执行与中断信号对应的处理程序，如果先前执行的指令是用户态下的程序，那么这个转换的过程自然也就发生了由用户态到内核态的切换。比如硬盘读写操作完成，系统会切换到硬盘读写的中断处理程序中执行后续操作等。\n  异常\n当CPU在执行运行在用户态下的程序时，发生了某些事先不可知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关程序中，也就转到了内核态，比如缺页异常。\n  free()函数如何知道要释放的空间大小❓ malloc有多种实现，有使用链表的，也有是由在申请内存头部记录信息的，还有使用伙伴的算法。没有一个统一的malloc算法。\n参考：https://www.zhihu.com/question/302440083\n中断和轮询的特点🥚 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。\n　程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。\n　轮询——效率低，等待时间很长，CPU利用率不高。\n　中断——容易遗漏一些问题，CPU利用率高。\n 中断是指在计算机执行期间，系统内发生任何非寻常的或非预期的急需处理事件，使得CPU暂时中断当前正在执行的程序而转去执行相应的事件处理程序。待处理完毕后又返回原来被中断处继续执行或调度新的进程执行的过程。\n 中断向量表\n外部设备的中断常常对应向量表中的某一项，这是通用框架的外部中断处理函数入口，因此在进入通用的中断处理函数之后，系统必须知道正在处理的中断是哪一个设备产生的，而这正是由软件中断号irq定的决。中断向量表的内容是由操作系统在初始化阶段来填写，对于外部中断，操作系统负责实现一个通用的外部中断处理函数，然后把这个函数的入口地址放到中断向量表中的对应位置。用户注册设备驱动ISR，实际上就是挂接到中断向量表中，覆盖某一项的默认处理实现特化。\n分段与分页👓 段式存储管理是一种符合用户视角的内存分配管理方案。在段式存储管理中，将程序的地址空间划分为若干段（segment），如代码段，数据段，堆栈段；这样每个进程有一个二维地址空间，相互独立，互不干扰。段式管理的优点是：没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）\n页式存储管理方案是一种用户视角内存与物理内存相分离的内存分配管理方案。在页式存储管理中，将程序的逻辑地址划分为固定大小的页（page），而物理内存划分为同样大小的帧，程序加载时，可以将任意一页放入内存中任意一个帧，这些帧不必连续，从而实现了离散分离。页式存储管理的优点是：没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）。\n两者的不同点：\n目的不同：分页是由于系统管理的需要而不是用户的需要，它是信息的物理单位；分段的目的是为了能更好地满足用户的需要，它是信息的逻辑单位，它含有一组其意义相对完整的信息；\n大小不同：页的大小固定且由系统决定，而段的长度却不固定，由其所完成的功能决定；\n地址空间不同： 段向用户提供二维地址空间；页向用户提供的是一维地址空间；\n信息共享：段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制；\n内存碎片：页式存储管理的优点是没有外碎片（因为页的大小固定），但会产生内碎片（一个页可能填充不满）；而段式管理的优点是没有内碎片（因为段大小可变，改变段大小来消除内碎片）。但段换入换出时，会产生外碎片（比如4k的段换5k的段，会产生1k的外碎片）。\n 段是信息的逻辑单位，它是根据用户的需要划分的，因此段对用户是可见的 ；页是信息的物理单位，是为了管理主存的方便而划分的，对用户是透明的。 段的大小不固定，有它所完成的功能决定；页大大小固定，由系统决定 段向用户提供二维地址空间；页向用户提供的是一维地址空间 段是信息的逻辑单位，便于存储保护和信息的共享，页的保护和共享受到限制。  页是信息的物理单位，分页是为实现离散分配方式，以消减内存的外零头，提高内存的利用率；或者说，分页仅仅是由于系统管理的需要，而不是用户的需要。\n段是信息的逻辑单位，它含有一组其意义相对完整的信息。分段的目的是为了能更好的满足用户的需要。\n页的大小固定且由系统确定，把逻辑地址划分为页号和页内地址两部分，是由机器硬件实现的，因而一个系统只能有一种大小的页面。段的长度却不固定，决定于用户所编写的程序，通常由编辑程序在对源程序进行编辑时，根据信息的性质来划分。\n分页的作业地址空间是一维的，即单一的线性空间，程序员只须利用一个记忆符，即可表示一地址。分段的作业地址空间是二维的，程序员在标识一个地址时，既需给出段名，又需给出段内地址。\n内存分段 程序是由若干个逻辑分段组成的，如可由代码分段、数据分段、栈段、堆段组成。不同的段是有不同的属性的，所以就用分段（Segmentation）的形式把这些段分离出来。\n 分段机制下，虚拟地址和物理地址是如何映射的？\n 分段机制下的虚拟地址由两部分组成，段选择子和段内偏移量。\n 段选择子就保存在段寄存器里面。段选择子里面最重要的是段号，用作段表的索引。段表里面保存的是这个段的基地址、段的界限和特权等级等。 虚拟地址中的段内偏移量应该位于 0 和段界限之间，如果段内偏移量是合法的，就将段基地址加上段内偏移量得到物理内存地址。  由上面可以知道虚拟地址是通过段表与物理地址进行映射的，分段机制会把程序的虚拟地址分成 4 个段，每个段在段表中有一个项，在这一项找到段的基地址，再加上偏移量，于是就能找到物理内存中的地址，如下图：\n分段的办法很好，解决了程序本身不需要关心具体的物理内存地址的问题，但它也有一些不足之处：\n 第一个就是内存碎片的问题。 第二个就是内存交换的效率低的问题。  为什么会产生内存碎片？\n假设我们执行了下面几个程序：\n 游戏占用了 512MB 内存 浏览器占用了 128MB 内存 音乐占用了 256 MB 内存。  假设有 1G 的物理内存，则空闲内存还有 1024 - 512 - 256 = 256MB。如果这个 256MB 不是连续的，被分成了两段 128 MB 内存，这就会导致没有空间再打开一个 200MB 的程序。\n这里的内存碎片的问题共有两处地方：\n 外部内存碎片，也就是产生了多个不连续的小物理内存，导致新的程序无法被装载； 内部内存碎片，程序所有的内存都被装载到了物理内存，但是这个程序有部分的内存可能并不是很常使用，这也会导致内存的浪费；  解决外部内存碎片的问题就是内存交换。\n可以把音乐程序占用的那 256MB 内存写到硬盘上，然后再从硬盘上读回来到内存里。不过再读回的时候，我们不能装载回原来的位置，而是紧紧跟着那已经被占用了的 512MB 内存后面。这样就能空缺出连续的 256MB 空间，于是新的 200MB 程序就可以装载进来。\n这个内存交换空间，在 Linux 系统里，也就是我们常看到的 Swap 空间，这块空间是从硬盘划分出来的，用于内存与硬盘的空间交换。\n分段为什么导致效率低？\n对于多进程的系统来说，用分段的方式，内存碎片是很容易产生的，产生了内存碎片，那不得不重新 Swap 内存区域，这个过程会产生性能瓶颈。\n因为硬盘的访问速度要比内存慢太多了，每一次内存交换，我们都需要把一大段连续的内存数据写到硬盘上。\n所以，如果内存交换的时候，交换的是一个占内存空间很大的程序，这样整个机器都会显得卡顿。\n内存分页 内存分页就是为了解决分段的内存碎片以及效率低而提出来的。\n分页是把整个虚拟和物理内存空间切成一段段固定尺寸的大小。这样一个连续并且尺寸固定的内存空间，我们叫页（Page）。在 Linux 下，每一页的大小为 4KB。\n虚拟地址与物理地址之间通过页表来映射：\n由于内存空间都是预先划分好的，也就不会像分段会产生间隙非常小的内存，这正是分段会产生内存碎片的原因。而采用了分页，那么释放的内存都是以页为单位释放的，也就不会产生无法给进程使用的小内存。\n如果内存空间不够，操作系统会把其他正在运行的进程中的「最近没被使用」的内存页面给释放掉，也就是暂时写在硬盘上，称为换出（Swap Out）。一旦需要的时候，再加载进来，称为换入（Swap In）。所以，一次性写入磁盘的也只有少数的一个页或者几个页，不会花太多时间，内存交换的效率就相对比较高。\n在分页机制下，虚拟地址分为两部分，页号和页内偏移。页号作为页表的索引，页表包含物理页每页所在物理内存的基地址，这个基地址与页内偏移的组合就形成了物理内存地址，见下图。\n段页式管理 内存分段和内存分页并不是对立的，它们是可以组合起来在同一个系统中使用的，那么组合起来后，通常称为段页式内存管理。\n段页式内存管理实现的方式：\n 先将程序划分为多个有逻辑意义的段，也就是前面提到的分段机制； 接着再把每个段划分为多个页，也就是对分段划分出来的连续空间，再划分固定大小的页；  这样，地址结构就由段号、段内页号和页内位移三部分组成。\n用于段页式地址变换的数据结构是每一个程序一张段表，每个段又建立一张页表，段表中的地址是页表的起始地址，而页表中的地址则为某页的物理页号，如图所示：\n段页式地址变换中要得到物理地址须经过三次内存访问：\n 第一次访问段表，得到页表起始地址； 第二次访问页表，得到物理页号； 第三次将物理页号与页内位移组合，得到物理地址。  可用软、硬件相结合的方法实现段页式地址变换，这样虽然增加了硬件成本和系统开销，但提高了内存的利用率。\n参考：\n 20 张图揭开「内存管理」的迷雾  进程调度算法🔌 FCFS(先来先服务)，优先级，时间片轮转，多级反馈\n  FCFS(先来先服务，队列实现，非抢占的)\n先请求CPU的进程先分配到CPU\n  SJF(最短作业优先调度算法)\n平均等待时间最短，但难以知道下一个CPU区间长度\n  **优先级调度算法(**可以是抢占的，也可以是非抢占的)：\n优先级越高越先分配到CPU，相同优先级先到先服务，存在的主要问题是：低优先级进程无穷等待CPU，会导致无穷阻塞或饥饿；解决方案：老化\n  高响应比优先调度算法\n根据“响应比=（进程执行时间+进程等待时间）/ 进程执行时间”这个公式得到的响应比来进行调度。高响应比优先算法在等待时间相同的情况下，作业执行的时间越短，响应比越高，满足段任务优先，同时响应比会随着等待时间增加而变大，优先级会提高，能够避免饥饿现象。优点是兼顾长短作业，缺点是计算响应比开销大，适用于批处理系统。\n  时间片轮转调度算法(可抢占的)\n队列中**没有进程被分配超过一个时间片的CPU时间，除非它是唯一可运行的进程。**如果进程的CPU区间超过了一个时间片，那么该进程就被抢占并放回就绪队列。\n  多级队列调度算法\n将就绪队列分成多个独立的队列，每个队列都有自己的调度算法，队列之间采用固定优先级抢占调度。其中，一个进程根据自身属性被永久地分配到一个队列中。\n  多级反馈队列调度算法\n与多级队列调度算法相比，其允许进程在队列之间移动：若进程使用过多CPU时间，那么它会被转移到更低的优先级队列；在较低优先级队列等待时间过长的进程会被转移到更高优先级队列，以防止饥饿发生。\n  参考：\n 五种进程调度算法的总结 大厂面试爱问的「调度算法」，20 张图一举拿下  页面置换算法💱 什么是页面置换算法？ 进程运行时，若其访问的页面不在内存而需将其调入，但内存已无空闲空间时，就需要从内存中调出一页程序或数据，送入磁盘的对换区，其中选择调出页面的算法就称为页面置换算法。\n常见的页面置换算法   FIFO先进先出算法\n（优先淘汰最早进入内存的页面）\n在操作系统中经常被用到，比如作业调度（主要实现简单，很容易想到）；\n  OPT（Optimal replacement）最优置换算法\n（淘汰以后不会使用的页面）\n理论的最优，理论；就是要保证置换出去的是不再被使用的页，或者是在实际内存中最晚使用的算法。\n FIFO 和 OPT 算法的区别在于：除了在时间上向后或向前看之外，FIFO 算法使用的是页面调入内存的时间，OPT 算法使用的是页面将来使用的时间\n   LRU（Least recently use）最近最少使用算法\n（淘汰最近没有使用的页面）\n选择最近最长时间未访问过的页面予以淘汰，它认为过去一段时间内未访问过的页面，在最近的将来可能也不会被访问。该算法为每个页面设置一个访问字段，来记录页面自上次被访问以来所经历的时间，淘汰页面时选择现有页面中值最大的予以淘汰。\n OPT 和 LRU 算法的区别在于：LRU 算法根据各页以前的情况，是“向前看”的，而最佳置换算法则根据各页以后的使用情况，是“向后看”的\nLRU 性能较好，但需要寄存器和栈的硬件支持\n LRU 是堆栈类的算法，理论上可以证明，堆栈类算法不可能出现 Belady 异常\n  LFU（Least frequently use**）最少使用次数算法**\n（根据使用次数来判断）\n最不经常使用（LFU）页面置换算法要求置换具有最小计数的页面。\n这种选择的原因是，积极使用的页面应当具有大的引用计数。然而，当一个页面在进程的初始阶段大量使用但是随后不再使用时，会出现问题。由于被大量使用，它有一个大的计数，即使不再需要却仍保留在内存中。一种解决方案是，定期地将计数右移 1 位，以形成指数衰减的平均使用计数。\n  Clock（时钟置换算法）\n简单的 CLOCK 算法是给每一帧关联一个附加位，称为使用位。\n当某一页首次装入主存时，该帧的使用位设置为1;\n当该页随后再被访问到时，它的使用位也被置为1。\n对于页替换算法，用于替换的候选帧集合看做一个循环缓冲区，并且有一个指针与之相关联。\n当某一页被替换时，该指针被设置成指向缓冲区中的下一帧。\n当需要替换一页时，操作系统扫描缓冲区，以查找使用位被置为0的一帧。\n每当遇到一个使用位为1的帧时，操作系统就将该位重新置为0；\n如果在这个过程开始时，缓冲区中所有帧的使用位均为0，则选择遇到的第一个帧替换；\n如果所有帧的使用位均为1,则指针在缓冲区中完整地循环一周，把所有使用位都置为0，并且停留在最初的位置上，替换该帧中的页。\n由于该算法循环地检查各页面的情况，故称为 CLOCK 算法，又称为最近未用( Not Recently Used, NRU )算法。\n  参考：\n 页面置换算法详解 大厂面试爱问的「调度算法」，20 张图一举拿下  磁盘调度算法💾 磁盘的结构：\n磁盘调度算法的目的很简单，就是为了提高磁盘的访问性能，一般是通过优化磁盘的访问请求顺序来做到的。\n寻道的时间是磁盘访问最耗时的部分，如果请求顺序优化的得当，必然可以节省一些不必要的寻道时间，从而提高磁盘的访问性能。\n常见的磁盘调度算法：\n  先来先服务算法\n  最短寻道时间优先算法\n  扫描算法算法\n  循环扫描算法\n只有磁头朝某个特定方向移动时，才处理磁道访问请求，而返回时直接快速移动至最靠边缘的磁道，也就是复位磁头，这个过程是很快的，并且返回中途不处理任何请求，该算法的特点，就是磁道只响应一个方向上的请求。\n  LOOK 与 C-LOOK 算法\n我们前面说到的扫描算法和循环扫描算法，都是磁头移动到磁盘「最始端或最末端」才开始调换方向。\n那这其实是可以优化的，优化的思路就是磁头在移动到「最远的请求」位置，然后立即反向移动。\n那针对 SCAN 算法的优化则叫 LOOK 算法，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中会响应请求\n而针 C-SCAN 算法的优化则叫 C-LOOK，它的工作方式，磁头在每个方向上仅仅移动到最远的请求位置，然后立即反向移动，而不需要移动到磁盘的最始端或最末端，反向移动的途中不会响应请求。\n  参考：\n 大厂面试爱问的「调度算法」，20 张图一举拿下  内存分配算法 首次适应算法（First Fit） 从空闲分区表的第一个表目起查找该表，把最先能够满足要求的空闲区分配给作业，这种方法的目的在于减少查找时间。为适应这种算法，空闲分区表（空闲区链）中的空闲分区要按地址由低到高进行排序。该算法优先使用低址部分空闲区，在低址空间造成许多小的空闲区，在高地址空间保留大的空闲区。\n最佳适应算法（Best Fit) 从全部空闲区中找出能满足作业要求的、且大小最小的空闲分区，这种方法能使碎片尽量小。为适应此算法，空闲分区表（空闲区链）中的空闲分区要按从小到大进行排序，自表头开始查找到第一个满足要求的自由分区分配。该算法保留大的空闲区，但造成许多小的空闲区。\n最差适应算法（Worst Fit) 从全部空闲区中找出能满足作业要求的、且大小最大的空闲分区，从而使链表中的结点大小趋于均匀，适用于请求分配的内存大小范围较窄的系统。为适应此算法，空闲分区表（空闲区链）中的空闲分区按大小从大到小进行排序，自表头开始查找到第一个满足要求的自由分区分配。该算法保留小的空闲区，尽量减少小的碎片产生。\n伙伴算法（buddy） 使用二进制优化的思想，将内存以2的幂为单位进行分配，合并时只能合并是伙伴的内存块，两个内存块是伙伴的三个条件是：\n1.大小相等（很好判断）\n2.地址连续（也很好判断）\n3.两个内存块分裂自同一个父块（其实只要判断低地址的内存块首地址是否是与父块地址对齐，即合并后的首地址为父块大小的整数倍）使用lowbit等位运算可以o(1)判断。\n伙伴算法在实现的时候可以使用数组+链表的形式（有点像邻接表那种），因为内存上限是固定的，比较容易确定。下列代码使用的是二维链表（写起来就没有数组加链表简洁）。在分配调整内存块时使用了递归，如果需要提高效率可以改为循环（递归更能体现出思想且代码简单，循环效率更高但是复杂一丢丢，自行选取）。\nSlab分配算法 CMA算法 应用程序中申请一块内存，在应用程序看来是连续的，因为虚拟地址本身是连续的，但实际的内存空间中，所申请的这片内存未必是连续的，不过这对应用程序来说是没关系的，因为应用程序不需要关心实际的内存情况，只要MMU把物理地址映射成虚拟地址就好了。但是如果没有MMU的情况呢，我们又需要一片连续的内存空间，比如设备通过DMA直接访问内存，这种情况下应该怎么办呢？\nCMA机制就是为了解决上面提到的问题而产生的。DMA zone并不是DMA专属，其它的程序也可以申请该zone的内存，如果当设备要申请DMA zone空间的一大片连续的内存时候，已经没有连续的大片内存了，只有1页，2页，4页的这种连续的小内存。解决办法就是我们标记某一片连续区域为CMA区域，这部分区域在没有大片连续内存申请的时候只给moveable的程序使用，当大片连续内存请求来的时候，我们去这片区域，把所有moveable的小片内存移动到其它的非CMA区域，更改对应的程序的页表，然后再把空出来的CMA区域给设备，从而实现了DMA大片连续内存的分配。\nCMA机制并不是单独存在的，它通常服务于DMA设备，在设备调用dma_alloc_coherent函数申请一块内存后，为了得到一片连续的内存，CMA机制被调用，它保证了申请的内存的连续性。\n另外CMA区域通常被分配在高端内存。\n参考：\n 内存分配算法——FF、BF、WF、buddy（伙伴算法） Linux学习-内存管理篇（四）-内存分配算法  伙伴算法和slab算法 伙伴算法(Buddy分配算法) 作用\n它要解决的问题是频繁地请求和释放不同大小的一组连续页框，必然导致在已分配页框的块内分散了许多小块的空闲页面，由此带来的问题是，即使有足够的空闲页框可以满足请求，但要分配一个大块的连续页框可能无法满足请求。(解决碎片问题)\n流程\n伙伴算法（Buddy system）把所有的空闲页框分为11个块链表，每块链表中分布包含特定的连续页框地址空间，比如第0个块链表包含大小为2^0个连续的页框，第1个块链表中，每个链表元素包含2个页框大小的连续地址空间，….，第10个块链表中，每个链表元素代表4M的连续地址空间。每个链表中元素的个数在系统初始化时决定，在执行过程中，动态变化。\n伙伴算法每次只能分配2的幂次页的空间，比如一次分配1页，2页，4页，8页，…，1024页(2^10)等等，每页大小一般为4K，因此，伙伴算法最多一次能够分配4M的内存空间。\n申请和回收过程\n比如，我要分配4(2^2)页（16k）的内存空间，算法会先从free_area[2]中查看nr_free是否为空，如果有空闲块，则从中分配，如果没有空闲块，就从它的上一级free_area[3]（每块32K）中分配出16K，并将多余的内存（16K）加入到free_area[2]中去。如果free_area[3]也没有空闲，则从更上一级申请空间，依次递推，直到free_area[max_order]，如果顶级都没有空间，那么就报告分配失败。\n释放是申请的逆过程，当释放一个内存块时，先在其对于的free_area链表中查找是否有伙伴存在，如果没有伙伴块，直接将释放的块插入链表头。如果有或板块的存在，则将其从链表摘下，合并成一个大块，然后继续查找合并后的块在更大一级链表中是否有伙伴的存在，直至不能合并或者已经合并至最大块2^10为止。\n内核试图将大小为b的一对空闲块（一个是现有空闲链表上的，一个是待回收的），合并为一个大小为2B的单独块，如果它成功合并所释放的块，它会试图合并2b大小的块，\n伙伴算法的优缺点\n优点：\n 较好的解决外部碎片问题 当需要分配若干个内存页面时，用于DMA的内存页面必须连续，伙伴算法很好的满足了这个要求 只要请求的块不超过512个页面(2K)，内核就尽量分配连续的页面。 针对大内存分配设计。  缺点：\n 合并的要求太过严格，只能是满足伙伴关系的块才能合并，比如第1块和第2块就不能合并。 碎片问题：一个连续的内存中仅仅一个页面被占用，导致整块内存区都不具备合并的条件(内部碎片问题) 浪费问题：伙伴算法只能分配2的幂次方内存区，当需要8K（2页）时，好说，当需要9K时，那就需要分配16K（4页）的内存空间，但是实际只用到9K空间，多余的7K空间就被浪费掉。 算法的效率问题： 伙伴算法涉及了比较多的计算还有链表和位图的操作，开销还是比较大的，如果每次2^n大小的伙伴块就会合并到2^(n+1)的链表队列中，那么2^n大小链表中的块就会因为合并操作而减少，但系统随后立即有可能又有对该大小块的需求，为此必须再从2^(n+1)大小的链表中拆分，这样的合并又立即拆分的过程是无效率的。  Linux针对大内存的物理地址分配，采用伙伴算法，如果是针对小于一个page的内存，频繁的分配和释放，有更加适宜的解决方案，如slab和kmem_cache等。\nSlab分配算法 在Linux中，伙伴系统（buddy system）是以页为单位管理和分配内存。但是现实的需求却以字节为单位，假如我们需要申请20Bytes，总不能分配一页吧！那岂不是严重浪费内存。那么该如何分配呢？slab分配器就应运而生了，专为小内存分配而生。slab分配器分配内存以Byte为单位。但是slab分配器并没有脱离伙伴系统，而是基于伙伴系统分配的大内存进一步细分成小内存分配。\nlinux 所使用的 slab 分配器的基础是 Jeff Bonwick 为SunOS 操作系统首次引入的一种算法。Jeff的分配器是围绕对象缓存进行的。在内核中，会为有限的对象集（例如文件描述符和其他常见结构）分配大量内存。Jeff发现对内核中**普通对象进行初始化所需的时间超过了对其进行分配和释放所需的时间。因此他的结论是不应该将内存释放回一个全局的内存池，而是将内存保持为针对特定目而初始化的状态。**例如，如果内存被分配给了一个互斥锁，那么只需在为互斥锁首次分配内存时执行一次互斥锁初始化函数（mutex_init）即可。后续的内存分配不需要执行这个初始化函数，因为从上次释放和调用析构之后，它已经处于所需的状态中了。\nslab层主要起到了两个方面的作用：\n  slab可以对小对象进行分配，这样就不用为每个小对象分配一个页框，节省了空间。\n  内核中的一些小对象创建析构很频繁，slab对这些小对象做了缓存，可以重复利用一些相同的对象，减少内存分配次数。\n  图中给出了 slab结构的高层组织结构。在最高层是 cache_chain，这是一个 slab 缓存的链接列表。cache_chain 的每个元素都是一个 kmem_cache 结构的引用（称为一个 cache）。它定义了一个要管理的给定大小的对象池。\n每个缓存都包含了一个 slabs 列表，这是一段连续的内存块（通常都是页面）。存在3 种 slab：\nslabs_full:完全分配的slab\nslabs_partial:部分分配的slab\nslabs_empty:空slab，或者没有对象被分配\nslab 列表中的每个 slab都是一个连续的内存块（一个或多个连续页），它们被划分成一个个对象。这些对象是从特定缓存中进行分配和释放的基本元素。注意 slab 是 slab分配器进行操作的最小分配单位，因此如果需要对 slab 进行扩展，这也就是所扩展的最小值。通常来说，每个 slab 被分配为多个对象。\n由于对象是从 slab 中进行分配和释放的，因此单个 slab 可以在 slab列表之间进行移动。例如，当一个 slab中的所有对象都被使用完时，就从slabs_partial 列表中移动到 slabs_full 列表中。当一个 slab完全被分配并且有对象被释放后，就从 slabs_full 列表中移动到slabs_partial 列表中。当所有对象都被释放之后，就从 slabs_partial 列表移动到 slabs_empty 列表中。\nslab背后的动机\n​\t与传统的内存管理模式相比， slab缓存分配器提供了很多优点。首先，内核通常依赖于对小对象的分配，它们会在系统生命周期内进行无数次分配。slab缓存分配器通过对类似大小的对象进行缓存而提供这种功能，从而避免了常见的碎片问题。slab分配器还支持通用对象的初始化，从而避免了为同一目而对一个对象重复进行初始化。\nslab描述符\n既然是对对象进行管理，那么就有一个内存的指针指向它所管理的对象：void* s_mem。并且它还需要记录哪些对象被使用了，哪些是空闲的。这时就需要有一个数组记录这个东西，这就是free变量。你可能会奇怪它的类型是一个unsigned int：\n它是如何记录这个数组的呢？事实上是记录在slab描述符后面的数组中，这个数组中的每一个元素记录着下一个空闲的内存对象的位置。而free记录的就是第一个空闲的对象。这样就可以从free开始遍历所有空闲的对象。\n下图显示了slab对象的内存分布，这里需要解释一下的是slab descriptor会根据情况被存放在当前slab的内存中或者存放在通用的高速缓存中。\nSlab与Buddy的关系  slab与Buddy都是内存分配器。 slab的内存来自Buddy slab与Buddy在算法上级别对等。Buddy把内存条当作一个池子来管理，slab是把从Buddy拿 到的内存当作一个池子来管理的  参考链接：\n Linux 伙伴算法简介 伙伴算法与slab算法  mmap和brk的区别 从操作系统角度来看，进程分配内存有两种方式，分别由两个系统调用完成：brk和mmap（不考虑共享内存）。\n brk是将数据段(.data)的最高地址指针_edata往高地址推；\n这是 brk 的内存分配方式，可以看到A、B新申请的内存都从堆的底部（堆的地址生长是从低到高的）开始向上生长。\n如果此时 free(A)，A的内存并不会被释放，而是会被回收，等待下一次的利用，或者说是等待B的回收。\n mmap是在进程的虚拟地址空间中（堆和栈中间，称为文件映射区域的地方）找一块空闲的虚拟内存。\nmmap直接从堆和栈之间的区域取出了一块区域，当回收这块内存时，操作系统也会直接将这块内存释放。\n但是系统调用和缺页中断比较消耗系统资源，为了CPU的执行效率，malloc只在申请的内存大于128K时才会调用mmap进行分配内存。\n  如果将 brk 比喻为批发的话，那么 mmap 就是零售。\n这两种方式分配的都是虚拟内存，没有分配物理内存。在第一次访问已分配的虚拟地址空间的时候，发生缺页中断，操作系统负责分配物理内存，然后建立虚拟内存和物理内存之间的映射关系。\n参考：\n 操作系统中 brk 和 mmap 的区别 linux下brk、mmap、malloc和new的区别 进程分配内存的两种方式\u0026ndash;brk() 和mmap()（不设计共享内存）  如何查看端口是否被占用？   使用netstat:\n1  netstat anp | grep 80     使用lsof:\n1  lsof -i:80     Linux的fork实现 fork的简单例子如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  #include \u0026lt;unistd.h\u0026gt;#include \u0026lt;stdio.h\u0026gt; int main() { int pid = fork(); if (pid == -1) return -1; if (pid) { printf(\u0026#34;I am father, my pid is %d\\n\u0026#34;, getpid()); return 0; } else { printf(\u0026#34;I am child, my pid is %d\\n\u0026#34;, getpid()); return 0; } }   I am father, my pid is 466 I am child, my pid is 469 看到这个结果是不是很奇怪，为什么if的分支执行到了，else的分支也执行到了❓\n对于函数原型pid_t fork();，它有三个返回值\n 该进程为父进程时，返回子进程的pid 该进程为子进程时，返回 fork执行失败，返回-1  fork它是如何知道一个进程是父进程还是子进程的❓\nfork本身的功能是克隆进程，也就是将原先的一个进程再克隆出一个来，克隆出的这个进程就是原进程的子进程，这个子进程和其他的进程没有什么区别，同样拥有自己的独立的地址空间。不同的是子进程是在fork返回之后才开始执行的，就像一把叉子一样，执行fork之后，父子进程就分道扬镳了，所以fork这个名字就很形象\nfork本质(两个进程+时间片轮转)\nfork在执行之后，会创建出一个新的进程，这个新的进程内部的数据是原进程所有数据的一份拷贝。因此fork就相当于把某个进程的全部资源复制了一遍，然后让cs：eip指向新进程的指令部分。\nfork给父进程返回子进程pid，给其拷贝出来的子进程返回0，这也是他的特点之一，一次调用，两次返回。两次返回看上去有点神秘，实质是在子进程的栈中构造好数据后，子进程从栈中获取到的返回值。\nfork的实现分为以下两步\n 复制进程资源 执行该进程  复制进程的资源包括以下几步\n 进程pcb 程序体，即代码段数据段等 用户栈 内核栈 虚拟内存池 页表  进行进程的话就比较简单了，只需要将其加入到就绪队列即可，接下来就等待cpu的调度了。\n1  pid=fork();   操作系统创建一个新的进程(子进程)，并且在进程表中相应为它建立一个新的表项。新进程和原有进程的可执行程序是同一个程序；上下文和数据，绝大部分就是原进程（父进程）的拷贝，但它们是两个相互独立的进程!此时程序寄存器pc，在父、子进程的上下文中都声称，这个进程目前执行到fork调用即将返回(此时子进程不占有CPU，子进程的pc不是真正保存在寄存器中，而是作为进程上下文保存在进程表中的对应表项内)。问题是怎么返回，在父子进程中就分道扬镳。\n父进程继续执行，操作系统对fork的实现，使这个调用在父进程中返回刚刚创建的子进程的pid(一个正整数)，所以下面的if语句中pid\u0026lt;0, pid==0的两个分支都不会执行。\n子进程在之后的某个时候得到调度，它的上下文被换入，占据 CPU，操作系统对fork的实现，使得子进程中fork调用返回0。所以在这个进程（注意这不是父进程了，虽然是同一个程序，但是这是同一个程序的另外一次执行，在操作系统中这次执行是由另外一个进程表示的，从执行的角度说和父进程相互独立）中pid=0。这个进程继续执行的过程中，if语句中 pid\u0026lt;0不满足，但是pid==0是true。\n相关代码\n将父进程的pcb、虚拟地址位图拷贝给子进程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  static int32_t copy_pcb_vaddrbitmap_stack0(task_struct *child_thread, task_struct *parent_thread) { /* a 复制pcb所在的整个页,里面包含进程pcb信息及特级0极的栈,里面包含了返回地址, 然后再单独修改个别部分 */ memcpy(child_thread, parent_thread, PG_SIZE); child_thread-\u0026gt;pid = fork_pid(); child_thread-\u0026gt;elapsed_ticks = 0; child_thread-\u0026gt;status = TASK_READY; child_thread-\u0026gt;ticks = child_thread-\u0026gt;priority; // 为新进程把时间片充满  child_thread-\u0026gt;parent_pid = parent_thread-\u0026gt;pid; child_thread-\u0026gt;general_tag.prev = child_thread-\u0026gt;general_tag.next = NULL; child_thread-\u0026gt;all_list_tag.prev = child_thread-\u0026gt;all_list_tag.next = NULL; block_desc_init(child_thread-\u0026gt;u_block_desc); /* b 复制父进程的虚拟地址池的位图 */ uint32_t bitmap_pg_cnt = DIV_ROUND_UP((0xc0000000 - USER_VADDR_START) / PG_SIZE / 8, PG_SIZE); void *vaddr_btmp = get_kernel_pages(bitmap_pg_cnt); if (vaddr_btmp == NULL) return -1; /* 此时child_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.bits还是指向父进程虚拟地址的位图地址 * 下面将child_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.bits指向自己的位图vaddr_btmp */ memcpy(vaddr_btmp, child_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.bits, bitmap_pg_cnt * PG_SIZE); child_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.bits = vaddr_btmp; ASSERT(strlen(child_thread-\u0026gt;name) \u0026lt; 11); // pcb.name的长度是16,为避免下面strcat越界  strcat(child_thread-\u0026gt;name, \u0026#34;_fork\u0026#34;); return 0; }   复制子进程的进程体(代码和数据)及用户栈\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  static void copy_body_stack3(task_struct *child_thread, task_struct *parent_thread, void *buf_page) { uint8_t *vaddr_btmp = parent_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.bits; uint32_t btmp_bytes_len = parent_thread-\u0026gt;userprog_vaddr.vaddr_bitmap.btmp_bytes_len; uint32_t vaddr_start = parent_thread-\u0026gt;userprog_vaddr.vaddr_start; uint32_t idx_byte = 0; uint32_t idx_bit = 0; uint32_t prog_vaddr = 0; /* 在父进程的用户空间中查找已有数据的页 */ while (idx_byte \u0026lt; btmp_bytes_len) { if (vaddr_btmp[idx_byte]) { idx_bit = 0; while (idx_bit \u0026lt; 8) { if ((BITMAP_MASK \u0026lt;\u0026lt; idx_bit) \u0026amp; vaddr_btmp[idx_byte]) { prog_vaddr = (idx_byte * 8 + idx_bit) * PG_SIZE + vaddr_start; /* 下面的操作是将父进程用户空间中的数据通过内核空间做中转,最终复制到子进程的用户空间 */ /* a 将父进程在用户空间中的数据复制到内核缓冲区buf_page, 目的是下面切换到子进程的页表后,还能访问到父进程的数据*/ memcpy(buf_page, (void *)prog_vaddr, PG_SIZE); /* b 将页表切换到子进程,目的是避免下面申请内存的函数将pte及pde安装在父进程的页表中 */ page_dir_activate(child_thread); /* c 申请虚拟地址prog_vaddr */ get_a_page_without_opvaddrbitmap(PF_USER, prog_vaddr); /* d 从内核缓冲区中将父进程数据复制到子进程的用户空间 */ memcpy((void *)prog_vaddr, buf_page, PG_SIZE); /* e 恢复父进程页表 */ page_dir_activate(parent_thread); } idx_bit++; } } idx_byte++; } }   为子进程构建thread_stack和修改返回值\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  static int32_t build_child_stack(task_struct *child_thread) { /* a 使子进程pid返回值为0 */ /* 获取子进程0级栈栈顶 */ intr_stack *intr_0_stack = (intr_stack *)((uint32_t)child_thread + PG_SIZE - sizeof(intr_stack)); /* 修改子进程的返回值为0 */ intr_0_stack-\u0026gt;eax = 0; /* b 为switch_to 构建 struct thread_stack,将其构建在紧临intr_stack之下的空间*/ uint32_t *ret_addr_in_thread_stack = (uint32_t *)intr_0_stack - 1; /* ebp在thread_stack中的地址便是当时的esp(0级栈的栈顶), 即esp为\u0026#34;(uint32_t*)intr_0_stack - 5\u0026#34; */ uint32_t *ebp_ptr_in_thread_stack = (uint32_t *)intr_0_stack - 5; /* switch_to的返回地址更新为intr_exit,直接从中断返回 */ *ret_addr_in_thread_stack = (uint32_t)intr_exit; /* 把构建的thread_stack的栈顶做为switch_to恢复数据时的栈顶 */ child_thread-\u0026gt;self_kstack = ebp_ptr_in_thread_stack; return 0; }   拷贝父进程本身所占资源给子进程\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  static int32_t copy_process(task_struct *child_thread, task_struct *parent_thread) { /* 内核缓冲区,作为父进程用户空间的数据复制到子进程用户空间的中转 */ void *buf_page = get_kernel_pages(1); if (buf_page == NULL) { return -1; } /* a 复制父进程的pcb、虚拟地址位图、内核栈到子进程 */ if (copy_pcb_vaddrbitmap_stack0(child_thread, parent_thread) == -1) { return -1; } /* b 为子进程创建页表,此页表仅包括内核空间 */ child_thread-\u0026gt;pgdir = create_page_dir(); if (child_thread-\u0026gt;pgdir == NULL) { return -1; } /* c 复制父进程进程体及用户栈给子进程 */ copy_body_stack3(child_thread, parent_thread, buf_page); /* d 构建子进程thread_stack和修改返回值pid */ build_child_stack(child_thread); /* e 更新文件inode的打开数 */ update_inode_open_cnts(child_thread); mfree_page(PF_KERNEL, buf_page, 1); return 0; }   主系统API调用\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  /* fork子进程,内核线程不可直接调用 */ pid_t sys_fork(void) { task_struct *parent_thread = running_thread(); task_struct *child_thread = get_kernel_pages(1); // 为子进程创建pcb(task_struct结构)  if (child_thread == NULL) { return -1; } ASSERT(INTR_OFF == intr_get_status() \u0026amp;\u0026amp; parent_thread-\u0026gt;pgdir != NULL); if (copy_process(child_thread, parent_thread) == -1) { return -1; } /* 添加到就绪线程队列和所有线程队列,子进程由调试器安排运行 */ ASSERT(!elem_find(\u0026amp;thread_ready_list, \u0026amp;child_thread-\u0026gt;general_tag)); list_append(\u0026amp;thread_ready_list, \u0026amp;child_thread-\u0026gt;general_tag); ASSERT(!elem_find(\u0026amp;thread_all_list, \u0026amp;child_thread-\u0026gt;all_list_tag)); list_append(\u0026amp;thread_all_list, \u0026amp;child_thread-\u0026gt;all_list_tag); return child_thread-\u0026gt;pid; // 父进程返回子进程的pid }   参考：\n 十九. fork的原理及实现 fork进程的过程  Malloc原理🚴  内存管理模块中是通过bitmap对内存进行管理的，bitmap中的每一个bit位就代表一页大小的内存，该位为1时表示这页已经分配出去了。那么对小块内存进行分配的时候，同样需要一个结构来记录这块内存的情况，也就是说，要通过一种结构来对内存的分配与释放进行管理。\n 任何实际的分配器都需要一些数据结构，允许它来区别块边界，以及区别已分配块和空闲块 。大多数分配器将这些信息嵌人块本身。一个简单的结构如下：\nLinux进程堆管理 Linux维护一个break指针，这个指针指向堆空间的某个地址。从堆起始地址到break之间的地址空间为映射好的，可以供进程访问；而从break往上，是未映射的地址空间，如果访问这段空间则程序会报错。\nbrk与sbrk 要增加一个进程实际的可用堆大小，就需要将break指针向高地址移动。Linux通过brk和sbrk系统调用操作break指针。两个系统调用的原型如下：\n1 2  int brk(void *addr); void *sbrk(intptr_t increment);   brk将break指针直接设置为某个地址，而sbrk将break从当前位置移动increment所指定的增量。brk在执行成功时返回0，否则返回-1并设置errno为ENOMEM；sbrk成功时返回break移动之前所指向的地址，否则返回(void *)-1。\n一个小技巧是，如果将increment设置为0，则可以获得当前break的地址。\n简单实现malloc 1 2 3 4 5 6 7 8 9 10 11  /* 一个玩具malloc */ #include \u0026lt;sys/types.h\u0026gt;#include \u0026lt;unistd.h\u0026gt;void *malloc(size_t size) { void *p; p = sbrk(0); if (sbrk(size) == (void *)-1) return NULL; return p; }   这个malloc每次都在当前break的基础上增加size所指定的字节数，并将之前break的地址返回。这个malloc由于对所分配的内存缺乏记录，不便于内存释放，所以无法用于真实场景。\n正式实现malloc 数据结构\n一个简单可行方案是将堆内存空间以块（Block）的形式组织起来，每个块由meta区和数据区组成，meta区记录数据块的元信息（数据区大小、空闲标志位、指针等等），数据区是真实分配的内存区域，并且数据区的第一个字节地址即为malloc返回的地址。\n1 2 3 4 5 6 7 8 9  typedef struct s_block *t_block; struct s_block { size_t size; /* 数据区大小 8字节*/ t_block next; /* 指向下个块的指针 8字节*/ int free; /* 是否是空闲块 4字节*/ int padding; /* 填充4字节，保证meta块长度为8的倍数 4字节*/ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */ }; // 总共32字节   由于我们只考虑64位机器，为了方便，我们在结构体最后填充一个int，使得结构体本身的长度为8的倍数，以便内存对齐。示意图如下：\n寻找合适的block\n　现在考虑如何在block链中查找合适的block。一般来说有两种查找算法：\n First fit：从头开始，使用第一个数据区大小大于要求size的块所谓此次分配的块 Best fit：从头开始，遍历所有块，使用数据区大小大于size且差值最小的块作为此次分配的块  　两种方法各有千秋，best fit具有较高的内存使用率（payload较高），而first fit具有更好的运行效率。这里我们采用first fit算法。\n1 2 3 4 5 6 7 8 9  /* First fit */ t_block find_block(t_block *last, size_t size) { t_block b = first_block; while(b \u0026amp;\u0026amp; !(b-\u0026gt;free \u0026amp;\u0026amp; b-\u0026gt;size \u0026gt;= size)) { *last = b; b = b-\u0026gt;next; } return b; }   find_block从frist_block开始，查找第一个符合要求的block并返回block起始地址，如果找不到这返回NULL。这里在遍历时会更新一个叫last的指针，这个指针始终指向当前遍历的block。这是为了如果找不到合适的block而开辟新block使用的。\n开辟新的block\n如果现有block都不能满足size的要求，则需要在链表最后开辟一个新的block。这里关键是如何只使用sbrk创建一个struct：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  #define BLOCK_SIZE 24 /* 由于存在虚拟的data字段，sizeof不能正确计算meta长度，这里手工设置 */ t_block extend_heap(t_block last, size_t s) { t_block b; b = sbrk(0); if(sbrk(BLOCK_SIZE + s) == (void *)-1) return NULL; b-\u0026gt;size = s; b-\u0026gt;next = NULL; if(last) last-\u0026gt;next = b; b-\u0026gt;free = 0; return b; }   分裂block\nFirst fit有一个比较致命的缺点，就是可能会让很小的size占据很大的一块block，此时，为了提高payload，应该在剩余数据区足够大的情况下，将其分裂为一个新的block，示意如下：\n实现代码：\n1 2 3 4 5 6 7 8 9  void split_block(t_block b, size_t s) { t_block new; new = b-\u0026gt;data + s; new-\u0026gt;size = b-\u0026gt;size - s - BLOCK_SIZE ; new-\u0026gt;next = b-\u0026gt;next; new-\u0026gt;free = 1; b-\u0026gt;size = s; b-\u0026gt;next = new; }   malloc实现\n注意首先我们要定义个block链表的头first_block，初始化为NULL；另外，我们需要剩余空间至少有BLOCK_SIZE + 8才执行分裂操作。\n由于我们希望malloc分配的数据区是按8字节对齐，所以在size不为8的倍数时，我们需要将size调整为大于size的最小的8的倍数：\n1 2 3 4 5  size_t align8(size_t s) { if(s \u0026amp; 0x7 == 0) return s; return ((s \u0026gt;\u0026gt; 3) + 1) \u0026lt;\u0026lt; 3; }   malloc代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  #define BLOCK_SIZE 24void *first_block=NULL; /* other functions... */ void *malloc(size_t size) { t_block b, last; size_t s; /* 对齐地址 */ s = align8(size); if(first_block) { /* 查找合适的block */ last = first_block; b = find_block(\u0026amp;last, s); if(b) { /* 如果可以，则分裂 */ if ((b-\u0026gt;size - s) \u0026gt;= ( BLOCK_SIZE + 8)) split_block(b, s); b-\u0026gt;free = 0; } else { /* 没有合适的block，开辟一个新的 */ b = extend_heap(last, s); if(!b) return NULL; } } else { b = extend_heap(NULL, s); if(!b) return NULL; first_block = b; } return b-\u0026gt;data; }   calloc的实现 有了malloc，实现calloc只要两步：\n malloc一段内存 将数据区内容置为0  由于我们的数据区是按8字节对齐的，所以为了提高效率，我们可以每8字节一组置0，而不是一个一个字节设置。我们可以通过新建一个size_t指针，将内存区域强制看做size_t类型来实现。\n1 2 3 4 5 6 7 8 9 10 11  void *calloc(size_t number, size_t size) { size_t *new; size_t s8, i; new = malloc(number * size); if(new) { s8 = align8(number * size) \u0026gt;\u0026gt; 3; for(i = 0; i \u0026lt; s8; i++) new[i] = 0; } return new; }   free的实现 free的实现并不像看上去那么简单，这里我们要解决两个关键问题：\n 如何验证所传入的地址是有效地址，即确实是通过malloc方式分配的数据区首地址 如何解决碎片问题  首先我们要保证传入free的地址是有效的，这个有效包括两方面：\n 地址应该在之前malloc所分配的区域内，即在first_block和当前break指针范围内 这个地址确实是之前通过我们自己的malloc分配的  第一个问题比较好解决，只要进行地址比较就可以了，关键是第二个问题。这里有两种解决方案：一是在结构体内埋一个magic number字段，free之前通过相对偏移检查特定位置的值是否为我们设置的magic number，另一种方法是在结构体内增加一个magic pointer，这个指针指向数据区的第一个字节（也就是在合法时free时传入的地址），我们在free前检查magic pointer是否指向参数所指地址。这里我们采用第二种方案：\n首先我们在结构体中增加magic pointer（同时要修改BLOCK_SIZE）：\n1 2 3 4 5 6 7 8 9  typedef struct s_block *t_block; struct s_block { size_t size; /* 数据区大小 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */ };   然后我们定义检查地址合法性的函数：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  t_block get_block(void *p) { char *tmp; tmp = p; return (p = tmp -= BLOCK_SIZE); } int valid_addr(void *p) { if(first_block) { if(p \u0026gt; first_block \u0026amp;\u0026amp; p \u0026lt; sbrk(0)) { return p == (get_block(p))-\u0026gt;ptr; } } return 0; }   当多次malloc和free后，整个内存池可能会产生很多碎片block，这些block很小，经常无法使用，甚至出现许多碎片连在一起，虽然总体能满足某此malloc要求，但是由于分割成了多个小block而无法fit，这就是碎片问题。\n一个简单的解决方式时当free某个block时，如果发现它相邻的block也是free的，则将block和相邻block合并。为了满足这个实现，需要将s_block改为双向链表。修改后的block结构如下：\n1 2 3 4 5 6 7 8 9 10  typedef struct s_block *t_block; struct s_block { size_t size; /* 数据区大小 */ t_block prev; /* 指向上个块的指针 */ t_block next; /* 指向下个块的指针 */ int free; /* 是否是空闲块 */ int padding; /* 填充4字节，保证meta块长度为8的倍数 */ void *ptr; /* Magic pointer，指向data */ char data[1] /* 这是一个虚拟字段，表示数据块的第一个字节，长度不应计入meta */ };   合并方法如下：\n1 2 3 4 5 6 7 8 9  t_block fusion(t_block b) { if (b-\u0026gt;next \u0026amp;\u0026amp; b-\u0026gt;next-\u0026gt;free) { b-\u0026gt;size += BLOCK_SIZE + b-\u0026gt;next-\u0026gt;size; b-\u0026gt;next = b-\u0026gt;next-\u0026gt;next; if(b-\u0026gt;next) b-\u0026gt;next-\u0026gt;prev = b; } return b; }   有了上述方法，free的实现思路就比较清晰了：首先检查参数地址的合法性，如果不合法则不做任何事；否则，将此block的free标为1，并且在可以的情况下与后面的block进行合并。如果当前是最后一个block，则回退break指针释放进程内存，如果当前block是最后一个block，则回退break指针并设置first_block为NULL。实现如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  void free(void *p) { t_block b; if(valid_addr(p)) { b = get_block(p); b-\u0026gt;free = 1; if(b-\u0026gt;prev \u0026amp;\u0026amp; b-\u0026gt;prev-\u0026gt;free) b = fusion(b-\u0026gt;prev); if(b-\u0026gt;next) fusion(b); else { if(b-\u0026gt;prev) b-\u0026gt;prev-\u0026gt;prev = NULL; else first_block = NULL; brk(b); } } }   realloc的实现 为了实现realloc，我们首先要实现一个内存复制方法。如同calloc一样，为了效率，我们以8字节为单位进行复制：\n1 2 3 4 5 6 7 8  void copy_block(t_block src, t_block dst) { size_t *sdata, *ddata; size_t i; sdata = src-\u0026gt;ptr; ddata = dst-\u0026gt;ptr; for(i = 0; (i * 8) \u0026lt; src-\u0026gt;size \u0026amp;\u0026amp; (i * 8) \u0026lt; dst-\u0026gt;size; i++) ddata[i] = sdata[i]; }   然后我们开始实现realloc。一个简单（但是低效）的方法是malloc一段内存，然后将数据复制过去。但是我们可以做的更高效，具体可以考虑以下几个方面：\n 如果当前block的数据区大于等于realloc所要求的size，则不做任何操作 如果新的size变小了，考虑split 如果当前block的数据区不能满足size，但是其后继block是free的，并且合并后可以满足，则考虑做合并  下面是realloc的实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  void *realloc(void *p, size_t size) { size_t s; t_block b, new; void *newp; if (!p) /* 根据标准库文档，当p传入NULL时，相当于调用malloc */ return malloc(size); if(valid_addr(p)) { s = align8(size); b = get_block(p); if(b-\u0026gt;size \u0026gt;= s) { if(b-\u0026gt;size - s \u0026gt;= (BLOCK_SIZE + 8)) split_block(b,s); } else { /* 看是否可进行合并 */ if(b-\u0026gt;next \u0026amp;\u0026amp; b-\u0026gt;next-\u0026gt;free \u0026amp;\u0026amp; (b-\u0026gt;size + BLOCK_SIZE + b-\u0026gt;next-\u0026gt;size) \u0026gt;= s) { fusion(b); if(b-\u0026gt;size - s \u0026gt;= (BLOCK_SIZE + 8)) split_block(b, s); } else { /* 新malloc */ newp = malloc (s); if (!newp) return NULL; new = get_block(newp); copy_block(b, new); free(p); return(newp); } } return (p); } return NULL; }   遗留问题和优化 以上是一个较为简陋，但是初步可用的malloc实现。还有很多遗留的可能优化点，例如：\n 同时兼容32位和64位系统 在分配较大快内存时，考虑使用mmap而非sbrk，这通常更高效 可以考虑维护多个链表而非单个，每个链表中的block大小均为一个范围内，例如8字节链表、16字节链表、24-32字节链表等等。此时可以根据size到对应链表中做分配，可以有效减少碎片，并提高查询block的速度 可以考虑链表中只存放free的block，而不存放已分配的block，可以减少查找block的次数，提高效率  参考：\n 十四. malloc\u0026amp;free的实现 如何实现一个malloc brk(）和sbrk()函数的使用  mmap() 创建进程时，建立虚存空间和具体文件之间的映射。但是需要注意的是建立映射的过程中完成很多复杂的需求，比如用函数指针来绑定一些对页面的操作。这两个系统调用的实现过程其实并不简单，非常值得研究，具体还是参看书籍。\n结论\n1）当开辟的空间小于 128K 时，调用 brk（）函数，malloc 的底层实现是系统调用函数 brk（），其主要移动指针 _enddata(此时的 _enddata 指的是 Linux 地址空间中堆段的末尾地址，不是数据段的末尾地址)\n2）当开辟的空间大于 128K 时，mmap（）系统调用函数来在虚拟地址空间中（堆和栈中间，称为“文件映射区域”的地方）找一块空间来开辟。\n参考：malloc 底层实现及原理\n内存管理的本质 对于社会来讲，“管理”是人类发展到一定阶段才产生的。拿时下最疯狂的一件事“买房”来举例，当我抵上未来20年的青春买到一套房子后，并不是将房子从地上挖起来送到我面前，而只是在合法部门将房子的所属权跟我的**号关联起来，我就有权住进这个房子了。腿长在我自己身上，按道理我想进谁的房子就进谁的房子呀，但除非是在原始社会，在有了“管理”的当今社会，乱跑就会被抓起来！原始社会只生活着一个或少量猿猴（需\u0026laquo;求），随便找个洞穴就是房子，一文不值，猿猴不会因为房子而发生冲突，所以才不需要管理。\n对计算机来讲，从加电到启动完成，也经历了“原始社会”到“当今社会”的过程，即“实模式→保护模式”，实模式时只有一个进程，一个巴掌拍不响，所以不担心干扰，只管为进入保护模式作好准备，并切换到保护模式。一旦进入保护模式，实际上就是启动一些防止相互干扰的“管理”，其中内存管理就是其中之一，从而多个进程才能和谐共处。\n内核要保证各个进程对物理内存（系统范围唯一）的使用不发生干扰，也要保证每个进程中不同的程序片段对虚拟内存（进程范围唯一）的使用不发生干扰：\n① 每个进程有自己独立的映射关系表，内核的视野能看见系统所有进程，自然也能保证各个进程对物理页面的使用不冲突。\n② 程序中的全局变量、static变量、函数名等，由编译器安排不冲突的虚拟地址，动态分配/释放时，对虚拟页面的使用都建立记录信息，所以也不会发生冲突。\n所以内存管理的本质就是为防止干扰、效率、换入换出等建立记录信息，并利用这些信息达到相应的目的。\n以下就是分配内存时，建立管理信息的大致示意图：\n  brk()\n从上图也可以看出Linux对虚拟空间的使用安排，brk()就是操作动态分配区间的虚拟地址（分配/释放）。glibc库中的malloc()函数，就是用brk()系统调用分配/释放虚拟页面。\n注意：\nchar *p = malloc(); // 不能free(p+1)\nbrk()得到的一个虚拟地址区间（图中灰色区域，用vm_area_struct结构表示），可以释放当中一部分，而裂为两个区域\n  Linux缓冲区🐃 linux中有两个级别的缓冲：IO缓冲与内核缓冲\n（1）IO缓冲:对于标准IO操作，都会有一个缓冲区，当用户想要写数据时，首先将数据写入缓冲区，待缓冲区满之后才能调用系统函数写入内核缓冲区。当用户想读取数据时，首先向内核读取一定的数据放入IO缓冲区，读操作从缓冲区中读数据，当读完IO缓冲区的数据时，才能再读取数据到IO缓冲区。\n目的：减少对磁盘的读写次数，提高工作效率。\n（2）内核缓冲区:操作系统内核部分也有缓冲，其与IO缓冲区是不同的，其主要区别用一张图表示：\n 操作系统（内核）先从磁盘读取数据到内核空间的内存（read①），再把数据从内核空间内存拷贝到用户空间内存（read②）。此后，用户应用程序才可以操作此数据。  那么内核缓冲做了什么事情呢？\n 读：数据预读 写：延时回写  参考链接：\n https://github.com/raxxarr/note/issues/2  什么是RPC RPC是指远程过程调用，也就是说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，需要通过网络来表达调用的语义和传达调用的数据。\n参考：\n 什么是RPC? 为什么要用RPC？ 什么是RPC？  线程同步的方式有哪些？  互斥量：采用互斥对象机制，只有拥有互斥对象的线程才有访问公共资源的权限。因为互斥对象只有一个，所以可以保证公共资源不会被多个线程同时访问。 信号量：它允许同一时刻多个线程访问同一资源，但是需要控制同一时刻访问此资源的最大线程数量。 事件（信号）：通过通知操作的方式来保持多线程同步，还可以方便的实现多线程优先级的比较操作。  中断和轮询的特点? 对I/O设备的程序轮询的方式，是早期的计算机系统对I/O设备的一种管理方式。它定时对各种设备轮流询问一遍有无处理要求。轮流询问之后，有要求的，则加以处理。在处理I/O设备的要求之后，处理机返回继续工作。尽管轮询需要时间，但轮询要比I/O设备的速度要快得多，所以一般不会发生不能及时处理的问题。当然，再快的处理机，能处理的输入输出设备的数量也是有一定限度的。而且，程序轮询毕竟占据了CPU相当一部分处理时间，因此，程序轮询是一种效率较低的方式，在现代计算机系统中已很少应用。\n　程序中断通常简称中断，是指CPU在正常运行程序的过程中，由于预先安排或发生了各种随机的内部或外部事件，使CPU中断正在运行的程序，而转到为响应的服务程序去处理。\n　轮询——效率低，等待时间很长，CPU利用率不高。\n　中断——容易遗漏一些问题，CPU利用率高\n输入与输出 设备\n  块设备\n块设备存储在固定大小的块中，每个块有自己的地址。块设备的基本特征是每个块都能独立于其他块而读写。硬盘、CD-ROM 和 USB 盘是最常见的块设备。\n  字符设备\n字符设备以字符为单位发送或接收一个字符流，而不考虑任何块结构。字符设备是不可寻址的，也没有任何寻道操作。打印机、网络接口、鼠标，以及大多数与磁盘不同的设备都可看作是字符设备。\n  IO控制方式\n  程序直接控制方式。计算机从外部设备读取数据到存储器，每次读一个字的数据。对读入的每个字，CPU 需要对外设状态进行循环检查知道确定该字已经在 I/O 控制器的数据寄存器中。\n  中断驱动方式。允许 I/O 设备主动打断 CPU 的运行并请求服务，从而“解放” CPU，使得其向 I/O 控制器发送读命令后可以继续做其他有用的工作。\n  DMA 方式。DMA(直接存储器)方式的基本思想是在 I/O 设备和内存之间开辟直接的数据交换通路，彻底“解放” CPU。DMA特点如下：（1）基本单位是数据块 （2）所传送的数据，是从设备直接送入内存的，或者相反 （3）仅在传送一个或多个数据块的开始和结束时，才需 CPU 干预，整块数据的传送是在 DMA 控制器的控制下完成的。\n为了在主机与控制器之间实现成块数据的直接交换，必须在 DMA 控制器中设置如下4类寄存器：\n 命令/状态寄存器（CR）。用于接收从 CPU 发来的 I/O 命令或有关控制信息，或设备的状态。 内存地址寄存器（MAR）。在输入时，它存放把数据从设备传送到内存的起始目标地址；在输出时，它存放由内存到设备的内存源地址。 数据寄存器（DR）。用于暂存从设备到内存或从内存到设备的数据。 数据计数器（DC）。存放本次要传送的字（节）数。    通道控制方式。I/O 通道是指专门负责输入/输出的处理机。I/O 通道是 DMA 方式的发展,它可以进一步减少 CPU 的干预，即把对一个数据块的读（或写）为单位的干预，减少为对一组数据块的读（或写）及有关控制和管理为单位的干预。I/O 通道与一般处理机的区别是：通道指令的类型单一没有自己的内存，通道所执行的通道程序是放在主机内存中的，也就是说通道与 CPU 共享内存。I/O 通道与 DMA 方式的区别是：DMA 方式需要 CPU 来控制传输的数据块大小、传输的内存位置，而通道方式中这些信息是由通道控制的。另外，每个 DMA 控制器对应一台设备与内存传递数据，而一个通道可以控制多台设备与内存的数据交换。\n  IO系统层次结构\n各层次及其功能如下：\n 用户层 I/O 软件。实现与用户交互的接口，用户可直接调用在用户层提供的、与 I/O 操作有关的库函数，对设备进行操作。 设备独立性软件。用于实现用户程序与设备驱动器的统一接口、设备命令、设备保护及设备分配与释放等，同时为设备管理和数据传送提供必要的存储空间。 设备驱动程序。与硬件直接相关，负责具体实现系统对设备发出的操作指令，驱动 I/O 设备工作的驱动程序。 中断处理程序。用于保护被中断进程的 CPU 环境，转入相应的中断处理程序进行处理，处理完并恢复被中断进程的现场后，返回到被中断程序。 硬件设备。I/O 设备通常包括一个机械部件和一个电子部件。为了达到设计的模块性和通用性，一般将其分开：电子部件称为设备控制器（或适配器），在个人计算机中，通常是一块插入主板扩充槽的印制电路板；机械部件则是设备本身。  参考:\n https://github.com/jx453331958/blog/issues/17 【操作系统】 输入/输出（I/O）管理  ","description":"","id":62,"section":"talks","tags":[""],"title":"interview","uri":"https://hugo.jiahongw.com/zh/talks/interview/"},{"content":"树是一种非常实用的结构！🌴\n以下的二叉树采用的结构都为链式结构\n1 2 3 4 5  typedef struct BiTNode /* 结点结构 */ { int data; /* 结点数据 */ struct BiTNode *lchild, *rchild; /* 左右孩子指针 */ } BiTNode, *BiTree;   1. 二叉排序树  二叉排序树又称“二叉查找树”、“二叉搜索树”。\n 定义 或者是一棵空树，或者是具有下列性质的二叉树：\n  若它的左子树不空，则左子树上所有结点的值均小于它的根结点的值；\n  若它的右子树不空，则右子树上所有结点的值均大于它的根结点的值；\n  它的左、右子树也分别为二叉排序树。\n   中序遍历二叉排序树可得到一个依据关键字的有序序列，一个无序序列可以通过构造一棵二叉排序树变成一个有序序列，构造树的过程即是对无序序列进行排序的过程。每次插入的新的结点都是二叉排序树上新的叶子结点，在进行插入操作时，不必移动其它结点，只需改动某个结点的指针，由空变为非空即可。搜索、插入、删除的时间复杂度等于树高，期望O(logn)，最坏O(n)（数列有序，树退化成线性表，如右斜树）。\n 查找算法 查找过程：\n1.若b是空树，则搜索失败，否则：\n2.若x等于b的根节点的数据域之值，则查找成功；否则：\n3.若x小于b的根节点的数据域之值，则搜索左子树；否则：\n4.查找右子树。\n5.若查找不成功， 则指针 p 指向查找路径上访问的最后一个结点并返回FALSE\n插入算法 插入过程：\n  先调用查找操作将要插入的关键字进行比较\n  如果在原有的二叉排序树中没有要插入的关键字，则将关键字与查找的结点p（在查找操作中返回的结点）的值进行比较\n  若p为空，则插入关键字赋值给该节点；\n  若小于结点p的值，则插入关键字作为结点p的左子树；\n  若大于结点p的值，则插入关键字作为结点p的右子树；\n   每次需要插入的节点都为叶子节点。\n 删除算法 删去一个结点，分三种情况讨论：\n  若*p结点为叶子结点，即PL(左子树)和PR(右子树)均为空树。由于删去叶子结点不破坏整棵树的结构，则只需修改其双亲结点的指针即可。\n  若p结点只有左子树PL或右子树PR，此时只要令PL或PR直接成为其双亲结点f的左子树（当p是左子树）或右子树（当p是右子树）即可，作此修改也不破坏二叉排序树的特性。\n  若p结点的左子树和右 子树均不空。在删去p之后，为保持其它元素之间的相对位置不变，可按中序遍历保持有序进行调整。比较好的做法是，找到*p的**直接前驱（或直接后继）s，用s来替换结点p，然后再删除结点s。(依靠中序遍历在p节点下进行遍历得到的最后一个数即为替换的节点)\n  性能分析  最好的情况是二叉排序树的形态和折半查找的判定树相同，其平均查找长度和logn成正比（O(log2(n))）。 最坏情况下，当先后插入的关键字有序时，构成的二叉排序树为一棵斜树，树的深度为n，其平均查找长度为(n + 1) / 2。也就是时间复杂度为O(n)，等同于顺序查找。   虽然二叉排序树的最坏效率是O(n)，但它支持动态查找。最好是把它构建成一棵平衡的二叉排序树（平衡二叉树），这些平衡二叉树可以使树高为O(logn)，如AVL、红黑树等。\n 2. 平衡二叉树（AVL） 定义 它或者是一颗空树，或者具有以下性质的二叉树：它的左子树和右子树的深度之差的绝对值不超过1，且它的左子树和右子树都是一颗平衡二叉树。\n平衡因子(bf)：结点的左子树的深度减去右子树的深度，那么显然-1\u0026lt;=bf\u0026lt;=1;\n 在AVL树中，任一节点对应的两棵子树的最大高度差为1，因此它也被称为高度平衡树。\n 查找、插入和删除在平均和最坏情况下的时间复杂度都是$O(log(n))$。增加和删除元素的操作则可能需要借由一次或多次树旋转，以实现树的重新平衡。\n查找操作 平衡二叉树的查找基本与二叉查找树相同。\n插入操作 在平衡二叉树中插入结点与二叉查找树最大的不同在于要随时保证插入后整棵二叉树是平衡的。那么调整不平衡树的基本方法就是： 旋转 。\n首先，还需要明白的一个概念就是：\n最小不平衡子树的根结点：也就是当你进行插入操作时，找到该需要插入结点的位置并插入后，从该结点起向上寻找（回溯），第一个不平衡的结点即平衡因子bf变为-2或2的节点。\n 那究竟是如何“转”的呢？\n其实，可以换一种思路思考，不让它叫“旋转”！而叫——\u0026gt;“两个结点的变换”\n 下面分情况分析四种旋转方式\n左左 即在x的左孩子a的左孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的左孩子（如图②），也可以是c的右孩子（不在画出）\n 这种左左插入方式有一个规律：不平衡子树的左子树深度比右子树深度大2.\n 图①②插入的节点都为y，此时向上回溯第一个不平衡的子树根节点为x，那么将x节点及其右子树(图①为NULL，图②为b)一起绕着x的左子树根节点(即a)右旋(即顺时针旋转),然后将a的右子树作为x的左子树，假如a的右子树为空则不必插入。那么这样旋转最后将不平衡子树变为平衡。\n右右 即在x的右孩子a的右孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n 这种右右插入方式有一个规律：不平衡子树的左子树深度比右子树深度小2.\n 图①②插入的节点都为y，此时向上回溯找到第一个不平衡子树的节点为x，需要将节点x及其左子树(图①为NULL，图二为b)绕着x右子树(两图都为a为根节点的子树)进行左旋(逆时针旋转),然后将其右子树(a)的左节点作为x的右节点，这样使得不平衡子树又再度平衡。\n左右 即在x的左孩子a的右孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n 这种左右插入的规律就是：不平衡子树的左子树高度比右子树大2且左子树的右子树比左子树的左子树深度深。\n 向上回溯的第一个不平衡子树为x，先对x的左子树左旋(旋转中心为c)，再对x的左子树进行右旋(旋转中心为c)。(旋转中心为左子树的右节点)\n 如果是图①，旋转中心为y\n 右左 即在x的右孩子a的左孩子c上插入一个结点y（该结点也可以是c,如图①），即y可以是c，也可以是c的右孩子（如图②），也可以是c的左孩子（不在画出）\n 这种右左插入的规律就是：不平衡子树的右子树高度比左子树大2且右子树的左子树比右子树的右子树深度深。\n 向上回溯的第一个不平衡子树为x，先对x的右子树右旋(旋转中心为c)，再对x的右子树进行左旋(旋转中心为c)。(旋转中心为左子树的右节点)\n 如果是图①，旋转中心为y\n AVL树的操作汇总：\n删除操作 删除类似插入的操作。删除时少一个结点，也就是该结点所在的子树深度可能会减小，而插入时多一个结点，该结点所在的子树深度可能会增加，所以递归删除一个结点时，回溯时找到最小不平衡子树的根结点时，要向相反的方向去找属于哪种情况；\n如图y为要删除的节点\n图①：y结点删除后，回溯到x结点从bf=-1变为bf=-2；则需从相反方向即从x的右孩子的方向向下检查属于哪种情况，显然第一个方向为1：右；第二个方向看a的bf的值——若为1时，那就相当于插入时‘右左’的情况；若为-1时，那就相当于插入时‘右右’的情况；可现在a的bf既不是1也不是-1而是0，这就是删除的特殊情况了！我们不妨试试对他进行类似于插入时的‘右右’操作，看怎么样~ 如上图，经过变换后该子树平衡了！但是因子的修改就跟插入时的‘右右’不一样了！此时变为：x的bf=-1,a的bf=1；所以我们不妨就把a的bf=0也归纳为删除的‘右右’或‘左左’（如图②，不再敖述）操作；\n那么删除时因子的改变需在插入时因子的改变中添加上：\n左左：前a:bf=0 后x:bf=1,a:bf=-1； 右右：前a:bf=0 后x:bf=-1,a:bf=1；其他不变！\n 可以想象，其实是很简单的道理：除了特殊情况其他都与插入的情况一模一样，说白了就是把深度大的子树（根结点的其中一个）向深度小子树贡献一个深度，那么这样一来，该子树（对于根结点所领导的树）的深度是不是比原来的小1了？！所以要继续向上一个一个进行检索，直到根结点为止！\n 代码实现 https://blog.csdn.net/nightwizard2030/article/details/72874715\n性能分析 优势 平衡二叉树的优势在于不会出现普通二叉查找树的最差情况。其查找的时间复杂度为$O(logN)$。\n缺陷  为了保证高度平衡，动态插入和删除的代价也随之增加. 所有二叉查找树结构的查找代价都与树高是紧密相关的，能否通过减少树高来进一步降低查找代价呢。  应用场景 应用：windows对进程地址空间的管理用到了AVL树。\n3. 红黑树 也被称为\u0026rdquo;对称二叉B树\u0026quot;。\n定义 红黑树(red-black tree) 是一棵满足下述性质的二叉查找树：\n  每一个结点要么是红色，要么是黑色。\n  根结点是黑色的。\n  所有叶子结点都是黑色的（实际上都是Null指针，下图用NIL表示）。叶子结点不包含任何关键字信息，所有查询关键字都在非终结点上。\n  每个红色结点的两个子节点必须是黑色的。换句话说：从每个叶子到根的所有路径上不能有两个连续的红色结点\n  从任一结点到其每个叶子的所有路径都包含相同数目的黑色结点\n  几个概念：\n黑深度 ——从某个结点x出发(不包括结点x本身)到叶结点(包括叶子结点)的路径上的黑结点个数,称为该结点x的黑深度,记为$bd(x)$,根结点的黑深度就是该红黑树的黑深度。叶子结点的黑深度为0。比如：上图$bd(13)=2， bd(8)=2， bd(1)=1$\n内部结点 —— 红黑树的非终结点\n外部节点 —— 红黑树的叶子结点\n相关原理  从根到叶子的最长的可能路径不多于最短的可能路径的两倍长。 红黑树的树高$(h)$不大于两倍的红黑树的黑深度$(bd)$，即$h\u0026lt;=2bd$ 一棵拥有n个内部结点(不包括叶子结点)的红黑树的树高$h\u0026lt;=2log(n+1)$  查找操作 因为每一个红黑树也是一个特化的二叉查找树，因此红黑树上的查找操作与普通二叉查找树上的查找操作相同.\n插入操作 我们首先以二叉查找树的方法增加节点并标记它为红色。下面要进行什么操作取决于其他临近节点的颜色。同人类的家族树中一样，我们将使用术语叔父节点来指一个节点的父节点的兄弟节点。\n假设新加入的结点为N，父亲结点为P，叔父结点为Ui(叔父结点就是一些列P的兄弟结点)，祖父结点G(父亲结点P的父亲)。\n情况1. 当前红黑树为空，新结点N位于树的根上，没有父结点。\n此时很简单，我们将直接插入一个黑结点N（满足性质2），因为是特殊大的情况，不插入红色而插入黑色节点。\n情况2. 新结点N的父结点P是黑色。\n在这种情况下，我们插入一个红色结点N(满足性质5)\n 注意：在情况3，4，5下，我们假定新节点有祖父节点，因为父节点是红色；并且如果它是根，它就应当是黑色。所以新节点总有一个叔父节点，尽管在情形4和5下它可能是叶子。\n 情况3.如果父节点P和叔父节点U二者都是红色。\n如下图，因为新加入的N结点必须为红色，那么我们可以将父结点P(保证性质4)，以及N的叔父结点U(保证性质5)重新绘制成黑色。如果此时祖父结点G是根，则结束变化。如果不是根，则祖父结点重绘为红色(保证性质5)。但是，G的父亲也可能是红色的，为了保证性质4。我们把G递归当做新加入的结点N在进行各种情况的重新检查。\n 注意：在情形4和5下，我们假定父节点P 是祖父结点G 的左子节点。如果它是右子节点，情形4和情形5中的左和右应当对调。\n 情况4. 父节点P是红色而叔父节点U是黑色或缺少; 另外，新节点N是其父节点P的右子节点，而父节点P又是祖父结点G的左子节点。\n如下图, 在这种情形下，我们进行一次左旋转调换新节点和其父节点的角色（与AVL树的左旋转相同）; 这导致某些路径通过它们以前不通过的新节点N或父节点P中的一个，但是这两个节点都是红色的，所以性质5没有失效。但目前情况将违反性质4，所以接着，我们按下面的情况5继续处理以前的父节点P。\n情况5. 父节点P是红色而叔父节点U 是黑色或缺少，新节点N 是其父节点的左子节点，而父节点P又是祖父结点的G的左子节点。\n如下图： 在这种情形下，我们进行针对祖父节点P 的一次右旋转; 在旋转产生的树中，以前的父节点P现在是新节点N和以前的祖父节点G 的父节点。我们知道以前的祖父节点G是黑色，否则父节点P就不可能是红色。我们切换以前的父节点P和祖父节点G的颜色，结果的树满足性质4[3]。性质 5[4]也仍然保持满足，因为通过这三个节点中任何一个的所有路径以前都通过祖父节点G ，现在它们都通过以前的父节点P。在各自的情形下，这都是三个节点中唯一的黑色节点。\n删除操作 相较于插入操作，红黑树的删除操作则要更为复杂一些。删除操作首先要确定待删除节点有几个孩子，如果有两个孩子，不能直接删除该节点。而是要先找到该节点的前驱（该节点左子树中最大的节点）或者后继（该节点右子树中最小的节点），然后将前驱或者后继的值复制到要删除的节点中，最后再将前驱或后继删除。由于前驱和后继至多只有一个孩子节点，这样我们就把原来要删除的节点有两个孩子的问题转化为只有一个孩子节点的问题，问题被简化了一些。我们并不关心最终被删除的节点是否是我们开始想要删除的那个节点，只要节点里的值最终被删除就行了，至于树结构如何变化，这个并不重要。\n应用场景 工业界最主要使用的二叉搜索平衡树，广泛用在C++的STL中。如map和set都是用红黑树实现的。Java用它来实现TreeMap。著名的linux进程调度Completely Fair Scheduler,用红黑树管理进程控制块。\n epoll在内核中的实现，用红黑树管理事件块 nginx中，用红黑树管理timer等  Code 实现：https://www.cnblogs.com/skywang12345/p/3624291.html\n红黑树节点定义 1 2 3 4 5 6 7 8 9 10 11 12  template \u0026lt;class T\u0026gt; class RBTNode { public: RBTColor color; // 颜色  T key; // 关键字(键值)  RBTNode *left; // 左孩子  RBTNode *right; // 右孩子  RBTNode *parent; // 父结点  RBTNode(T value, RBTColor c, RBTNode *p, RBTNode *l, RBTNode *r) : key(value), color(c), parent(), left(l), right(r) {} };   颜色定义 1 2 3 4 5  enum RBTColor { RED, BLACK };   4.B树 背景\n一个比较实际的问题：就是大量数据存储中，实现查询这样一个实际背景下，平衡二叉树由于树深度过大而造成磁盘IO读写过于频繁，进而导致效率低下。那么如何减少树的深度（当然不能减少查询数据量），一个基本的想法就是：\n  每个节点存储多个元素 （但元素数量不能无限多，否则查找就退化成了节点内部的线性查找了）。\n  摒弃二叉树结构，采用多叉树 （由于节点内元素数量不能无限多，自然子树的数量也就不会无限多了）。\n  这样我们就提出来了一个新的查找树结构 ——多路查找树。 根据AVL给我们的启发，一颗平衡多路查找树(B~树) 自然可以使得数据的查找效率保证在O(logN)这样的对数级别上。\n 目前大部分数据库系统及文件系统都采用B-Tree或其变种B+Tree作为索引结构\n B-树 B-树是一种多路搜索树。\nB-Tree 是满足下列条件的数据结构：\n d 为大于 1 的一个正整数，称为 B-Tree 的度。 h 为一个正整数，称为 B-Tree 的高度。 每个非叶子节点由 n-1 个 key 和 n 个指针组成，其中 d\u0026lt;=n\u0026lt;=2d。 每个叶子节点最少包含一个 key 和两个指针，最多包含 2d-1 个 key 和 2d 个指针，叶节点的指针均为 null 。 所有叶节点具有相同的深度，等于树高 h。 key 和指针互相间隔，节点两端是指针。 一个节点中的 key 从左到右非递减排列。 所有节点组成树结构。 每个指针要么为 null，要么指向另外一个节点。 如果某个指针在节点 node 最左边且不为 null，则其指向节点的所有 key 小于 v(key1)，其中 v(key1) 为 node 的第一个 key 的值。 如果某个指针在节点 node 最右边且不为 null，则其指向节点的所有 key 大于 v(keym)，其中 v(keym) 为 node 的最后一个 key 的值。 如果某个指针在节点 node 的左右相邻 key 分别是 keyi 和 keyi+1 且不为 null，则其指向节点的所有 key 小于 v(keyi+1) 且大于 v(keyi)。  性质：\n  根结点至少有两个子女；\n  每个非根节点所包含的关键字个数 j 满足：┌m/2┐ - 1 \u0026lt;= j \u0026lt;= m - 1；\n  除根结点以外的所有结点（不包括叶子结点）的度数正好是关键字总数加1，故内部子树个数 k 满足：┌m/2┐ \u0026lt;= k \u0026lt;= m ；\n  所有的叶子结点都位于同一层。\n   用在磁盘文件组织 数据索引和数据库索引。\n B-Tree 中的每个节点根据实际情况可以包含大量的关键字信息和分支，例：\n每个节点占用一个盘块的磁盘空间，一个节点上有两个升序排序的关键字和三个指向子树根节点的指针，指针存储的是子节点所在磁盘块的地址。\n两个关键词划分成的三个范围域对应三个指针指向的子树的数据的范围域。\n以根节点为例，关键字为 17 和 35，P1 指针指向的子树的数据范围为小于 17，P2 指针指向的子树的数据范围为 17~35，P3 指针指向的子树的数据范围为大于 35。\n模拟查找关键字 29 的过程：\n 根据根节点找到磁盘块 1，读入内存。【磁盘 I/O 操作第 1 次】 比较关键字 29 在区间（17,35），找到磁盘块 1 的指针 P2。 根据 P2 指针找到磁盘块 3，读入内存。【磁盘 I/O 操作第 2 次】 比较关键字 29 在区间（26,30），找到磁盘块 3 的指针 P2。 根据 P2 指针找到磁盘块 8，读入内存。【磁盘 I/O 操作第 3 次】 在磁盘块 8 中的关键字列表中找到关键字 29。   B-Tree 相对于 AVLTree 缩减了节点个数，使每次磁盘 I/O 取到内存的数据都发挥了作用，从而提高了查询效率。\n B+树 B+树是B-树的变体，也是一种多路搜索树：\n1.其定义基本与B-树同，除了：\n2.非叶子结点的子树指针与关键字个数相同；\n3.非叶子结点的子树指针P[i]，指向关键字值属于[K[i], K[i+1])的子树\n（B-树是开区间）；\n5.为所有叶子结点增加一个链指针；\n6.所有关键字都在叶子结点出现；\n 用在磁盘文件组织 数据索引和数据库索引。MySQL常用的引擎InnoDB 和 Myisam 都是用 B+Tree 来存储数据的。\nB和B+主要用在文件系统以及数据库中做索引等，比如Mysql：B-Tree Index in MySql\n  在 B-Tree 中，每个节点中有 key，也有 data，而每一个页的存储空间是有限的，如果 data 数据较大时将会导致每个节点（即一个页）能存储的 key 的数量很小。当存储的数据量很大时同样会导致 B-Tree 的深度较大，增大查询时的磁盘 I/O 次数，进而影响查询效率。\n B+Tree 是在 B-Tree 基础上的一种优化，使其更适合实现外存储索引结构，InnoDB 存储引擎就是用 B+Tree 实现其索引结构。\nB+Tree 在 B-Tree 的基础上有两点变化：\n 数据是存在叶子节点中的； 数据节点之间是有指针指向的。  由于 B+Tree 的非叶子节点只存储键值信息，假设每个磁盘块能存储 4 个键值及指针信息，则变成 B+Tree 后其结构如下图所示：\nMySQL应用 我们通常所说的在某个字段上建索引，意思就是让 MySQL 对该字段以索引这种数据结构来存储，然后查找的时候就有对应的查找算法。\n建索引的根本目的是为了查找的优化，特别是当数据很庞大的时候，一般的查找算法有顺序查找、折半查找、快速查找等。\n InnoDB\nInnoDB 的存储文件有两个，后缀名分别是 .frm 和 .idb，其中 .frm 是表的定义文件，而 idb 是数据文件。  InnoDB 中存在表锁和行锁，不过行锁是在命中索引的情况下才会起作用。\nInnoDB 支持事务，且支持四种隔离级别（读未提交、读已提交、可重复读、串行化），默认的为可重复读；而在 Oracle 数据库中，只支持串行化级别和读已提交这两种级别，其中默认的为读已提交级别。\nInnoDB 通过 B+Tree 结构对 ID 建索引，然后在叶子节点中存储记录。\nMyisam\nMyisam 的存储文件有三个，后缀名分别是 .frm、.MYD、MYI，其中 .frm 是表的定义文件，.MYD 是数据文件，.MYI 是索引文件。  Myisam 只支持表锁，且不支持事务。Myisam 由于有单独的索引文件，在读取数据方面的性能很高 。\n由于 Myisam 中的索引和数据分别存放在不同的文件，所以在索引树中的叶子节点中存的数据是该索引对应的数据记录的地址，由于数据与索引不在一起，所以 Myisam 是非聚簇索引。\n红黑树和多路查找树都是属于深度有界查找树（depth-bounded tree —DBT）\n2-3-4树 2-3-4 树在计算机科学中是阶为 4 的B树。\n2-3-4 树把数据存储在叫做元素的单独单元中。它们组合成节点，每个节点都是下列之一\n 2-节点，就是说，它包含 1 个元素和 2 个儿子， 3-节点，就是说，它包含 2 个元素和 3 个儿子， 4-节点，就是说，它包含 3 个元素和 4 个儿子 。  每个儿子都是（可能为空）一个子 2-3-4 树。根节点是其中没有父亲的那个节点；它在遍历树的时候充当起点，因为从它可以到达所有的其他节点。叶子节点是有至少一个空儿子的节点。\n同B树一样，2-3-4 树是有序的：每个元素必须大于或等于它左边的和它的左子树中的任何其他元素。每个儿子因此成为了由它的左和右元素界定的一个区间。\n2-3-4 树是红黑树的一种等同，这意味着它们是等价的数据结构。换句话说，对于每个 2-3-4 树，都存在着至少一个数据元素是相同次序的红黑树。在 2-3-4 树上的插入和删除操作也等价于在红黑树中的颜色翻转和旋转。这使得它成为理解红黑树背后的逻辑的重要工具。\n字典树 (又称trie 树，单词查找树)\n1.又称单词查找树，Trie树，是一种树形结构，是一种哈希树的变种。\n典型应用是用于统计，排序和保存大量的字符串（但不仅限于字符串），所以经常被搜索引擎系统用于文本词频统计。\n2.它的优点是：利用字符串的公共前缀来节约存储空间，最大限度地减少无谓的字符串比较，查询效率比哈希表高。\n3.字典树与字典很相似,当你要查一个单词是不是在字典树中,首先看单词的第一个字母是不是在字典的第一层,如果不在,说明字典树里没有该单词,如果在就在该字母的孩子节点里找是不是有单词的第二个字母,没有说明没有该单词,有的话用同样的方法继续查找.字典树不仅可以用来储存字母,也可以储存数字等其它数据。\n 用在统计和排序大量字符串，如自动机。\ntrie 树的一个典型应用是前缀匹配，比如下面这个很常见的场景，在我们输入时，搜索引擎会给予提示\n还有比如IP选路，也是前缀匹配，一定程度会用到trie\n  后缀树\n  广义后缀树\n  参考：\n https://www.cnblogs.com/zhuyf87/archive/2012/11/09/2763113.html 二叉排序树 https://www.cnblogs.com/fornever/archive/2011/11/15/2249492.html 平衡二叉树（解惑） https://www.iteye.com/blog/hxraid-609949 平衡二叉查找树 https://www.iteye.com/blog/hxraid-611816 红黑树(RBT) https://www.zhihu.com/question/30527705 树的应用场景 说一下聚簇索引 \u0026amp; 非聚簇索引 MySQL索引背后的数据结构及算法原理 ","description":"","id":63,"section":"posts","tags":["二叉树"],"title":"高级的二叉树","uri":"https://hugo.jiahongw.com/zh/posts/algorithmstructure/bst/"},{"content":"地址：http://markdown.xiaoshujiang.com/\nThis is a Test!\n","description":"","id":64,"section":"posts","tags":["小书匠"],"title":"使用小书匠在线编写博文","uri":"https://hugo.jiahongw.com/zh/posts/hugo/xiaoshujiang/"},{"content":"需要从 UGameViewportClient 类继承 修改返回值为true,路径：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n1  virtual bool RequiresHitProxyStorage() override { return true; }   在FViewportClient类中新建DrawHitProxy函数 文件UnrealClient.h\n在GameViewportClient类中声明并且实现 声明：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n将GameViewportClient类中的函数Draw()内容复制到该函数DrawHitProxy，修改下面的的地方：\n修改FViewport类中的GetRawHitProxyData函数 在GetRawHitProxyData函数中进行以下的修改：Engine\\Source\\Runtime\\Engine\\Private\\UnrealClient.cpp\n调用\u0026ndash;获取屏幕坐标Hitproxy 相关类型 HHitProxy：用于检测用户界面命中的基类\nFHitProxyMap：从2D坐标到缓存命中代理的地图。\n参考：\n How to select an actor in-game using GetHitProxy? UE4 编辑器的光标拾取 编辑器Viewport窗口中的鼠标拾取原理 场景基本对象 渲染总流程 https://docs.unrealengine.com/zh-CN/Programming/Rendering/MeshDrawingPipeline/index.html Unreal Mesh Drawing源码分析 白袍笑道  ","description":"","id":65,"section":"posts","tags":["C++","UE4","Game"],"title":"UE编辑器下模拟使用HitProxy","uri":"https://hugo.jiahongw.com/zh/posts/ue/ue-hitproxy/"},{"content":"在UE4中获取深度缓存，调用渲染命令读取。\n获取深度缓存 深度像素格式 键入命令vis scenedepthz uv0以查看实际使用的深度缓冲区。UE4对场景使用“反向”深度缓冲区。\nWay1：直接使用ENQUEUE_RENDER_COMMAND命令获取(效率较低) 在任意tick函数或者其他函数添加以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32  struct DepthPixel\t//定义深度像素结构体 \t{ float depth; char stencil; char unused1; char unused2; char unused3; }; float* cpuDataPtr;\t// Texture深度值数组首地址 \tTArray\u0026lt;DepthPixel\u0026gt; mydata;\t//最终获取色深度值数据 \tFIntPoint buffsize;\t//深度长宽大小X和Y  ENQUEUE_RENDER_COMMAND(ReadSurfaceFloatCommand)(\t// 将读取深度数据的命令推给渲染线程进行执行 \t[\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize](FRHICommandListImmediate\u0026amp; RHICmdList) //\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize为传入的外部参数 \t{ FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, 1); FTexture2DRHIRef uTex2DRes = FSceneRenderTargets::Get(RHICmdList).GetSceneDepthSurface();\tbuffsize = uTex2DRes-\u0026gt;GetSizeXY(); uint32 sx = buffsize.X; uint32 sy = buffsize.Y; mydata.AddUninitialized(sx * sy); uint32 Lolstrid = 0; cpuDataPtr = (float*)RHILockTexture2D(uTex2DRes,0,RLM_ReadOnly,Lolstrid,true);\t// 加锁 获取可读depth Texture深度值数组首地址 \tmemcpy(mydata.GetData(), cpuDataPtr, sx * sy * sizeof(DepthPixel));\t//复制深度数据 \tRHIUnlockTexture2D(uTex2DRes, 0, true);\t//解锁 \tFSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, -1);\t}); FlushRenderingCommands();\t//等待渲染线程执行  mydata; //最终获取深度数据   最终返回的mydata数据就是最终的深度值数组，其中每个深度值的结构是DepthPixel，其中一个成员为depth，另外四个不不使用。其中使用上面的几个命令需要添加\u0026quot;RHI.h\u0026quot;头文件\nWay2：写个请求类读取 UML图：\n流程图：\n1. 首先在项目的build.cs文件添加： 添加引擎源码地址\n1 2 3 4 5 6 7 8 9 10  // 添加引擎源码地址  string EnginePath = \u0026#34;C:/Program Files (x86)/UE4+VS2017/UnrealEngine/\u0026#34;; PrivateIncludePaths.AddRange( new string[] { EnginePath + \u0026#34;Source/Runtime/Renderer/Private\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/CompositionLighting\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/PostProcess\u0026#34; } );   添加引依赖项\n2. 类实现 将下面类代码复制到PostProcessing.h文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83  /*****************************************Get Depth Class*******************************************************/ /*\t存储一个像素的缓存 depth 深度缓存 stencil （抠图缓存）*/ struct DepthPixel { float depth; char stencil; char unused1; char unused2; char unused3; }; /*\t存储整个视窗的缓存 data\t像素缓存数组 bufferSizeX\t缓存大小X bufferSizeY\t缓存大小Y pixelSizeBytes\t像素缓存字节数*/ struct DepthResult { TArray\u0026lt;DepthPixel\u0026gt; data; int bufferSizeX; int bufferSizeY; int pixelSizeBytes; }; /*\t获取深度缓存的类\t*/ class RENDERER_API DepthCapture { public: /*\t静态成员，当用户发出一个获取深度缓存的请求后，waitForCapture长度加1，新增DepthResult内容为空 当系统完成一个深度缓存的请求后，waitForCapture长度减一 */ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; waitForCapture; /*\t静态成员，当系统完成一个深度缓存的请求后，finishedCapture长度加1， 新增DepthResult含有深度缓存信息\t*/ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; finishedCapture; public: /*用户发出一个获取深度缓存的请求时调用*/ static void AddCapture() { waitForCapture.Enqueue(new DepthResult()); } /*系统完成一个深度缓存请求后调用*/ static void FinishedCapture(DepthResult *result) { finishedCapture.Enqueue(result); } /*返回是否存在已经完成的请求*/ static bool HasFinishedCapture() { return !finishedCapture.IsEmpty(); } /*如果存在已完成的请求，返回一个深度结果*/ static DepthResult* GetIfExistFinished() { DepthResult* result = NULL; if (!finishedCapture.IsEmpty()) { finishedCapture.Dequeue(result); } return result; } /*返回是否存在等待系统执行的请求*/ static bool HasCaptureRequest() { return !waitForCapture.IsEmpty(); } /*如果存在待完成的请求，返回一个深度结果（为空）*/ static DepthResult* GetIfExistRequest() { DepthResult* result = NULL; if (!waitForCapture.IsEmpty()) { waitForCapture.Dequeue(result); } return result; } //friend void AddPostProcessingPasses(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, const FPostProcessingInputs\u0026amp; Inputs); }; /*****************************************end******************************************************/   将下面类中静态成员初始化和添加执行获取代码代码复制到PostProcessing.cpp文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37  /*类静态成员的定义*/ TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::waitForCapture; TQueue\u0026lt; DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::finishedCapture; /*获取深度缓存*/ void AddDepthInspectorPass(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, DepthResult* result) { RDG_EVENT_SCOPE(GraphBuilder, \u0026#34;DepthInspector\u0026#34;); { // 获取渲染对象 \tFSceneRenderTargets\u0026amp; renderTargets = FSceneRenderTargets::Get(GRHICommandList.GetImmediateCommandList()); // 定义拷贝参数 \tuint32 striped = 0; FIntPoint size = renderTargets.GetBufferSizeXY(); result-\u0026gt;bufferSizeX = size.X; result-\u0026gt;bufferSizeY = size.Y; result-\u0026gt;data.AddUninitialized(size.X * size.Y); // 获取视窗某一帧的深度缓存对象 \tFRHITexture2D* depthTexture = (FRHITexture2D *)renderTargets.SceneDepthZ-\u0026gt;GetRenderTargetItem().TargetableTexture.GetReference(); // 执行拷贝深度缓存操作，将GPU显存中的缓存信息拷贝到CPU内存中，返回指向这块CPU内存的首地址 \tvoid* buffer = RHILockTexture2D(depthTexture, 0, EResourceLockMode::RLM_ReadOnly, striped, true); // 将缓存结果拷贝到result，用于输出 \tmemcpy(result-\u0026gt;data.GetData(), buffer, size.X * size.Y * 8); // 必须执行解锁语句，否则被锁住的GPU缓存信息将不能释放 \tRHIUnlockTexture2D(depthTexture, 0, true); // 拷贝结果入队 \tDepthCapture::FinishedCapture(result); } } ////////////////////////////////////////   PostProcessing.cpp中该位置添加以下代码：\n代码如下：\n1 2 3 4 5 6 7 8 9 10  // Capture depth buffer，otherwise the buffer will be changed \tif (DepthCapture::HasCaptureRequest()) { DepthResult *reuslt; reuslt = DepthCapture::GetIfExistRequest(); if (reuslt) { AddDepthInspectorPass(GraphBuilder, View, reuslt); } }   3. 调用 使用以下的代码可以获取深度值，获取的结果为result：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  int tickcount = 0; // Called every frame void ATestPawn::Tick(float DeltaTime) { tickcount++; if (tickcount % 2 == 0)\t// 设计几帧调用  DepthCapture::AddCapture(); // 定时发出获取深度缓存的请求  // 如果存在已完成的深度缓存请求  if (DepthCapture::HasFinishedCapture()) { DepthResult *result; // 获取已完成的深度缓存结果  result = DepthCapture::GetIfExistFinished(); if (result) { int n = result-\u0026gt;data.Num(); //this is test  GEngine-\u0026gt;AddOnScreenDebugMessage(-1, -1, FColor::Blue, FString::Printf(TEXT(\u0026#34;Get Depth Size: %d \u0026#34;), n)); } } }   ","description":"","id":66,"section":"posts","tags":["C++","UE4","Game"],"title":"UE4获取深度值","uri":"https://hugo.jiahongw.com/zh/posts/ue/ue-depth/"},{"content":"探索UE4游戏线程的进入\n游戏线程 \u0026amp; 渲染线程 UE4游戏线程启动 游戏线程每一帧更新所有内容。\n这个tick是哪里打开的？\n头文件：Engine\\Source\\Runtime\\Launch\\Private\\Launch.cpp\nLauch.cpp定义了一个全局的变量FEngineLoop GEngineLoop;\n该类路径：Engine\\Source\\Runtime\\Launch\\Public\\LaunchEngineLoop.h，继承一个接口类IEngineLoop，定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145  /** * Implements the main engine loop.\t*/ class FEngineLoop #if WITH_ENGINE\t: public IEngineLoop #endif{ public: /** Default constructor. */ FEngineLoop(); virtual ~FEngineLoop() { } public: /** * Pre-Initialize the main loop, and generates the commandline from standard ArgC/ArgV from main(). * * @param ArgC The number of strings in ArgV. * @param ArgV The command line parameters (ArgV[0] is expected to be the executable name). * @param AdditionalCommandLine Optional string to append to the command line (after ArgV is put together). * @return Returns the error level, 0 if successful and \u0026gt; 0 if there were errors. */ int32 PreInit(int32 ArgC, TCHAR* ArgV[], const TCHAR* AdditionalCommandline = nullptr); /** * Pre-Initialize the main loop - parse command line, sets up GIsEditor, etc. * * @param CmdLine The command line. * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ int32 PreInit(const TCHAR* CmdLine); /** First part of PreInit. */ int32 PreInitPreStartupScreen(const TCHAR* CmdLine); /** Second part of PreInit. */ int32 PreInitPostStartupScreen(const TCHAR* CmdLine); /** Load all modules needed before Init. */ void LoadPreInitModules(); /** Load core modules. */ bool LoadCoreModules(); /** Clean up PreInit context. */ void CleanupPreInitContext(); #if WITH_ENGINE\t/** Load all core modules needed at startup time. */ bool LoadStartupCoreModules(); /** Load all modules needed at startup time. */ bool LoadStartupModules(); /** * Initialize the main loop (the rest of the initialization). * * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ virtual int32 Init() override; /** Initialize the timing options from the command line. */ void InitTime(); /** Performs shut down. */ void Exit(); /** Whether the engine should operate in an idle mode that uses no CPU or GPU time. */ bool ShouldUseIdleMode() const; // Advances the main loop.推进主循环 \tvirtual void Tick() override; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() override; #endif // WITH_ENGINE  /** RHI post-init initialization */ static void PostInitRHI(); /** Pre-init HMD device (if necessary). */ static void PreInitHMDDevice(); public: /** Initializes the application. */ static bool AppInit(); /** * Prepares the application for shutdown. * * This function is called from within guarded exit code, only during non-error exits. */ static void AppPreExit(); /** * Shuts down the application. * * This function called outside guarded exit code, during all exits (including error exits). */ static void AppExit(); private: /** Utility function that processes Slate operations. */ void ProcessLocalPlayerSlateOperations() const; protected: /** Holds a dynamically expanding array of frame times in milliseconds (if FApp::IsBenchmarking() is set). */ TArray\u0026lt;float\u0026gt; FrameTimes; /** Holds the total time spent ticking engine. */ double TotalTickTime; /** Holds the maximum number of seconds engine should be ticked. */ double MaxTickTime; /** Holds the maximum number of frames to render in benchmarking mode. */ uint64 MaxFrameCounter; /** Holds the number of cycles in the last frame. */ uint32 LastFrameCycles; #if WITH_ENGINE /** Holds the objects which need to be cleaned up when the rendering thread finishes the previous frame. */ FPendingCleanupObjects* PendingCleanupObjects; #endif //WITH_ENGINE  private: #if WITH_ENGINE /** Holds the engine service. */ FEngineService* EngineService; /** Holds the application session service. */ TSharedPtr\u0026lt;ISessionService\u0026gt; SessionService; #endif // WITH_ENGINE \tFPreInitContext PreInitContext; };    该文件只需#include \u0026quot;CoreMinimal.h\u0026quot;，最多加上#include \u0026quot;UnrealEngine.h\u0026quot;\n 接口类，位于路径Engine\\Source\\Runtime\\Engine\\Public\\UnrealEngine.h：\n1 2 3 4 5 6 7 8 9  /** Public interface to FEngineLoop so we can call it from editor or editor code */ class IEngineLoop { public: virtual int32 Init() = 0; virtual void Tick() = 0; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() = 0; };   开启Tick函数之前需要初始化，初始化函数在Launch.cpp这个文件中：\n1 2 3 4 5 6  /* Inits the engine loop */ int32 EngineInit() { int32 ErrorLevel = GEngineLoop.Init(); return( ErrorLevel ); }   GEngineLoop.Init()函数：\n其中会判断是进入那种引擎模式，分为Game模式与Editor模式。\n结束引擎的函数为：\n1 2 3 4 5 6 7 8 9 10  /** * Shuts down the engine */ void EngineExit( void ) { // Make sure this is set \tRequestEngineExit(TEXT(\u0026#34;EngineExit() was called\u0026#34;)); GEngineLoop.Exit(); }   也在Launch.cpp\nLaunch.cpp中的函数多次使用GEngine这个外部变量，这个变量在上面的初始化函数会自定设置为相应的引擎，即Game引擎或者Editor引擎：\n 所在文件Engine.h\n 在FEngineLoop::Tick()函数会调用GEngine的Tick函数：\n也就是本文开始的那个Tick函数。\n","description":"","id":67,"section":"posts","tags":["C++","UE4","Game"],"title":"UE游戏、渲染线程","uri":"https://hugo.jiahongw.com/zh/posts/ue/ue-game-render/"},{"content":"==通常的游戏引擎中游戏线程和渲染线程都是独立的，相互之间会存在一个同步的机制==\nKeyWord: UMG 虚幻示意图形界面设计器（Unreal Motion Graphics UI Designer）(UMG) 是一个可视化的UI创作工具，可以用来创建UI元素，如游戏中的HUD、菜单或您希望呈现给用户的其他界面相关图形。UMG的核心是控件，这些控件是一系列预先制作的函数，可用于构建界面（如按钮、复选框、滑块、进度条等）。这些控件在专门的控件蓝图中编辑，该蓝图使用两个选项卡进行构造：设计器（Designer）选项卡允许界面和基本函数的可视化布局，而图表（Graph）选项卡提供所使用控件背后的功能。\nSlate Slate 是完全自定义、与平台无关的用户界面框架，旨在让工具和应用程序（比如虚幻编辑器）的用户界面或游戏中用户界面的构建过程变得有趣、高效。它将声明性语法与轻松设计、布局和风格组件的功能相结合，允许在UI上轻松实现创建和迭代。\nSlate UI解决方案使得为工具和应用程序组合图形用户界面和快速迭代这些界面变得极其简单。\nRHICmdList 这是一组独特的宏，用于将操作发送到渲染线程进行操作。\n主要是对Texture之类的数据在GPU以及GPU相关的指令进行执行。\n渲染线程的通信 参考链接：\n 《Exploring in UE4》多线程机制详解[原理分析] 纹理和采样器 虚幻4 Task Graph System 介绍  预览 UE4引擎运行时的部分线程，在UE中，许多模块都使用多线程，如渲染模块、物理模块、网络通信、音频系统、IO：\n虽然UE4遵循C++11的标准，但是他并没有使用std::thread，而是自己实现了一套多线程机制（应该是从UE3时代就有了，未考证），用法上很像Java。\n使用线程 在UE4里面，使用线程有三个方法：\n 我们可以自己继承FRunnable接口创建单个线程 直接创建AsyncTask来调用线程池里面空闲的线程 通过TaskGraph系统来异步完成一些自定义任务。  FRunnable 线索：\n   模块 Core     .h /Engine/Source/Runtime/Core/Public/HAL/Runnable.h   include #include \u0026ldquo;HAL/Runnable.h\u0026rdquo;     UE4中最基础的模型就是FRunnable和FRunnableThread，FRunnable抽象出一个可以执行在线程上的对象，而FRunnableThread是平台无关的线程对象的抽象。后面的篇幅会详细讨论这些基础设施。\n 创建一个继承于FRunnable的类，FRunnable声明如下：\n FRunnable就是一个很简单的类，里面只有5，6个函数接口，为了与真正的线程区分，我这里称FRunnable为“线程执行体”；所谓真正的线程其实就是FRunnableThread，不同平台的线程都继承自他，如FRunnableThreadWin，里面会调用Windows平台的创建线程的API接口。\n 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59  class CORE_API FRunnable { public: /** * Initializes the runnable object. * * This method is called in the context of the thread object that aggregates this, not the * thread that passes this runnable to a new thread. * * @return True if initialization was successful, false otherwise * @see Run, Stop, Exit */ virtual bool Init() { return true; } /** * Runs the runnable object. * * This is where all per object thread work is done. This is only called if the initialization was successful. * * @return The exit code of the runnable object * @see Init, Stop, Exit */ virtual uint32 Run() = 0; /** * Stops the runnable object. * * This is called if a thread is requested to terminate early. * @see Init, Run, Exit */ virtual void Stop() { } /** * Exits the runnable object. * * Called in the context of the aggregating thread to perform any cleanup. * @see Init, Run, Stop */ virtual void Exit() { } /** * Gets single thread interface pointer used for ticking this runnable when multi-threading is disabled. * If the interface is not implemented, this runnable will not be ticked when FPlatformProcess::SupportsMultithreading() is false. * * @return Pointer to the single thread interface or nullptr if not implemented. */ virtual class FSingleThreadRunnable* GetSingleThreadInterface( ) { return nullptr; } /** Virtual destructor */ virtual ~FRunnable() { } };   FRunnable与线程之间的关系类图：\nUE4中的多线程模型用一句话概括为: A FRunnable runs on a FRunnableThread.\n FQueuedThreadPool线程池    模块 Core      /Engine/Source/Runtime/Core/Public/Misc/QueuedThreadPool.h    #include \u0026ldquo;Misc/QueuedThreadPool.h\u0026rdquo;    FQueuedThreadPool。和一般的线程池实现类似，线程池里面维护了多个线程FQueuedThread与多个任务队列IQueuedWork，线程是按照队列的方式来排列的。\n在线程池里面所有的线程都是FQueuedThread类型，不过更确切的说FQueuedThread是继承自FRunnable的线程执行体，每个FQueuedThread里面包含一个FRunnableThread作为内部成员。\n相比一般的线程，FQueuedThread里面多了一个成员FEvent* DoWorkEvent，也就是说FQueuedThread里面是有一个事件触发机制的。那么这个事件机制的作用是什么？一般情况下来说，就是在没有任务的时候挂起这个线程，在添加并分配给该线程任务的时候激活他，不过你可以灵活运用它，在你需要的时候去动态控制线程任务的执行与暂停。\n AsyncTask系统 AsyncTask系统是一套基于线程池的异步任务处理系统。\nFAsyncTask有几个特点：\n FAsyncTask是一个模板类，真正的AsyncTask需要你自己写。通过DoWork提供你要执行的具体任务，然后把你的类作为模板参数传过去 使用FAsyncTask就默认你要使用UE提供的线程池FQueuedThreadPool，前面代码里说明了在引擎PreInit的时候会初始化线程池并返回一个指针GThreadPool。在执行FAsyncTask任务时，如果你在执行StartBackgroundTask的时候会默认使用GThreadPool线程池，当然你也可以在参数里面指定自己创建的线程池 创建FAsyncTask并不一定要使用新的线程，你可以调用函数StartSynchronousTask直接在当前线程上执行任务 FAsyncTask本身包含一个DoneEvent，任务执行完成的时候会激活该事件。当你想等待一个任务完成时再做其他操作，就可以调用EnsureCompletion函数，他可以从队列里面取出来还没被执行的任务放到当前线程来做，也可以挂起当前线程等待DoneEvent激活后再往下执行  Task Graph 系统 Task Graph 系统是UE4一套抽象的异步任务处理系统，可以创建多个多线程任务，指定各个任务之间的依赖关系，按照该关系来依次处理任务。\nTick函数\n平时调试的时候，我们随便找个Tick断点一下都能看到类似下图这样的函数堆栈。如果你前面的章节都看懂的话，这个堆栈也能大概理解。World在执行Tick的时候，触发了FNamedTaskThread线程去执行任务（FTickFunctionTask），任务FTickFunctionTask具体的工作内容就是执行ACtorComponent的Tick函数。其实，这个堆栈也说明了所有Actor与Component的Tick都是通过TaskGraph系统来执行的（在TG_PrePhysics阶段）。\nCconclusion ==对于消耗大的，复杂的任务不建议使用TaskGraph，一是因为TaskGraph如果被分配到游戏线程，就会阻塞整个游戏线程的执行，二是即使你不在那几个有名字的线程上执行，也可能会影响到游戏的其他逻辑。==\n全家福：\n线程同步 UE4对操作系统提供的线程同步相关接口进行了一定的封装。\nAtomics \u0026hellip;\u0026hellip;\n","description":"","id":68,"section":"posts","tags":["UE","C++"],"title":"UE4多线程","uri":"https://hugo.jiahongw.com/zh/posts/ue/ue-thread-commuicate/"},{"content":"UE4问题汇总   UE4光照构建失败⚠\nhttps://blog.csdn.net/earlyAutumnOfRain/article/details/80863561\n  UE4导入灰度图\nhttps://www.cnblogs.com/gucheng/p/10116857.html\n  详解UE4静态库与动态库的导入与使用\nhttps://gameinstitute.qq.com/community/detail/121551\n  Ue4_序列化浅析_\nhttps://blog.csdn.net/mohuak/article/details/83027211\n  UE快捷键\nhttps://www.unrealengine.com/zh-CN/tech-blog/designer-s-guide-to-unreal-engine-keyboard-shortcuts\n  UE4资源加载（一）从StaticLoadObject开始\nhttp://suo.im/6v7hUc\n  Unreal Cookbook：创建对象的的几种姿势（C++）\nhttps://blog.csdn.net/Neil3D/article/details/51488401\n  Aery的UE4 C++游戏开发之旅（1）基础对象模型\nhttps://www.cnblogs.com/KillerAery/p/11986316.html\n  目录结构\nhttps://docs.unrealengine.com/zh-CN/Engine/Basics/DirectoryStructure/index.html\n  引擎世界\nhttps://www.engineworld.cn/\n  《InsideUE4》GamePlay架构（一）Actor和Component\nhttps://zhuanlan.zhihu.com/p/22833151\n  实时渲染中的坐标系变换（5）：投影变换-3\nhttps://zhuanlan.zhihu.com/p/115395322\n  UE4 屏幕坐标转换到世界坐标\nhttps://blog.csdn.net/weixin_36412907/article/details/77306212\n  UE4必读文章列表_个人整理\nhttps://zhuanlan.zhihu.com/p/126611976\n  OpenGL 学习系列\u0026mdash;投影矩阵\nhttps://juejin.im/post/5b0ec5fef265da092a2b79b1\n  Alpha Test\nhttp://geekfaner.com/shineengine/blog13_OpenGLESv2_12.html\n  Rendoc使用\nhttps://www.cnblogs.com/kekec/p/11760288.html\n  [多视图几何] - 逆透视变换\nhttps://blog.csdn.net/chishuideyu/article/details/79136903\n  UE4必读文章列表_个人整理\nhttps://zhuanlan.zhihu.com/p/126611976\n  UE4中的Tone Mapping\nhttps://www.dingshukai.com/blog/ue4-tone-mapping.html\n  UE4 渲染流程\nhttps://blog.csdn.net/or_7r_ccl/article/details/81102771\n  [UE4]尝试使用自定义深度 fq\nhttp://monsho.blog63.fc2.com/blog-entry-138.html#comment469\n  [UE4]扩展GBuffer\nhttp://monsho.blog63.fc2.com/blog-entry-191.html\n  https://ue4study-osaka.connpass.com/event/120568/\n  UE4文件系统  模块是UE4的构建块。引擎是以大量模块的集合形式实现的，游戏提供自己的模块来扩充自己。每个模块都封装了一组功能，并且可以提供公共接口和编译环境（包括宏、路径等）供其他模块使用。\n .build.cs文件的典型结构如下。\n1 2 3 4 5 6 7 8 9  using UnrealBuildTool; using System.Collections.Generic; public class MyModule : ModuleRules { public MyModule(ReadOnlyTargetRules Target) : base(Target) { // Settings go here  } }     \\Engine\\Source\\ThirdParty目录\n存放第三方的库\n  F:\\UnrealEngine4.14\\Engine\\Plugins目录(或者F:\\UE4Project\\项目名称\\Plugins目录)\n保存插件的目录\n  UE创世，万物皆UObject，接着有Actor。\nComponent和Actor  UE4让Actor们轻装上阵，只提供一些通用的基本生存能力，而把众多的“技能”抽象成了一个个“Component”并提供组装的接口，让Actor随用随组装，把自己武装成一个个专业能手。\n 相关组件 RootComponent 定义这个演员在世界上的变换(位置、旋转、缩放)的组件，所有其他组件必须以某种方式附加到这个组件\n弹簧臂组件 弹簧臂组件用于自动控制摄像机受阻时的应对方式。\nUE文件存储的方式 UE 中使用统一的格式存储资源 (uasset， umap)，每个 uasset 对应一个包 (package)，存储一个 UPackage 对象时，会将该包下的所有对象都存到 uasset 中。\n 一个资源在文件中对应uasset，在内存中对应为UPackage。\n uasset文件格式  File Summary 文件头信息 Name Table 包中对象的名字表 Import Table 存放被该包中对象引用的其它包中的对象信息(路径名和类型) Export Table 该包中的对象信息(路径名和类型) Export Objects 所有Export Table中对象的实际数据。  FlinkerLoad FLinkerLoad是作为uasset和内存UPackage的中间桥梁。在加载内容生成UPackage的时候，UPackage会根据名字找到uasset文件，由FLinkerLoad来负责加载。\nFLinkerLoad主要内容如下：\n FArchive* Loader;\t//Loader负责读取具体文件 TArray ImportMap; //将uasset的ImportTable加载到ImportMap中，FObjectImport是需要依赖（导入）的UObject TArray ExportMap; //FObjectExport是这个UPackage所拥有的UObject（这些UObject都能提供给其他UPackage作为Import）  StaticLoadObject加载 步骤：\n 根据文件名字创建一个空的包（没有任何文件相关的数据） 建立一个LinkerLoad去加载对应的uasset文件 序列化。 优先加载ImportMap 加载ExportMap（本身的数据）  1、建立一个UPackage\n2、序列化uasset\n3、加载ImportMap\nPawn默认组件 UE相机 http://www.geodesic.games/2019/03/27/projection-matrices-in-unreal-engine/\n Firstly, Unreal inverses the perspective divide, applying 1 instead of -1 for the “W” value.（虚幻处理投影与 Unity 中使用的标准 OpenGL 透视矩阵不同。） Secondly, Unreal applies a matrix transposition to all their perspective matrices.（其次，Unreal 对所有的透视矩阵进行了矩阵移位。  缺省情况下，Unreal 提供了各种方便的透视矩阵构造函数。 有两种变体，一种是普通透视矩阵，另一种是逆向透视矩阵。  右手坐标系： https://zhuanlan.zhihu.com/p/114729671\n透视投影：\n归一化齐次坐标以后的结果是：\n camera space 3D空间中，相同的x，z越大，投影变换以后的x分量越靠近0。\u0026ldquo;近大远小\u0026quot;的透视效果，就是这么算出来的。\n  Unity的投影矩阵，是把视锥内的所有3D坐标，转换到 [-1,1] 范围之内。最后转化为Screen Space，范围为[0,1]\n 深度值是到近平面的距离：\n正交投影：\n 透视投影变换，有\u0026quot;近大远小\u0026quot;的透视效果。3D空间中的两条平行线，在投影变换以后会相交于某个\u0026quot;灭点\u0026rdquo;。\n正交投影变换，没有\u0026quot;近大远小\u0026quot;的透视效果。3D空间中的两条平行线，在投影变换以后，仍旧是平行的。\n Unreal 正交矩阵：\n UE4里的透视投影矩阵的计算方式，参见引擎源代码的OrthoMatrix.h文件。\n 代码1：\n1  UGameplayStatics::DeprojectScreenToWorld(UGameplayStatics::GetPlayerController(GetWorld(), 0), forwardCursorPos, forwardWorldPos, forwardMoveDirection);   代码2：\n1 2 3  FVector forwardMoveDirection; GetWorld()-\u0026gt;GetFirstPlayerController()-\u0026gt;GetMousePosition(forwardCursorPos.X, forwardCursorPos.Y); UGameplayStatics::DeprojectScreenToWorld(UGameplayStatics::GetPlayerController(GetWorld(), 0), forwardCursorPos, forwardWorldPos, forwardMoveDirection);    APlayerController 玩家控制器被人类玩家用来控制棋子。地址 ULocalPlayer 当前客户端上的每个玩家都有一个LocalPlayer。地址 FViewportClient 视窗客户端的抽象接口。地址 ViewportClient 在玩家中包含此玩家视图的主视窗.。 地址 ULocalPlayer::GetProjectionData 用于导出投影所需的各种数据位的辅助函数。 地址  bianxngjing:\nhttps://v.qq.com/x/page/t0770a2b6f6.html\nAPI UGameplayStatics::DeprojectScreenToWorld  Unity 与 NGUI 坐标转换原理   将给定的2D屏幕空间坐标转换为3D世界空间点和方向。\nAPI地址： https://docs.unrealengine.com/en-US/API/Runtime/Engine/Kismet/UGameplayStatics/DeprojectScreenToWorld/index.html\n语法：\n1 2 3 4 5 6 7  static bool DeprojectScreenToWorld ( APlayerController const * Player,\t// 玩家视角  const FVector2D \u0026amp; ScreenPosition,\t// 2D点  FVector \u0026amp; WorldPosition,\t// 世界空间三维坐标 输出  FVector \u0026amp; WorldDirection\t// 在给定的2d点上远离相机的世界空间方向矢量。\t输出 )   源码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22  bool UGameplayStatics::DeprojectScreenToWorld(APlayerController const* Player, const FVector2D\u0026amp; ScreenPosition, FVector\u0026amp; WorldPosition, FVector\u0026amp; WorldDirection) { // 获取LocalPlayer \tULocalPlayer* const LP = Player ? Player-\u0026gt;GetLocalPlayer() : nullptr; if (LP \u0026amp;\u0026amp; LP-\u0026gt;ViewportClient) {//ViewpoetClient 包含此玩家视图的主视窗。 \t// get the projection data \tFSceneViewProjectionData ProjectionData; //立体渲染通过。FULL表示此过程中未启用立体渲染，eSSP_FULL \tif (LP-\u0026gt;GetProjectionData(LP-\u0026gt;ViewportClient-\u0026gt;Viewport, eSSP_FULL, /*out*/ ProjectionData)) {// 获取投影数据 \tFMatrix const InvViewProjMatrix = ProjectionData.ComputeViewProjectionMatrix().InverseFast(); FSceneView::DeprojectScreenToWorld(ScreenPosition, ProjectionData.GetConstrainedViewRect(), InvViewProjMatrix, /*out*/ WorldPosition, /*out*/ WorldDirection); return true; } } // something went wrong, zero things and return false，错误不管 \tWorldPosition = FVector::ZeroVector; WorldDirection = FVector::ZeroVector; return false; }   逆透视变换 投影矩阵：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43  // Projection data for a FSceneView struct FSceneViewProjectionData { FVector ViewOrigin;\t//源视图向量 \t/** Rotation matrix transforming from world space to view space. */ FMatrix ViewRotationMatrix;\t// 从世界空间到视图空间的旋转矩阵转换。 \t/** UE4 projection matrix projects such that clip space Z=1 is the near plane, and Z=0 is the infinite far plane. */ FMatrix ProjectionMatrix;\t// UE4投影矩阵投影使得剪辑空间Z=1是近平面，Z=0是无限远平面。 protected: //The unconstrained (no aspect ratio bars applied) view rectangle (also unscaled) \tFIntRect ViewRect;\t// 无约束(未应用宽高比条)视图矩形(也未缩放) \t// The constrained view rectangle (identical to UnconstrainedUnscaledViewRect if aspect ratio is not constrained) \tFIntRect ConstrainedViewRect;\t// 受约束的视图矩形(如果长宽比不受约束，则与UnconstrainedUnscaledViewRect相同) public: void SetViewRectangle(const FIntRect\u0026amp; InViewRect) { ViewRect = InViewRect; ConstrainedViewRect = InViewRect; } void SetConstrainedViewRectangle(const FIntRect\u0026amp; InViewRect) { ConstrainedViewRect = InViewRect; } // 上面两个函数设置Rect窗口  bool IsValidViewRectangle() const {//判断窗口是否有效 \treturn (ConstrainedViewRect.Min.X \u0026gt;= 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Min.Y \u0026gt;= 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Width() \u0026gt; 0) \u0026amp;\u0026amp; (ConstrainedViewRect.Height() \u0026gt; 0); } bool IsPerspectiveProjection() const {// 判断是不是透视投影矩阵 \treturn ProjectionMatrix.M[3][3] \u0026lt; 1.0f; } const FIntRect\u0026amp; GetViewRect() const { return ViewRect; } const FIntRect\u0026amp; GetConstrainedViewRect() const { return ConstrainedViewRect; } FMatrix ComputeViewProjectionMatrix() const {// 计算视图投影矩阵 \treturn FTranslationMatrix(-ViewOrigin) * ViewRotationMatrix * ProjectionMatrix; } };   上面平移矩阵：\n1 2 3 4 5 6 7 8  FORCEINLINE FTranslationMatrix::FTranslationMatrix(const FVector\u0026amp; Delta)\t//基于给定向量的构造函数转换矩阵，//转置矩阵 \t: FMatrix( FPlane(1.0f,\t0.0f,\t0.0f,\t0.0f), FPlane(0.0f,\t1.0f,\t0.0f,\t0.0f), FPlane(0.0f,\t0.0f,\t1.0f,\t0.0f), FPlane(Delta.X,\tDelta.Y,Delta.Z,1.0f) ) { }   难点一：GetProjectionData函数\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141  bool ULocalPlayer::GetProjectionData(FViewport* Viewport, EStereoscopicPass StereoPass, FSceneViewProjectionData\u0026amp; ProjectionData) const { // If the actor  //Size为分配给此玩家的主视口子区域的大小。0-1  // Viewport-\u0026gt;GetSizeXY()获取视端的X与Y \tif ((Viewport == NULL) || (PlayerController == NULL) || (Viewport-\u0026gt;GetSizeXY().X == 0) || (Viewport-\u0026gt;GetSizeXY().Y == 0) || (Size.X == 0) || (Size.Y == 0)) { return false; } // 将浮点数转换为截断值接近零的整数。即向下取整  // Origin为分配给该玩家的主视口子区域左上角的坐标。0-1 \tint32 X = FMath::TruncToInt(Origin.X * Viewport-\u0026gt;GetSizeXY().X); int32 Y = FMath::TruncToInt(Origin.Y * Viewport-\u0026gt;GetSizeXY().Y); // 加上视端初始的坐标值 \tX += Viewport-\u0026gt;GetInitialPositionXY().X; Y += Viewport-\u0026gt;GetInitialPositionXY().Y; //新的窗口大小 \tuint32 SizeX = FMath::TruncToInt(Size.X * Viewport-\u0026gt;GetSizeXY().X); uint32 SizeY = FMath::TruncToInt(Size.Y * Viewport-\u0026gt;GetSizeXY().Y); //X=0,Y = 0 #if !(UE_BUILD_SHIPPING || UE_BUILD_TEST) // We expect some size to avoid problems with the view rect manipulation \t// 我们希望有一定的大小来避免view rect操作的问题 \tif(SizeX \u0026gt; 50 \u0026amp;\u0026amp; SizeY \u0026gt; 50) { int32 Value = CVarViewportTest.GetValueOnGameThread();\t//根据value的值分类各种视端  if(Value) { int InsetX = SizeX / 4; int InsetY = SizeY / 4; // this allows to test various typical view port situations (todo: split screen)  // 这允许测试各种典型的视图端口情况(todo:分割屏幕) \tswitch(Value) { case 1: X += InsetX; Y += InsetY; SizeX -= InsetX * 2; SizeY -= InsetY * 2;break; case 2: Y += InsetY; SizeY -= InsetY * 2; break; case 3: X += InsetX; SizeX -= InsetX * 2; break; case 4: SizeX /= 2; SizeY /= 2; break; case 5: SizeX /= 2; SizeY /= 2; X += SizeX;\tbreak; case 6: SizeX /= 2; SizeY /= 2; Y += SizeY; break; case 7: SizeX /= 2; SizeY /= 2; X += SizeX; Y += SizeY; break; } } } #endif\t// FIntRect为二维空间中整数矩形的结构。新的视端矩阵 \tFIntRect UnconstrainedRectangle = FIntRect(X, Y, X+SizeX, Y+SizeY);//InMin(X,Y),InMax(X+SizeX,Y+SizeY) \t// 设置投影数据的窗口 \tProjectionData.SetViewRectangle(UnconstrainedRectangle); // Get the viewpoint.  // 获得视点 \tFMinimalViewInfo ViewInfo; //结构  /** enum EStereoscopicPass { eSSP_FULL, eSSP_LEFT_EYE, eSSP_RIGHT_EYE, eSSP_LEFT_EYE_SIDE, eSSP_RIGHT_EYE_SIDE, } **/ GetViewPoint(/*out*/ ViewInfo, StereoPass);\t//检索该玩家的视点。  // If stereo rendering is enabled, update the size and offset appropriately for this pass  // 如果启用了立体渲染，请为此过程适当更新大小和偏移 \tconst bool bNeedStereo = IStereoRendering::IsStereoEyePass(StereoPass) \u0026amp;\u0026amp; GEngine-\u0026gt;IsStereoscopic3D(); const bool bIsHeadTrackingAllowed = GEngine-\u0026gt;XRSystem.IsValid() \u0026amp;\u0026amp; GEngine-\u0026gt;XRSystem-\u0026gt;IsHeadTrackingAllowed(); if (bNeedStereo) { GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;AdjustViewRect(StereoPass, X, Y, SizeX, SizeY); } // scale distances for cull distance purposes by the ratio of our current FOV to the default FOV  // 根据我们当前的FOV与默认FOV的比率，为选择距离的目的缩放距离 \tPlayerController-\u0026gt;LocalPlayerCachedLODDistanceFactor = ViewInfo.FOV / FMath::Max\u0026lt;float\u0026gt;(0.01f, (PlayerController-\u0026gt;PlayerCameraManager != NULL) ? PlayerController-\u0026gt;PlayerCameraManager-\u0026gt;DefaultFOV : 90.f); FVector StereoViewLocation = ViewInfo.Location; // 加入立体渲染或者  if (bNeedStereo || bIsHeadTrackingAllowed) {// 假如启用了立体渲染和头部追踪 \tauto XRCamera = GEngine-\u0026gt;XRSystem.IsValid() ? GEngine-\u0026gt;XRSystem-\u0026gt;GetXRCamera() : nullptr;\t//虚拟现实相机 \tif (XRCamera.IsValid()) { AActor* ViewTarget = PlayerController-\u0026gt;GetViewTarget(); const bool bHasActiveCamera = ViewTarget \u0026amp;\u0026amp; ViewTarget-\u0026gt;HasActiveCameraComponent(); XRCamera-\u0026gt;UseImplicitHMDPosition(bHasActiveCamera); } if (GEngine-\u0026gt;StereoRenderingDevice.IsValid()) { GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;CalculateStereoViewOffset(StereoPass, ViewInfo.Rotation, GetWorld()-\u0026gt;GetWorldSettings()-\u0026gt;WorldToMeters, StereoViewLocation); } } // Create the view matrix  // 创建视图矩阵  // FPlane 三维平面的结构。(X,Y,Z,W)  // FMatrix 浮点值的4x4矩阵。 \tProjectionData.ViewOrigin = StereoViewLocation; ProjectionData.ViewRotationMatrix = FInverseRotationMatrix(ViewInfo.Rotation) * FMatrix( FPlane(0,\t0,\t1,\t0), FPlane(1,\t0,\t0,\t0), FPlane(0,\t1,\t0,\t0), FPlane(0,\t0,\t0,\t1)); // @todo viewext this use case needs to be revisited  // 重新考虑viewext \tif (!bNeedStereo)\t//假如没有立体渲染 \t{ // Create the projection matrix (and possibly constrain the view rectangle)  // 创建投影矩阵(并可能约束视图矩形)  // ViewInfo视点 \tFMinimalViewInfo::CalculateProjectionMatrixGivenView(ViewInfo, AspectRatioAxisConstraint, Viewport, /*inout*/ ProjectionData);//计算给定视图投影矩阵 \t// 视图扩展对象可以在没有运动控制器组件的情况下保留在渲染线程上，大概是设置相关试图拓展的投影矩阵 \tfor (auto\u0026amp; ViewExt : GEngine-\u0026gt;ViewExtensions-\u0026gt;GatherActiveExtensions()) { ViewExt-\u0026gt;SetupViewProjectionMatrix(ProjectionData); }; } else {\t// 有三维渲染 \t// Let the stereoscopic rendering device handle creating its own projection matrix, as needed  // 让立体渲染设备根据需要处理创建自己的投影矩阵，调用一系列函数GetProjectMatrix \tProjectionData.ProjectionMatrix = GEngine-\u0026gt;StereoRenderingDevice-\u0026gt;GetStereoProjectionMatrix(StereoPass); // calculate the out rect \tProjectionData.SetViewRectangle(FIntRect(X, Y, X + SizeX, Y + SizeY)); } return true; }   难点：计算给定视图投影矩阵\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78  void FMinimalViewInfo::CalculateProjectionMatrixGivenView(const FMinimalViewInfo\u0026amp; ViewInfo, TEnumAsByte\u0026lt;enum EAspectRatioAxisConstraint\u0026gt; AspectRatioAxisConstraint, FViewport* Viewport, FSceneViewProjectionData\u0026amp; InOutProjectionData) { // Create the projection matrix (and possibly constrain the view rectangle)  // 创建投影矩阵(并可能约束视图矩形) \tif (ViewInfo.bConstrainAspectRatio) { // Enforce a particular aspect ratio for the render of the scene. \t// Results in black bars at top/bottom etc. \tInOutProjectionData.SetConstrainedViewRectangle(Viewport-\u0026gt;CalculateViewExtents(ViewInfo.AspectRatio, InOutProjectionData.GetViewRect())); InOutProjectionData.ProjectionMatrix = ViewInfo.CalculateProjectionMatrix(); } else { // Avoid divide by zero in the projection matrix calculation by clamping FOV \tfloat MatrixFOV = FMath::Max(0.001f, ViewInfo.FOV) * (float)PI / 360.0f; float XAxisMultiplier; float YAxisMultiplier; const FIntRect\u0026amp; ViewRect = InOutProjectionData.GetViewRect(); const int32 SizeX = ViewRect.Width(); const int32 SizeY = ViewRect.Height(); // if x is bigger, and we\u0026#39;re respecting x or major axis, AND mobile isn\u0026#39;t forcing us to be Y axis aligned \tif (((SizeX \u0026gt; SizeY) \u0026amp;\u0026amp; (AspectRatioAxisConstraint == AspectRatio_MajorAxisFOV)) || (AspectRatioAxisConstraint == AspectRatio_MaintainXFOV) || (ViewInfo.ProjectionMode == ECameraProjectionMode::Orthographic)) { //if the viewport is wider than it is tall \tXAxisMultiplier = 1.0f; YAxisMultiplier = SizeX / (float)SizeY; } else { //if the viewport is taller than it is wide \tXAxisMultiplier = SizeY / (float)SizeX; YAxisMultiplier = 1.0f; } if (ViewInfo.ProjectionMode == ECameraProjectionMode::Orthographic) {\t//判断投影模式 \tconst float OrthoWidth = ViewInfo.OrthoWidth / 2.0f * XAxisMultiplier; const float OrthoHeight = (ViewInfo.OrthoWidth / 2.0f) / YAxisMultiplier; const float NearPlane = ViewInfo.OrthoNearClipPlane; const float FarPlane = ViewInfo.OrthoFarClipPlane; const float ZScale = 1.0f / (FarPlane - NearPlane); const float ZOffset = -NearPlane; InOutProjectionData.ProjectionMatrix = FReversedZOrthoMatrix( // 计算反向Z正交矩阵 \tOrthoWidth, OrthoHeight, ZScale, ZOffset );\t} else { InOutProjectionData.ProjectionMatrix = FReversedZPerspectiveMatrix(\t// 反转Z透视矩阵 \tMatrixFOV, MatrixFOV, XAxisMultiplier, YAxisMultiplier, GNearClippingPlane, GNearClippingPlane ); } } if (!ViewInfo.OffCenterProjectionOffset.IsZero()) { const float Left = -1.0f + ViewInfo.OffCenterProjectionOffset.X; const float Right = Left + 2.0f; const float Bottom = -1.0f + ViewInfo.OffCenterProjectionOffset.Y; const float Top = Bottom + 2.0f; InOutProjectionData.ProjectionMatrix.M[2][0] = (Left + Right) / (Left - Right); InOutProjectionData.ProjectionMatrix.M[2][1] = (Bottom + Top) / (Bottom - Top); } }   反向Z正交：\n1 2 3 4 5 6 7 8  FORCEINLINE FReversedZOrthoMatrix::FReversedZOrthoMatrix(float Width,float Height,float ZScale,float ZOffset) : FMatrix( FPlane((Width != 0.0f) ? (1.0f / Width) : 1.0f, 0.0f, 0.0f, 0.0f), FPlane(0.0f, (Height != 0.0f) ? (1.0f / Height) : 1.f, 0.0f, 0.0f), FPlane(0.0f, 0.0f, -ZScale, 0.0f), FPlane(0.0f, 0.0f, 1.0f - ZOffset * ZScale, 1.0f) ) { }   难点2：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53  void FSceneView::DeprojectScreenToWorld(const FVector2D\u0026amp; ScreenPos, const FIntRect\u0026amp; ViewRect, const FMatrix\u0026amp; InvViewProjMatrix, FVector\u0026amp; out_WorldOrigin, FVector\u0026amp; out_WorldDirection) { float PixelX = FMath::TruncToFloat(ScreenPos.X); float PixelY = FMath::TruncToFloat(ScreenPos.Y); // Get the eye position and direction of the mouse cursor in two stages (inverse transform projection, then inverse transform view).  // //分两个阶段获取鼠标光标的眼睛位置和方向(逆变换投影，然后逆变换视图)。  // This avoids the numerical instability that occurs when a view matrix with large translation is composed with a projection matrix \t// //这避免了当具有大平移的视图矩阵由投影矩阵组成时出现的数值不稳定性  // Get the pixel coordinates into 0..1 normalized coordinates within the constrained view rectangle  // 将像素坐标转换为0..1约束视图矩形内的标准化坐标 \tconst float NormalizedX = (PixelX - ViewRect.Min.X) / ((float)ViewRect.Width()); const float NormalizedY = (PixelY - ViewRect.Min.Y) / ((float)ViewRect.Height()); // Get the pixel coordinates into -1..1 projection space  // 将像素坐标转换为-1..1投影空间 \tconst float ScreenSpaceX = (NormalizedX - 0.5f) * 2.0f; const float ScreenSpaceY = ((1.0f - NormalizedY) - 0.5f) * 2.0f; // The start of the ray trace is defined to be at mousex,mousey,1 in projection space (z=1 is near, z=0 is far - this gives us better precision)  // //光线跟踪的开始被定义为在投影空间中mousex，mousey，1处(z = 1是近的，z=0是远的-这给了我们更好的精度) \t// To get the direction of the ray trace we need to use any z between the near and the far plane, so let\u0026#39;s use (mousex, mousey, 0.5)  // //为了得到光线轨迹的方向，我们需要使用近平面和远平面之间的任何z，所以让我们使用(mousex，mousey，0.5) \tconst FVector4 RayStartProjectionSpace = FVector4(ScreenSpaceX, ScreenSpaceY, 1.0f, 1.0f); const FVector4 RayEndProjectionSpace = FVector4(ScreenSpaceX, ScreenSpaceY, 0.5f, 1.0f); // Projection (changing the W coordinate) is not handled by the FMatrix transforms that work with vectors, so multiplications  // //投影(改变w坐标)不是由处理向量的矩阵变换来处理的，所以乘法  // by the projection matrix should use homogeneous coordinates (i.e. FPlane).  // 由投影矩阵应使用齐次坐标(即平面)。 \tconst FVector4 HGRayStartWorldSpace = InvViewProjMatrix.TransformFVector4(RayStartProjectionSpace); const FVector4 HGRayEndWorldSpace = InvViewProjMatrix.TransformFVector4(RayEndProjectionSpace); FVector RayStartWorldSpace(HGRayStartWorldSpace.X, HGRayStartWorldSpace.Y, HGRayStartWorldSpace.Z); FVector RayEndWorldSpace(HGRayEndWorldSpace.X, HGRayEndWorldSpace.Y, HGRayEndWorldSpace.Z); // divide vectors by W to undo any projection and get the 3-space coordinate  // //将向量除以w以撤销任何投影并获得3-空间坐标 \tif (HGRayStartWorldSpace.W != 0.0f) { RayStartWorldSpace /= HGRayStartWorldSpace.W; } if (HGRayEndWorldSpace.W != 0.0f) { RayEndWorldSpace /= HGRayEndWorldSpace.W; } const FVector RayDirWorldSpace = (RayEndWorldSpace - RayStartWorldSpace).GetSafeNormal(); // Finally, store the results in the outputs \tout_WorldOrigin = RayStartWorldSpace; out_WorldDirection = RayDirWorldSpace; }   FPlane:\nFMatrix:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  FORCEINLINE FMatrix::FMatrix(const FPlane\u0026amp; InX,const FPlane\u0026amp; InY,const FPlane\u0026amp; InZ,const FPlane\u0026amp; InW) { M[0][0] = InX.X; M[0][1] = InX.Y; M[0][2] = InX.Z; M[0][3] = InX.W; M[1][0] = InY.X; M[1][1] = InY.Y; M[1][2] = InY.Z; M[1][3] = InY.W; M[2][0] = InZ.X; M[2][1] = InZ.Y; M[2][2] = InZ.Z; M[2][3] = InZ.W; M[3][0] = InW.X; M[3][1] = InW.Y; M[3][2] = InW.Z; M[3][3] = InW.W; } FORCEINLINE FMatrix::FMatrix(const FVector\u0026amp; InX,const FVector\u0026amp; InY,const FVector\u0026amp; InZ,const FVector\u0026amp; InW) { M[0][0] = InX.X; M[0][1] = InX.Y; M[0][2] = InX.Z; M[0][3] = 0.0f; M[1][0] = InY.X; M[1][1] = InY.Y; M[1][2] = InY.Z; M[1][3] = 0.0f; M[2][0] = InZ.X; M[2][1] = InZ.Y; M[2][2] = InZ.Z; M[2][3] = 0.0f; M[3][0] = InW.X; M[3][1] = InW.Y; M[3][2] = InW.Z; M[3][3] = 1.0f; }   step1:\nAPI UGameplayStatics::ProjectWorldToScreen 将给定的3D世界空间点转换为其2D屏幕空间坐标。\nAPI地址： https://docs.unrealengine.com/en-US/API/Runtime/Engine/Kismet/UGameplayStatics/ProjectWorldToScreen/index.html\n语法：\n1 2 3 4 5 6 7  static bool ProjectWorldToScreen ( APlayerController const * Player, const FVector \u0026amp; WorldPosition, FVector2D \u0026amp; ScreenPosition, bool bPlayerViewportRelative\t//这是否应该与玩家视窗子区域相关(在分割屏幕中使用玩家附加的小部件时很有用) )   Z-Buffer 用Renderdoc对UE4(PC，DX11）截帧，UE4的版本为4.18. 可以看到UE4一帧画面的渲染过程如下\n获取GBuffer的一种方式 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  ENQUEUE_UNIQUE_RENDER_COMMAND_ONEPARAMETER( DZRenderSutioBP_InterceptSceneBaseColor, UTexture2D*, vTextureAsset, TextureAsset, { /*if (!IsInRenderingThread()) return;*/ FRHICommandListImmediate\u0026amp; RHICmdList = GRHICommandList.GetImmediateCommandList(); //计数加一避免Render完成后直接清空了GBuffer,但会慢一帧，你猜 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, 1); static const FString ScrollingMessage(TEXT(\u0026#34;Hello World: \u0026#34;)); GEngine-\u0026gt;AddOnScreenDebugMessage(-1, 0.2f, FColor::Red, ScrollingMessage); FSceneRenderTargets\u0026amp; SceneContext = FSceneRenderTargets::Get(RHICmdList); if (SceneContext.GBufferA) { FTexture2DRHIRef vTextTarget = SceneContext.GetGBufferATexture(); FString vSiceStr = FString::Printf(TEXT(\u0026#34;FSceneRenderTargets GBufferA Size = %d*%d\u0026#34;), vTextTarget-\u0026gt;GetSizeX(), vTextTarget-\u0026gt;GetSizeY()); GEngine-\u0026gt;AddOnScreenDebugMessage(-1, 0.2f, FColor::Red, vSiceStr); } //移除 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, -1); } );   How to export FTexture2DRHIRef to png?\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  class SceneDepthCapture { public: TArray\u0026lt;FLinearColor\u0026gt; sceneDepthData; FIntPoint bufferSize; void SceneDepthCaptureSync() { ENQUEUE_RENDER_COMMAND(ReadSurfaceFloatCommand)( [this](FRHICommandListImmediate\u0026amp; RHICmdList) { FSceneRenderTargets\u0026amp; context = FSceneRenderTargets::Get(RHICmdList); bufferSize = context.GetBufferSizeXY(); FIntRect Rect(0, 0, bufferSize.X, bufferSize.Y); RHICmdList.ReadSurfaceData( context.GetSceneDepthTexture(), Rect, sceneDepthData, FReadSurfaceDataFlags()); }); FlushRenderingCommands(); } };   使用模块的方式 使用模块\n添加自定义Pass的方法  添加Shader  了解了一个Pass要完成的工作，我们就可以动手实现一个自己的 Pass 了。首先要确定的问题是 Shader。既然要把同一个模型画两次，那必然要用到不同的Shader。关于如何在UE4中添加 Shader，可以参考 DepthPass 的 VS/PS(在DepthRendering.h中) 和 UE4 的官方文档：https://docs.unrealengine.com/en-US/Programming/Rendering/ShaderDevelopment/index.html。MobileBasePass的Shader因为涉及环境光，点光源数等可开关的Defination，所以对应的 C++ 类是以 template 的形式实现的。一般来说自定义 Pass 的 Shader 会继承 FMaterialShader 并用 IMPLEMENT_MATERIAL_SHADER_TYPE 宏来绑定对应的 usf 文件。 可以完全自己写新的 usf 文件，也可以在 FMaterialShader::ModifyCompilationEnvironment() 中应用不同的 SetDefine() 来实现不同的 Shader。需要注意的是 UE4 的 Shader 编译是一个比较漫长的过程，所以最好在 FMaterialShader::ShouldCompilePremutation() 中对材质进行筛选，只编译必要的Shader。否则所有的 Material 都会编译对应的 Shader，效率很低。还有注意 Shader 要在构造函数中绑定需要的 Uniform Buffer，在 GetShaderBinding 中绑定对应的UniformBuffer，否则会出现 ResourceMiss。\n2. 添加 MeshProcessor\n根据对UE4的渲染流程分析我们可以看出，Pass 生成 DrawCall 的主要逻辑是在 MeshProcessor 中完成的。MeshProcessor 是 4.22 中新加入的类名，之前对应的是 DrawingPolicy。添加 MeshProcessor 很简单，只需要继承 FMeshPassProcessor 并复写其 AddMeshBatch() 方法即可。一般我们会在 AddMeshBatch 方法中获取 Material Resource 的信息并对 MeshBatch 做进一步筛选，最后调用 Process 方法绑定 Shader，Mesh 和 Material，计算 Mesh 的 CullMode，ZTest，Zwrite，BlendOP 和 SortKey等等并用 BuildMeshCommands 生成 DrawCall。\n3. 添加 Pass\n所有的 Pass 都可以在 Enum EMeshPass中找到，所以第一步就是在 MeshProcessor.h 的 EMeshPass 中添加对应的 Enum。然后我们要为 Pass 创建对应的 MeshProcessor，我们可以在对应 .cpp 文件中实现对应 MeshProcessor 的 Creator 方法，并定义对应的 FRegisterPassProcessorCreatFunction 在其构造函数中传入对应的 Creator 方法指针和 Pass Enum。这一部分可以参考 MobileBasePass.cpp 最后的 CreateMobileBasePassProcessor 和 RegisterMobileBasePass 部分。之后我们就要在 MobileSceneRenderer 的 Render 方法中插入自定义 Pass 的渲染流程，这一部分主要是一些 Profile 标签和 RHICmdList 的Setup 和 Flush，还有生成 Pass 的多线程 DrawTask。这一部分逻辑可以参考 MobileBasePassRendering.cpp 中的 RenderMobileBasePass 方法。\n","description":"虚幻引擎相关问题","id":69,"section":"talks","tags":[""],"title":"UE4 Problems","uri":"https://hugo.jiahongw.com/zh/talks/ue4-talks/"},{"content":"大概介绍以下UE4的主要渲染过程。\nUE4渲染过程 延迟渲染 所谓延迟渲染，是指将一个场景的几何体（3D模型、多边形）的光照、阴影、质感搁置到一旁，先着手于绘画，然后在后半段再对光照、阴影、质感进行处理的处理方式。即给人一种把原本的多边形先绘制出来的印象，实际上不仅要绘制多边形，前者的参数还需要配合后面光照和阴影的处理。其输出目标，在成为复数缓冲时具有普遍性，但是这里的缓冲我们称之为\u0026quot;物理缓冲\u0026rdquo;。物体缓冲是指使用后照明和后处理特效的中间过渡环节\n相关术语 RHI\n渲染硬件接口，是为不同平台抽象出不同图形API的一层。所有渲染命令均通过RHI层传递，以转换为适用的渲染器。\n延迟渲染\n虚幻引擎4中的默认渲染器。它因将照明/阴影计算推迟到全屏过程而不是绘制每个网格时而得名。\n顶点工厂\n顶点工厂是封装顶点数据源并链接到顶点着色器上的输入的类。静态网格物体，骨架网格物体和过程网格组件均使用不同的顶点工厂。\n着色器\n在虚幻引擎中，着色器是HLSL代码（以.ush / .usf文件的形式）和材质图的内容的组合。在Unreal中创建材质时，它会根据设置（如着色模式）和用法来编译多个着色器排列。\n渲染数据 相关的渲染的数据包括深度值及一些Gbuffer，如下图：\n几个Pass Z Pre Pass UE4的渲染管道，是在Bass Pass的物体缓冲写出来之前，在仅预处理深度值（Z值）之后，运行Z预阶段。\n事先预处理深度值的目的，是将最终影像和同一深度缓冲的内容结果，在透视前获得。Z预阶段之后的Base Pass则是，参考预先得出的深度值缓冲进行Z预测试，因此通过在最终的画面里不留下像素痕迹（即编写后又被消去的像素），以回避像素着色器的运行。\nBase Pass\n使用Base Pass输出物体缓冲需要注意的两点：\n  不绘制没进入视线的对象\n这种\u0026quot;投影剔除\u0026rdquo;（Frustum Culling），一般是通过CPU端来处理；为了整体覆盖被称为\u0026quot;包围球\u0026rdquo;（Bounding sphere）的各个3D对象，对象是否在视野内的判定标准，是通过预先设定的包围球来实行的。\n 什么程度的剔除会成功，可以通过Stat初始视图（Stat InitViews）指令的\u0026quot;视锥体裁剪基元（Frustum Culled Primitives）\u0026ldquo;进行确认。\n   不计算多余的像素\n在图像处理的流程中，使用像素着色器实际处理前，会有运行深度测试（Z 测试）的\u0026quot;Pre Z 测试\u0026quot;这一步骤。从这里着手处理的像素，会因为被某个东西所遮挡而无法绘制出来，这时可以进行撤销处理。\n 但是，像半透明对象这种会伴随α测试的绘制、视差遮蔽映射这种像素着色器处理后会重新编写深度值的情况，就不进行Pre Z测试，而通过处理实行分路迂回。\n    UE4 绘制策略DrawingPolicy\n绘制策略在UE4渲染中使用很多， 中文也不好翻译。 其实就是根据策略 使用了哪些 着色器 。\n \u0026hellip;\u0026hellip;\u0026hellip;.\nUE4渲染一帧 渲染管道 首先，虚幻的渲染由三个线程共同完成。分别是CPU线程，DRAW线程，和GPU线程。\n知乎：https://zhuanlan.zhihu.com/p/57158725\nRender模块 调用Render()函数在Render模块RendererModule.h中，以下函数：\n1 2 3 4 5  class FRendererModule : public IRendererModule { // 开始渲染视图族  virtual void BeginRenderingViewFamily(FCanvas* Canvas,FSceneViewFamily* ViewFamily) override; }   ==谁最终调用了Render？==\n实时渲染流程图： part1:https://i.loli.net/2020/05/30/qU8vN2WZVbt9hkF.jpg\npart2:https://i.loli.net/2020/05/30/3trKVpOMU5sTQfB.jpg\n渲染函数Render 路径：Engine \\ Source \\ Runtime \\ Renderer \\ Private \\ DeferredShadingRenderer.cpp（660）\n函数：FDeferredShadingSceneRenderer :: Render（）渲染路径\n   全局系统纹理初始化 DeferredShadingRenderer.cpp（677） GSystemTextures.InitializeTextures（）     保护 必要的渲染目标您是否已确保可以保护的最大目标数目？ DeferredShadingRenderer.cpp（680） GSceneRenderTargets.Allocate（）   初始化每个视口 设置视口显示的对象，选择使用动态阴影时显示的对象，对半透明对象进行排序 DeferredShadingRenderer.cpp（683） InitViews()（）   FXSystem预处理 GPU粒子正在被仿真 DeferredShadingRenderer.cpp（758） FXSystem-\u0026gt; PreRender（）   启用Z Pre-Pass时执行的早期Z绘制 不绘制Tile渲染的硬件（移动设备，Android或iOS）对于 PC或PS4，将生成深度缓冲区和HiZ，因此后续绘制速度很快成为？ DeferredShadingRenderer.cpp（768） RenderPrePass（）   安全GBuffer DeferredShadingRenderer.cpp（774） GSceneRenderTargets.AllocGBufferTargets（）   透明光传播量 DeferredShadingRenderer.cpp（779） ClearLPVs（）   使用DBuffer时绘制延期贴图单击此处获取 DBuffer和延期贴图 DeferredShadingRenderer.cpp（796） GCompositionLighting.ProcessBeforeBasePass（）   如有必要，请 在绘制线框图时清除GBuffer透明颜色缓冲区， 有些游戏在发行游戏时无法清除GBuffer或屏幕。 DeferredShadingRenderer.cpp（805） SetAndClearViewGBuffer（） DeferredShadingRenderer.cpp（816） RHICmdList.Clear（）   渲染不透明的对象渲染 项目，这些项目根据它们是Masked还是Default，是否有LightMap等按每种排序顺序进行了精细分类 DeferredShadingRenderer.cpp（828） RenderBasePass（）   清除 GBuffer 的未绘制部分如果事先清除GBuffer，则不必要。 DeferredShadingRenderer.cpp（851） ClearGBufferAtMaxZ（）   绘制 自定义深度请参见此处以获取自定义深度 DeferredShadingRenderer.cpp（860） RenderCustomDepthPass（）   在这里再次模拟GPU粒子除了在这里 处理使用深度缓冲区执行碰撞检测的 粒子外，还对GPU粒子进行排序 DeferredShadingRenderer.cpp（865） 场景-\u0026gt; FXSystem-\u0026gt; PostRenderOpaque（）   为SceneDepthTexture创建一个半分辨率（每个方面为1/4分辨率）的缓冲区 DeferredShadingRenderer.cpp（875） UpdateDownsampledDepthSurface（）   执行阻塞测试 HZB的构建，执行提交 的HZB Attotempkinder的这篇文章指 DeferredShadingRenderer.cpp（881） BeginOcclusionTests（）   开始写 因为有点复杂，所以要写一些细节 DeferredShadingRenderer.cpp（890）   不使用DBuffer绘制延迟的贴图 CompositionLighting.cpp（293） AddDeferredDecalsBeforeLighting（）   在屏幕空间中绘制环境光遮挡 CompositionLighting.cpp（300） AddPostProcessingAmbientOcclusion（）   后期处理环境立方体贴图 CompositionLighting.cpp（305） AddPostProcessingAmbientCubemap（）   到这里为止的一系列处理 DeferredShadingRenderer.cpp（904） GCompositionLighting.ProcessAfterBasePass（）   透明的体积光缓冲液可提高透明度 DeferredShadingRenderer.cpp（908） ClearTranslucentVolumeLighting（）   从此处开始的主要照明设备 收集要绘制的灯光并将其排序 不要投影，不使用灯光功能的灯光将使用“ 基于图块” 绘制（如果可能）如果不能使用“ 基于图块”关于延迟渲染，这是味o，但请参见此处 LightRendering.cpp（312-348） LightRendering.cpp（423） RenderTiledDeferredLighting（） LightRendering.cpp（429） RenderSimpleLightsStandardDeferred（）   它不会阴影，也不会使用灯光功能，但是似乎无法使用TBDR绘制的灯光 被称为标准延迟灯光。 LightRendering.cpp（445） RenderLight（）   如果用于半透明的体积光是有效的，则将每个光注入到体积光中 ，从而在3D纹理上绘制光效果。 LightRendering.cpp（455） InjectTranslucentVolumeLightingArray（） LightRendering.cpp（461） InjectSimpleTranslucentVolumeLightingArray（）   使用灯光功能投射阴影的灯光将单独处理 LightRendering.cpp（468-552）   首先，我在投射阴影时 绘制了一个阴影贴图；在这里我还绘制了一个 半透明的阴影贴图；我记得半透明的当然是傅立叶不透明度贴图。 LightRendering.cpp（495） RenderTranslucentProjectedShadows（） LightRendering.cpp（497） RenderProjectedShadows（）   使用LPV时绘制反射阴影贴图 LightRendering.cpp（508） RenderReflectiveShadowMaps（）   灯光功能图 阴影指示器图 LightRendering.cpp（515） RenderLightFunction（） LightRendering.cpp（522） RenderPreviewShadowsIndicator（）   衰减缓冲器中的分辨 光的衰减信息是否曾经被吸入另一个缓冲器中？ LightRendering.cpp（534） GSceneRenderTargets.FinishRenderingLightAttenuation（）   注入体积光以获得半透明 LightRendering.cpp（541） InjectTranslucentVolumeLighting（）   这 是使用光功能投射阴影的光处理的结束。 LightRendering.cpp（550） RenderLight（）   这 是每个光的LPV 的主要注入照明过程的结尾 LightRendering.cpp（561-593） Lpv-\u0026gt; InjectLightDirect（）   注入体积光以实现环境立方体贴图的半透明 DeferredShadingRenderer.cpp（916） InjectAmbientCubemapTranslucentVolumeLighting（）   过滤体积光以获得半透明 DeferredShadingRenderer.cpp（919） FilterTranslucentVolumeLighting（）   LPV传输过程 此外，第921行的注释上写有“ copypimis”，例如“ Clear LPV buffer”。 DeferredShadingRenderer.cpp（924） PropagateLPVs（）   动态天光绘图 DeferredShadingRenderer.cpp（928） RenderDynamicSkyLighting（）   延迟的反射图形 捕获的反射图形而不是屏幕空间 DeferredShadingRenderer.cpp（931） RenderDeferredReflections（）   LPV的GI绘图 CompositionLighting.cpp（344） AddPostProcessingLpvIndirect（）   屏幕空间次表面散射（SSSSS）的后处理 CompositionLighting.cpp（347-376）   如果启用了“光轴”，则绘制“光轴遮挡” DeferredShadingRenderer.cpp（953） RenderLightShaftOcclusion（）   大气雾图 DeferredShadingRenderer.cpp（977） RenderAtmosphere（）   绘图雾 这是高度雾吗？ DeferredShadingRenderer.cpp（986） RenderFog（）   画一个半透明的物体 在这里也画一个单独的半透明的东西 DeferredShadingRenderer.cpp（1000） RenderTranslucency（）   折射变形处理 DeferredShadingRenderer.cpp（1008） RenderDistortion（）   光轴的起霜处理 DeferredShadingRenderer.cpp（1013） RenderLightShaftBloom（）   距离场AO处理不能在 当前不支持多个视口 的分屏游戏中使用吗？ DeferredShadingRenderer.cpp（1019） RenderDistanceFieldAOSurfaceCache（）   它只是在查看网格的“距离场”的可视化处理结果吗？ DeferredShadingRenderer.cpp（1024） RenderMeshDistanceFieldVisualization（）   由于速度模糊而绘制运动对象的速度 DeferredShadingRenderer.cpp（1034） RenderVelocities（）   从这里到最后的发布过程， 这也很复杂而且很长 DeferredShadingRenderer.cpp（1047） GPostProcessing.Process（）   使用BeforeTranslucency设置绘制后处理材料 PostProcessing.cpp（878） AddPostProcessMaterial（）   景深处理 通过高斯模糊进行DOF 处理之后，正在执行散焦处理（使用指定的光圈形状的纹理进行绘制）， 在此阶段似乎合并了单独的半透明缓冲区 PostProcessing.cpp（888） AddPostProcessDepthOfFieldGaussian（） PostProcessing.cpp（898） AddPostProcessDepthOfFieldBokeh（） PostProcessing.cpp（905） FRCPassPostProcessBokehDOFRecombine （如果未启用模糊）   使用BeforeTonemapping设置绘制后处理材料 PostProcessing.cpp（913） AddPostProcessMaterial（）   如果要使用TemporalAA ，请在此处绘制，如果使用FXAA，请稍后再绘制 PostProcessing.cpp（921） AddTemporalAA（） PostProcessing.cpp（928） AddTemporalAA（） （如果不使用速度缓冲区，请单击此处）   运动模糊处理 设置，分辨率下采样，高斯模糊，运动模糊绘制，组合处理 PostProcessing.cpp（932-994） FRCPassPostProcessMotionBlurSetup FRCPassPostProcessDownsample RenderGaussianBlur（） FRCPassPostProcessMotionBlur FRCPassPostProcessMotionBlurRecombine   SceneColor下采样 PostProcessing.cpp（1000） FRCPassPostProcessDownsample   直方图 PostProcessing.cpp（1006-1040） FRCPassPostProcessHistogram FRCPassPostProcessHistogramReduce   此处需要眼睛适应图直方图 PostProcessing.cpp（1046） AddPostProcessEyeAdaptation（）   布卢姆绘图 PostProcessing.cpp（1057） AddBloom（） PostProcessing.cpp（1060-1148） （对于移动设备，请单击此处）   色调映射 仅替换ReplacecingTonemapper设置工程图的一种后处理材料，但是 如果存在该材料，则执行默认色调映射 PostProcessing.cpp（1155） AddSinglePostProcessMaterial（） PostProcessing.cpp（1171） AddTonemapper（） （默认色调映射）   如果启用了FXAA，请在此处处理 PostProcessing.cpp（1177） AddPostProcessAA（）   绘制一些编辑器（如选定的轮廓）， 然后使用AfterTonemapping设置绘制后期处理材料 PostProcessing.cpp（1244） AddPostProcessMaterial（）   用于地下和GBuffer的可视化 调试 PostProcessing.cpp（1246-1254）   用于HMD的后处理 Oculus或Morpheus PostProcessing.cpp（1256-1277） FRCPassPostProcessHMD FRCPassPostProcessMorpheus   之后，调试和高分辨率屏幕截图功能等。 之后，进行后处理并结束！ 谢谢！ PostProcessing.cpp（1279-）    哦，很长。\n参考链接：\n  如何在C ++中从UTexture2D读取数据\n  https://forums.unrealengine.com/development-discussion/c-gameplay-programming/1422920-casting-converting-frhitexture-to-utexture\n  Unreal渲染相关的缓冲区\n  https://qiita.com/mechamogera/items/a0c369a3b853a3042cae\n  https://answers.unrealengine.com/questions/17862/access-color-and-depth-buffer-of-each-frame.html\n  https://segmentfault.com/a/1190000012737548\n  Gbuff数据\n  渲染系统概述 图片\n  ","description":"","id":70,"section":"posts","tags":["C++","UE4","Game"],"title":"UE4渲染过程","uri":"https://hugo.jiahongw.com/zh/posts/ue/ue4-render/"},{"content":"RSA算法 RSA加密算法是一种非对称加密算法，在公开密钥加密和电子商业中被广泛使用。\n 对极大整数做因数分解的难度决定了 RSA 算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用 RSA 加密的信息的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的 RSA 钥匙才可能被强力方式破解。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被破解的。\n 公钥/双密钥/非对称 加密 涉及到两个密钥的使用:\n 一个公钥, 可以被任何人知道，用于加密消息和验证签名 一个私钥, 只有接收方才知道，用于解密消息和创造签名  RSA实现过程 1. 公钥与私钥的产生 生成公钥e和私钥d的步骤如下：\n 随意选择两个大的质数$p$和$q$，$p$不等于$q$，计算$n=pq$。 根据欧拉函数，求$r = \\varphi (N) = \\varphi (p)\\varphi (q) = (p - 1)(q - 1)$ 选择一个小于$r$的整数$e$，使$e$与$r$互质。并求得$e$关于$r$的模反元素，命名为$d$(求$d$令$ed \\equiv 1(\\bmod ;r)$)。(模反元素存在，当且仅当$e$与$r$互质) 将$p$和$q$的记录销毁  经过上面四个步骤最终可以得到公钥$(n,e)$和私钥$(n,d)$。\n接收消息的人将自己的公钥$(n,e)$发送给发送消息的人,发送的人使用这个公钥加密信息发送给接收方，而接收方将私钥$(n,d)$保存起来用于解密。\n下面实现RSA类\n 参考资料：\n 米勒-拉宾素性检验 RSA加密算法 C++实现   实验步骤与结果 1.实现大整数类 因为该加密算法涉及的数可能很大，而C++中并没有像Java一样，内置大整数类BigInteger，故需自己实现，这里我参考了网上的一些资料设计了BigInteger类，实现了加减乘除以及模幂等运算，也实现了运算符重载，具体参考实现的方法如下：\n2. 设计RSA类 编写rsa.h头文件，定义RSA类，其中包含的成员以及成员函数如下：\n下面分别实现上述的各个方法\n首先要生成密钥对，即生成公钥和私钥，那么，我们首先需要生成两个大素数p和q,显然，素数是不可能是偶数的，故定义一个生成随机奇数的函数BigInteger createOddNum(unsigned len)参数为奇数的长度。\n使用16进制的随机字母，然后随机选取其中的len/4个得到一个随机的大奇数，只需要末尾那个数为奇数即可，最后返回BigInteger类型的奇数大整数，关键代码如下：\n然后定义一个生成素数的函数，其中用到米勒-拉宾素性检验算法判断生成的素数是否为素数素数：\n米勒-拉宾素性检测算法 基于以下定理：\n 费马小定理  要测试$N$是否为素数，首先将$N−1$分解为$2^{s}d$。在每次测试开始时，先随机选一个介于$[1,N−1]$的整数$a$，之后如果对所有的$r∈[0,s−1]$，若${a^d}\\bmod N \\ne 1$且${a^{{2^r}d}}\\bmod N \\ne - 1$，则$N$是合数。否则，$N$有$3/4$的概率为素数。\n关键代码如下：\n生成素数的逻辑就是首先使用函数createOddNum生成一个大奇数，然后调用isPrime判断是否为一个素数，是的话就可以return，不然继续寻找，知道生成一个素数。\n接下来计算n值，n值的计算很简单，直接使用$n = p * q$ 这个式子就能够计算出来；计算欧拉值也一样，可以使用$\\varphi(n) = (p-1) * (q-1)$得出。其中比较难的是生成的私钥d。\n下面定义一个RSA类的初始化函数init()​，生成p、q以及密钥对，如下：\n在创建公钥e和私钥d的函数createExponent(eul)中，首先创建一个比欧拉值小的公钥e，其中e为一个素数，直接调用函数createPrime()生成，然后使用大整数类中的求模逆元，即求出私钥d。\n扩展欧几里得算法  逆元\n逆元是模运算中的一个概念，我们通常说 A 是 B 模 C 的逆元，实际上是指 A * B = 1 mod C，也就是说 A 与 B 的乘积模 C 的余数为 1。可表示为 A = B^(-1) mod C。\n打个比方，7 模 11 的逆元，即：7^(-1) mod 11 = 8，这是因为 7 × 8 = 5 × 11 + 1，所以说 7 模 11 的逆元是 8。\n 扩展欧几里得算法是欧几里得算法（又叫辗转相除法）的扩展。已知整数a、b，扩展欧几里得算法可以在求得a、b的最大公约数的同时，能找到整数x、y（其中一个很可能是负数），使它们满足贝祖等式\n$$\nax{\\rm{ }} + {\\rm{ }}by{\\rm{ }} = {\\rm{ }}gcd\\left( {a,b} \\right).\n$$\n在RSA算法中求私钥中的整数d时，需要使得 (e * d ) % n = 1，该方程等价于 e * d = 1 + y * n （y为整数），也等价于 e * d - y * n = 1。\n因此求解d的过程就是求解该二元一次方程组（e和n已知，求解d），即求e模n的逆元。\n关键代码如下：\n我们知道，RSA的加密与解密其实就是一个模幂的运算，而这个模幂的运算已经在大整数类中实现了，如下：\n使用RSA类进行加密解密的函数只需要调用这个模幂运算即可，例如私钥加密可以这样调用：\n以上就设计完了RSA类的相关操作，主要是包括密钥的生成。下面将RSA加密解密的操作封装在一个类中。\n3. 设计加密解密类EncryptDecrypt 主要的方法及成员如下：\n实现RSA加密解密字符串 加密字符串的逻辑是，先将字符串以每两个字符 一组，转化为一个16进制数据序列，使用vector容器保存，之后调用rsa的公钥加密函数进行加密，如下是关键代码：\n解密函数其实是接受一个加密后的16进制序列，然后对这个序列调用RSA的私钥解密函数进行解密，然后得到解密后的16进制数据序列，最后还有一步就是需要将这个16进制序列最终转化为原来的字符串，只需要根据ascii码的数值即可得到，这里编写了一个hex2string函数，关键代码如下：\n实现效果\n首先显示密钥：\n加密字符串\n解密字符串\n实现RSA加密解密文件 实现RSA加密解密文件时基于RSA加密解密字符串实现的，其中主要的加密逻辑就是将一个文件看作是一行一行的字符串文本，没每读取一行，就调用加密字符串的函数进行加密，然后将加密得到的16进制序列写入到另外一个文件中，而这个文件也就是加密后的文件，主要关键代码如下：\n解密文件的函数稍微有点不一样，是从打开的待解密文件中循环读取每一个16进制数据，然后对每一个16进制数据调用解密函数得到解密后的16进制数据，将16进制数据转为字符串后再相继的写到另外一个文件中，即解密后的文件，关键代码如下：\n实现效果\n加密文件\n解密文件\n加密文件解密文件对比\n实现RSA数字签名及验证 实现数字签名方案，按照以下的流程图进行操作。\n首先需要对文件进行信息的摘要，得到Hash值，这里选择的Hash算法是SHA512算法，可以直接对文件进行信息摘要。\n可以直接include C++ 实现的\u0026quot;sha512.h\u0026quot;文件头，然后使用以下的语句就能够生成一个长度为512的Hash值，如下：\n可以在命令行输出文件的Hash摘要值如下:\n数字签名的实现类似字符串加密，对文件的hash值进行加密得到后面的16进制序列，然后将16进制序列伴随文件发送出去，签名的关键代码就是对hash值进行加密，如下：\n验证函数直接将16进制序列进行解密，然后还原成字符串再与收到的文件的hash值进行比较，如果相等，那么验证成功；否则验证失败，关键代码如下：\n实现效果\n数字签名\n验证数字签名\n","description":"","id":71,"section":"posts","tags":["rsa"],"title":"RSA加密算法","uri":"https://hugo.jiahongw.com/zh/posts/cryptography/rsa/"},{"content":"费马大定理在数学里有一个特殊的现象，即在于它是错误证明数量最多的数学题。\n费马小定理 费马小定理是数论中的一个定理：假如$a$是一个整数，$p$是一个质数，那么$a^{p}-a$是$p$的倍数，可以表示为\n$$\na^{p} \\equiv a \\pmod p\n$$\n当a不是p的倍数时也可以表示为\n$$\na^{p-1} \\equiv 1 \\pmod p\n$$\n 同余符号\n两个整数a，b，若它们除以正整数m所得的余数相等，则称a，b对于模m同余\n记作$a \\equiv b\\pmod {m}$\n读作a同余于b模m，或读作a与b关于模m同余。\n比如$26 \\equiv 14 \\pmod{12}$\n 一种证明：\n考虑一根有 [公式] 颗珠子的项链，其每颗珠子有 [公式] 种染色选择，然后由下图蕴含的精神可得原命题成立。\n费马大定理 当整数$n\u0026gt;2$时，关于$x, y, z$的不定方程\n$$\nx^{n} + y^{n} = z^{n}\n$$\n没有整数解\n","description":"费马大定理、费马小定理","id":72,"section":"posts","tags":["费马"],"title":"费马🦓定理","uri":"https://hugo.jiahongw.com/zh/posts/math/feima/"},{"content":"操作流程 用到的云产品及服务            序号 云产品 功能及用途 备注   1 容器镜像仓库 用于存放示例demo镜像    2 云编译 编译和打包实例demo代码，同时将镜像推送至容器镜像仓库    3 私有网络 创建用于Kubernetes集群，工作节点所需的VPC    4 Access Key 授权K8S集群访问京东智联云各个服务API的授权凭证。 例如：集群向京东智联云监控中心，推送业务监控数据就需要用到AK/SK。   5 Kubernetes集群 创建K8S集群，部署应用服务 规格：通用型1核4GB，公网IP 5Mpbs   6 云监控 查询业务监控数据，配置告警服务。     实操 第一步：准备Docker镜像 创建容器镜像仓库 新建注册表\n  登录京东智联云控制台，选择云服务-\u0026gt;弹性计算-\u0026gt;容器镜像仓库。\n  进入注册表页面，选择“华北-北京”地域，点击“新建”按钮，进入新建注册表页面。\n  在新建注册表页面，设置名称，勾选同意服务条款。点击“保存”按钮即可。\n  新建镜像仓库\n  切换至“镜像仓库”列表页面，选择地域“华北-北京”，点击“创建”按钮。\n  在新建镜像仓库页面， 选择刚新建的注册表，配置注册表名称信息\n  创建成功后，在镜像仓库里列表可以看到到仓库名称。以及镜像仓库的URI\n  编译构建Docker镜像 新建编译任务\n  选择云服务-\u0026gt;开发者工具-\u0026gt;云编译，进入云编译服务页面。\n  在任务列表页面，选择华北-北京地域， 点击“创建”按钮，选择中“创建任务”\n  在创建任务页面做如下配置：\n任务配置与源码配置如下，其中代码库地址为:https://code.jdcloud.com/jdcloud-monitor/prometheus-demo.git\n构建存放的配置如下：\n其他选项保持默认配置\n  点击“保存”按钮，完成任务的创建。\n  构建任务\n  选中刚创建的任务，点击操作了下的执行构建按钮。\n  在弹出的构建页面，配置如下信息,其中CommitID为ece523fc68cce1cd3d48b38fc07252f81ba2c44c\n  点击“确定”按钮，执行编译构建操作。当产物归档状态变为完成状态时，完成构建。\n  第二步：用K8S部署应用服务 前提准备 创建kubernetes进群时，需要用到VPC 和 密钥信息， 只需创建VPC即可，无需创建子网，工作节点组用到的子网会自己创建。\n创建VPC\n  选择云服务-\u0026gt;网络-\u0026gt;私有网络，进入私有网络VPC列表页面。\n  在私有网络页面，选中华北-北京地域，点击“创建”按钮。\n  配置网络名称，IPv4CIRD选择 192.168.0.0/16。\n  创建AK/SK密钥\n  点击顶部导航的账户名称，在弹出的下拉框中点击“Access Key管理”\n  在进入的Access Key管理页面中，点击“创建Access Key”，会提示输入短信验证码，输入完就可以创建了\n  创建Kubernetes集群   选择云服务-\u0026gt;弹性计算-\u0026gt; Kubernetes集群，进入集群列表页面。\n  选择“华北-北京”地域，点击“创建”按钮，在新建Kubernetes集群，进行如下配置\n集群信息配置\n网络与工作节点配置\n密码配置\n  部署服务 注册镜像仓库\n 本操作是将容器镜像仓库的注册表在K8S服务中进行注册，便于后续pod上部署应用服务。\n   选择云服务-\u0026gt;弹性计算-\u0026gt; 云主机，进入云主机列表页面。在云主机列表可以看到新创建了2台云主机实例。\n  找到k8s-***-nat-vm-***命名的云主机，其为K8S集群的管理节点云主机， 可以公网SSH远程登录进去。\n  获取集群凭据， 选择云服务-\u0026gt;弹性计算-\u0026gt; Kubernetes集群, 进入集群列表页面。选中刚创建的集群信息，点击名称，进入详情页面。切换至kubectl客户端配置页。\n  管理节点登录成功后，ssh 登录至 k8s-node-*** 节点的云主机（**命令： ssh root@your_node_ip, 需要将 your_node_ip 替换为你的node云主机的内网ip。点击回车后输入密码即可** ）。\n  配置kubectl客户端\n执行如下的命令\n1 2 3 4 5  mkdir -p $HOME/.kube cd $HOME/.kube vi config   将kubectl客户端配置的凭据，拷贝至config中，保存后退出。执行 sudo chown $(id -u):$(id -g) $HOME/.kube/config 命令。\n  执行以下操作命名，注册镜像仓库。\nkubectl create secret -n default docker-registry my-secret --docker-server=k8s-monitor-demo01-cn-north-1.jcr.service.jdcloud.com --docker-username=jdcloud --docker-password=Eoj3Ja4mSeXasAbX --docker-email=1427298682@qq.com 输入指令如下：\n  创建Pod\n  在kubernetes集群页面，菜单切换至Workloads-\u0026gt;Pod，进入Pod列表页面。点击创建pod\n  配置如下信息\na. 集群：请确认刚创建的集群，例如：monitor-demo\nb. Yaml 文件：将如下内容拷贝至黑色输入框，注意黄色标注内容。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  apiVersion:v1kind:Podmetadata:name:prometheus-demolabels:app:prometheus-demospec:imagePullSecrets:- name:my-secretcontainers:- name:flaskapp-demoimage:k8s-monitor-demo01-cn-north-1.jcr.service.jdcloud.com/k8s-monitor-demo-repo:job-ANbzZdjyyYKEBRX-1587872493ports:- containerPort:5000- containerPort:7777   注意：\n  name：为您注册镜像仓库创建的secret名称，示例用的my-secret。\n  image 标注为黄色的内容包含2个部分，URI:镜像版本，请一定要替换为自己镜像仓库的内容。可通过如下截图位置获取。\n     创建Pod  可以看到创建的pod，进入pod详情，切换至Container可以查看其运行状态，等待3分钟左右，其状态变为运行，服务部署成功。\n  配置访问策略 创建Service\n 注：基于K8S部署的应用服务，若需要外网访问，则需要创建一个负载均衡，同时绑定公网IP，以下步骤就是通过创建Service为服务配置一个负载均衡。\n   切换至service列表页面，选择“华北-北京”，点击“创建”按钮。\n  进入创建Service页面\n配置如下信息\na. 集群：确认选中的集群。\nb. Yaml：将如下信息拷贝至输入框中。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31  kind:ServiceapiVersion:v1metadata:name:prometheus-demoannotations:prometheus.io/path:/metricsprometheus.io/port:\u0026#39;7777\u0026#39;prometheus.io/scrape:\u0026#39;true\u0026#39;spec:ports:- protocol:TCPport:5000targetPort:5000selector:app:prometheus-demotype:LoadBalancer    点击“确定”按钮，完成service创建。点击名称，进入详情页面，可查看到pod状态为running。\n  点击顶部导航云服务-\u0026gt;网络-\u0026gt;负载均衡，进入应用负载均衡页面。可以看到刚新建的的LoadBalancer。\n  访问服务\n  在新建的负载均衡服务页面，获取到公网IP， 在浏览器端输入http://公网IP:5000，可看到如下界面。\n  第三步：业务监控告警 查看监控图   选择云服务-\u0026gt;监控与运维-\u0026gt; 云监控，进入云监控控制台。\n  在左侧菜单选中“自定义监控”，进入自定义监控页面。\n   输入以下查询条件，可以看到Demo示例内置采集的一些业务数据。查询条件如下：\n  配置告警   在上述查看的的监控图中，点击“配置报警”按钮，进入设置告警页面，进行如下配置：\n基本信息配置\n触发条件配置\n通知策略配置\n  上面配置完之后当访问页面次数超过10此的时候就会有邮件和短信的通知\n邮件\n短信\n","description":"","id":73,"section":"posts","tags":["云计算","京东云"],"title":"使用云监控管理k8s-京东云实践","uri":"https://hugo.jiahongw.com/zh/posts/cloudcomputing/cloud-kubernetes/"},{"content":"[toc]\n1. 鲲鹏云服务 鲲鹏处理器与服务器 鲲鹏处理器 华为鲲鹏处理器是华为自主研发的基于ARM架构的企业级系列处理器产品，包含“算、存、传、管、智”五个产品系统体系。\n架构介绍： 华为鲲鹏处理器基于ARM架构。ARM是一种CPU架构，有别于Intel、AMD CPU采用的CISC复杂指令集，ARM CPU采用RISC精简指令集（reduced instruction set computer，精简指令集计算机）。\n处理器对比：\n优点：  采用ARM架构，同样功能性能占用的芯片面积小、功耗低、集成度更高，更多的硬件CPU核具备更好的并发性能。 支持16位、32位、64位多种指令集，能很好的兼容从IOT、终端到云端的各类应用场景。 大量使用寄存器，大多数数据操作都在寄存器中完成，指令执行速度更快。 采用RISC指令集，指令长度固定，寻址方式灵活简单，执行效率高。  规格发展 华为鲲鹏920处理器规格 技术创新 内置多种加速引擎 Taishan服务器 系列 TaiShan 200机架服务器全景图 TaiShan 200高密服务器 云服务 云计算 美国国家标准与技术研究院（NIST）定义：\n云计算是一种模型，它可以实现随时随地，便捷地，随需应变地从可配置计算资源共享池中获取所需的资源（例如，网络、服务器、存储、应用、及服务），资源能够快速供应并释放，使管理资源的工作量和与服务提供商的交互减小到最低限度。\n云计算的特点:\n 快捷的网络访问 自服务和随需分配 资源池 灵活有弹性 服务可度量  云计算的本质就是自动化和规模化在IT行业的服务化体现！  云服务实例 而云服务正是由于云计算的发展而孕育而生,主要依靠云计算的虚拟化技术.将所有的硬件资源进行计算虚拟化和存储虚拟化,最后得到我们的云服务.\n一个简单的网站例子可以是下面这张图:\n计算类云服务 计算类云服务有如下这么多种:\nECS-(弹性云主机) 弹性云服务器（ Elastic Cloud Server ）是一种可随时自助获取、可弹性伸缩的云服务器，帮助用户打造可靠、安全、灵活、高效的应用环境，确保服务持久稳定运行，提升运营效率。\n需要注意的是,ECS一般要配合硬盘系统盘、数据盘以及VPC等组件进行使用.  如下是一个简单的多态ECS服务器的拓扑图:\nBMS裸金属服务器 弹性裸金属服务器(Bare Metal Server)服务, 为用户提供专属的物理服务器，提供卓越的计算性能，满足核心应用场景对高性能及稳定性的需求，结合了传统托管服务器带来的稳定性能与云中资源高度弹性的优势。\n这个云服务的应用场景主要针对部署在物理机上的场景.\n规格和场景：\n 自带SDI卡，实现无系统盘挂载的技术。\n IMS镜像服务 镜像是由基础操作系统、预装的公共应用以及用户私有应用组成的模板，便于用户批量发放弹性云主机或裸金属服务器。\n有了镜像之后,就相当于有了一个当前系统的备份,可以复制到其他云服务器上,减少配置的时耗.  镜像服务提供镜像生命周期管理能力。用户可以通过服务器或外部文件创建系统盘镜像或数据盘镜像，也可以使用弹性云服务器或云服务器备份创建带数据盘的整机镜像。并对镜像进行修改，共享，加密，复制，导出，标签管理，企业多项目管理，发布市场镜像等操作。\nAS弹性伸缩服务 弹性伸缩（Auto Scaling）可根据用户的业务需求和预设策略，自动调整计算资源或弹性IP资源，使云服务器数量或弹性IP带宽自动随业务负载增长而增加，随业务负载降低而减少，节省云上业务资费，保证业务平稳健康运行.\n应用场景主要有:\n 企业网站、电商、移动应用等，业务特点：业务请求有突发式暴增或者访问量起伏不定 视频网站、媒体编解码应用、媒体内容回传应用、高流量内容管理系统、分布式高速缓存系统,业务特点:需要根据计算量动态调整计算、网络等资源  AS服务一般配合负载均衡(ELB)一起使用,例如:\n AS系统架构如下:\n云容器服务 CCE(云容器引擎)\n云容器引擎（Cloud Container Engine，简称CCE）提供高度可扩展的、高性能的企业级Kubernetes集群，支持运行Docker容器。借助云容器引擎，您可以在云上轻松部署、管理和扩展容器化应用程序。\n实用实例：\n优点：\n 多平台混合部署 跨云管理 一键式交付 高性能  CCI(云容器实例)\n云容器实例（Cloud Container Instance， CCI）服务提供 Serverless Container（无服务器容器）引擎，让您无需创建和管理服务器集群即可直接运行容器。\n使用云容器实例\n优点\n 免运维 高安全 极致性能 秒级付费 开放生态 极速弹性  云容器特性\n服务总览\n存储类云服务 存储类云服务主要分为如下三种:\n云硬盘EVS 云硬盘（Elastic Volume Service）是一种为ECS、BMS等计算服务提供持久性块存储的服务，通过数据冗余和缓存加速等多项技术，提供高可用性和持久性，以及稳定的低时延性能。您可以对云硬盘做格式化、创建文件系统等操作，并对数据做持久化存储。云硬盘提供多种性能规格，用户可以根据不同业务场景按需、灵活配置。\n使用图解:\n相当于在云上的硬盘.\n对象存储服务OBS 对象存储服务（OBS）是一个基于对象的海量存储服务，为您提供海量、低成本、高可靠、安全的数据存储能力。\n图解如下:\n弹性文件服务SFS和SFS 弹性文件服务（Scalable File Service）为用户的弹性云服务器（ECS）提供一个完全托管的共享文件存储，符合标准文件协议（NFS），能够弹性伸缩至PB规模（SFS Turbo最大320TB），具备可扩展的性能，为海量数据、高带宽型应用提供有力支持。\n云备份服务 最简单的备份服务，可将云服务器数据恢复到任意备份点,例如:\nSDRS 存储容灾服务 存储容灾服务（Storage Disaster Recovery Service，简称SDRS）是一种服务化容灾方案，可大幅降低企业容灾TCO。通过简单三步操作（创建保护组、创建保护实例、开启保护）即可为云上虚拟机提供跨可用区级别的容灾保护，确保数据零丢失（RPO=0），并可在灾难发生时迅速恢复业务，减少损失。\n简单例子:\n网络类云服务 主要有如下几种:\nVPC虚拟私有云服务 虚拟私有云（Virtual Private Cloud): 用户在华为云上申请的隔离的、私密的虚拟网络环境。用户可以自由配置VPC内的IP地址段、子网、安全组等子服务，也可以申请弹性公网IP和带宽搭建面向Internet的业务系统。\n主要包括如下四个方向内容:\n弹性公网IP 弹性公网IP（Elastic IP）提供独立的公网IP资源，包括公网IP地址与公网出口带宽服务。可以与弹性云服务器、裸金属服务器、虚拟IP、弹性负载均衡、NAT网关等资源灵活地绑定及解绑。\n 简单来说,就是外界可以访问的ip地址.并且是其他功能的依赖.\n 使用模型：\nNAT网关服务 NAT网关（NAT Gateway）能够为VPC内的弹性云服务器提供SNAT和DNAT功能，通过灵活简易的配置，即可轻松构建VPC的公网出入口\n SNAT和DNAT分别为源地址转换和目的地址转换。\nSNAT架构：\nDNAT架构：\n 使用NAT这个功能主要是为了节省弹性公网IP资源并且避免云主机IP直接暴露在公网上。\n虚拟专用网络 VPN 虚拟专用网络（Virtual Private Network）用于搭建用户本地数据中心与华为云VPC之间便捷、灵活，即开即用的IPsec加密连接通道，实现灵活一体，可伸缩的混合云计算环境\n 主要面向的是企业用户。\n 满足需求：\n 混合云部署 跨地域VPC 互联  云专线 DC 云专线（Direct Connect）用于搭建用户本地数据中心与华为云VPC之间高速、低时延、稳定安全的专属连接通道，充分利用华为云服务优势的同时，继续使用现有的IT设施，实现灵活一体，可伸缩的混合云计算环境\n应用场景：\n 混合云部署 异地容灾  弹性负载均衡服务ELB 弹性负载均衡（Elastic Load Balance，简称ELB）是将访问流量根据转发策略分发到后端多台弹性云服务器的流量分发控制服务。弹性负载均衡可以通过流量分发扩展应用系统对外的服务能力，提高应用程序的容错能力。\n简单来说，ELB就是用来处理多用户连接时候的资源缺乏的，临时制造多个副本来缓解压力。应用场景有：大型门户网站、跨可用区同城容灾、电商抢购。\nPPT  2. 鲲鹏应用移植 两种语言 1. 编译型语言 2. 解释型语言 策略 迁移过程 迁移工具 华为鲲鹏代码迁移工具主要面向鲲鹏平台的开发者、用户和第三方待移植软件提供方开发工程师，用来分析待移植软件源码文件，并给出代码移植指导报告，同时能够自动分析出需修改的代码内容，并指导如何修改，帮助用户顺利完成应用从x86平台向鲲鹏平台的移植。\n逻辑架构 容器迁移 容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。开发人员在自己笔记本上创建并测试好的容器，无需任何修改就能够在生产系统的虚拟机、物理服务器或公有云主机上运行。\n容器与虚拟机的不同 前提 跨平台的容器无法运行，会出现格式错误\n x86平台获取的镜像是适用于x86平台，当迁移到鲲鹏平台，容器无法执行。 在基于ARM的平台中，docker pull方式或者Dockerfile方式获取或者构建的镜像均为基于ARM平台的，同样也无法在x86上运行。  容器迁移的原理 迁移容器同时涉及到两个操作，备份和恢复。我们可以将任何一个Docker容器从一台机器迁移到另一台机器。在迁移过程中，首先我们将把容器备份为Docker镜像快照。然后，该Docker镜像或者是被推送到了Docker注册中心，或者被作为tar包文件保存到了本地。如果我们将镜像推送到了Docker注册中心，我们简单地从任何我们想要的机器上使用 docker run 命令来恢复并运行该容器，或者通过docker pull命令拉取我们想要的镜像。\n迁移策略 Docker容器迁移有两种策略：使用Docker pull获取镜像或使用Dockerfile构建镜像。\n主要流程  Docker安装 Docker构建基础镜像 Dockerfile创建应用镜像 验证应用镜像  性能调优 性能调优就是对计算机硬件、操作系统和应用程序有相当深入的了解，调节三者之间的关系，实现整个系统（包括硬件、操作系统、应用程序）的性能最大化，并能不断地满足现有的业务需求。\n华为鲲鹏性能优化工具 为解决客户软件运行遇到性能问题时凭人工经验定位困难、调优能力弱的痛点，华为推出了Kunpeng Tuning Kit鲲鹏性能优化工具。\n华为鲲鹏性能优化工具主要面向华为FAE、开放实验室能力建设工程师或客户工程师，针对应用程序部署在TaiShan服务器的场景下，通过收集服务器的处理器硬件、操作系统、进程/线程、函数等各层次的性能数据，分析出系统性能指标，定位到瓶颈点及热点函数。\n华为鲲鹏性能优化工具功能特性  支持采集整个系统或指定进程的CPU Cycles性能事件，能够快速定位热点函数。 支持热点函数按照CPU核/线程/模块进行分组，支持查看热点函数调用栈。 支持通过火焰图查看热点函数及其调用栈。 支持代码映射功能，即查看函数内的热点指令及该指令对应的高级语言文件及行号。 支持显示汇编代码的控制流图。 支持分析Java代码的热点函数及热点指令。  华为鲲鹏性能优化工具逻辑架构 主要分为Analysis和Agent两个模块。\n子模块 Analysis子模块\nAgent子模块\n部署方式 当前版本只支持单机部署，即将华为鲲鹏性能优化工具所有组件部署在一台服务器上，完成对该台服务器软件的性能数据采集和分析。\n如以下示例图：\n 部署环境要求如下表所示：\n 部署后访问方式  华为鲲鹏性能优化工具部署在TaiShan服务器上，该服务器上同时运行客户的应用软件。 华为鲲鹏性能优化工具提供Web界面访问方式，用户只需要在浏览器地址栏中输入：https:// 部署服务器的IP:端口号 即可。  访问Web界面时，对本地浏览器的要求如下表所示。\n优化工具业务流程 C/C++程序性能分析和优化 Java Mixed-Mode程序性能分析和优化 3. 容灾备份安全 云架构 基础架构：\n安全架构：\n企业主机安全（HSS） 企业主机安全（Host Security Service）是提升主机整体安全性的服务，包括账户破解防护、弱口令检测、恶意程序检测、双因子认证、漏洞管理，网页防篡改等功能，帮助企业构建服务器安全防护体系，降低当前服务器面临的主要安全风险\nWAF：最常用最有效的防护方案 Web应用防火墙（Web Application Firewall）对网站业务流量进行多维度检测和防护，结合深度机器学习智能识别恶意请求特征和防御未知威胁，阻挡诸如SQL注入或跨站脚本等常见攻击，避免这些攻击影响Web应用程序的可用性、安全性或过度消耗资源，降低数据被篡改、失窃的风险\nDBSS-数据库安全服务 数据库安全服务（Database Security Service）是一个智能的数据库安全防护服务，基于反向代理及机器学习机制，提供敏感数据发现、数据脱敏、数据库审计和防注入攻击等功能，保障云上数据库的安全\nCBH-云堡垒机：云运维审计的瑞士军刀 云堡垒机（Cloud Bastion Host）开箱即用，包含主机管理、权限控制、运维审计、安全合规等功能，支持Chrome等主流浏览器随时随地远程运维，开启高效运维新时代。\n案例 容灾备份 系统可靠性设计之高可用、双活、容灾、备份 容灾指标 RTO： RTO (Recovery Time Objectives)，关键业务功能（CBF）从中断点恢复到其最低业务连续目标（MBCO）所能承受的最大时间，从而使中断对业务所带领的冲击最小化。\nRPO： RPO (Recovery Point Objectives)，灾难恢复中的恢复时间点目标，指业务可接受的、灾难发生后，系统和数据从灾难发生时间点到可恢复至灾难前的时间点的目标。\nMBCO MBCO（Minimum Business Continuity Objectives），在突发事件、紧急状态、或灾难发生期间，企业为完成其业务目标所能接受的最低服务及生产水平。\n  标准 容灾方案 混合云容灾整体方案 4. GaussDB 5. 大数据 算存分离 解决方案 6. 解决方案 全览\n华为鲲鹏通用解决方案 华为鲲鹏行业解决方案 性能调优分析工具 Kunpeng Tuning Kit鲲鹏性能优化工具\n华为鲲鹏性能优化工具主要面向华为FAE、开放实验室能力建设工程师或客户工程师，针对应用程序部署在TaiShan服务器的场景下，通过收集服务器的处理器硬件、操作系统、进程/线程、函数等各层次的性能数据，分析出系统性能指标，定位到瓶颈点及热点函数。\n高性能计算 项目:个人同步网盘\n","description":"","id":74,"section":"talks","tags":["云计算"],"title":"鲲鹏Learning🏸","uri":"https://hugo.jiahongw.com/zh/talks/kubpeng_exercise/"},{"content":"C++学习路线🌱 hode on!💠\n","description":"","id":75,"section":"talks","tags":["C++"],"title":"C++学习路线","uri":"https://hugo.jiahongw.com/zh/talks/cpp_router/"},{"content":"| 管道符，“|”，表示将前一个命令的处理结果输出传递给后面的命令处理。\ngrep Linux系统中grep命令是一种强大的文本搜索工具，它能使用正则表达式搜索文本，并把匹 配的行打印出来。grep全称是Global Regular Expression Print，表示全局正则表达式版本，它的使用权限是所有用户。\n语法 grep [选项] 查找内容 源文件 选项参数   -a --text #不要忽略二进制的数据。\n  -A\u0026lt;显示行数\u0026gt; --after-context=\u0026lt;显示行数\u0026gt; #除了显示符合范本样式的那一列之外，并显示该行之后的内容。\n  -b  --byte-offset  #在显示符合样式的那一行之前，标示出该行第一个字符的编号。⭐\n  -B\u0026lt;显示行数\u0026gt; --before-context=\u0026lt;显示行数\u0026gt; #除了显示符合样式的那一行之外，并显示该行之前的内容。\n  -c --count #计算符合样式的列数。⭐\n  -C\u0026lt;显示行数\u0026gt; --context=\u0026lt;显示行数\u0026gt;或-\u0026lt;显示行数\u0026gt; #除了显示符合样式的那一行之外，并显示该行之前后的内容。\n  -d \u0026lt;动作\u0026gt; --directories=\u0026lt;动作\u0026gt; #当指定要查找的是目录而非文件时，必须使用这项参数，否则grep指令将回报信息并停止动作。⭐\n  -e\u0026lt;范本样式\u0026gt; --regexp=\u0026lt;范本样式\u0026gt; #指定字符串做为查找文件内容的样式。\n  -E --extended-regexp #将样式为延伸的普通表示法来使用。\n  -f\u0026lt;规则文件\u0026gt; --file=\u0026lt;规则文件\u0026gt; #指定规则文件，其内容含有一个或多个规则样式，让grep查找符合规则条件的文件内容，格式为每行一个规则样式。\n  -F --fixed-regexp #将样式视为固定字符串的列表。\n  -G --basic-regexp #将样式视为普通的表示法来使用。\n  -h --no-filename #在显示符合样式的那一行之前，不标示该行所属的文件名称。\n  -H --with-filename  #在显示符合样式的那一行之前，表示该行所属的文件名称。\n  -i --ignore-case  #忽略字符大小写的差别。⭐\n  -l --file-with-matches #列出文件内容符合指定的样式的文件名称。\n  -L --files-without-match #列出文件内容不符合指定的样式的文件名称。\n  -n --line-number #在显示符合样式的那一行之前，标示出该行的列数编号。\n  -q --quiet或--silent #不显示任何信息。\n  -r --recursive #此参数的效果和指定“-d recurse”参数相同。\n  -s --no-messages #不显示错误信息。\n  -v --revert-match #显示不包含匹配文本的所有行。\n  -V --version #显示版本信息。\n  -w --word-regexp #只显示全字符合的列。\n  -x --line-regexp #只显示全列符合的列。\n  -y #此参数的效果和指定“-i”参数相同。\n   其中标⭐号的为比较常实用的\n 查找内容规则 查找内容的规则与正则表达式大同小异。\n  ^ #锚定行的开始 如：\u0026lsquo;^grep'匹配所有以grep开头的行。\n  $ #锚定行的结束 如：\u0026lsquo;grep$'匹配所有以grep结尾的行。\n  . #匹配一个非换行符的字符 如：\u0026lsquo;gr.p'匹配gr后接一个任意字符，然后是p。\n  *#匹配零个或多个先前字符 如：'*grep'匹配所有一个或多个空格后紧跟grep的行。\n  .* #一起用代表任意字符。\n  [] #匹配一个指定范围内的字符，如\u0026rsquo;[Gg]rep'匹配Grep和grep。\n  [^]  #匹配一个不在指定范围内的字符，如：'[^A-FH-Z]rep'匹配不包含A-R和T-Z的一个字母开头，紧跟rep的行。\n  \\(..\\) #标记匹配字符，如\u0026rsquo;(love)'，love被标记为1。\n  \\\u0026lt; #锚定单词的开始，如:'\u0026lt;grep'匹配包含以grep开头的单词的行。\n  \\\u0026gt; #锚定单词的结束，如\u0026rsquo;grep\u0026gt;'匹配包含以grep结尾的单词的行。\n  x\\{m\\} #重复字符x，m次，如：\u0026lsquo;0{5}\u0026lsquo;匹配包含5个o的行。\n  x\\{m,\\}  #重复字符x,至少m次，如：\u0026lsquo;o{5,}\u0026lsquo;匹配至少有5个o的行。\n  x\\{m,n\\} #重复字符x，至少m次，不多于n次，如：\u0026lsquo;o{5,10}\u0026lsquo;匹配5\u0026ndash;10个o的行。\n  \\w  #匹配文字和数字字符，也就是[A-Za-z0-9]，如：\u0026lsquo;G\\w*p'匹配以G后跟零个或多个文字或数字字符，然后是p。\n  \\W  #\\w的反置形式，匹配一个或多个非单词字符，如点号句号等。\n  \\b  #单词锁定符，如: \u0026lsquo;\\bgrep\\b'只匹配grep。\n  在/etc/profile文件中查找关键字CLASS_PATH所在位置\n查询ssh相关进程\n压缩解压类命令 gzip/gunzip gzip用于压缩文件，gunzip用于解压\n语法：\ngzip文件名（功能描述：压缩文件，只能将文件压缩为*.gz文件）\ngunzip 文件名(.gz结尾)：(功能描述：解压缩文件命令）\n压缩b.txt文件\n解压b.txt.gz压缩文件\nzip/unzip zip用于压缩文件，unzip用于解压的，这个在项目打包发布中很有用的.\n语法：\nzip [选项] XXX.zip 将要压缩的内容（功能描述：压缩文件和目录的命令）\nunzip [选项] XXX.zip (功能描述：解压缩文件）\n加密a.txt文件\n解密a.zip文件\ntar tar指令是打包指令，最后打包后的文件可以是.tar.gz的文件。\n语法：\ntar [选项] XXX.tar.gz 打包的内容（功能描述：打包目录，压缩后的文件格式tar.gz)\n选项参数：\n  -A 新增压缩文件到已存在的压缩\n  -B 设置区块大小\n  -c 建立新的压缩文件\n  -d 记录文件的差别\n  -r 添加文件到已经压缩的文件\n  -u 添加改变了和现有的文件到已经存在的压缩文件\n  -x 从压缩的文件中提取文件\n  -t 显示压缩文件的内容\n  -z 支持gzip解压文件\n  -j 支持bzip2解压文件\n  -Z 支持compress解压文件\n  -v 显示操作过程\n  -l 文件系统边界设置\n  -k 保留原有文件不覆盖\n  -m 保留文件不被覆盖\n  -W 确认压缩文件的正确性\n  可选参数如下：\n  -b 设置区块数目\n  -C 切换到指定目录\n  -f 指定压缩文件\n  --help 显示帮助信息\n  --version 显示版本信息\n  实例：\n打包/victor文件夹下所有内容，打包后的文件名为victor.tar\n解压victor.tar文件\n打包文件夹/victor并且压缩成data.tar.gz\n将多个文件压缩成a.tar.gz\n将a.tar.gz解压到当前目录\n解压到文件夹/a(文件夹必须存在，不然报错)\n![](https://i.loli.net/2020/04/16/xALa9JldzXuBjRi.png\n https://www.cnblogs.com/peida/archive/2012/12/17/2821195.html https://www.cnblogs.com/peida/archive/2012/12/19/2824418.html https://www.cnblogs.com/peida/archive/2012/12/06/2804323.html ","description":"","id":76,"section":"posts","tags":["Linux","grep","tar","gzip"],"title":"Linux实用指令","uri":"https://hugo.jiahongw.com/zh/posts/linux/linux-grep/"},{"content":"每一个用户都是一个个体，每一个个体都属于一个群组，而每一个群组又有区别!\n——Users\n Linux系统是一个多用户多任务的操作系统，任何一个要使用系统资源的用户，都必须首先向系统管理员申请一个账号，然后以这个账号的身份进入系统。\n 添加用户 基本语法 useradd [选项] 用户名 实操 输入以下命令之后创建一个用户victor\n这里我们选项参数什么也没有写，此时会默认在/home目录下创建一个/victor的文件夹用于保存用户victor用户的数据信息。\n当然我们可以指定参数：\n用参数 -d 目录指定用户信息存储的目录，使用命令useradd -d /home/test tom创建用户tom。\n使用-g 用户组指定将当前创建的用户添加到指定的用户组，使用命令useradd -g root wjh将新建用户wjh添加到root用户组。\n给用户设置密码 基本语法 passwd 用户名 实操 给用户victor设置密码(默认密码是不会显示出来的)\n下面可以使用victor这个用户登陆\n默认是不能访问root用户的文件的，因为不在同一个组\n切换用户 基本语法 su - 切换用户名 实操 切换到root。其中低权限用户切换到高权限用户需要输入密码。\n退出切换使用exit删除用户 基本语法 userdel [选项] 用户名 其中选项参数可以添加-r，表示删除用户时同时删除保存用户的文件夹。\n实操 删除用户tom\n可以看到之前tom致电给创建的文件夹test并没有删除。\n 注意，删除用户必须要root权限，不然删除不了。\n 删除用户victor，同时删除其文件夹，victor文件夹消失了\n其他操作 查询用户信息 语法\nid 用户名 如下查询用户root的信息\nroot用户的用户id为0，组id为0，组为0\n查询当前用户 语法\nwhoami 用户组  类似于角色，系统可以对有共性的多个用户进行统一的管理。\n 用户组关系图：\n增加组 语法\ngroupadd 组名 增加用户组test\n删除组 语法\ngroupdel 组名 删除用户组test\n修改用户的组 语法\nusermod -g 用户组 用户名 相关配置文件  用户信息文件：/etc/passwd 密码文件： /etc/shadow 用户组文件：/etc/group 用户组密码文件： /etc/gshadow 用户配置文件：\n/etc/login.defs\n/etc/default/useradd 新用户信息文件：/etc/skel 登录信息：/etc/motd  /etc/passwd 每一行内容存放一个用户的信息，每个用户信息有7部分组成\nroot​：x:0:0:root:/root:/bin/bash\nroot 用户名 用户登录系统时使用的用户名\nx 密码 密码位\n2 UID 用户标识号\n2 GID 缺省组标识\nroot 注释性描述 例如存放用户全名等信息\n/root 宿主目录 用户登录系统后的缺省目录\n/bin/bash 命令解释器 用户使用的Shell ,默认为bash\n UID分类\n超级用户：（root UID=0）\n普通用户： （UID 500~60000）\n伪用户： （UID 1~499）\n什么是伪用户?\n 伪用户与系统和程序服务相关  bin、daemon、shutdown、halt等，任何Linux系统默认都有这些伪用户。\nmail、news、games、apache、ftp、mysql及sshd等，与linux系统的进程相关。\n 伪用户通常不需要或无法登录系统\n  可以没有宿主目录\n   /etc/shadow 每行的含义： 登录名: 加密口令: 最后一次修改时间: 最小时间间隔: 最大时间间隔:警告时间: 不活动时间: 失效时间:标志\n/etc/group 每行含义： 组名: 口令: 组标识号: 组内用户列表\n https://www.cnblogs.com/qmfsun/p/3674024.html linux用户管理命令 ","description":"","id":77,"section":"posts","tags":["Linux","用户管理"],"title":"Linux用户管理","uri":"https://hugo.jiahongw.com/zh/posts/linux/linux-users/"},{"content":"在大学时代，Vim 的大名就已如雷贯耳，但由于它陡峭的学习曲线，一直望而却步。等真正开始学习之后，发现并没有想象中的复杂，也没有所谓的瓶颈，只要在实际写代码中强迫自己使用就可以了，无形中就会形成习惯。\n​\t——GeekPlux\n三种模式 正常模式 以 vim 打开一个档案就直接进入一般模式了(这是默认的模式)。正常模式可以使用快捷键。\n编辑模式 按下i, I, o, O, a, A, r, R等任何一个字母之后才会进入编辑模式, 一般来说按i即可.\n命令行模式 在这个模式当中， 可以提供你相关指令，完成读取、存盘、替换、离开 vim 、显示行号等的动作则是在此模式中达成的。\n vi 和vim模式的相互切换\n 常用快捷键  使用快捷键在正常模式下输入！\n 复制粘贴 拷贝当前行输入yy，然后再按下p键的时候就可以粘贴了。\n复制多行可以输入nyy，其中n为一个数字，例如5yy，即复制当前行向下的5行，同样粘贴也是按p键。\n删除 删除当前行输入dd\n删除多行输入ndd，表示删除当前行向下的n行。\n查找单词 再正常模式下输入/关键字即可查找关键字所在的位置，例如/hello为查找hello这个单词所有的所在位置，输入 n 就是查找下一个。\n设置文件行号 有时候为了看文档更清楚，想要知道每一行的行数，可以先进入命令模式，在输入set nu，即再正常模式下输入:set nu,然后回车。\n取消行号可以输入:set nonu\n移动到底部到首部 有时候需要直接看文档的末尾，可以输入G移动到文件末行。\n而移动到首行则是输入gg，然后回车即可。\n撤销 取消上一次做的操作，输入u。表示undo。\n移动到某行 假如我们要移动到第20行，我们可以这样输入：20 + shift + g\n更多快捷键可以参考：https://zhuanlan.zhihu.com/p/77283813\nVim键盘图\n思维导图：\n","description":"","id":78,"section":"posts","tags":["Linux","Vim"],"title":"Linux编辑利器-Vim","uri":"https://hugo.jiahongw.com/zh/posts/linux/vim-use/"},{"content":"问题描述 给定一个字符串 s，找到 s 中最长的回文子串。你可以假设 s 的最大长度为 1000。\n示例 1：\n输入: \u0026quot;babad\u0026quot; 输出: \u0026quot;bab\u0026quot; 注意: \u0026quot;aba\u0026quot; 也是一个有效答案。 示例 2：\n输入: \u0026quot;cbbd\u0026quot; 输出: \u0026quot;bb\u0026quot; 解答 使用动态规划，把原来的字符串倒置，然后找最长的公共子串就可以了。例如 S = \u0026ldquo;caba\u0026rdquo; ，S = \u0026ldquo;abac\u0026rdquo;，最长公共子串是 \u0026ldquo;aba\u0026rdquo;，所以原字符串的最长回文串就是 \u0026ldquo;aba\u0026rdquo;。其中求最大公共子串就是使用动态规划的方法。\n示意图：\n 当S[i]==S[j]时，矩阵arr[i][j]=arr[i-1][j-1]+1；特殊情况i、j为0时arr[i][j]=1 其他情况跳过。   另外，还需要考虑最长公共子串不是回文的情况，只需要判断翻转前后的末尾字符下标是否一样即可，比如 S=\u0026quot;caba\u0026rdquo;，S'=\u0026quot;abac\u0026rdquo; ，S’ 中 aba 的下标是 0 1 2 ，倒置前是 3 2 1，和 S 中 aba 的下标符合，所以 aba 就是我们需要找的。当然我们不需要每个字符都判断，我们只需要判断末尾字符就可以。\n 代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46  #include \u0026lt;iostream\u0026gt;#include \u0026lt;algorithm\u0026gt;class Solution { public: string longestPalindrome(string s) { //暴力法  int len = s.length(); if (len \u0026lt;= 1) return s; std::string r; std::string real = s; reverse(s.begin(), s.end()); std::string reverse = s; int arr[len][len]; for (int i = 0; i \u0026lt; len; ++i) for (int j = 0; j \u0026lt; len; ++j) arr[i][j] = 0; int maxLen(0), maxEnd(0); for (int i = 0; i \u0026lt; len; ++i) { for (int j = 0; j \u0026lt; len; ++j) { if (real[i] == reverse[j]) { if (i == 0 || j == 0) arr[i][j] = 1; else { arr[i][j] = arr[i - 1][j - 1] + 1; } } if (arr[i][j] \u0026gt; maxLen) { int beforeindex = len - 1 - j; if ((beforeindex + arr[i][j] - 1) == i) { maxLen = arr[i][j]; maxEnd = i; } } } } return real.substr(maxEnd - maxLen + 1, maxLen); } };   结果： ","description":"","id":79,"section":"posts","tags":["C++","leetcode"],"title":"Leetcode-最长回文子串","uri":"https://hugo.jiahongw.com/zh/posts/leetcode/leetcode-0/"},{"content":"Linux基本操作。🤠\nLinux 目录结构及解释 查看命令行执行完位置：\n1  echo $BASH   命令记录 mkdir mkdir命令 用来创建目录。\n语法：mkdir (选项)(参数)\n 主要选项：\n-m\u0026lt;目标属性\u0026gt;或\u0026ndash;mode\u0026lt;目标属性\u0026gt;建立目录的同时设置目录的权限；\n-p或\u0026ndash;parents 若所要建立目录的上层目录目前尚未建立，则会一并建立上层目录；\n参数：\n指定要创建的目录列表，多个目录之间用空格隔开。\n 创建多层目录：\n1  mkdir a/b/c/d   chmod chmod命令用来变更文件或目录的权限。\n语法：chmod(选项)(参数)\n权限范围的表示法如下：\nu User，即文件或目录的拥有者；\ng Group，即文件或目录的所属群组；\no Other，除了文件或目录拥有者或所属群组之外，其他用户皆属于这个范围；\na All，即全部的用户，包含拥有者，所属群组以及其他用户；\nr 读取权限，数字代号为“4”;\nw 写入权限，数字代号为“2”；\nx 执行或切换权限，数字代号为“1”；\n- 不具任何权限，数字代号为“0”；\ns 特殊功能说明：变更文件或目录的权限。\n例子：\n1 2 3 4  chmod u+x,g+w f01　//为文件f01设置自己可以执行，组员可以写入的权限 chmod u=rwx,g=rw,o=r f01 chmod 764 f01 chmod a+x f01　//对文件f01的u,g,o都设置可执行属性   可以输入命令ll -d 文件名查看文件的权限：\nlinux文件的用户权限的分析图\n例：rwx　rw-　r\u0026ndash;\nr=读取属性　//值＝4\nw=写入属性　//值＝2\nx=执行属性　//值＝1\n对demo.sh执行chmod a+x demo.sh之后，查看其权限，三个组都含x，表示所有用户都能执行：\nShell脚本 shell脚本一般以.sh结尾。如demo.sh：\n1 2 3  #!/bin/bash #This is my First shell echo \u0026#34;Hello World!\u0026#34;    第一行表示脚本的位置\n第二行为注释\n第三行为脚本的命令\n 如何执行？在Linux下需要先赋予权限\n1  chmod o+x demo.sh   执行\n1  ./demo.sh   常见的变量\n$0当前程序的名称\n$n当前程序的第 n 个参数,n=1,2,…9\n$* 当前程序的所有参数(不包括程序本身)\n$# 当前程序的参数个数(不包括程序本身)\n$? 命令或程序执行完后的状态，一般返回 0 表示执行成功。\n$UID 当前用户的 ID\n$PWD 当前所在的目录\nIf 条件判断语句 格式：\n1 2 3 4 5  if (表达式) #if ( Variable in Array ) 语句 1 else 语句 2 fi   例：\n1 2 3 4 5  #!/bin/sh NUM=100 if (( $NUM \u0026gt; 4 )) ;then echo “this num is $NUM greater 4 !” fi   参考：\n https://wangchujiang.com/linux-command/ ","description":"","id":80,"section":"posts","tags":["Linux","Shell","bash"],"title":"Linux命令与Shell","uri":"https://hugo.jiahongw.com/zh/posts/linux/linux-shell/"},{"content":"Docker是基于内核的容器,可以运行在宿主机上,看作是一个容器.\nDocker🐋 安装配置 略,可以百度搜索.如下:\nhttps://juejin.im/post/5dc241ce6fb9a04aa333c1bd\n基本使用 安装完成之后,可以使用以下命令查看版本\n1  docker version   拉取并且运行hello-world镜像进行测试\ndocker run hello-world 查看本地镜像:\ndocker image ls 本地有一个hello-world镜像\nImage的获取 1. 从Dockerfile制作 2. 从Register拉取(Pull from Register) 例如:\n1  docker pull ubuntu:14.04   可以在DockerHub里面搜索相关的镜像\n添加Docker用户权限，创建docker组\n1  sudo groupadd docker   1  sudo gpasswd -a vagrant docker   1  sudo service docker restart   最后重新登陆服务器即可\n自定义image 构建一个输出信息的C语言编译的可执行文件镜像\n首先编写C文件,如下:\n1 2 3 4 5 6  #include \u0026lt;stdio.h\u0026gt;int main(){ printf(\u0026#34;Hello,Docker!\\n\u0026#34;); return 0; }   安装gcc及相关库:\n1 2  sudo yum install gcc sudo yum install glibc-static   编译:\n1  gcc -static hello.c -o hello   在当前文件夹下创建Dockerfile\n1  vim Dockerfile   编写下面的内容\n1 2 3  FROM scratch ADD hello / CMD [\u0026#34;/hello\u0026#34;]   使用docker构建:\n1  docker build -t victorhong/hello .   其中victorhong是用户名,hello是镜像名,.表示当前文件夹下的内容\n构建完可以查看到镜像:\n查看构建的历史\n运行容器\ndocker run victorhong/hello Container 什么是container?\n查看container\n1  docker container ls   查看所有cpntainer,包括结束的\n1  docker container ls -a   运行ubuntu:16.04是马上就会结束的,要想交互式的执行容器,使用以下的mingl\n1  docker run -it ubuntu:16.04   另外开一个窗口,查看container\n1  docker container ls   可以看到有一个ubuntu容器正在运行\n构建自己的Docker镜像   docker container commit\n1  docker commit clever_franklin victorhong/centos-vim   在对容器进行修改了之后,clever_franklin为容器名,victorhong/centos-vim为提交的镜像名\n  Dockerfile build\n1 2  FROMcentosRUN yum install -y vim  然后执行\n1  docker build -t victorhong/centos-vim-new .     Dockerfile语法 FROM 定义base image\nLabel 定义数据信息,类似注释\n Metadata不可少\n RUN 每执行一次run,都会新建一层,尽量少用多次run\nWORKDIR 设定当前工作目录,类似cd\n 注意:\n ADD and COPY ADD还有解压功能\nENV 设置环境变量或者常量变量\n尽量使用ENV增加可维护性\nVOLUME ADN EXPOSE VOLUME用于挂载数据卷，EXPOSE用于暴露端口\nCMD and ENTRYPOINT 区别:\n执行命令格式:\nGitHub上的官方Dockerfile\n镜像的发布 使用DockerHub去push\n登陆docker\n1  docker login   push\n1  docker push victorhongdream/hello:latest   查看DockerHub\n","description":"","id":81,"section":"posts","tags":["docker"],"title":"入门Docker","uri":"https://hugo.jiahongw.com/zh/posts/middleware/docker-begin/"},{"content":"C++特性之多态🍄\n静态类型 是指不需要考虑表达式的执行期语义，仅分析程序文本而决定的表达式类型。\n动态类型 是指由一个左值表达式表示的左值所引用的最终派生对象的类型。\n动态绑定与静态绑定 **静态绑定：**编译时绑定，通过对象调用\n**动态绑定：**运行时绑定，通过地址实现\n何时使用动态绑定?\n 只有采用“指针-\u0026gt;函数()”或“引用变量.函数()”的方式调用C++类中的虚函数才会执行动态绑定。 对于C++中的非虚函数，因为其不具备动态绑定的特征，所以不管采用什么样的方式调用，都不会执行动态绑定。   总的来所,动态绑定执行的函数只针对虚函数,执行虚函数会动态执行,而非虚函数就直接执行基类类型的函数,也就是说指针类型是什么，就会调用该类型相应的函数。\n 例如下面的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34  #include \u0026lt;iostream\u0026gt;using namespace std; class Base { public: void func() { cout \u0026lt;\u0026lt; \u0026#34;func() in Base.\u0026#34; \u0026lt;\u0026lt; endl; } virtual void test() { cout \u0026lt;\u0026lt; \u0026#34;test() in Base.\u0026#34; \u0026lt;\u0026lt; endl; } }; class Derived : public Base { void func() { cout \u0026lt;\u0026lt; \u0026#34;func() in Derived.\u0026#34; \u0026lt;\u0026lt; endl; } virtual void test() { cout \u0026lt;\u0026lt; \u0026#34;test() in Derived.\u0026#34; \u0026lt;\u0026lt; endl; } }; int main() { Base *b; b = new Derived(); b-\u0026gt;func(); b-\u0026gt;test(); }   输出为:\nfunc() in Base. test() in Derived. 再例如下面的代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20  class A { public: virtual void func(int val = 1) { std::cout\u0026lt;\u0026lt;\u0026#34;A-\u0026gt;\u0026#34;\u0026lt;\u0026lt;val \u0026lt;\u0026lt;std::endl;} virtual void test() { func();} }; class B : public A { public: void func(int val=0) {std::cout\u0026lt;\u0026lt;\u0026#34;B-\u0026gt;\u0026#34;\u0026lt;\u0026lt;val \u0026lt;\u0026lt;std::endl;} }; int main(int argc ,char* argv[]) { B*p = new B; p-\u0026gt;test(); return 0; }   输出为: B-\u0026gt;1\n test()是虚函数,p-\u0026gt;test()会动态调用B类中的test()函数,并且,还需要记住一个结论:virtual 函数是动态绑定，而缺省参数值却是静态绑定,绝不重新定义继承而来的缺省参数值！\n 虚函数、动态绑定、运行时多态之间的关系 要触发动态绑定，需满足两个条件：\n  只有虚函数才能进行动态绑定，非虚函数不进行动态绑定。\n  必须通过基类类型的引用或指针进行函数调用。\n  简单地说，虚函数是动态绑定的基础；动态绑定是实现运行时多态的基础。\n https://blog.csdn.net/iicy266/article/details/11906509 C++中的动态类型与动态绑定、虚函数、运行时多态的实现 ","description":"","id":82,"section":"posts","tags":["C++","多态"],"title":"C++动态与静态","uri":"https://hugo.jiahongw.com/zh/posts/candcplusplus/cpp-duotai/"},{"content":"c文件读写🗃\nFILE对象结构体 1 2 3 4 5 6 7 8  typedef struct { int _fd; // 文件号  int _cleft; // 缓冲区中剩下的字节数  int _mode; // 文件操作模式  char * _nextc; // 下一个字节的位置  char * _buff; // 文件缓冲区位置 }FILE;   打开文件 可以使用 fopen( ) 函数来创建一个新的文件或者打开一个已有的文件，这个调用会初始化类型 FILE 的一个对象，类型 FILE 包含了所有用来控制流的必要的信息。下面是这个函数调用的原型：\n1  FILE *fopen( const char * filename, const char * mode );   mode 的值可以是r,w,a,,r+,w+,a+:\n   r 打开一个已有的文本文件，允许读取文件。     w 打开一个文本文件，允许写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会从文件的开头写入内容。如果文件存在，则该会被截断为零长度，重新写入。   a 打开一个文本文件，以追加模式写入文件。如果文件不存在，则会创建一个新文件。在这里，您的程序会在已有的文件内容中追加内容。   r+ 打开一个文本文件，允许读写文件。   w+ 打开一个文本文件，允许读写文件。如果文件已存在，则文件会被截断为零长度，如果文件不存在，则会创建一个新文件。   a+ 打开一个文本文件，允许读写文件。如果文件不存在，则会创建一个新文件。读取会从文件的开头开始，写入则只能是追加模式。    如果处理的是二进制文件，则需使用下面的访问模式来取代上面的访问模式：\n1  \u0026#34;rb\u0026#34;, \u0026#34;wb\u0026#34;, \u0026#34;ab\u0026#34;, \u0026#34;rb+\u0026#34;, \u0026#34;r+b\u0026#34;, \u0026#34;wb+\u0026#34;, \u0026#34;w+b\u0026#34;, \u0026#34;ab+\u0026#34;, \u0026#34;a+b\u0026#34;     关闭文件 关闭文件非常简单,只需要调用**fclose()**函数即可,其中参数就是指向文件对象的指针.\n1  int fclose( FILE *fp );   如果成功关闭文件，fclose( ) 函数返回零，如果关闭文件时发生错误，函数返回 EOF。这个函数实际上，会清空缓冲区中的数据，关闭文件，并释放用于该文件的所有内存。EOF 是一个定义在头文件 stdio.h 中的常量。  demo 1 2 3 4 5 6 7 8 9 10 11 12 13  void open_close_file(){ char fname[10]; printf(\u0026#34;pease input file name: \u0026#34;); scanf(\u0026#34;%s\u0026#34;,fname); FILE *p = fopen(fname,\u0026#34;r+\u0026#34;); if(p == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return ; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;,fname); fclose(p); printf(\u0026#34;file %s had be closed!\\n\u0026#34;,fname); }   读取文件 读取单个字符的最简单的函数:\n1  int fgetc( FILE * fp );   读取多个字符的函数(也可以读取单个字符):\n1  char *fgets( char *buf, int n, FILE *fp );   fgetc() 函数从 fp 所指向的输入文件中读取一个字符。返回值是读取的字符，如果发生错误则返回 EOF。\n函数 fgets() 从 fp 所指向的输入流中读取 n - 1 个字符。它会把读取的字符串复制到缓冲区 buf，并在最后追加一个 null 字符来终止字符串。\n 例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  void read_file_demo() { char fname[10] = \u0026#34;basic.sql\u0026#34;; FILE *fp = fopen(fname, \u0026#34;r+\u0026#34;); if (fp == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;, fname); char ch; int n = 5; printf(\u0026#34;\\nusing fgetc()......\\n\u0026#34;); while (n--) { ch = fgetc(fp); if(ch != EOF) printf(\u0026#34;char = %c\\n\u0026#34;, ch); } char str[20]; printf(\u0026#34;\\nusing fgets()......\\n\u0026#34;); fgets(str,20,fp); printf(\u0026#34;str[20] = %s\\n\u0026#34;,str); fclose(fp); printf(\u0026#34;file %s had be closed!\\n\u0026#34;, fname); }   读取二进制输入:\n1  size_t fread(void *buffer, size_t size, size_t count, FILE * stream);    buffer为接收数据的地址，size为一个单元的大小，count为单元个数，stream为文件流。\n返回实际读取的单元个数。如果小于count，则可能文件结束或读取出错；可以用ferror()检测是否读取出错，用feof()函数检测是否到达文件结尾。如果size或count为0，则返回0。\n 写入文件 写入单个字符的最简单的函数:\n1  int fputc( int c, FILE *fp );   写入多个字符的函数(也可以写入单个字符):\n1  int fputs( const char *s, FILE *fp );   函数 fputc() 把参数 c 的字符值写入到 fp 所指向的输出流中。如果写入成功，它会返回写入的字符，如果发生错误，则会返回 EOF。\n函数 fputs() 把字符串 s 写入到 fp 所指向的输出流中。如果写入成功，它会返回一个非负值，如果发生错误，则会返回 EOF。\n 例子:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  void write_file_demo() { char fname[10] = \u0026#34;test.txt\u0026#34;; FILE *fp = fopen(fname, \u0026#34;w+\u0026#34;); if (fp == NULL) { printf(\u0026#34;file open fail!\\n\u0026#34;); return; } printf(\u0026#34;file %s open sucessful!\\n\u0026#34;, fname); char ch; int n = 5; printf(\u0026#34;\\nusing fputc()......\\n\u0026#34;); while (n--) { ch = (char)(100+n); if((ch = fputc(ch,fp)) != EOF) printf(\u0026#34;char %c write successful!\\n\u0026#34;,ch); } char str[30] = \u0026#34;\\nIt`s a test for write!\u0026#34;; printf(\u0026#34;\\nusing fputs()......\\n\u0026#34;); int r = fputs(str,fp); if(r \u0026gt;= 0) printf(\u0026#34;str[30] = %s write successful!\\n\u0026#34;,str); fclose(fp); printf(\u0026#34;file %s had be closed!\\n\u0026#34;, fname); }   二进制输出:\n1  size_t fwrite(void * buffer, size_t size, size_t count, FILE * stream);    buffer为数据源地址，size为每个单元的字节数，count为单元个数，stream为文件流指针。\n返回成功写入的单元个数。如果小于count，则说明发生了错误，文件流错误标志位将被设置，随后可以通过ferror()函数判断。\n 参考:\n https://www.runoob.com/cprogramming/c-file-io.html ","description":"","id":83,"section":"posts","tags":["C","文件读写"],"title":"C文件读写","uri":"https://hugo.jiahongw.com/zh/posts/candcplusplus/c-read-write/"},{"content":"在markdown文件中嵌入html代码.🛶\n使用自定义文字样式 输入代码:\n1  \u0026lt;span style=\u0026#34;font-size:2rem; background:yellow;\u0026#34;\u0026gt;**Bigger**\u0026lt;/span\u0026gt;   Bigger\n设置键盘按键 输入代码:\n1  \u0026lt;kbd\u0026gt;Ctrl\u0026lt;/kbd\u0026gt;+\u0026lt;kbd\u0026gt;F9\u0026lt;/kbd\u0026gt;   Ctrl+F9\n其他网站摘录的html 1  \u0026lt;blockquote class=\u0026#34;twitter-tweet\u0026#34;\u0026gt;\u0026lt;p lang=\u0026#34;en\u0026#34; dir=\u0026#34;ltr\u0026#34;\u0026gt;Sunsets don\u0026amp;#39;t get much better than this one over \u0026lt;a href=\u0026#34;https://twitter.com/GrandTetonNPS?ref_src=twsrc%5Etfw\u0026#34;\u0026gt;@GrandTetonNPS\u0026lt;/a\u0026gt;. \u0026lt;a href=\u0026#34;https://twitter.com/hashtag/nature?src=hash\u0026amp;amp;ref_src=twsrc%5Etfw\u0026#34;\u0026gt;#nature\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;https://twitter.com/hashtag/sunset?src=hash\u0026amp;amp;ref_src=twsrc%5Etfw\u0026#34;\u0026gt;#sunset\u0026lt;/a\u0026gt; \u0026lt;a href=\u0026#34;http://t.co/YuKy2rcjyU\u0026#34;\u0026gt;pic.twitter.com/YuKy2rcjyU\u0026lt;/a\u0026gt;\u0026lt;/p\u0026gt;\u0026amp;mdash; US Department of the Interior (@Interior) \u0026lt;a href=\u0026#34;https://twitter.com/Interior/status/463440424141459456?ref_src=twsrc%5Etfw\u0026#34;\u0026gt;May 5, 2014\u0026lt;/a\u0026gt;\u0026lt;/blockquote\u0026gt; \u0026lt;script async src=\u0026#34;https://platform.twitter.com/widgets.js\u0026#34; charset=\u0026#34;utf-8\u0026#34;\u0026gt;\u0026lt;/script\u0026gt;   Sunsets don\u0026#39;t get much better than this one over @GrandTetonNPS. #nature #sunset pic.twitter.com/YuKy2rcjyU\n\u0026mdash; US Department of the Interior (@Interior) May 5, 2014 ","description":"","id":84,"section":"posts","tags":["markdown","html"],"title":"在markdown使用html","uri":"https://hugo.jiahongw.com/zh/posts/writingtips/markdown-html/"},{"content":"TCP/IP编程\n  目标:  能进行网络编程\n1.如果你说你会select,epoll,iocp模型,那会让对方觉得更靠谱\n2.如果你说出你做过im,下载之类那会让对方来兴趣.\n3.如果你说设计了通讯协议,会让对方觉得更贴切\n4.如果你说做过,熟悉, ftp http snmp smtp 这些简单的老古董协议,会加分,但不大.\n5.如果你说熟悉bt,emule,udt等协议,那会对你很有好感.\n6.如果你说你破解过某大牌 qq,360内某通讯协议,那会对你加分很大.\n阶段:\n1)熟悉TCP/IP协议族的基本原理\nIP地址的分类，定义，获得，大概的管理方法\nTCP、UDP等主要协议的特点，主要格式，以及重要字段在协议交互中起到的作用。\n2）对于简单的TCP/IP协议导致的问题，有基本的判断\n熟悉网络问题的解决方法，一个问题，应该是由上而下（top-button），还是由下而上（button-top）来分析？\n3）基本的编程知识。\n在系统内，构建简单通信。\n在系统间，构建简单的通信。\n熟悉系统内的API，知道在什么时候，改使用哪些API协调工作。\n能够熟练使用这些API，在系统间传递信息，文件。\n能够熟练使用这些API，实现自己的简单的私有协议。\n4）进阶编程知识\n知道一两个已经封装好的框架（framwork），它们之间的差别。\n使用一个框架，写过能正常工作的程序。\n知道网络协议处理也是要讲究性能的，知道性能的瓶颈会在什么地方产生。\n能有较好的设计技巧，将私有协议设计得更加具有弹性，优雅。\n熟悉系统间协议处理的细微的差异，以及将会对业务造成的影响，时延、状态不一致、自定义字段、、、、、\n5）熟练阶段的知识\n针对业务的需求，快速选型，定框架。\n不再认为多线程是万能的。\n知道稳定性比性能更加重要。\n数据包去了哪儿，不用看代码，也能预估出来。\n6）源代码是最好的老师，永远都是。\n以上，差不多或者已经达到4）的时候，就是“熟悉”了。\n  网络模型 OSI模型 TCP/IP模型 示例 协议对应 数据封装 C++UDP/TCP实例 套接字 为了区分不同应用程序进程和连接，许多计算机操作系统为应用程序与TCP/IP交互提供了称为**嵌套字(Socket)**的接口。\n常用的TCP/IP有以下三种类型的嵌套字：\n  流式嵌套字（SOCK_STREAM）\n用于提供面向连接的、可靠的数据传输服务，即使用TCP进行传输。\n  数据报嵌套字（SOCK_DGRAM）\n用于提供无连接的服务，即使用UDP进行传输。\n  原始嵌套字（SOCK_RAW\n可以读写内核没有处理的IP数据报，而流式嵌套字只能读取TCP的数据，数据报嵌套字只能读取UDP的数据.\n   如果要访问其它协议发送的数据必须使用原始嵌套字，它允许对底层协议(如IP或ICMP)直接访问\n 端口对应进程 单单之后ip地址还不足以辨识通信的两个进程,因为操作系统是并发的,使用端口来辨认某个进程.所以套接字必须的两个信息为: ip地址 + 端口,例如: 192.168.1.4 1500\n参考:\n https://www.jianshu.com/p/c1015f5ffa74 进程间通信 https://segmentfault.com/a/1190000003063859 Linux IO模式及 select、poll、epoll详解 https://cloud.tencent.com/developer/article/1373483 各种IO复用模式之select，poll，epoll，kqueue，iocp分析 ","description":"","id":85,"section":"posts","tags":["tcp","udp","网络"],"title":"Udp-Tcp编程","uri":"https://hugo.jiahongw.com/zh/posts/network/udp-tcp/"},{"content":"每次push都需要输入用户名和密码,其实可以免去这些操作.🚛\n1. 使用.git-credentials文件 在git项目目录下新建.git-credentials这个文件,然后在里面填写下面内容(大括号不用填写):\nhttps://{username}:{password}@github.com 然后在git项目目录执行:\n1  git config --global credential.helper store   执行此命令后，用户主目录下的.gitconfig文件会多了一项：[credential]\nhelper = store  注意: Linux用户主目录一般在~/下,而Windows下一般为C:\\users\\Administrator\n 这样以后push就不需要用户名和密码了\n2. 使用ssh协议 首先生成密钥对,执行\n1  ssh-keygen -t rsa -C \u0026#34;youremail\u0026#34;   接下来按照提示操作，默认可以一路往下。\n然后将生成的位于~/.ssh/的id_rsa.pub的内容复制到你github setting里的ssh key中。\n复制之后，如果你还没有克隆你的仓库，那你直接使用ssh协议用法：git@github.com:yourusername/yourrepositoryname克隆就行了。\n如果已经使用https协议克隆了，那么按照如下方法更改协议：\ngit remote set-url origin git@github.com:yourusername/yourrepositoryname.git\nDone!\n3. 管理多git账号 参考:\n https://www.jianshu.com/p/f7f4142a1556 简书 https://segmentfault.com/a/1190000012432367 https://juejin.im/post/5d6a23d45188252bd90f601a 掘金 https://www.cnblogs.com/popfisher/p/5731232.html ","description":"","id":86,"section":"posts","tags":["git","github"],"title":"Git免密push","uri":"https://hugo.jiahongw.com/zh/posts/git/git-push-no-pw/"},{"content":"AES算法是继DES之后比较快且比较简单的加密算法.⚖\n对称加密 对称加密模型 如下图，发送者和接收者共享一个一样的密钥，相当于现实生活中的锁，\n对称加密的使用要求  一个强加密算法 只有发送发和接收方知道私钥   加密算法是公开的，不需保密；并且解密算法本质上是加密算法的反向执行。\n 但是，如何安全的分发安全密钥呢？——————安全分发不可能单靠对称加密算法，常常使用的是非对称加密算法。\n所以，对称加密的安全性取决于密钥的保密性而非算法的保密性，通常认为已知密文和加密/加密算法的基础上不能够破译信息。\nAES算法 算法原理： AES密码与分组密码Rijndael基本上完全一致，Rijndael分组大小和密钥大小都可以为128位、192位和256位。然而AES只要求分组大小为128位，因此只有分组长度为128Bit的Rijndael才称为AES算法。\n下面是分组长度为128位的AES算法,而key位数可以是128/192/256,本次实验选择key的大小位128位.\n特点  明文分组被描述为一个字节方阵并复制到状态数组，在每轮替换和移位时都并行处理整个状态分组。 矩阵中字节的顺序是按列排序的，例如128比特的明文分组的前4个字节占输入矩阵的第一列，接下来的4个字节占第二列，依次类推。扩展子密钥数组也类似操作。 假设AES使用128比特的密钥，其密钥被描述为一个字节方阵并将扩展成为一个子密钥数组w[i]（具有44个32比特字），4个不同的字（共128比特）用作每轮的轮密钥。 AES在每轮运算中将进行4个不同的步骤，1个是移位，3个是替换。  数学知识 在AES算法中的MixColumn层中会用到伽罗瓦域中的乘法运算，而伽罗瓦域的运算涉及一些数学知识。\n素域 有限域有时也称伽罗瓦域，它指的是由有限个元素组成的集合，在这个集合内可以执行加、减、乘和逆运算。而在密码编码学中，我们只研究拥有有限个元素的域，也就是有限域。域中包含元素的个数称为域的阶。只有当m是一个素数幂时，即$m=p^n$(其中n为正整数是p的次数，p为素数)，阶为m的域才存在。p称为这个有限域的特征。\n例如，有限域中元素的个数可以是11(p=11是一个素数,n=1)、可以是81(p=3是一个素数，n=4)、也可以是256(p=2是一个素数，n=8)\u0026hellip;..但有限域的中不可能拥有12个元素，因为12=2·2·3，因此12也不是一个素数幂。因此满足p是一个素数且满足$m = p^n$这个公式，m才是一个素数幂。\n有限域中最直观的例子就是阶为素数的域，即n=1的域。域GF(p)的元素可以用整数0、1、\u0026hellip;、p-1l来表示。域的两种操作就是模整数加法和整数乘法模p。加上p是一个素数，整数环Z表示为GF(p)，也成为拥有素数个元素的素数域或者伽罗瓦域。GF(p)中所有的非零元素都存在逆元，GF(p)内所有的运算都是模p实现的。\n素域内的算数运算规则如下  加法和乘法都是通过模p实现的； 任何一个元素a的加法逆元都是由a+(a的逆元)=0 mod p得到的； 任何一个非零元素a的乘法逆元定义为a·a的逆元=1。  举个例子，在素域GF(5)={0、1、2、3、4}中，2的加法逆元为3，这是因为2+(3)=5，5mod5=0,所以2+3=5mod5=0。2的乘法逆元为3，这是因为2·3=6，6mod5=1，所以2·3=6mod5=1。(在很多地方a的加法逆元1用$-a$表示，a的乘法逆元2用$1/a$表示)\n 注：GF(2)是一个非常重要的素域，也是存在的最小的有限域，由于GF(2)的加法，即模2加法与异或(XOR)门等价，GF(2)的乘法与逻辑与(AND)门等价，所以GF(2)对AES非常重要。\n模2加法与异或(XOR)门等价:\n$$\n(1 + 0) \\mod 2 = 1\\\\\n(0 + 1) \\mod 2 = 1\\\\\n(0 + 0) \\mod 2 = 0\\\\\n(1 + 1) \\mod 2 = 0\\\\\n$$\n乘法与逻辑与(AND)门等价:\n$$\n(1 \\times 0) \\mod 2 = 0\\\\\n(0 \\times 1) \\mod 2 = 0\\\\\n(0 \\times 0) \\mod 2 = 0\\\\\n(1 \\times 1) \\mod 2 = 1\\\\\n$$\n 扩展域 如果有限域的阶不是素数，则这样的有限域内的加法和乘法运算就不能用模整数加法和整数乘法模p表示。而且m\u0026gt;1的域被称为扩展域，为了处理扩展域，我们就要使用不同的符号表示扩展域内的元素，使用不同的规则执行扩展域内元素的算术运算。\n在扩展域$GF(2^m)$中，元素并不是用整数表示的，而是用系数为域$GF(2)$中元素的多项式表示。这个多项式最大的度(幂)为m-1​，所以每个元素共有m个系数，在AES算法使用的域$GF(2^8)$中，每个元素$A∈GF(2^8)$都可以表示为：\n$$\nA(x) = a_7x^7 + a_6x^6 + a_5x^5 + a_4x^4 + a_3x^3 + a_2x^2+a_1x + a_0,x_i \\in GF(2) = 0,1\n$$\n注意：在域GF(2^8)中这样的多项式共有256个，这256个多项式组成的集合就是扩展域GF(2^8)。每个多项式都可以按一个8位项链的数值形式存储：\n$$\nA = (a_7,a_6,a_5,a_4,a_3,a_2,a_1,a_0)\n$$\n像$x^7$、$x^6$等因子都无需存储，因为从位的位置就可以清楚地判断出每个系数对应的幂。\n扩展域$GF(2^m)$内的加减法 在AES算法中的密钥加法层中就使用了这部分的知识，但是不是很明显，因为我们通常把扩展域中的加法当作异或运算进行处理了，因为在扩展域中的加减法处理都是在底层域GF(2)内完成的，与按位异或运算等价。假设$A(x)$、$B(x)∈GF(2^m)$，计算两个元素之和的方法就是：\n$$\nC(x) = A(x) + B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i + b_i) \\mod 2\n$$\n而两个元素之差的计算公式就是：\n$$\nC(x) = A(x) - B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i - b_i) \\mod 2 = (a_i + b_i) \\mod 2\n$$\n 注：在减法运算中减号之所以变成加号，这就和二进制减法的性质有关了，大家可以试着验算下。从上述两个公式中我们发现在扩展域中加法和减法等价，并且与XOR等价(异或运算也被称作二进制加法)。\n 扩展域GF(2^m)内的乘法 扩展域的乘法主要运用在AES算法的列混淆层(Mix Column)中，也是列混淆层中最重要的操作。我们项要将扩展域中的两个元素用多项式形式展开，然后使用标准的多项式乘法规则将两个多项式相乘：\nAES步骤详解 AES算法主要有四种操作处理，分别是密钥加法层(也叫轮密钥加，英文Add Round Key)、字节代换层(SubByte)、行位移层(Shift Rows)、列混淆层(Mix Column)。而明文x和密钥k都是由16个字节组成的数据(当然密钥还支持192位和256位的长度)，它是按照字节的先后顺序从上到下、从左到右进行排列的。而加密出的密文读取顺序也是按照这个顺序读取的，相当于将数组还原成字符串的模样了，然后再解密的时候又是按照4·4数组处理的。AES算法在处理的轮数上只有最后一轮操作与前面的轮处理上有些许不同(最后一轮只是少了列混淆处理)，在轮处理开始前还单独进行了一次轮密钥加的处理。在处理轮数上，只考虑128位密钥的10轮处理。\n其中字节排列方式需要按照如下转换:\nAES算法流程图如下:\n实现步骤及代码 按照AES流程图,对每一层的代码进行实现.\n密钥加法层 在密钥加法层中有两个输入的参数，分别是明文和子密钥k[0]，而且这两个输入都是128位的。在扩展域中加减法操作和异或运算等价，所以这里的处理也就异常的简单了，只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n如下图：\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4 * 4], word k[4]) { for (int i = 0; i \u0026lt; 4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i + 4] = mtx[i + 4] ^ byte(k2.to_ulong()); mtx[i + 8] = mtx[i + 8] ^ byte(k3.to_ulong()); mtx[i + 12] = mtx[i + 12] ^ byte(k4.to_ulong()); } }   AES密钥生成 首先定义位置变换函数RotWord(),作用是接受一个字 $[a0, a1, a2, a3] $作为输入，循环左移一个字节后输出$ [a1, a2, a3, a0]$,代码如下:\n1 2 3 4 5 6  word RotWord(const word \u0026amp;w) { word result(0x0); result = (w \u0026lt;\u0026lt; 8) | (w \u0026gt;\u0026gt; 24); return result; }   定义S盒变换函数SubWord()，接受一个字 $[a0, a1, a2, a3]$ 作为输入，然后每一个byte，例如a0，前四个字节为行，后四个字节为列，从S_Box中查找并且返回四个元素。，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13  word SubWord(const word\u0026amp; sw) { word temp; for(int i=0; i\u0026lt;32; i+=8) { int row = sw[i+7]*8 + sw[i+6]*4 + sw[i+5]*2 + sw[i+4]; int col = sw[i+3]*8 + sw[i+2]*4 + sw[i+1]*2 + sw[i]; byte val = S_Box[row][col]; for(int j=0; j\u0026lt;8; ++j) temp[i+j] = val[j]; } return temp; }   轮常数Rcon[]作为一个常量数组，每一轮生成密钥的时候需要作为参数异或\n1 2 3  // 轮常数，密钥扩展中用到。（AES-128只需要10轮） word Rcon[10] = {0x01000000, 0x02000000, 0x04000000, 0x08000000, 0x10000000, 0x20000000, 0x40000000, 0x80000000, 0x1b000000, 0x36000000};   密钥拓展函数KeyExpansion(),接受一个参数为外部密钥，另外一个为需要拓展的轮密钥数组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25  //密钥扩展函数 - 对128位密钥进行扩展得到 w[4*(Nr+1),Nr为轮数 void KeyExpansion(byte key[4 * N_key], word w[4 * (N_round + 1)]) { word temp; int i = 0; while (i \u0026lt; N_key)\t//前四个word就是输入的key  { w[i] = ToWord(key[4 * i], key[4 * i + 1], key[4 * i + 2], key[4 * i + 3]); ++i; } i = N_key; while (i \u0026lt; 4 * (N_round + 1)) { temp = w[i - 1]; //记录前一个word  if (i % N_key == 0) { //temp先位置表换RotWord，再S盒变换，然后与轮常数异或，最后w[i-N_key] 异或  w[i] = w[i - N_key] ^ SubWord(RotWord(temp)) ^ Rcon[i / N_key - 1]; } else { w[i] = w[i - N_key] ^ temp; } i++; } }   字节替换层 S盒字节替换，主要功能就是让输入的数据通过S_box表完成从一个字节到另一个字节的映射，读取S_box数据的方法就是要将输入数据的每个字节的高四位作为第一个下标，第四位作为第二个下标。然后返回数据，字节替换主要是为了扰乱数据。\nS盒：\n逆S盒：\n图解如下：\n正向S盒变换代码如下：\n1 2 3 4 5 6 7 8 9 10  //S盒变换 - 前4位为行号，后4位为列号 void SubBytes(byte mtx[4 * 4]) { for (int i = 0; i \u0026lt; 16; ++i) { int row = mtx[i][7] * 8 + mtx[i][6] * 4 + mtx[i][5] * 2 + mtx[i][4]; int col = mtx[i][3] * 8 + mtx[i][2] * 4 + mtx[i][1] * 2 + mtx[i][0]; mtx[i] = S_Box[row][col]; } }   反向S盒变换代码如下:\n1 2 3 4 5 6 7 8 9 10  // 逆S盒变换 void InvSubBytes(byte mtx[4*4]) { for(int i=0; i\u0026lt;16; ++i) { int row = mtx[i][7]*8 + mtx[i][6]*4 + mtx[i][5]*2 + mtx[i][4]; int col = mtx[i][3]*8 + mtx[i][2]*4 + mtx[i][1]*2 + mtx[i][0]; mtx[i] = Inv_S_Box[row][col]; } }   行移位层 将输入数据作为一个$4·4$的字节矩阵进行处理，然后将这个矩阵的字节进行位置上的置换。在加密时行位移处理与解密时的处理相反，我们这里将解密时的处理称作逆行位移。它之所以称作行位移，是因为它只在$4·4$矩阵的行间进行操作，每行4字节的数据。在加密时，保持矩阵的第一行不变，第二行向左移动8Bit(一个字节)、第三行向左移动2个字节、第四行向左移动3个字节。而在解密时恰恰相反，依然保持第一行不变，将第二行向右移动一个字节、第三行右移2个字节、第四行右移3个字节。最终结束。\n正向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  //正向行变换 - 按字节循环移位 void ShiftRows(byte mtx[4 * 4]) { // 第二行循环左移一位  byte temp = mtx[4]; for (int i = 0; i \u0026lt; 3; ++i) mtx[i + 4] = mtx[i + 5]; mtx[7] = temp; // 第三行循环左移两位  for (int i = 0; i \u0026lt; 2; ++i) { temp = mtx[i + 8]; mtx[i + 8] = mtx[i + 10]; mtx[i + 10] = temp; } // 第四行循环左移三位  temp = mtx[15]; for (int i = 3; i \u0026gt; 0; --i) mtx[i + 12] = mtx[i + 11]; mtx[12] = temp; }   反向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  // 逆行变换 - 以字节为单位循环右移 void InvShiftRows(byte mtx[4*4]) { // 第二行循环右移一位 \tbyte temp = mtx[7]; for(int i=3; i\u0026gt;0; --i) mtx[i+4] = mtx[i+3]; mtx[4] = temp; // 第三行循环右移两位 \tfor(int i=0; i\u0026lt;2; ++i) { temp = mtx[i+8]; mtx[i+8] = mtx[i+10]; mtx[i+10] = temp; } // 第四行循环右移三位 \ttemp = mtx[12]; for(int i=0; i\u0026lt;3; ++i) mtx[i+12] = mtx[i+13]; mtx[15] = temp; }   列混淆层 列混淆子层是AES算法中最为复杂的部分，属于扩散层，列混淆操作是AES算法中主要的扩散元素，它混淆了输入矩阵的每一列，使输入的每个字节都会影响到4个输出字节。行位移子层和列混淆子层的组合使得经过三轮处理以后，矩阵的每个字节都依赖于16个明文字节成可能。\n在加密的正向列混淆中，我们要将输入的$4·4$矩阵左乘一个给定的$4·4$矩阵。而它们之间的加法、乘法都在扩展域$GF(2^8)$中进行，,在矩阵相乘计算中，出现了加法和乘法，而前面提到了在拓展域中加法等同于异或运算，而对于乘法，需要特殊的方式进行处理，于是将+号换成^号，然后将伽罗瓦域的乘法定义成一个有两个参数的函数，并让他返回最后计算结果，最后列混淆代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  //正向列变换 void MixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x02, arr[0]) ^ GFMul(0x03, arr[1]) ^ arr[2] ^ arr[3]; mtx[i+4] = arr[0] ^ GFMul(0x02, arr[1]) ^ GFMul(0x03, arr[2]) ^ arr[3]; mtx[i+8] = arr[0] ^ arr[1] ^ GFMul(0x02, arr[2]) ^ GFMul(0x03, arr[3]); mtx[i+12] = GFMul(0x03, arr[0]) ^ arr[1] ^ arr[2] ^ GFMul(0x02, arr[3]); } }   在解密的逆向列混淆中与正向列混淆的不同之处在于使用的左乘矩阵不同，它与正向列混淆的左乘矩阵互为逆矩阵，也就是说，数据矩阵同时左乘这两个矩阵后，数据矩阵不会发生任何变化。下面是图解：\n正向混淆处理：\n逆向混淆处理：\n反向列变换代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  //反向列混淆 void InvMixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x0e, arr[0]) ^ GFMul(0x0b, arr[1]) ^ GFMul(0x0d, arr[2]) ^ GFMul(0x09, arr[3]); mtx[i+4] = GFMul(0x09, arr[0]) ^ GFMul(0x0e, arr[1]) ^ GFMul(0x0b, arr[2]) ^ GFMul(0x0d, arr[3]); mtx[i+8] = GFMul(0x0d, arr[0]) ^ GFMul(0x09, arr[1]) ^ GFMul(0x0e, arr[2]) ^ GFMul(0x0b, arr[3]); mtx[i+12] = GFMul(0x0b, arr[0]) ^ GFMul(0x0d, arr[1]) ^ GFMul(0x09, arr[2]) ^ GFMul(0x0e, arr[3]); } }   密钥加法层 这一层主要是明文矩阵盒子密钥矩阵进行异或操作,在密钥加法层中有两个输入的参数，分别是明文和子密钥，而且这两个输入都是128位的。只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4*4], word k[4]) { for(int i=0; i\u0026lt;4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i+4] = mtx[i+4] ^ byte(k2.to_ulong()); mtx[i+8] = mtx[i+8] ^ byte(k3.to_ulong()); mtx[i+12] = mtx[i+12] ^ byte(k4.to_ulong()); } }   实现加密函数 加密函数按照流程图,首先开始是先进行一次轮密钥加,然后开始9轮的字节替换+行移位+列混淆+轮密钥加的操作,循环之后再做一次字节替换+行移位+轮密钥加就完成加密操作了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  void encrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); for(int round=1; round\u0026lt;N_round; ++round) { SubBytes(in); ShiftRows(in); MixColumns(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); } SubBytes(in); ShiftRows(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); }   实现解密函数 解密函数与加密差不多,只不过将行移位变成反向行移位,列混淆变成反向列混淆,字节替换变成逆字节替换即可.\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  void decrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); for(int round=N_round-1; round\u0026gt;0; --round) { InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); InvMixColumns(in); } InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); }   测试加密解密函数 可以发现上面面的测试中明文与解密之后的明文是完全正确的,说明加密函数与解密函数正确!\n测试代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49  void Aes_test() { byte key[16] = {0x2b, 0x7e, 0x15, 0x16, 0x28, 0xae, 0xd2, 0xa6, 0xab, 0xf7, 0x15, 0x88, 0x09, 0xcf, 0x4f, 0x3c}; byte plain[16] = {0x32, 0x88, 0x31, 0xe0, 0x43, 0x5a, 0x31, 0x37, 0xf6, 0x30, 0x98, 0x07, 0xa8, 0x8d, 0xa2, 0x34}; // 输出密钥  cout \u0026lt;\u0026lt; \u0026#34;Key is : \u0026#34;; for (int i = 0; i \u0026lt; 16; ++i) cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; key[i].to_ulong() \u0026lt;\u0026lt; \u0026#34;\u0026#34;; cout \u0026lt;\u0026lt; endl; word w[4 * (N_round + 1)]; KeyExpansion(key, w); // 输出待加密的明文  cout \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;the plaintext to encrypy:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34;\u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 加密，输出密文  encrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;cipher : \u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34;\u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 解密，输出明文  decrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;plain arter decrypt:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34;\u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; }   实现加解密文件 加密文件函数,返回加密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  string encryptFile(string oname, string suffix, word w[4 * (N_round + 1)]) { string outputfilename = oname + \u0026#34;_cipher.bin\u0026#34;; bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining encrypy...........\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); // 将文件加密到 oname + cipher.bin 中  ifstream in; ofstream out; in.open(oname + suffix, ios::binary); //输入文件  out.open(outputfilename, ios::binary); //输出加密文件  while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); encrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0  } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;encrypy finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;encrypy cost time : \u0026#34; \u0026lt;\u0026lt; (end - start) \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; //返回加密之后的文件 }   解密文件函数,返回解密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27  string decryptFile(string filename, string oname, string suffix, word w[4 * (N_round + 1)]) { ifstream in; ofstream out; in.open(filename, ios::binary); string outputfilename = oname + \u0026#34;_decrypt\u0026#34; + suffix; out.open(outputfilename, ios::binary); bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining decrypt............\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); decrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0  } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;decrypt finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;decrypt cost time : \u0026#34; \u0026lt;\u0026lt; end - start \u0026lt;\u0026lt; \u0026#34;ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; }   实现效果:\n加密txt文件:\n加密jpg文件:\n加密mp3文件:\n加密doc文件:\nAES五种加密模式 实现五种加密方式的密钥是一个置换表unsigned char Table[4] = {0x12, 0xb1, 0x53, 0x28};,加密函数是原文与密钥的异或.\nECB模式(电子密码本模式) 加密前根据加密块大小（如AES为128位）分成若干块，之后将每块使用相同的密钥单独加密，解密同理。\nECB模式由于每块数据的加密是独立的因此加密和解密都可以并行计算，ECB模式最大的缺点是相同的明文块会被加密成相同的密文块，这种方法在某些环境下不能提供严格的数据保密性。\n流程图如下:\n实现代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  //电子密码本模式,分组大小为4 unsigned char* ECB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量  //密文  unsigned char *cipher = new unsigned char[N]; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for(int j = 0;j \u0026lt; groupSize;++j) temp[j] = plain[count++]; //加密  encrypt(temp,groupSize); for(int j = i*4;j \u0026lt; i*4 + 4;++j) cipher[j] = temp[j - i * 4]; } return cipher;//返回密文 }   解密方法也是让密文与密钥进行异或即可,实现效果如下:\nCBC模式(分组链接模式) CBC模式对于每个待加密的密码块在加密前会先与前一个密码块的密文异或然后再用加密器加密。第一个明文块与一个叫初始化向量的数据块异或。\n可用公式总结为:\n$$\nC_i = E_K(P_i XOR C_{i-1}) \\\nC_{-1} = IV\n$$\n流程图如下:\nCBC模式相比ECB有更高的保密性，但由于对每个数据块的加密依赖与前一个数据块的加密所以加密无法并行。与ECB一样在加密前需要对数据进行填充，不是很适合对流数据进行加密。\n代码如下:\n加密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  //CCB加密函数 unsigned char *CCB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量  //密文  unsigned char *cipher = new unsigned char[N]; //设置初始向量  unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = plain[count++]; //加密  for (int j = 0; j \u0026lt; groupSize; ++j) //先与初始向量异或  temp[i] ^= C[i]; encrypt(temp, groupSize); //加密  for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { cipher[j] = temp[j - i * 4]; C[j - i * 4] = temp[j - i * 4];//设置新向量  } } return cipher; }   解密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  //CCB解密函数 unsigned char *dCCB(unsigned char *cipher, int N) { int gNum = N / groupSize; //分组数量  //明文  unsigned char *plain = new unsigned char[N]; //设置初始向量  unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = cipher[count++]; //解密  encrypt(temp, groupSize); //先解密  for (int j = 0; j \u0026lt; groupSize; ++j) //然后与初始向量异或  temp[i] ^= C[i]; for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { plain[j] = temp[j - i * 4]; C[j - i * 4] = cipher[j];//设置新向量  } } return plain; }   实现效果:\nCFB模式(密文反馈模式) 与前面的模式不同,CFB模式可以将消息被当成是比特流.可以总结为如下的公式:\n$$\nC_i = P_i XOR E_K(C_{i-1})\\\nC_{-1} = IV\n$$\n流程图如下:\n加密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //密文反馈模式,加密函数 unsigned char *CFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2  //密文  unsigned char *cipher = new unsigned char[N]; //设置初始向量  unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节  int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文,大小为2  for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密  //先对初始向量进行加密  encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或  for(int j = 0;j \u0026lt; gsize;++j){ temp[j] ^= C[j]; S[j] = temp[j]; //获取密文的2bit  } //设置密文  for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移  for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; }   解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38  //密文反馈解密 unsigned char *dCFB(unsigned char *cipher, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2  //明文  unsigned char *plain = new unsigned char[N]; //设置初始向量  unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节  int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组密文  for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = cipher[count++]; //解密  //先对初始向量进行加密  encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或  for(int j = 0;j \u0026lt; 2;++j){ S[j] = temp[j]; temp[j] = C[j] ^ temp[j]; } //设置明文  for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { plain[j] = temp[j - i * gsize]; } //设置新向量,新向量左移  for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j+gsize] = S[j]; } } return plain; }   实现效果:\nOFB模式(输出反馈模式) OFB是先用块加密器生成密钥流（Keystream），然后再将密钥流与明文流异或得到密文流，解密是先用块加密器生成密钥流，再将密钥流与密文流异或得到明文，由于异或操作的对称性所以加密和解密的流程是完全一样的。\nOFB与CFB一样都非常适合对流数据的加密，OFB由于加密和解密都依赖与前一段数据，所以加密和解密都不能并行。\n流程图如下:\n加密解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39  //输出反馈模式,加密解密函数相同 unsigned char *OFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2  //密文  unsigned char *cipher = new unsigned char[N]; //设置初始向量  unsigned char C[4] = {0xee, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节  int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文  for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密  //先对初始向量进行加密  encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或  for(int j = 0;j \u0026lt; 2;++j){ S[j] = C[j]; //取向量加密后的前两位  temp[j] ^= C[j]; } //设置密文  for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移  for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; }   实现效果:\nCTR模式(计数器模式) 类型于CFB，但是加密每个计数值，而不是任何反馈值,对每个明文分组，必须有不同的密钥和计数值 (从不重复使用),,可以用如下公式表示:\n$$\nO_i = E_K(i)\\\nC_i = P_i XOR O_i\n$$\n计数器模式流程图如下:\n计数器模式加密函数与解密函数一样,代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33  //计数器模式,加密函数 unsigned char *CTR(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量  //密文  unsigned char *cipher = new unsigned char[N]; //设置随机值  unsigned char Counter[groupSize*groupSize] = {0x44, 0xa9, 0x5d, 0x99, 0xe5, 0xf1, 0x3d, 0x91, 0x16, 0xa6, 0xe1, 0x33, 0x22, 0xdd, 0xab, 0x1f}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; //明文分组  unsigned char C[groupSize]; //分组随机值  for (int j = 0; j \u0026lt; groupSize; ++j) { temp[j] = plain[count++]; C[j] = Counter[i*4+j]; } //加迷  //首先加密随机值C  encrypt(C, groupSize); //然后与明文进行异或  for(int j = 0;j \u0026lt; groupSize;++j) temp[j] ^= C[j]; //设置密文  for(int j = i*groupSize;j \u0026lt; i*groupSize+groupSize;j++) cipher[j] = temp[j-i*groupSize]; } return cipher; }   实现效果如下:\n参考:\n https://www.cnblogs.com/RabbitHu/p/bitset.html bitset用法 https://blog.csdn.net/liushu1231/article/details/8844631 bitset的空间大小 http://c.biancheng.net/cpp/html/2834.html 文件处理 https://bbs.pediy.com/thread-253884.htm AES算法带图解 https://blog.csdn.net/lisonglisonglisong/article/details/41909813 AES算法 CSDN https://blog.csdn.net/sinat_23338865/article/details/72869841 AES五种加密模式   设“+”为一个交换性的二元运算，即对于所有x,y，x+y=y+x。若该集内存在一个元素0，使得对于所有x，x+0=0+x=x，则此元素是唯一的。如果对于一个给定的x，存在一个x'使得x+x'=x'+x=0，则称x'是x的加法逆元。 \u0026#x21a9;\u0026#xfe0e;\n 乘法逆元，是指数学领域群G中任意一个元素a，都在G中有唯一的逆元a‘，具有性质a×a'=a'×a=e，其中e为该群的单位元。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":87,"section":"posts","tags":["AES","密码学","加密"],"title":"Aes-高级加密标准","uri":"https://hugo.jiahongw.com/zh/posts/cryptography/aes/"},{"content":"简单地说，云计算就是计算服务的提供（包括服务器、存储、数据库、网络、软件、分析和智能）- 通过 Internet（云）提供快速创新、弹性资源和规模经济。对于云服务，通常你只需使用多少支付多少，从而帮助降低运营成本，使基础设施更有效地运行，并能根据业务需求的变化调整对服务的使用。\n行云趣码记录 行云趣码官网：http://mart.cloudtogo.cn/\nLinux服务器 生成自己的服务器 进入应用商店，选择需要的Linux服务器，这里选择CentOS\n点击部署，等待生成自己的服务器\n发布成功\n参数解释 点击访问，会跳出访问地址，部署区域以及提示信息，一步一步看。\n访问地址\n部署区域\n部署区域没什么好说的，就是这个服务器部署的区域。\n详情\n从上面给的信息，可以归为如下：\n  ssh远程访问的地址为2c56369b3c95a919.c.cloudtogo.cn，端口为34920(注意：端口不是22)。远程登陆的用户名为：root，密码为：123456.\n  有五个映射端口，他们的对应关系如下：\n   Linux内部 外部访问     8001 34921(预留a端口)   8002 34916(预留b端口)   8003 34917(预留c端口)   8004 34918(预留d端口)   8005 34924(预留e端口)    也就是说，当我们在Linux内部启用8001-8005这五个端口运行相应的应用时，我们可以访问对应的外部预留端口以及子域名进行访问测试。\n例如在Linux内运行了一个web应用在8001端口，我们可以在浏览器访问61823a63ab19b300.c.cloudtogo.cn:34921\n  ssh远程连接：\n查看配置 查看CPU型号: Intel(R) Xeon(R) CPU E5-2680 v3\n1  cat /proc/cpuinfo | grep name | cut -f2 -d: | uniq -c   查看物理CPU个数: 2\n1  cat /proc/cpuinfo | grep \u0026#34;physical id\u0026#34; | sort | uniq|wc -l   查看逻辑CPU的个数: 8个\n1  cat /proc/cpuinfo | grep \u0026#34;processor\u0026#34; |wc -l   查看CPU是几核: 4核\n1  cat /proc/cpuinfo | grep \u0026#34;cores\u0026#34;|uniq   设置远程访问jupyter 安装完jupyter之后，输入以下命令生成配置文件：\n1  jupyter notebook --generate-config   参考：\nhttps://www.jianshu.com/p/960f011f712e\nhttps://zhuanlan.zhihu.com/p/64524822\n结果：\n添加虚拟环境：https://ofooo.github.io/wiki/python/%E5%B7%A5%E5%85%B7/jupyter-notebook/\n更换pip源：https://www.linuxidc.com/Linux/2019-04/158178.htm\n部署nodejs：https://blog.csdn.net/xerysherryx/article/details/78920978\nnpm镜像：https://www.cnblogs.com/alps/p/12439387.html\nCentOS基本命令 查看服务进程\n1 2 3  [victor@mylove ~]$ ps -aux|grep mysql victor 23477 0.0 0.0 110656 2688 pts/3 S+ 12:26 0:00 grep --color=auto mysql   查看进程端口\n1  netstat -anp |grep 1506   查看端口进程\n1  netstat -lnp|grep 3306   关闭进程\n1  kill –9 1506   生产应用 使用docker生产自己的应用 开发网页App 进入应用工厂,打开一个Blank的模板继续,然后再设计页面拖入一个代码组件,如下:\n输入名字为webpy,应为使用的是web.py框架进行编写,然后点击下一步.\n然后输入存放代码的地址,代码需要编写完成之后存到GitHub上,程序默认的运行入口时main.py,在运行main.py之前,还会执行pip install -r requirements.txt这个代码,所以我们可以将所需要的依赖包都写在requirements.txt这个文件中.\n我的代码地址: https://github.com/redisread/webpy.git\n编写组件向导,有许多参数\n其他的参数作用:\n 环境变量: 存储系统的相关需要运行的程序的位置 多副本: 多副本设置支持可以使用弹性伸缩功能,可开启可不开启 会话保持: 维持客户端与一台服务器的连接,即对于某个客户端,,不会更换与他进行连接的服务器 执行命令: 可以执行Linux的相关命令 存储路径: 可以设置存储到数据卷中,填写的Linux的位置就是数据卷存放的位置 root权限: 是否开启root权限 服务名称: 就是服务的名称 读取指定文件: **0 日志文件: 填写日志文件存放的的地方 映射配置文件: 可以映射(相当于替换)配置文件,例如nginx的nginx.conf文件. 健康检查: 特权模式: 资源限制: 限制CPUy以及内存的设置  最后点击完成就可以发发布应用了\n发布一般不需要配置什么,需要的话可以自行设置.\n发布成功!\n访问该地址就能够访问我们写的应用了.\n运维管理 在发布页的侧边栏有一个运维按钮,点击进入运维界面\n如下就是可以进行查看的相关信息\n","description":"","id":88,"section":"posts","tags":["云计算","行云趣码"],"title":"行云开发","uri":"https://hugo.jiahongw.com/zh/posts/cloudcomputing/xingyun-begin/"},{"content":"。。集万滴雨水，成一条江河🌊🌊\nRedis  REmote DIctionary Server(Redis) 是一个由Salvatore Sanfilippo写的key-value存储系统。\nRedis是一个开源的使用ANSI C语言编写、遵守BSD协议1、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。\n它通常被称为数据结构服务器，因为值（value）可以是 字符串(String), 哈希(Hash), 列表(list), 集合(sets) 和 有序集合(sorted sets)等类型。\n  开源界的 5 大许可协议：五大开源许可协议分别是GPL,LGPL,BSD,MIT,Apache。\n 存储类型：\n String: 字符串 Hash: 散列 List: 列表 Set: 集合 Sorted Set: 有序集合  三个特点：\n Redis支持数据的持久化，可以将内存中的数据保存在磁盘中，重启的时候可以再次加载进行使用。 Redis不仅仅支持简单的key-value类型的数据，同时还提供list，set，zset，hash等数据结构的存储。 Redis支持数据的备份，即master-slave模式2的数据备份。  Redis与其他key-value存储有什么不同？\n Redis有着更为复杂的数据结构并且提供对他们的原子性操作3，这是一个不同于其他数据库的进化路径。Redis的数据类型都是基于基本数据结构的同时对程序员透明，无需进行额外的抽象。 Redis运行在内存中但是可以持久化到磁盘，所以在对不同数据集进行高速读写时需要权衡内存，因为数据量不能大于硬件内存。在内存数据库方面的另一个优点是，相比在磁盘上相同的复杂的数据结构，在内存中操作起来非常简单，这样Redis可以做很多内部复杂性很强的事情。同时，在磁盘格式方面他们是紧凑的以追加的方式产生的，因为他们并不需要进行随机访问。  安装 github链接：https://github.com/microsoftarchive/redis/releases\nRedis是C语言开发，安装Redis需要先将官网下载的源码进行编译，编译依赖gcc环境，如果没有gcc环境，需要安装gcc。\n安装GCC 步骤：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  ## 先安装 gcc 编译环境,如果已经安装, 请忽略 yum -y install gcc automake autoconf libtool make ## 下载 redis 源代码 wget http://download.redis.io/releases/redis-4.0.1.tar.gz ## 下载完成后,解压 tar zxvf redis-4.0.1.tar.gz ## 跳转到 redis 目录 cd redis-4.0.1 ## 编译 make ## 安装编译后的软件到 /usr/local/redis ## PREFIX必须大写,自动为我们创建redis目录，并将结果安装此目录 make PREFIX=/usr/local/redis install ## 查看安装的结果 cd /usr/local/redis/bin ls -l -rwxr-xr-x 1 root root 2451864 Mar 12 13:28 redis-benchmark -rwxr-xr-x 1 root root 5741096 Mar 12 13:28 redis-check-aof -rwxr-xr-x 1 root root 5741096 Mar 12 13:28 redis-check-rdb -rwxr-xr-x 1 root root 2606088 Mar 12 13:28 redis-cli lrwxrwxrwx 1 root root 12 Mar 12 13:28 redis-sentinel -\u0026gt; redis-server -rwxr-xr-x 1 root root 5741096 Mar 12 13:28 redis-server   配置  Redis 的配置文件位于 Redis 安装目录下，文件名为 redis.conf(Windows 名为 redis.windows.conf)。\n redis.conf配置文件详解：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116  ## 指定包含其它的配置文件，可以多个Redis实例使用同一份配置文件，而各个实例又拥有自己的特定配置文件 include /path/to/local.conf ## 绑定的主机地址, 可以监听一个或多个, 如果为 127.0.0.1 只能本机才能访问 bind 127.0.0.1 ## Redis默认不是以守护进程的方式运行，可以通过该配置项修改，使用yes启用守护进程 daemonize no ## Redis以守护进程方式运行时,Redis默认会把 pid 写入 /var/run/redis.pid 文件,可以通过 pidfile 指定 pidfile /var/run/redis_6379.pid ## 指定Redis监听端口，默认端口为6379 port 6379 ## 当客户端闲置多长时间后关闭连接，如果指定为0，表示关闭该功能 timeout 0 ## 指定日志记录级别，Redis总共支持四个级别：debug、verbose、notice、warning，默认为verbose ## debug 会打印出很多信息，适用于开发和测试阶段 ## verbose 包含很多不太有用的信息，但比debug要清爽一些 ## notice 适用于生产模式 ## warning 警告信息（仅记录非常重要/重要的消息） loglevel verbose ## 日志记录方式，默认为标准输出 ## 如果 Redis 以守护进程方式运行，而这里又配置为日志记录方式为标准输出，则日志将会发送给/dev/null logfile stdout ## 设置数据库的数量，默认数据库为0，可以使用SELECT \u0026lt;dbid\u0026gt;命令在连接上指定数据库id databases 16 ## 指定在多长时间内，有多少次更新操作，就将数据同步到数据文件(持久化)，可以多个条件配合 ## save \u0026lt;seconds\u0026gt; \u0026lt;changes\u0026gt; save 900 1 ## 900秒内有一个更新 save 300 10 ## 300秒内有10个更新 save 60 10000 ## 60秒内有10000个更新 ## 指定存储至本地数据库时是否压缩数据，默认为yes ## Redis采用LZF压缩，如果为了节省CPU时间，可以关闭该选项，但会导致数据库文件变的巨大 rdbcompression yes ## 指定本地数据库文件名，默认值为dump.rdb dbfilename dump.rdb ## 也就是安装目录下我们看到的那个文件 ## 指定本地数据库存放目录 dir ./ ## 当本机为slav服务时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步 slaveof \u0026lt;masterip\u0026gt; \u0026lt;masterport\u0026gt; ## 当master服务设置了密码保护时，slav服务连接master的密码 masterauth \u0026lt;master-password\u0026gt; ## 设置Redis连接密码 ## 如果配置了连接密码，客户端在连接Redis时需要通过AUTH \u0026lt;password\u0026gt;命令提供密码，默认关闭 requirepass foobared ## 设置同一时间最大客户端连接数，默认无限制 ## Redis可以同时打开的客户端连接数为Redis进程可以打开的最大文件描述符数 ## 如果设置 maxclients 0，表示不作限制 ## 客户端连接数到达限制时,Redis会关闭新的连接并向客户端返回max number of clients reached错误信息 maxclients 128 ## Redis最大内存限制 ## Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key ## 当此方法处理后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。 ## Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory \u0026lt;bytes\u0026gt; ## 指定是否在每次更新操作后进行日志记录, 默认为 no ## Redis在默认情况下是异步的把数据写入磁盘，如果不开启，可能会在断电时导致一段时间内的数据丢失 ## 因为 redis本身同步数据文件是按上面save条件来同步的，所以有的数据会在一段时间内只存在于内存中 appendonly no ## 指定更新日志文件名，默认为 appendonly.aof appendfilename appendonly.aof ## 指定更新日志条件 ## no : 表示等操作系统进行数据缓存同步到磁盘（快） ## always : 表示每次更新操作后手动调用fsync()将数据写到磁盘（慢，安全） ## everysec : 表示每秒同步一次（折中，默认值） appendfsync everysec ## 指定是否启用虚拟内存机制，默认值为no ## VM机制将数据分页存放,将访问量较少的页即冷数据swap到磁盘上,访问多的页面由磁盘自动换出到内存中 vm-enabled no ## 虚拟内存文件路径，默认值为/tmp/redis.swap，不可多个Redis实例共享 vm-swap-file /tmp/redis.swap ## 将所有大于vm-max-memory的数据存入虚拟内存 ## 无论vm-max-memory设置多小,所有索引数据都是内存存储的(Redis的索引数据 就是keys), ## 也就是说,当vm-max-memory设置为0的时候,其实是所有value都存在于磁盘。默认值为0 vm-max-memory 0 ## Redis swap文件分成了很多的page，一个对象可以保存在多个page上面，但一个page上不能被多个对象共享 vm-page-size 32 ## 设置swap文件中的page数量 ## 由于页表（一种表示页面空闲或使用的bitmap）是在放在内存中的,在磁盘上每8个pages将消耗1byte的内存。 vm-pages 134217728 ## 设置访问swap文件的线程数,最好不要超过机器的核数, ## 如果设置为0,那么所有对swap文件的操作都是串行的，可能会造成比较长时间的延迟。默认值为4 vm-max-threads 4 ## 设置在向客户端应答时，是否把较小的包合并为一个包发送，默认为开启 glueoutputbuf yes ## 指定在超过一定的数量或者最大的元素超过某一临界值时，采用一种特殊的哈希算法 hash-max-zipmap-entries 64 hash-max-zipmap-value 512 ## 指定是否激活重置哈希，默认为开启（后面在介绍Redis的哈希算法时具体介绍） activerehashing yes   注意事项 我们查看了配置文件信息, 总结如下\n   如果你想要以加载配置文件的方式启动 Redis, 那么你需要使用 ./redis-server /path/to/redis.conf 命令启动 Redis 服务端.\n  内存设置大小单位\n   1k =\u0026gt; 1000 bytes 1kb =\u0026gt; 1024 bytes 1m =\u0026gt; 1000000 bytes 1mb =\u0026gt; 1024*1024 bytes 1g =\u0026gt; 1000000000 bytes 1gb =\u0026gt; 102410241024 bytes 1GB 1Gb 1gB 表达一样的意思, 单位不区分大小写    121321\n   基本操作 连接远程服务器：redis-cli -h host -p port -a password\n例如：$redis-cli -h 127.0.0.1 -p 6379 -a \u0026quot;mypass\u0026quot;\n键Key 与 Redis 键相关的基本命令：\n   序号 命令及描述     1 DEL key 该命令用于在 key 存在时删除 key。   2 DUMP key 序列化给定 key ，并返回被序列化的值。   3 EXISTS key 检查给定 key 是否存在。   4 EXPIRE key seconds 为给定 key 设置过期时间，以秒计。   5 EXPIREAT key timestamp EXPIREAT 的作用和 EXPIRE 类似，都用于为 key 设置过期时间。 不同在于 EXPIREAT 命令接受的时间参数是 UNIX 时间戳(unix timestamp)。   6 PEXPIRE key milliseconds 设置 key 的过期时间以毫秒计。   7 PEXPIREAT key milliseconds-timestamp 设置 key 过期时间的时间戳(unix timestamp) 以毫秒计   8 KEYS pattern 查找所有符合给定模式( pattern)的 key 。   9 MOVE key db 将当前数据库的 key 移动到给定的数据库 db 当中。   10 PERSIST key 移除 key 的过期时间，key 将持久保持。   11 PTTL key 以毫秒为单位返回 key 的剩余的过期时间。   12 TTL key 以秒为单位，返回给定 key 的剩余生存时间(TTL, time to live)。   13 RANDOMKEY 从当前数据库中随机返回一个 key 。   14 RENAME key newkey 修改 key 的名称   15 RENAMENX key newkey 仅当 newkey 不存在时，将 key 改名为 newkey 。   16 TYPE key 返回 key 所储存的值的类型。    设置键值对 set key value 与取出键值对 get key\n删除键值使用del key\n字符串存储 Hash存储 之前变量没删除会报错\nRedis hash 是一个键值(key=\u0026gt;value)对集合。\nRedis hash 是一个 string 类型的 field 和 value 的映射表，hash 特别适合用于存储对象。\n每个 hash 可以存储 232 -1 键值对（40多亿）。\n列表存储 Redis 列表是简单的字符串列表，按照插入顺序排序。你可以添加一个元素到列表的头部（左边）或者尾部（右边）\n展示：\n列表最多可存储 232 - 1 元素 (4294967295, 每个列表可存储40多亿)。\n集合存储 指令：sadd key member 向集合key添加元素。\n指令：smembers key，展示集合key中的元素：\n有序集合-zset 指令：zadd key score member ，向有序集合添加元素，并且设置相应的score。\n上面设置A且score为0，B且score为2，C且score为1.\n指令：zrangebyscore key l r,展示有序集合按score排序之后且在范围l到r的元素。\n显然元素已经按照score的顺序排列。\n 跟其他条款相比，从GNU通用公共许可证（GPL）到限制重重的著作权（Copyright），BSD许可证比较宽松，甚至跟公有领域更为接近。事实上，BSD许可证被认为是copycenter（中间著作权），介乎标准的copyright与GPL的copyleft之间。\u0026ldquo;Take it down to the copy center and make as many copies as you want\u0026rdquo;[1]。可以说，GPL强迫后续版本必须一样是自由软件，BSD的后续版本可以选择要继续是BSD或其他自由软件条款或封闭软件等等。 \u0026#x21a9;\u0026#xfe0e;\n 主从设备模式也叫做主仆模式英文简称为Master-Slave,核心思想是基于分而治之的思想,将一个原始任务分解为若干个语义等同的子任务,并由专门的工作者线程来并行执行这些任务,原始任务的结果是通过整合各个子任务的处理结果形成的 \u0026#x21a9;\u0026#xfe0e;\n 意思就是要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务，即原子性，通过MULTI和EXEC指令包起来。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":89,"section":"posts","tags":["redis","分布式计算","云计算","数据库"],"title":"分布式-Redis","uri":"https://hugo.jiahongw.com/zh/posts/database/redis/"},{"content":"走得慢的时候，为什么不跑呢？#️⃣\n哈希散列表 两个概念：\n散列表：\n散列表（Hash table，也叫哈希表），是根据键（Key）而直接访问在内存存储位置的数据结构。也就是说，它通过计算一个关于键值的函数，将所需查询的数据映射到表中一个位置来访问记录，这加快了查找速度。这个映射函数称做散列函数，存放记录的数组称做散列表。\n散列函数：\n散列函数，顾名思义，它是一个函数。如果把它定义成 hash(key) ，其中 key 表示元素的键值，则 hash(key) 的值表示经过散列函数计算得到的散列值。\n散列函数特点：\n 确定性 散列碰撞（collision） 不可逆性(一个哈希值对应无数个明文，理论上你并不知道哪个是。) 混淆特性  常见的散列函数：\n MD51 SHA-12  为什么哈希算法查找数组元素会更快？\n 原来使用下标进行匹配的画，会一个一个从一整个数组进行元素匹配，知道找到相等的元素才得到数组的信息。例如在Arr[20]查找值为12的,就需要从下标0到19进行查找。\n但是哈希散列表将一个一个按顺序的查找转换为使用计算的方式进行查找，将运算结果的下标映射成一个哈希表，实现了跳跃式的查找，从而效率更高。\n 问题:散列冲突\n 对于散列表而言，无论设置的存储区域（n）有多大，当需要存储的数据大于 n 时，那么必然会存在哈希值相同的情况。这就是所谓的散列冲突。\n 解决散列函数的两个方法：\n  链表法\n就是使用链表来保存冲突下标的数据，例如$12 % 5 = 2$和$7 % 5 = 2$,那么在下标为2的表下用一个链表存储12和7。\n  开放寻址法。\n常见三种方法：线性探测法、二次探测法、双散列\n假设哈希函数为：\n$$\nH(key) = key \\mod10\n$$\n线性探测法：\n还是$12 % 10 = 2 $和$22 % 10 = 2$这两个例子，当22这个数字需要存入哈希表时，发现已经有12这个元素存放在下标为2的哈希表上了，那么对Hash后的数字加一在进行Hash。即对7进行这样的操作：\n$$\nH((H(key)+1)) = ((22 \\mod 10) + 1) \\mod 10 = (2 + 1) \\mod 10 = 3\n$$\n但是这种方式的问题是冲突较多的时候会出现数据聚集在一个区域，这样不利于查询数据。\n二次探测法：\n二次探测法使用下面的函数解决冲突：\n$$\n(H(key) \\pm j^2) \\mod 10,j = 0,1,2\u0026hellip;\n$$\n这种方法较为复杂，而且虽然不会连续的聚集一片，但是会在多个间断的位置聚集。\n双散列：\n双散列，顾名思义就需要增加一个二级散列函数，例如$G(key) = q - (key \\mod q) q为素数且q\u0026lt;N$，发现冲突使用如下操作：\n$$\nH(key) + j * G(key),j = 0,1,2\u0026hellip;\u0026hellip;\n$$\n双散列方法有很多组合的方法，这里只是其中的一种，也有一些例如:$H(key) + G(key)$,没有j这个参数。\n  密码学中的哈希算法  hash（散列、杂凑）函数，是将任意长度的数据映射到有限长度的域上。直观解释起来，就是对一串数据m进行杂糅，输出另一段固定长度的数据h，作为这段数据的特征（指纹）。也就是说，无论数据块m有多大，其输出值h为固定长度。到底是什么原理？将m分成固定长度（如128位），依次进行hash运算，然后用不同的方法迭代即可（如前一块的hash值与后一块的hash值进行异或）。如果不够128位怎么办？用0补全或者用1补全随意，算法中约定好就可以了。\n 一般来说，公司不会直接将用户的密码保存在数据库中，而是保存经过哈希操作的密码得到的哈希值。这样，当哈希值被不法分子窃取，也不能还原出用户的密码；并且，公司只需要将用户输入的密码进行哈希操作，将哈希值与存储在数据库中的哈希值进行对比就能够验证用户了。\n哈希的其他用法 数据校验：\n  Git的- git commit id\n每次git提交后都有一个commit id，比如:\n19d02d2cc358e59b3d04f82677dbf3808ae4fc40\n  版权校验\n判断两个文件是不是一样的，对两个文件都进行哈希操作，得到哈希值，若哈希值相同，则两个文件为同一个文件。\n  大文件分块校验\n例如使用bt下载，在p2p网络中会把一个大文件拆分成很多小的数据各自传输。这样的好处是如果某个小的数据块在传输过程中损坏了，只要重新下载这个块就好。为了确保每一个小的数据块都是发布者自己传输的，我们可以对每一个小的数据块都进行一个hash的计算，维护一个hash List，在收到所有数据以后，我们对于这个hash List里的每一块进行遍历比对。这里有一个优化点是如果文件分块特别多的时候，如果遍历对比就会效率比较低。可以把所有分块的hash值组合成一个大的字符串，对于这个字符串再做一次Hash运算，得到最终的hash（Root hash）。在实际的校验中，我们只需要拿到了正确的Root hash，即可校验Hash List，也就可以校验每一个数据块了。\n  负载均衡：\n一致性hash的基本原理是将输入的值hash后，对结果的hash值进行2^32取模，这里和普通的hash取模算法不一样的点是在一致性hash算法里将取模的结果映射到一个环上。将缓存服务器与被缓存对象都映射到hash环上以后，从被缓存对象的位置出发，沿顺时针方向遇到的第一个服务器，就是当前对象将要缓存于的服务器，由于被缓存对象与服务器hash后的值是固定的，所以，在服务器不变的情况下，一个openid必定会被缓存到固定的服务器上，那么，当下次想要访问这个用户的数据时，只要再次使用相同的算法进行计算，即可算出这个用户的数据被缓存在哪个服务器上，直接去对应的服务器查找对应的数据即可。这里的逻辑其实和直接取模的是一样的。如下图所示：\n这部分不是很深入，之后再补充\u0026hellip;\u0026hellip;🚴\n参考链接：\n https://www.zhihu.com/question/26762707?sort=created-知乎 动画：什么是散列表？-五分钟算法 什么是 hash？-知乎   MD5 即 Message-Digest Algorithm 5（信息-摘要算法5），用于确保信息传输完整一致。是计算机广泛使用的杂凑算法之一，主流编程语言普遍已有 MD5 实现。 \u0026#x21a9;\u0026#xfe0e;\n SHA-1（英语：Secure Hash Algorithm 1，中文名：安全散列算法1）是一种密码散列函数，SHA-1可以生成一个被称为消息摘要的160位（20字节）散列值，散列值通常的呈现形式为40个十六进制数。 \u0026#x21a9;\u0026#xfe0e;\n  ","description":"","id":90,"section":"posts","tags":["Hash","Algorithm","md5","sha"],"title":"什么是Hash？","uri":"https://hugo.jiahongw.com/zh/posts/algorithmstructure/hash-circle/"},{"content":"排序是最基本的算法，里面包含了最基础的思想。一个简单的优化可以让排序快很多。\n$O(n^2)$的排序算法 冒泡排序 1 2 3 4 5 6 7 8 9 10 11 12 13  //冒泡排序 template \u0026lt;typename T\u0026gt; void bubbleSort(T *arr, int size) { for (int i = 0; i \u0026lt; size; ++i) { for (int j = 0; j \u0026lt; size - i - 1; ++j) { if (arr[j] \u0026gt; arr[j + 1]) swap(arr[j], arr[j + 1]); } } }   插入排序 ​\n1 2 3 4 5 6 7 8 9  template\u0026lt;typename T\u0026gt; void insertSort(T *arr,int size) { for(int i = 0;i \u0026lt; size;++i) { int j; for(j = i;j \u0026gt; 0 \u0026amp;\u0026amp; arr[j] \u0026lt; arr[j-1];--j){swap(arr[j],arr[j-1]);} } }   选择排序 1 2 3 4 5 6 7 8 9 10 11 12 13 14  //选择排序 复杂度O(n^2) template\u0026lt;typename T\u0026gt; void selectionSort(T *arr,int size) { int k; for(int i = 0;i \u0026lt; size-1; ++i) { k = i; for(int j = i+1;j \u0026lt; size;++j) if(arr[j] \u0026lt; arr[k]) k = j; if(k != i) mySwap(arr[k],arr[i]); } }   测试排序使用时间的时候，总是选择排序快于插入排序，按理说，插入排序应该比选择排序要快啊，因为插入排序可以提前终止循环，这是为什么呢？\n 原因是选择排序比较的是下标，而插入排序每一次比较都要交换，而交换所耗费的时间是高于简单的比较的。\n 插入排序优化-将交换变成赋值\n1 2 3 4 5 6 7 8 9 10 11  template\u0026lt;typename T\u0026gt; void insertSort(T *arr,int size) { for(int i = 0;i \u0026lt; size;++i) { T e = arr[i]; int j; for(j = i;j \u0026gt; 0 \u0026amp;\u0026amp; arr[j-1] \u0026gt; e;--j){arr[j] = arr[j-1];} arr[j] = e; } }   运行时间明显变快了\n 对于近乎有序的数据来说，插入排序的速度要快很多，近乎$O (n)$。而插入排序的实际应用有很多，比如日志，日志的时间是近乎有序的，但是生成日志可能会出错，需要进行时间排序处理，这个时候使用插入排序会更好；还有银行的一些流水单等等\n 拓展： C++运算符重载\n 一般在类中实现，有两种可以实现的方法\n  运算符重载例子，使用在一个类中\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  class Student { public: string name; int score; bool operator\u0026lt;(const Student \u0026amp;otherStudent) { return this-\u0026gt;score \u0026lt; otherStudent.score; } friend ostream \u0026amp;operator\u0026lt;\u0026lt;(ostream \u0026amp;os, const Student \u0026amp;student) { os \u0026lt;\u0026lt; \u0026#34;Student:\u0026#34; \u0026lt;\u0026lt; student.name \u0026lt;\u0026lt; \u0026#34;\u0026#34;\u0026lt;\u0026lt;student.score\u0026lt;\u0026lt;endl; return os; } };      使用友元函数\n1 2 3 4 5 6 7 8  返回值类型 operator 运算符(形参表) { ... } //例Complex是一个复数类 friend Complex operator+(const Complex \u0026amp;c1,const Complex \u0026amp;c2){ return Complex(c1.i + c2.i,c1.j + c2.j); }     使用类里面的函数\n1 2 3 4 5 6 7 8  返回值类型 operator 运算符(形参表) { ... } //例Complex是一个复数类 Complex operator+(const Complex \u0026amp;complex){ return Complex(this-\u0026gt;i + complex.i,this-\u0026gt;j + complex.j); }     它们的区别就是参数的个数不同以及需不需要加上fridend这个关键字\n$O(n\\log (n))$的排序算法 归并排序 代码实现\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50  template \u0026lt;typename T\u0026gt; void __merge(T *arr, int l, int middle, int r) { T aux[r - l + 1]; for (int i = l; i \u0026lt;= r; ++i) aux[i - l] = arr[i]; int i = l, j = middle + 1; for (int k = l; k \u0026lt;= r; ++k) { if (i \u0026gt; middle) { arr[k] = aux[j - l]; j++; } else if (j \u0026gt; r) { arr[k] = aux[i - l]; i++; } else if (aux[i - l] \u0026lt; aux[j - l]) { arr[k] = aux[i - l]; i++; } else { arr[k] = aux[j - l]; j++; } } } template \u0026lt;typename T\u0026gt; void __mergeSort(T *arr, int l, int r) { if (l \u0026gt;= r) return; int middle = (l + r) / 2; __mergeSort(arr, l, middle); __mergeSort(arr, middle+1, r); if(arr[middle] \u0026gt; arr[middle+1]) __merge(arr, l, middle, r); } //归并排序 template \u0026lt;typename T\u0026gt; void mergeSort(T *arr, int size) { __mergeSort(arr, 0, size - 1); }   下面这段代码的标记部分需要考虑溢出的问题\n 归并排序快是快，但是要耗费多一倍$O(n)$的存储空间，也就是使用空间换时间。\n 希尔排序 动画演示(来自@五分钟算法)：\n代码实现:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19  //希尔排序 template \u0026lt;typename T\u0026gt; void shellSort(T *arr, int size) { int dk[] = {5, 3, 1}; for (int index = 0; index \u0026lt; 3; ++index) { for (int i = 0; i \u0026lt; size / dk[index]; ++i) { int j; int e = arr[i]; for (j = i + dk[index]; j \u0026gt; dk[index] \u0026amp;\u0026amp; arr[j] \u0026gt; e; j -= dk[index]) { arr[j] = arr[j - dk[index]]; } arr[j] = e; } } }    希尔排序相当于是插入排序的升级版，增加了一个步长参数，使用希尔排序可以让零散的数据实现跳跃行的交换，最后逐渐将数组转化为有序，这样最后使用步长为1的插入排序就非常快了。\n 快速排序 被称为二十世纪影响最大的算法之一！\n动画演示(来自@五分钟算法)：\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29  template\u0026lt;typename T\u0026gt; int __partition(T *arr,int l,int r){ T v = arr[l]; int j = l; for(int i = l+1;i \u0026lt;= r;++i){ if(arr[i] \u0026lt; v){ swap(arr[i],arr[++j]); } } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void __quickSort(T *arr,int l,int r) { if(l \u0026gt;= r) return; int p = __partition(arr,l,r); __quickSort(arr,l,p-1); __quickSort(arr,p+1,r); } //快速排序 template\u0026lt;typename T\u0026gt; void quickSort(T *arr,int size) { __quickSort(arr,0,size-1); }   优化一：\n在数组的元素个数小于15个的时候使用插入排序进行优化:\n1 2 3 4 5 6 7 8  template\u0026lt;typename T\u0026gt; void __quickSort(T *arr,int l,int r) { + if(r - l \u0026lt;= 15) insertionSort(arr,l,r);  int p = __partition(arr,l,r); __quickSort(arr,l,p-1); __quickSort(arr,p+1,r); }   优化二：\n使用随机值作为划分标准\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21  template\u0026lt;typename T\u0026gt; int __partition(T *arr,int l,int r){ + swap(arr[l],arr[rand() % (r-l+1) + l]);  T v = arr[l]; int j = l; for(int i = l+1;i \u0026lt;= r;++i){ if(arr[i] \u0026lt; v){ swap(arr[i],arr[++j]); } } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void quickSort(T *arr,int size) { + srand(time(NULL));  __quickSort(arr,0,size-1); }   缺点:\n 在近乎有序的数组排序中，快速排序的性能很差。时间复杂度也近乎$O(n^2 )$ 对于有很多重复元素的数组，快速排序的性能也很差  快速排序版本二：两路快排 使用两个下标分别处理大于v与小于v的部分。(v为基准元素)\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36  template\u0026lt;typename T\u0026gt; int __partition2(T *arr,int l,int r){ swap(arr[l],arr[rand() % (r-l+1) + l]); T v = arr[l]; int i = l + 1,j = r; while(true) { while(arr[i] \u0026lt; v \u0026amp;\u0026amp; i \u0026lt;= r) ++i; while(arr[j] \u0026gt; v \u0026amp;\u0026amp; j \u0026gt;= l+1) --j; if(i \u0026gt; j) break; swap(arr[i++],arr[j--]); } swap(arr[l],arr[j]); return j; } template\u0026lt;typename T\u0026gt; void __quickSort2(T *arr,int l,int r) { if(r - l\u0026lt;= 15){ insertSort(arr,l,r); return; } int p = __partition2(arr,l,r); __quickSort2(arr,l,p-1); __quickSort2(arr,p+1,r); } //快速排序版本二，双路快排 template\u0026lt;typename T\u0026gt; void quickSort2(T *arr,int size) { srand(time(NULL)); __quickSort2(arr,0,size-1); }   快速排序版本三：三路快排 使用三个下标分别处理大于v、等于v与小于v的部分。(v为基准元素)\n代码实现：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35  template\u0026lt;typename T\u0026gt; void __quickSort3(T *arr,int l,int r) { if(r - l\u0026lt;= 15){ insertSort(arr,l,r); return; } swap(arr[l],arr[rand() % (r-l+1) + l]); T v = arr[l]; int lt = l; //arr[l+1...lt] \u0026lt; v  int gt = r + 1; //arr[gt...r] \u0026gt; v  int i = l+1; //arr[lt+1...i] == v  while(i \u0026lt; gt){ if(arr[i] \u0026lt; v){ swap(arr[i++],arr[++lt]); }else if(arr[i] \u0026gt; v){ swap(arr[i],arr[--gt]); }else{ i++; } } swap(arr[l],arr[lt]); __quickSort3(arr,l,lt-1); __quickSort3(arr,gt,r); } //快速排序版本三，三路快排 template\u0026lt;typename T\u0026gt; void quickSort3(T *arr,int size) { srand(time(NULL)); __quickSort3(arr,0,size-1); }   堆排序 基数排序 桶排序 排序算法总结 图片：\n未完待续\u0026hellip;\u0026hellip;🛴\n参考：\n https://www.cnblogs.com/onepixel/p/7674659.html https://github.com/MisterBooo/Article ","description":"","id":91,"section":"posts","tags":["算法","排序","C++"],"title":"排序算法总结","uri":"https://hugo.jiahongw.com/zh/posts/algorithmstructure/sort/"},{"content":"机器学习有这些基本的算法组成，要门机器学习，就需要打个地基✒\nK近邻算法-KNN-(k-Nearest-Neighbors) 可以解决的问题:\n 分类问题 回归问题  预测一个人是天才还是白痴 首先先生成模拟数据，,x1和x2分别表示两个特征\nIQ值低的数据\n1 2 3  x1_low = np.random.random(10) + 3 x2_low = np.random.random(10) + 6 x1_low,y2_low   (array([3.72183336, 3.16146551, 3.88914234, 3.85673496, 3.1573191 , 3.4293751 , 3.96033808, 3.78793864, 3.94939642, 3.57378294]), array([6.47227974, 6.49537929, 6.98666118, 6.79440424, 6.99201224, 6.73386195, 6.63275792, 6.65411763, 6.42891099, 6.49695701])) IQ值高的数据\n1 2 3  x1_high = 4 + np.random.random(8) x2_high = 7 + np.random.random(8) x1_high,x2_high   (array([4.39543051, 4.73302502, 4.02667743, 4.46232039, 4.68128181, 4.92115752, 4.45267816, 4.84647668]), array([7.40538131, 7.3356809 , 7.90412483, 7.45237382, 7.15550294, 7.3764611 , 7.52492352, 7.67692014])) 总的数据和标签\n1 2 3 4 5 6  x1 = np.append(x1_low,x1_high) x2 = np.append(x2_low,x2_high) x_train = np.c_[x1.T,x2.T] print(x_train) y_train = np.append(np.zeros_like(x_low),np.ones_like(x_high)) print(y_train)   [[3.72183336 6.47227974] [3.16146551 6.49537929] [3.88914234 6.98666118] [3.85673496 6.79440424] [3.1573191 6.99201224] [3.4293751 6.73386195] [3.96033808 6.63275792] [3.78793864 6.65411763] [3.94939642 6.42891099] [3.57378294 6.49695701] [4.28739637 7.71057536] [4.31513454 7.70173516] [4.10934692 7.38111019] [4.35094666 7.33731866] [4.01739934 7.41472044] [4.98558165 7.72054925] [4.80075428 7.12604512] [4.48912715 7.08753069]] [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.] 绘制散点图\n1 2 3 4 5  plt.scatter(x_train[y_train==0,0],x_train[y_train==0,1]) plt.scatter(x_train[y_train==1,0],x_train[y_train==1,1]) plt.xlabel(\u0026#39;t\u0026#39;) plt.ylabel(\u0026#39;IQ\u0026#39;) plt.show()    上图红色表示天才，蓝色表示白痴\n 假设输入一个样本的数据为 (4.36,7.465)，判断它天才还是白痴\n1 2 3 4 5 6 7 8  example = np.array([4.36,7.456]) # 首先再图上画出来观察 plt.scatter(x_train[y_train==0,0],x_train[y_train==0,1]) plt.scatter(x_train[y_train==1,0],x_train[y_train==1,1]) plt.scatter(example[0],example[1],color=\u0026#39;black\u0026#39;) plt.xlabel(\u0026#39;t\u0026#39;) plt.ylabel(\u0026#39;IQ\u0026#39;) plt.show()    黑点表示输入的样本\n 获取距离列表\n1 2  distance = [sqrt(sum(((x-example)**2))) for x in x_train] distance   [1.172587826601725, 1.5359938425092403, 0.6648201732802982, 0.8312548678718089, 1.2890795094301544, 1.177941448784469, 0.9151268590623418, 0.9850226059672444, 1.1061225623709607, 1.2401212526176475, 0.2647260841097585, 0.24979727210937175, 0.26160170347749107, 0.1190261413334191, 0.3450785650776031, 0.6792191910080055, 0.5505765678982287, 0.39044007348145965] 对于KNN，假设k=3，就是求出与样本最近的三个点的数据\n1 2  result = np.argsort(distance) result[:k]   array([13, 11, 12], dtype=int64)  可以得知，前三个的训练样本的点的下标分别围殴13，11，12\n 接下来根据这三个训练样本的类别来预测输入的样本是天才还是白痴，假如这三个训练样本是天才的数量多于白痴，就认为它是天才；不然，就认为它是白痴\n1 2 3 4 5 6 7  from collections import Counter votes = Counter(r) y_hat = votes.most_common(1)[0][0] if y_hat == 1: print(\u0026#34;预测它为天才\u0026#34;) else: print(\u0026#34;预测它为白痴\u0026#34;)   预测它为天才 主成分分析法-PCA-(Principal Component Analysis)  PAC主要用于数据的降维\n 二维降到一维\n 由上面两个降维的图来看，第二张图片是一个更好的图，因为图二点和点的距离相对比较大，也就是说，点之间的区分度比较高\n 更好的降维方案\n 此时点和点之间的距离最大，区分度更大\n 那么如何定义样本之间的间距呢？\n可以使用方差(Variance),方差可以表示样本整体分布的疏密程度\n$$\nVar(x) = \\frac{1}{m}\\sum_{i = 1}^{m}(x_{i} - \\bar x)^2\n$$\n可以转化成：\n​\t希望找到一条轴，使得样本投影到该轴上的各点之间的方差最大\nPCA操作步骤：\n  将样例的均值归为0(demean)\n这样，就相当于坐标轴变成如下的图：\n  当均值$\\bar x = 0$时，原来的方差公式变为\n$$\nVar(x) = \\frac{1}{m}\\sum_{i = 1}^{m}(x_{i} - \\bar x)^2 \\Rightarrow Var(x) = \\frac{1}{m}\\sum_{i = 1}^{m}x_{i}^2\n$$\n假设两个维度的特征为$w1$,$w2$,那么需要求得的直线的方向为$w =（w_{1},w_{2}）$,映射到$w$后，有:\n$$\nVar(X_{project}) = \\frac{1}{m} \\sum_{1}^{m} (X_{project}^{(i)} - \\bar X{project})^2\n$$\n使得上面的公式最大\n其实最后的结果还是向量，因为$X$每一个点都包含两个元素，即应该是\n由均值为0，得到\n  计算过程\n目标即：\n与线性回归的不同：\n PCA的两个坐标轴表示的是两个特征，而线性回归的横轴是特征，纵轴是输出标记 PCA使得点之间的方差最大，而线性回归则是需要使得输出标记尽量拟合一条直线，是在纵轴上的  决策树 例子：\n数值特征例子：\n特点：\n 非参数学习算法 可以解决分类问题 天然的解决多分类问题 也可以解决回归问题 非常好的可解释性  问题：\n 每个节点在哪个维度作划分 某个维度的哪个值作划分    支持向量机-SVM-(Support Vector Machine) 主要思想：\nSVM分类:\n  Hard Margin SVM\t解决的是线性可分问题\n  Soft Margin SVM 可解决线性不可分问题\n  🤠未完待续\u0026hellip;\u0026hellip;\n","description":"机器学习必须掌握的基础算法，学会这些基础，对后面的理解才会透彻","id":92,"section":"posts","tags":["机器学习","SVM","决策树","kNN","PCA"],"title":"机器学习基本算法","uri":"https://hugo.jiahongw.com/zh/posts/deeplearning/machine-learning-base/"},{"content":"一些英雄的图案🌿\n","description":"","id":93,"section":"gallery","tags":[""],"title":"Hero","uri":"https://hugo.jiahongw.com/zh/gallery/hero/"},{"content":"使用Scrapy爬取文章的一个小项目..\nScrapy 框架图：\n抓取小程序社区文章 创建爬虫项目 创建项目（项目名为MyTest）\n1  scrapy startproject MyTest   创建爬虫🐞(先进入到MyTest目录)\n1  scrapy genspider -t crawl wx wxapp-union.com    wx为爬虫的名字，wxapp-union.com为爬取的域名，使用了模板crawl\n 定义爬取的数据结构 爬取的数据结构类继承Item类，在items.py文件中，如下是设置需要爬取的数据结构，其中包括:标题、作者、时间、访问者、前言、正文。\n1 2 3 4 5 6 7 8 9 10  from scrapy import Item,Field # 定义文章数据结构 class ArticleItem(Item): title = Field() author = Field() _time = Field() visitors = Field() pre_talk = Field() article_content = Field()   编写爬虫规则与解析规则  爬虫的爬取网页的链接的规则和解析页面的规则都是在新建的spider文件中的类中，也即在wx.py中\n 编写的spider类如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  import scrapy from scrapy.linkextractors import LinkExtractor from scrapy.spiders import CrawlSpider, Rule from MyTest.items import ArticleItem class WxSpider(CrawlSpider): name = \u0026#39;wx\u0026#39; allowed_domains = [\u0026#39;wxapp-union.com\u0026#39;] start_urls = [\u0026#39;http://www.wxapp-union.com/portal.php?mod=list\u0026amp;catid=2\u0026amp;page=255\u0026#39;] rules = ( Rule(LinkExtractor(allow=r\u0026#39;.+mod=list\u0026amp;catid=2\u0026amp;page=\\d\u0026#39;), follow=True), Rule(LinkExtractor(allow=r\u0026#39;.+article-.+\\.html\u0026#39;),callback=\u0026#34;parse_item\u0026#34;,follow=False) ) def parse_item(self, response): title = response.xpath(\u0026#39;//h1[@class=\u0026#34;ph\u0026#34;]/text()\u0026#39;).get() author = response.xpath(\u0026#39;//p[@class=\u0026#34;authors\u0026#34;]//a\u0026#39;).get() _time = response.xpath(\u0026#39;//span[@class=\u0026#34;time\u0026#34;]/text()\u0026#39;).get() visitors = response.xpath(\u0026#39;//div[contains(@class,\u0026#34;focus_num\u0026#34;)]//a/text()\u0026#39;).get() pre_talk = response.xpath(\u0026#39;//div[@class=\u0026#34;blockquote\u0026#34;]//p/text()\u0026#39;).get() article_content = response.xpath(\u0026#39;//td[@id=\u0026#34;article_content\u0026#34;]\u0026#39;).get() item = ArticleItem(title=title,author=author,_time=_time,visitors=visitors,pre_talk=pre_talk,article_content=article_content) print(\u0026#39;*\u0026#39;*40) print(title) print(\u0026#39;*\u0026#39;*40) return item    首先rules定义了爬取链接规则，有两个规则，第一个规则是爬取页面的链接，每一页有多个文章的链接，而第二个规则则是定义爬取的具体文章内容的链接。 第一个规则需要Follow，因为需要根据每一页的内容查找文章的链接；而第二个规则是文章链接，故不需要继续Follow 第一个页面链接规则不需要回调函数，因为不需要解析，只需要获取文章链接；第二个文章链接规则则需要设置回调函数来对返回的文章网页内容进行解析。  parse_item说明：\n parse_item是解析页面返回内容的函数，其返回Item数据结构，使用Xpath分别获取数据结构各个元素的内容并且返回Item\n 保存数据  pipelines是一个最后处理Item的管道\n 在pipelines.py文件中新建pipleline对返回的Item进行处理，可以保存为文件，或者存储到数据库。\n首先文件中需要导入必要的库‘\n1 2 3 4 5  import re\t# 正则处理 from html2text import HTML2Text\t# 将网页转化为Markdown格式 from scrapy.exporters import JsonLinesItemExporter\t# 输出Json文件输出器 from urllib.parse import urljoin\t# 补全URL，因为有些URL只显示相对位置 import pymongo\t# MongoDB操作库   第一个Pipeline：保存到Json文件 程序的构造函数新建一个Json文件输出器，process_item进行数据的存储，关闭的时候close_spider会调用关闭文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  # 存储到Json文件中 class JsonPipeline(object): def __init__(self): self.f = open(\u0026#39;wxjc.json\u0026#39;,\u0026#39;wb\u0026#39;) self.exporter = JsonLinesItemExporter(self.f, ensure_ascii=False,encoding=\u0026#34;utf-8\u0026#34;) def process_item(self, item, spider): # 将内容转化为MarkDown格式 item[\u0026#39;article_content\u0026#39;] = convert_md(item[\u0026#39;article_content\u0026#39;]) self.exporter.export_item(item) return item def close_spider(self,spider): self.f.close()   第二个Pipeline：保存到Markdown文件 方法与第一发Pipeline类似，只是写文件使用最简单的追加方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17  # 写入Markdown class MDPipeline(object): def __init__(self): self.f = open(\u0026#39;wx_teaches.md\u0026#39;,\u0026#39;a\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) def process_item(self,item,spider): if self.f: self.f.write(\u0026#39;\\n\u0026#39;) self.f.write(\u0026#34;# \u0026#34; + item[\u0026#39;title\u0026#39;] + \u0026#39;\\n\u0026#39;) header_info = \u0026#34;作者:{} 发布时间:{} Visitors:{}\\n\u0026#34;.format(item[\u0026#39;author\u0026#39;],item[\u0026#39;_time\u0026#39;],item[\u0026#39;visitors\u0026#39;]) self.f.write(header_info) self.f.write(\u0026#39;\u0026gt; \u0026#39; + item[\u0026#39;pre_talk\u0026#39;] + \u0026#39;\\n\u0026#39;) self.f.write(item[\u0026#39;article_content\u0026#39;]) return item def close_spider(self,spider): self.f.close()   第三个Pileline：保存到MongoDB 其中使用了类方法装饰器@classmethod,意思就是直接用类名调用该函数，就能够直接返回一个MongoPipeline类了，还定义了打开spider与关闭spider的操作，就是连接数据库与关闭数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24  # 存储到MongoDB数据库 class MongoPipeline(object): def __init__(self,mongo_uri,mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls,crawler): return cls(mongo_uri = crawler.settings.get(\u0026#39;MONGO_URI\u0026#39;), mongo_db = crawler.settings.get(\u0026#39;MONGO_DB\u0026#39;)) def open_spider(self,spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db =self.client[self.mongo_db] def process_item(self,item,spider): name = item.__class__.__name__ # \u0026lt;a href=\\\u0026#34;space-uid-17761.html\\\u0026#34;\u0026gt;Rolan\u0026lt;/a\u0026gt;  item[\u0026#39;author\u0026#39;] = re.search(\u0026#39;\u0026lt;a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;\u0026#39;,item[\u0026#39;author\u0026#39;]).group(1) self.db[name].insert(dict(item)) return item def close_spider(self,spider): self.client.close()    最后需要在settings.py中添加如下字段:\n1 2  MONGO_URI = \u0026#39;localhost\u0026#39; MONGO_DB = \u0026#39;WX\u0026#39;    最后需要在settings.py中添加如下字段 1 2 3 4 5 6 7 8 9  ITEM_PIPELINES = { \u0026#39;MyTest.pipelines.JsonPipeline\u0026#39;: 300, \u0026#39;MyTest.pipelines.MDPipeline\u0026#39;: 301, \u0026#39;MyTest.pipelines.MongoPipeline\u0026#39;: 400, } # 修改为False ROBOTSTXT_OBEY = False # 设置延迟1s DOWNLOAD_DELAY = 1   开始爬取 可以在项目目录中新建一个脚本start.py，文件内容如下，自动运行脚本\n1 2  from scrapy import cmdline cmdline.execute(\u0026#39;scrapy crawl test\u0026#39;.split(\u0026#39;\u0026#39;))   爬取结果 Json结果 Markdown结果 Markdown文件由于太大了使用Markdown文件打不开，只好使用文本编辑器打开\nMongoDB结果 ","description":"","id":94,"section":"posts","tags":["爬虫","Scrapy"],"title":"Scrapy框架","uri":"https://hugo.jiahongw.com/zh/posts/spider/scrapy-1/"},{"content":"好的工具🗝 就成功了一半。\n工具🚡 创造与记录 GitBook 使用前提：  安装NodeJS 使用npm安装：npm install gitbook-cli -g(这是命令行工具)  GitNote Notion Typora 信息聚合 irreader🔖 下载地址:http://irreader.fatecore.com/\n羽雀-云端知识库☁ 如果英语不好，或者看着英文的文档很烦恼，可以试试这个。🍃\n地址:https://www.yuque.com/\n下载微信公众号文章  链接：https://pan.baidu.com/s/1v2LAAZUn94azCtG_gllncw\n提取码：6cl3\n复制这段内容后打开百度网盘手机App，操作更方便哦\n 今日热榜 https://tophub.today/\n在线Create🍨 GitMind GitMind 是一款全新的云端智能思维导图、流程图制作软件，同时支持在电脑、手机浏览器上使用。\n官网：https://gitmind.cn/\n微信版本：\nProcessOn🤴 https://www.processon.com/\n数字绘 https://www.myshuju.net/\ncarbon(代码美化)🔰 https://carbon.now.sh/\n图片   https://xinquji.com/r/d232a93deb8766\n  https://burst.shopify.com/\n  https://wallhaven.cc/\n  https://wallpapershome.com/\n  Emoji\n ","description":"实用的工具集合","id":95,"section":"talks","tags":[""],"title":"Tools","uri":"https://hugo.jiahongw.com/zh/talks/tools/"},{"content":"All about Intresting in Github.\nPython好玩的库 html2text  将网页转化为Markdown文件格式\n 使用前提： 1  pip install htmltotext   使用方法： 1 2 3  ## 转化为TEXT h = HTML2Text() text = h.handle(parse_html) # text为markdown文件   pypandoc  对文件进行任意的转换\n 使用前提： 安装pypandoc库：pip install pypandoc.\n使用方法 导入库:import pypandoc\nMarkdown \u0026mdash;\u0026ndash;\u0026gt; docx 1  output = pypandoc.convert_file(\u0026#39;somefile.md\u0026#39;, \u0026#39;docx\u0026#39;, outputfile=\u0026#34;somefile.docx\u0026#34;)   Markdown \u0026mdash;\u0026ndash;\u0026gt; Rst 1 2 3  output = pypandoc.convert_file(\u0026#39;somefile.md\u0026#39;, \u0026#39;rst\u0026#39;)\t# way1 output = pypandoc.convert_file(\u0026#39;somefile.txt\u0026#39;, \u0026#39;rst\u0026#39;, format=\u0026#39;md\u0026#39;)\t# way 2 output = pypandoc.convert_text(\u0026#39;#some title\u0026#39;, \u0026#39;rst\u0026#39;, format=\u0026#39;md\u0026#39;)\t# 直接转化文本    其中有对应的工具Pandoc\n 如何把 Markdown 文件批量转换为 PDF mdout转换脚本 项目地址:https://github.com/JabinGP/mdout\n使用方法：  打开项目地址查看，其中主要命令为:mdout filename -t pdf\n","description":"Github上好玩的那些库~","id":96,"section":"talks","tags":[""],"title":"Good库","uri":"https://hugo.jiahongw.com/zh/talks/github-lib/"},{"content":"🚴一些收集视频的方法⚒\n视频归总方法 BiliBli视频嵌入代码 使用方法 首先找到嵌入代码\n然后复制代码到Markdown文件就可以得到如下显示效果：\n 代码如下: 1  \u0026lt;iframe src=\u0026#34;//player.bilibili.com/player.html?aid=6731067\u0026amp;cid=10959711\u0026amp;page=1\u0026#34; scrolling=\u0026#34;no\u0026#34; border=\u0026#34;0\u0026#34; frameborder=\u0026#34;no\u0026#34; framespacing=\u0026#34;0\u0026#34; allowfullscreen=\u0026#34;true\u0026#34;\u0026gt; \u0026lt;/iframe\u0026gt;    其中可以在ifram中添加相关属性\n weibo上传的视频 使用方法 在微博中上传视频后，打开视频的页面，按F12打开工具,鼠标点击视频找到链接\n接下来直接在Markdown中添加代码\nYour browser does not support the video tag.\n代码如下:\n1  \u0026lt;video poster=\u0026#34;https://i.loli.net/2020/03/02/GabXC4JmfN6H2hE.png\u0026#34; src=\u0026#34;https://f.video.weibocdn.com/00393mgEgx07BmNCEF4j01041200eeW00E010.mp4?label=mp4_720p\u0026amp;template=1280x720.25.0\u0026amp;trans_finger=721584770189073627c6ee9d880087b3\u0026amp;Expires=1583079687\u0026amp;ssig=%2BAmJANwAPn\u0026amp;KID=unistore,video\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the video tag.\u0026lt;/video\u0026gt;   QQ空间发布的视频 使用方法 与微博的操作类似，打开视频页面，先点击下载按钮\n然后会自动跳转，搜索栏上的地址就是视频的地址\n接下来直接在Markdown中添加代码\nYour browser does not support the video tag.\n代码如下:\n1  \u0026lt;video poster=\u0026#34;https://i.loli.net/2020/03/02/GabXC4JmfN6H2hE.png\u0026#34; src=\u0026#34;http://photovideo.photo.qq.com/1075_0b53zeiu6vidieapa3kya5pdbsiej6zqhfsa.f20.mp4?dis_k=97f710c26b204f7f2312614fbcf8f897\u0026amp;dis_t=1583082992\u0026amp;vuin=1427298682\u0026amp;save=1\u0026amp;d=1\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the video tag.\u0026lt;/video\u0026gt;   ","description":"","id":97,"section":"posts","tags":["blog","视频","BliBli","weibo"],"title":"视频的收集","uri":"https://hugo.jiahongw.com/zh/posts/settings/collect-videos/"},{"content":"在Pt页面增加了一些用JS实现的PPT，主要展示一些效果。🔌\n网页PPT 主题 beige black blood monokai league moon night serif simple solarized sky white 使用方法🌌 在markdown文件的ymal头部添加:revealTheme: serif\n在线制作PPT Slides https://slides.com/\n","description":"","id":98,"section":"posts","tags":["ppt","blog"],"title":"Slides和网页PPT","uri":"https://hugo.jiahongw.com/zh/posts/settings/ppt-use/"},{"content":"使用MXNet的好处你永远想象不到。🉑\n本地环境搭建教程  参考:\nhttps://discuss.gluon.ai/t/topic/13576?u=bigbigwolf-ai\n 范数 L0范数：指向量中非0元素的个数。（难优化求解）\nL1范数：指向量中各个元素的绝对值之和\nL2范数：指向量各元素的平方和然后求平方根\n设$n$维向量$x$中的元素为$x_1, \\ldots, x_n$。向量$x$的$L_{p}$范数为:\n$$\n|\\boldsymbol{x}|_p = \\left(\\sum_{i=1}^n \\left|x_i \\right|^p \\right)^{1/p}.\n$$\n$L_{1}$范数：\n$$\n|\\boldsymbol{x}|_1 = \\sum_{i=1}^n \\left|x_i \\right|.\n$$\n$L_{2}$范数：\n$$\n|\\boldsymbol{x}|_2 = \\sqrt{\\sum_{i=1}^n x_i^2}.\n$$\n设$X$是一个$m$行$n$列矩阵。矩阵$X$的Frobenius范数为该矩阵元素平方和的平方根：\n$$\n|\\boldsymbol{X}|_F = \\sqrt{\\sum_{i=1}^m \\sum_{j=1}^n x_{ij}^2},\n$$\n查阅文档 1 2  from mxnet import nd print(dir(nd.random))   ['NDArray', '_Null', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_internal', '_random_helper', 'current_context', 'exponential', 'exponential_like', 'gamma', 'gamma_like', 'generalized_negative_binomial', 'generalized_negative_binomial_like', 'multinomial', 'negative_binomial', 'negative_binomial_like', 'normal', 'normal_like', 'numeric_types', 'poisson', 'poisson_like', 'randint', 'randn', 'shuffle', 'uniform', 'uniform_like']  help函数可以查询具体的函数作用及用法\n1  help(nd.ones_like)   Help on function ones_like: ones_like(data=None, out=None, name=None, **kwargs) Return an array of ones with the same shape and type as the input array. Examples:: x = [[ 0., 0., 0.], [ 0., 0., 0.]] ones_like(x) = [[ 1., 1., 1.], [ 1, 1., 1.]] Parameters ---------- data : NDArray The input out : NDArray, optional The output NDArray to hold the result. Returns ------- out : NDArray or list of NDArrays The output of this function.  线性回归 导入必要的库\n1 2 3 4 5  %matplotlib inline from IPython import display from matplotlib import pyplot as plt from mxnet import autograd, nd import random   生成数据集，其中每个例子输入数据个数为2，有1000个数据\n1 2 3 4 5 6 7  num_inputs = 2 num_examples = 1000 true_w = nd.array([2, -3.4]) true_b = nd.array([4.2]) features = nd.random.normal(scale=1, shape=(num_examples, num_inputs)) labels = nd.dot(true_w,features.T) + true_b labels += nd.random.normal(scale=0.01, shape=labels.shape)   查看数据\n1  features[0], labels[0]   ( [ 0.28752208 -0.04466231] \u0026lt;NDArray 2 @cpu(0)\u0026gt;, [4.927063] \u0026lt;NDArray 1 @cpu(0)\u0026gt;)  定义相关函数\n1 2 3 4 5 6 7 8 9 10 11  def use_svg_display(): # 用矢量图显示 display.set_matplotlib_formats(\u0026#39;svg\u0026#39;) def set_figsize(figsize=(3.5, 2.5)): use_svg_display() # 设置图的尺寸 plt.rcParams[\u0026#39;figure.figsize\u0026#39;] = figsize set_figsize() plt.scatter(features[:, 1].asnumpy(), labels.asnumpy(), 1); # 加分号只显示图   data_iter函数作用:\n 扰乱读取顺序，使得读取随机 按Batch_size分段取数据，需要判断是否到结尾，使用yield构建生成器节省内存  1 2 3 4 5 6 7 8  # 本函数已保存在d2lzh包中方便以后使用 def data_iter(batch_size, features, labels): num_examples = len(features) indices = list(range(num_examples)) random.shuffle(indices) # 样本的读取顺序是随机的 for i in range(0, num_examples, batch_size): j = nd.array(indices[i: min(i + batch_size, num_examples)]) yield features.take(j), labels.take(j) # take函数根据索引返回对应元素   1 2 3 4 5  batch_size = 10 for X, y in data_iter(batch_size, features, labels): print(X, y) break   [[-0.65439206 0.74410725] [ 0.69013244 -0.6483847 ] [-0.59409887 0.3589477 ] [-0.47491348 0.6438462 ] [ 0.5074032 0.42834154] [-0.18589513 -0.21707669] [ 0.70281196 -1.3320632 ] [ 1.2072632 1.6909351 ] [-0.17264698 -1.5742793 ] [-1.6516455 -0.29966688]] \u0026lt;NDArray 10x2 @cpu(0)\u0026gt; [ 0.37379816 7.7938933 1.7758217 1.0414512 3.743439 4.5605783 10.148926 0.84148276 9.19984 1.9295483 ] \u0026lt;NDArray 10 @cpu(0)\u0026gt;  初始化\n1 2  w = nd.random.normal(scale=0.01, shape=(num_inputs, 1)) b = nd.zeros(shape=(1,))   添加保存梯度的空间\n1 2  w.attach_grad() b.attach_grad()   1 2  def linreg(X, w, b): # 本函数已保存在d2lzh包中方便以后使用 return nd.dot(X, w) + b   1 2  def squared_loss(y_hat, y): # 本函数已保存在d2lzh包中方便以后使用 return (y_hat - y.reshape(y_hat.shape)) ** 2 / 2   1 2 3  def sgd(params, lr, batch_size): # 本函数已保存在d2lzh包中方便以后使用 for param in params: param[:] = param - lr * param.grad / batch_size   开始训练\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15  lr = 0.03 num_epochs = 3 net = linreg loss = squared_loss for epoch in range(num_epochs): # 训练模型一共需要num_epochs个迭代周期 # 在每一个迭代周期中，会使用训练数据集中所有样本一次（假设样本数能够被批量大小整除）。X # 和y分别是小批量样本的特征和标签 for X, y in data_iter(batch_size, features, labels): with autograd.record(): l = loss(net(X, w, b), y) # l是有关小批量X和y的损失 l.backward() # 小批量的损失对模型参数求梯度 sgd([w, b], lr, batch_size) # 使用小批量随机梯度下降迭代模型参数 train_l = loss(net(features, w, b), labels) print(\u0026#39;epoch %d, loss %f\u0026#39; % (epoch + 1, train_l.mean().asnumpy()))   epoch 1, loss 0.040809 epoch 2, loss 0.000157 epoch 3, loss 0.000051  对比\n1  true_w, w   ( [ 2. -3.4] \u0026lt;NDArray 2 @cpu(0)\u0026gt;, [[ 1.9991481] [-3.3992586]] \u0026lt;NDArray 2x1 @cpu(0)\u0026gt;)  1  true_b, b   ( [4.2] \u0026lt;NDArray 1 @cpu(0)\u0026gt;, [4.19921] \u0026lt;NDArray 1 @cpu(0)\u0026gt;) ","description":"","id":101,"section":"posts","tags":["python","MXNet","深度学习","liner"],"title":"MXNet回顾","uri":"https://hugo.jiahongw.com/zh/posts/deeplearning/mxnet-begin/"},{"content":"重新学习一下DL，这次使用PyTorch框架🔦\n 参考资料：\nhttps://github.com/dsgiitr/d2l-pytorch\n 导入PyTorch库 1 2  import torch import numpy as np   创建Tensor 5x3的未初始化的张量\n1 2  x = torch.empty(5,3) x   tensor([[1.0286e-38, 9.0919e-39, 8.9082e-39], [9.2755e-39, 8.4490e-39, 1.0194e-38], [9.0919e-39, 8.4490e-39, 8.7245e-39], [1.0102e-38, 1.0653e-38, 8.7245e-39], [1.0286e-38, 9.6429e-39, 4.2244e-39]])  5x3随机初始化的张量\n1 2  x = torch.rand(5,3) x   tensor([[0.2518, 0.0419, 0.3233], [0.1493, 0.1408, 0.8559], [0.5145, 0.4648, 0.4605], [0.2555, 0.2502, 0.4506], [0.9798, 0.5056, 0.2726]])  5x3全0的张量\n1 2  x = torch.zeros(5,3) # 可以指定类型 x = torch.zeros(5,3,dtype=torch.long) x   tensor([[0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.], [0., 0., 0.]])  数据张量\n1 2  x = torch.tensor([5.5,3]) x   tensor([5.5000, 3.0000])  默认创建和原来的张量一样的dtype和device的张量，也可以另外设置\n1 2 3 4  x = x.new_ones(5,3,dtype=torch.double) print(x) x = torch.randn_like(x,dtype=torch.float) print(x)   tensor([[1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.], [1., 1., 1.]], dtype=torch.float64) tensor([[-0.7829, -0.4010, 0.3230], [ 0.2660, 0.4766, 0.3186], [ 0.6096, 1.1226, -1.7942], [ 1.3255, 0.1835, -0.9078], [ 1.7743, -0.0944, -0.1704]])  获取Tensor的形状\n1  x.shape,x.size()   (torch.Size([5, 3]), torch.Size([5, 3]))  其他创建Tensor的函数:\n   函数 功能     Tensor(*sizes) 基础构造函数   tensor(data,) 类似np.array的构造函数   ones(*sizes) 全1Tensor   zeros(*sizes) 全0Tensor   eye(*sizes) 对角线为1，其他为0   arange(s,e,step) 从s到e，步长为step   linspace(s,e,steps) 从s到e，均匀切分成steps份   rand/randn(*sizes) 均匀/标准分布   normal(mean,std)/uniform(from,to) 正态分布/均匀分布   randperm(m) 随机排列     这些创建方法都可以在创建的时候指定数据类型dtype和存放device(cpu/gpu)\n 操作 1 2 3  x = torch.rand(5,3) y = torch.rand(5,3) x,y   (tensor([[0.7706, 0.7674, 0.0476], [0.3675, 0.3652, 0.1215], [0.2842, 0.4927, 0.0903], [0.1202, 0.7635, 0.1862], [0.1391, 0.5023, 0.0580]]), tensor([[0.2149, 0.4744, 0.6664], [0.5948, 0.3451, 0.6485], [0.2303, 0.6660, 0.3796], [0.7194, 0.3815, 0.7536], [0.7886, 0.0630, 0.2459]]))  加法，三种方法\n1 2 3 4  z1 = torch.add(x,y) z2 = x.add_(y) # x会改变 z3 = x + y z1,z2,z3   (tensor([[0.9855, 1.2418, 0.7140], [0.9623, 0.7103, 0.7700], [0.5145, 1.1588, 0.4699], [0.8396, 1.1450, 0.9397], [0.9276, 0.5653, 0.3040]]), tensor([[0.9855, 1.2418, 0.7140], [0.9623, 0.7103, 0.7700], [0.5145, 1.1588, 0.4699], [0.8396, 1.1450, 0.9397], [0.9276, 0.5653, 0.3040]]), tensor([[1.2004, 1.7163, 1.3804], [1.5571, 1.0554, 1.4185], [0.7448, 1.8248, 0.8495], [1.5590, 1.5265, 1.6933], [1.7162, 0.6283, 0.5499]]))  索引\n1 2  y = x[0, :] y   tensor([0.9855, 1.2418, 0.7140])  修改y会修改原来的数据，因为共享内存\n1 2 3  y+=1 print(y) print(x[0,:])   tensor([1.9855, 2.2418, 1.7140]) tensor([1.9855, 2.2418, 1.7140])  PyTorch还提供了一些高级的选择函数:\n   函数 功能     index_select(input, dim, index) 在指定维度dim上选取，比如选取某些行、某些列   masked_select(input, mask) 例子如上，a[a\u0026gt;0]，使用ByteTensor进行选取   nonzero(input) 非0元素的下标   gather(input, dim, index) 根据index，在dim维度上选取数据，输出的size与index一样    改变形状 用view()来改变Tensor的形状：\n1 2 3  y = x.view(15) z = x.view(-1,5) # -1为自动计算维度 print(x.size(),y.size(),z.size())   torch.Size([5, 3]) torch.Size([15]) torch.Size([3, 5])   注意view()返回的新Tensor与源Tensor虽然可能有不同的size，但是是共享data的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，view仅仅是改变了对这个张量的观察角度，内部数据并未改变)\n 1 2  x += 1 x,y   (tensor([[4.9855, 5.2418, 4.7140], [3.9623, 3.7103, 3.7700], [3.5145, 4.1588, 3.4699], [3.8396, 4.1450, 3.9397], [3.9276, 3.5653, 3.3040]]), tensor([4.9855, 5.2418, 4.7140, 3.9623, 3.7103, 3.7700, 3.5145, 4.1588, 3.4699, 3.8396, 4.1450, 3.9397, 3.9276, 3.5653, 3.3040]))  使用reshape()函数会拷贝一份\n1 2  y = x.reshape(15) y   tensor([4.9855, 5.2418, 4.7140, 3.9623, 3.7103, 3.7700, 3.5145, 4.1588, 3.4699, 3.8396, 4.1450, 3.9397, 3.9276, 3.5653, 3.3040])  也可以使用克隆后view\n 使用clone还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源Tensor。\n 1 2  y = x.clone().view(15) y   tensor([4.9855, 5.2418, 4.7140, 3.9623, 3.7103, 3.7700, 3.5145, 4.1588, 3.4699, 3.8396, 4.1450, 3.9397, 3.9276, 3.5653, 3.3040])  item(), 它可以将一个标量Tensor转换成一个Python number：\n1 2 3  x = torch.randn(1) print(x) print(x.item())   tensor([0.3816]) 0.3816383183002472  线性代数API    函数 功能     trace 对角线元素之和(矩阵的迹)   diag 对角线元素   triu/tril 矩阵的上三角/下三角，可指定偏移量   mm/bmm 矩阵乘法，batch的矩阵乘法   addmm/addbmm/addmv/addr/baddbmm.. 矩阵运算   t 转置   dot/cross 内积/外积   inverse 求逆矩阵   svd 奇异值分解    广播机制 什么是广播机制？简单的说就是形状不同的运算会自动变换为适合的运算\n1 2 3 4 5  x = torch.arange(3).view(1,3) print(x) y = torch.arange(2).view(2,1) print(y) print(x + y)   tensor([[0, 1, 2]]) tensor([[0], [1]]) tensor([[0, 1, 2], [1, 2, 3]]) ","description":"","id":102,"section":"posts","tags":["PyTorch","python","Tensor"],"title":"Pytorch Begin","uri":"https://hugo.jiahongw.com/zh/posts/deeplearning/pytorch-begin/"},{"content":"一份还算可以的翻墙清单📇\n本文介绍的方法归总: PC端 Mobile端   谷歌访问助手 插件(可以现在极简插件中下载） Astar VPN 插件 SSR    云帆VPN 老王VPN     'use strict'; var containerId = JSON.parse(\"\\\"635a6660b3cf14fc\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  PC端 谷歌访问助手 首先是不能通过谷歌的应用商店下载的，可以在国内的一些插件网站下载，这些推荐极简插件，找到谷歌访问助手进行下载。\n将CRT文件拖入谷歌浏览器的拓展程序界面中(这里用的助手是另一个版本)\n之后就可以访问谷歌的一部分服务了，例如谷歌搜索，Gmail，谷歌应用商店.\n安装过程可能会出现一些问题，具体可以参考:安装指引    其他类似的插件   PP谷歌访问助手:https://chrome.zzzmh.cn/info?token=kahndhhhcnignmbbpiobmdlgjhgfkfil 集装箱:https://chrome.zzzmh.cn/info?token=kbgigmcnifmaklccibmlepmahpfdhjch 谷歌访问助手:https://chrome.zzzmh.cn/info?token=gocklaboggjfkolaknpbhddbaopcepfp 谷歌学术助手:https://chrome.zzzmh.cn/info?token=jkicnibdkfemnfhojeajbldjgdddpajk 谷歌服务助手:https://chrome.zzzmh.cn/info?token=cgncbhnhlkbdieckbbmeppcefokppagh 谷歌上网助手:https://chrome.zzzmh.cn/info?token=nonmafimegllfoonjgplbabhmgfanaka    Astar VPN Astar VPN也是一个Chrome插件，在谷歌应用商店可以下载。经过第一步之后，we\u0026rsquo;re good to go!😁\n应用商店搜索Astar VPN进行下载，直接就可以在Chrome中进行自动安装。\n之后再插件选项中开启该插件，其中可以选择不同的服务器进行连接，速度还不错。\n使用该插件进行科学上网是真正意义上的，它可以访问国外任何网站!  ShadowsSocks ShadowsSocks是一款在github上的开源软件，可以用来进行连接节点服务器，但是节点需要自己去找，下面会介绍节点的选择。\n首先去github下载这个软件，链接为：https://github.com/shadowsocks/shadowsocks-windows/releases/tag/4.1.9.2\n将两个文件解压之后，将第一个文件夹内的exe文件移动到第二个文件夹的根目录并且打开即可\n关于免费节点，这里有一个网址：https://free-ss.site/(需要科学上网)\n右键ShadowSocks的图标，选择服务器，在选择扫描屏幕二维码，即可添加节点，之后点击系统代理并开启系统代理为全局模式。\n之后就可以🤙🤙🤙!\nMobile端 下面两个软件都是需要科学上网的，建议先在PC端下载再传到手机安装。  云帆VPN 下载地址：https://apkpure.com/store/apps/details?id=cc.dingnet.yunfangp\n虽然每天只能使用1小时，但是基本够了。\n老王VPN 下载地址：https://apkpure.com/wang-vpn-%E2%9D%A4%EF%B8%8F-free-fast-stable-best-vpn-just-try-it/com.findtheway\n老王的东西永远免费！\n参考链接\n 2020年Android高速稳定翻墙方法 Windows上长期有效的免费且高速稳定翻墙法！ ","description":"","id":103,"section":"posts","tags":["科学上网","ShadowShocks"],"title":"2020翻墙指南👈","uri":"https://hugo.jiahongw.com/zh/posts/settings/2020-fanqiang/"},{"content":"👱‍♀介绍一些markdown中比较实用的一些写作方法。\n任务列表✍  a task list item list syntax required normal formatting, @mentions, #1234 refs incomplete completed  上面的代码如下：\n1 2 3 4 5  - [ ] a task list item - [ ] list syntax required - [ ] normal **formatting**, @mentions, #1234 refs - [ ] incomplete - [x] completed   数学公式📐 使用MathJax渲染LaTeX数学表达式。💡\n$$\n\\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix}\n\\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\\n\\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\\\\n\\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\\\\n\\end{vmatrix}\n$$\n上面的代码如下：\n1 2 3 4 5 6 7  $$ \\mathbf{V}_1 \\times \\mathbf{V}_2 = \\begin{vmatrix} \\mathbf{i} \u0026amp; \\mathbf{j} \u0026amp; \\mathbf{k} \\\\\\\\ \\frac{\\partial X}{\\partial u} \u0026amp; \\frac{\\partial Y}{\\partial u} \u0026amp; 0 \\\\\\\\ \\frac{\\partial X}{\\partial v} \u0026amp; \\frac{\\partial Y}{\\partial v} \u0026amp; 0 \\\\\\\\ \\end{vmatrix} $$   $$\n\\begin{align*}\ny = y(x,t) \u0026amp;= A e^{i\\theta} \\\\\n\u0026amp;= A (\\cos \\theta + i \\sin \\theta) \\\\\n\u0026amp;= A (\\cos(kx - \\omega t) + i \\sin(kx - \\omega t)) \\\\\n\u0026amp;= A\\cos(kx - \\omega t) + i A\\sin(kx - \\omega t) \\\\\n\u0026amp;= A\\cos \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) + i A\\sin \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) \\\\\n\u0026amp;= A\\cos \\frac{2\\pi}{\\lambda} (x - v t) + i A\\sin \\frac{2\\pi}{\\lambda} (x - v t)\n\\end{align*}\n$$\n上面代码如下：\n1 2 3 4 5 6 7 8 9 10  $$ \\begin{align*} y = y(x,t) \u0026amp;= A e^{i\\theta} \\\\\\\\ \u0026amp;= A (\\cos \\theta + i \\sin \\theta) \\\\\\\\ \u0026amp;= A (\\cos(kx - \\omega t) + i \\sin(kx - \\omega t)) \\\\\\\\ \u0026amp;= A\\cos(kx - \\omega t) + i A\\sin(kx - \\omega t) \\\\\\\\ \u0026amp;= A\\cos \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) + i A\\sin \\Big(\\frac{2\\pi}{\\lambda}x - \\frac{2\\pi v}{\\lambda} t \\Big) \\\\\\\\ \u0026amp;= A\\cos \\frac{2\\pi}{\\lambda} (x - v t) + i A\\sin \\frac{2\\pi}{\\lambda} (x - v t) \\end{align*} $$   脚注👣 如下是使用的代码，将鼠标悬停在“ fn1”或“ fn2”上标上可以查看脚注的内容。您可以将任何喜欢的唯一标识用作脚注标记（例如“ fn1”）。\n1 2  [^fn1]: Here is the *text* of the first **footnote**. [^fn2]: Here is the *text* of the second **footnote**   你也可以内嵌脚注，就像^[Here is the text of the first footnote.]\n水平线〰 🌟在空行输入***或---，如下：\nYMAL首要事项🤔 包含YAML前事块的文件将作为特殊文件进行处理，下面是一个例子\n1 2 3 4  ---layout:posttitle:BloggingLikeaHacker---  目录📑 输入[toc]并回车即可。\n内部链接🔗 这是一个跳转到任务列表的链接,this link ！\n代码如下：\n1  [this link](#任务列表✍)   参考链接📖 参考链接使用两组方括号的格式，第一个是显示的文字，第二个括号内是查找的id，代码如下：\n1 2 3 4 5  This is [an example][id] reference-style link. Then, anywhere in the document, you define your link label on a line by itself like this: [id]: http://example.com/ \u0026#34;Optional Title Here\u0026#34;   隐式链接，直接使用Google查阅：\n[Google][] And then define the link: [Google]: http://google.com/ 删除线❌ 删除Mistaken text.，代码为~~Mistaken text.~~\n高亮🔆 ==highlight==，使用两个等号在两边进行包围，代码如下：\n1  ==highlight==   插入视频📹 Your browser does not support the video tag.\n上面的代码即：\n1  \u0026lt;video poster=\u0026#34;https://i.loli.net/2020/02/29/S4oN2djFDZYiqAx.png\u0026#34; src=\u0026#34;https://files.catbox.moe/bqrntc.flv\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; loop=\u0026#34;loop\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the video tag.\u0026lt;/video\u0026gt;   插入音乐🎼 Your browser does not support the audio tag.\n上面的代码即：\n1  \u0026lt;audio src=\u0026#34;https://files.catbox.moe/wjiywu.mp3\u0026#34; style=\u0026#34;max-height :100%; max-width: 100%; display: block; margin-left: auto; margin-right: auto;\u0026#34; controls=\u0026#34;controls\u0026#34; loop=\u0026#34;loop\u0026#34; preload=\u0026#34;meta\u0026#34;\u0026gt;Your browser does not support the audio tag.\u0026lt;/audio\u0026gt;   更多：\n随机图片🌳 网址:https://picsum.photos/1920/1080\n","description":"","id":104,"section":"posts","tags":["markdown","Typora"],"title":"Markdown深入使用","uri":"https://hugo.jiahongw.com/zh/posts/settings/markdown-deep/"},{"content":"SM.MS sm.ms 支持的图片格式包括 JPG、JPEG、GIF、PNG 及 BMP，单档不超过 5 MB，单次可上传图片最大 10 张。图片永久保存，请勿上传政治相关图片\n速度：高速服务器 ❤ ❤ ❤ ❤ ❤(15 年成立)\n如优图床 支持大量免费图床分发，网站稳定性未知\n速度：动态 ❤ ❤ ❤ ❤ ❤\n牛图网 速度：日本服务器 ❤ ❤ ❤ ❤(2010 年)\nniupic.com 稳定性不错，不要上传违法图片\nvim-cn 上传界面十分简单，但十分稳定。\n速度： ❤ ❤ ❤(12年到现在)\nimgbb 无需注册，支持最大 16M 图片上传，支持 https，速度不错\n速度：亚太服务器 ❤ ❤ ❤ ❤\nmeotu 16 年成立的免费图片外链网站。上传下载速度快。\n需要注册，默认原图上传，支持 https\n速度：高速服务器 ❤ ❤ ❤ ❤ ❤\n遇见图床 18 年成立的免费图片外链网站。上传下载速度快。\n需要注册，默认原图上传，支持最大 10M，支持 https\n速度：高速服务器 ❤ ❤ ❤ ❤ ❤\nz4a 图床 需要注册，支持 HTTPS 速度块\n速度：高速服务器 ❤ ❤ ❤ ❤ ❤\nz4a.net 由于成立时间较短，稳定性未知。\nupload 2012 年成立的免费图片上传外链网站，至今依然稳定\n无需注册，默认原图上传，支持 https\n速度：亚太服务器 ❤ ❤ ❤\ncatbox 无需注册，支持 https\n速度：海外服务器 ❤ ❤ ❤\ncatbox.moe 支持 200m 主流格式文件外链网站\n","description":"","id":105,"section":"posts","tags":["photo","图床"],"title":"几款好用的图床","uri":"https://hugo.jiahongw.com/zh/posts/settings/free-image-bed/"},{"content":"Freenom 是目前为数不多的免费域名提供商，提供 .ga, .ml, .gq, .tk, .cf 五个免费顶级域。当然也有一些付费的域名，对于普通人来说，免费域名就够了。😏\n第一步，找域名 打开Freenom，登陆后直接在搜索栏搜索自己想要的域名名字，然后系统会返回可以使用的免费域名，选择一个结算即可\n第二步，配置解析服务 使用cloudflare解析服务 打开cloudflare，首先需要注册一个账号。然后他会要求输入需要解析的域名\n填写相应的DNS信息，并且将下面的NS信息填写到freenom的custom nameservers\n等待个几分钟就好了。Over 🤞\n","description":"","id":106,"section":"posts","tags":["域名","freenom"],"title":"Freenom 免费域名申请","uri":"https://hugo.jiahongw.com/zh/posts/settings/freenom-domain/"},{"content":"安装MinGW之后，我们可以那它来作为C或C++的编译器.🕸\nCMD编译程序  编译过程分为四个步骤：预处理、编译、汇编、链接。\n 使用g++可以在命令行分别实现上面四个步骤。使用下面的程序作为例子。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18  #include \u0026lt;iostream\u0026gt;#include \u0026lt;cmath\u0026gt;using namespace std; // this is my test program  #ifndef myNum#define myNum 666 #endifint main() { cout \u0026lt;\u0026lt; \u0026#34;Hello!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;myNum = \u0026#34; \u0026lt;\u0026lt; myNum \u0026lt;\u0026lt;endl; return 0; }   预处理 预处理主要完成的工作有：\n（1）删除#define，展开宏；\n（2）处理条件编译指令，预处理程序先判断条件，在根据条件修改源代码；\n（3）删除注释；\n（4）添加行号，以及文件名标识，便于调试\n（5）删除“#include”，插入相应的头文件；\n 使用下面的命令，得到预处理后的文件test.i\n1  g++ -E test.cpp -o test.i   查看test.i文件\n编译 使用下面的代码生成汇编文件test.s\n1  g++ -S test.i -o test.s   注意：直接从test.cpp文件得到汇编文件也可以。直接使用命令 g++ -S test.cpp -o test.s  查看test.s文件\n汇编 使用下面的命令将汇编指令转化为机器指令，生成文件test.o\n1  g++ -c test.s -o test.o   查看文件test.o\n链接 通过链接库文件，可以将目标文件test.o转化为可执行文件test.exe\n注意:Windows下可执行文件的后缀为exe，而Linux下不需要后缀。  CMD输入以下代码\n1  g++ test.o -o test.exe   注意:Windows下.o文件已经可以执行，在命令行输入test.o就可以看到如下的效果：\n 另外一个命令是\n1  g++ test.o -o test.exe -L 所需库文件路径   其中L为link的缩写。 快速生成可执行文件 一般情况下，可以直接使用g++ test.cpp -o test 就可以生成可执行程序了。\n运行程序 如下：\nMinGW + SublimeText配置C++环境 下载MinGW和SublimeText SublimeText下载\nMinGW下载及相关配置\n使用SublimeText 因为前面配置好环境变量了，所以可以直接在SublimeText下编译运行程序\nTools-\u0026gt;build(或者按快捷键Ctrl+B 或 Ctrl + Shift + B)\n可以在最下面一栏看到输出结果\nenjoy it!\n解决SublimeText下不能使用输入的问题 SublimeText是把shell执行的结果读回来显示在终端，这意味无法使用输入语句，无法使用调试功能。  解决方法:让程序直接运行在CMD\n在sublime-\u0026gt;Tools\u0026gt;Build System里新建编译系统，输入以下内容构建C++编译环境,保存名字为C++Buider\n1 2 3 4 5 6 7 8 9 10 11 12  {\u0026#34;cmd\u0026#34;: [\u0026#34;g++\u0026#34;,\u0026#34;$file_name\u0026#34;,\u0026#34;-o\u0026#34;,\u0026#34;${file_base_name}\u0026#34;,\u0026#34;-lm\u0026#34;,\u0026#34;-Wall\u0026#34;],\u0026#34;file_regex\u0026#34;: \u0026#34;^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$\u0026#34;,\u0026#34;selector\u0026#34;: \u0026#34;source.c, source.c++\u0026#34;,\u0026#34;shell\u0026#34;: false,\u0026#34;working_dir\u0026#34;: \u0026#34;$file_path\u0026#34;,\u0026#34;variants\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;RunInCommand\u0026#34;,\u0026#34;cmd\u0026#34;: [\u0026#34;cmd\u0026#34;,\u0026#34;/c\u0026#34;,\u0026#34;g++\u0026#34;,\u0026#34;-g\u0026#34;,\u0026#34;${file}\u0026#34;,\u0026#34;-o\u0026#34;,\u0026#34;${file_path}/${file_base_name}\u0026#34;,\u0026#34;\u0026amp;\u0026amp;\u0026#34;,\u0026#34;start\u0026#34;,\u0026#34;cmd\u0026#34;,\u0026#34;/k\u0026#34;,\u0026#34;${file_path}/${file_base_name}\u0026#34;]}]}  然后可以使用快捷键Ctrl + Shift + B，会显示如下，使用命令行打开模式选项即可\n结果如下：\n其他编译环境的配置也类似：\nC编译配置文件：\n1 2 3 4 5 6 7 8 9 10 11 12  {\u0026#34;cmd\u0026#34;: [\u0026#34;gcc\u0026#34;,\u0026#34;$file_name\u0026#34;,\u0026#34;-o\u0026#34;,\u0026#34;${file_base_name}\u0026#34;,\u0026#34;-lm\u0026#34;,\u0026#34;-Wall\u0026#34;],\u0026#34;file_regex\u0026#34;: \u0026#34;^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$\u0026#34;,\u0026#34;selector\u0026#34;: \u0026#34;source.c, source.c++\u0026#34;,\u0026#34;shell\u0026#34;: false,\u0026#34;working_dir\u0026#34;: \u0026#34;$file_path\u0026#34;,\u0026#34;variants\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;RunInCommand\u0026#34;,\u0026#34;cmd\u0026#34;: [\u0026#34;cmd\u0026#34;,\u0026#34;/c\u0026#34;,\u0026#34;gcc\u0026#34;,\u0026#34;-g\u0026#34;,\u0026#34;${file}\u0026#34;,\u0026#34;-o\u0026#34;,\u0026#34;${file_path}/${file_base_name}\u0026#34;,\u0026#34;\u0026amp;\u0026amp;\u0026#34;,\u0026#34;start\u0026#34;,\u0026#34;cmd\u0026#34;,\u0026#34;/k\u0026#34;,\u0026#34;${file_path}/${file_base_name}\u0026#34;]}]}  Java编译配置文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16  { \u0026#34;cmd\u0026#34;: [\u0026#34;javac\u0026#34;, \u0026#34;$file_name\u0026#34;], \u0026#34;file_regex\u0026#34;: \u0026#34;^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$\u0026#34;, \u0026#34;selector\u0026#34;: \u0026#34;source.java\u0026#34;, \u0026#34;shell\u0026#34;: false, \u0026#34;working_dir\u0026#34;: \u0026#34;$file_path\u0026#34;, \u0026#34;variants\u0026#34;: [ { \u0026#34;name\u0026#34;: \u0026#34;RunInCommand\u0026#34;, \u0026#34;cmd\u0026#34;: [\u0026#34;cmd\u0026#34;, \u0026#34;/c\u0026#34;, \u0026#34;javac\u0026#34;, \u0026#34;${file}\u0026#34;, \u0026#34;\u0026amp;\u0026amp;\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;cmd\u0026#34;, \u0026#34;/k\u0026#34;, \u0026#34;java $file_name\u0026#34;] }, { \u0026#34;name\u0026#34;: \u0026#34;Debug\u0026#34;, \u0026#34;cmd\u0026#34;: [\u0026#34;cmd\u0026#34;, \u0026#34;/c\u0026#34;, \u0026#34;javac\u0026#34;, \u0026#34;${file}\u0026#34;, \u0026#34;\u0026amp;\u0026amp;\u0026#34;, \u0026#34;start\u0026#34;, \u0026#34;cmd\u0026#34;, \u0026#34;/k\u0026#34;, \u0026#34;gdb ${file_path}/${file_base_name}\u0026#34;] }] }   解决不能输入中文的问题 使用下面的编译配置文件即可：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23  {\u0026#34;encoding\u0026#34;: \u0026#34;GBK\u0026#34;,\u0026#34;working_dir\u0026#34;: \u0026#34;$file_path\u0026#34;,\u0026#34;shell_cmd\u0026#34;: \u0026#34;g++ -fexec-charset=GBK -Wall -std=c++11 \\\u0026#34;$file_name\\\u0026#34; -o \\\u0026#34;$file_base_name\\\u0026#34;\u0026#34;,\u0026#34;file_regex\u0026#34;: \u0026#34;^(..[^:]*):([0-9]+):?([0-9]+)?:? (.*)$\u0026#34;,\u0026#34;selector\u0026#34;: \u0026#34;source.c++\u0026#34;,\u0026#34;variants\u0026#34;: [{\u0026#34;name\u0026#34;: \u0026#34;Run in sublime\u0026#34;,\u0026#34;shell_cmd\u0026#34;: \u0026#34;g++ -fexec-charset=GBK -Wall -std=c++11 \\\u0026#34;$file_name\\\u0026#34; -o \\\u0026#34;$file_base_name\\\u0026#34; \u0026amp;\u0026amp; cmd /c \\\u0026#34;${file_path}/${file_base_name}\\\u0026#34;\u0026#34;},{\u0026#34;name\u0026#34;: \u0026#34;CMD Run\u0026#34;,\u0026#34;shell_cmd\u0026#34;: \u0026#34;g++ -fexec-charset=GBK -Wall -std=c++11 \\\u0026#34;$file\\\u0026#34; -o \\\u0026#34;$file_base_name\\\u0026#34; \u0026amp;\u0026amp; start cmd /c \\\u0026#34;\\\u0026#34;${file_path}/${file_base_name}\\\u0026#34; \u0026amp; pause\\\u0026#34;\u0026#34;},{\u0026#34;name\u0026#34;: \u0026#34;gdb Debug\u0026#34;,\u0026#34;shell_cmd\u0026#34;: \u0026#34;g++ -fexec-charset=GBK -g -std=c++11 \\\u0026#34;$file\\\u0026#34; -o \\\u0026#34;$file_base_name\\\u0026#34; \u0026amp;\u0026amp; start cmd /c gdb ${file_path}/${file_base_name} \u0026amp; pause\u0026#34;}]}  配置代码格式化 从菜单里选View-\u0026gt;Show Console，跳出Console，下面有一行输入的（光标位置），把下面这段代码输入进去回车(只适用sublime Text 3)\n1  import urllib.request,os; pf = \u0026#39;Package Control.sublime-package\u0026#39;; ipp = sublime.installed_packages_path(); urllib.request.install_opener( urllib.request.build_opener( urllib.request.ProxyHandler()) ); open(os.path.join(ipp, pf), \u0026#39;wb\u0026#39;).write(urllib.request.urlopen( \u0026#39;http://sublime.wbond.net/\u0026#39; + pf.replace(\u0026#39;\u0026#39;,\u0026#39;%20\u0026#39;)).read())   安装CoolFormat，按Ctrl+Shift+P，然后输入install,就会出现“Package Control: Install Package”，输入CoolFormat进行下载，下载完成之后输入Ctrl+Shift+P，然后输入CoolFormat，选下Formatter Settings，可以看到如下配置:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14  ;Pleasevisithttp://akof1314.github.io/CoolFormat/doc/index.htmlformoreinformation[SynTidy]C++=\u0026#34;\u0026#34;-A1-p-N-Y-k3\u0026#34;\u0026#34;Java=\u0026#34;\u0026#34;-A1-p-N-Y-k3\u0026#34;\u0026#34;C#=\u0026#34;\u0026#34;-A1-p-N-Y-k3\u0026#34;\u0026#34;Objective-C=\u0026#34;\u0026#34;-A1-p-N-Y-k3\u0026#34;\u0026#34;HTML=\u0026#34;\u0026#34;-aan-dep-fb-fbc-fu-js-ll-n-ox-pe-qa-qn-m-wa-wj-wp-ws-sw-fo-i0-d1-ce0-ie0-oe0-w0-sbo0\u0026#34;\u0026#34;XML=\u0026#34;\u0026#34;-aan-dep-fb-fbc-js-ll-n-ix-qa-qn-m-wa-wj-wp-ws-sw-fo-i1-ce0-ie0-oe0-w0\u0026#34;\u0026#34;PHP=\u0026#34;\u0026#34;-sas-icd-samt-salo-saeo-saro-sabo-saao-samp-aas-rsl-iel-rpc-rst-st\u0026#34;\u0026#34;JavaScript=\u0026#34;\u0026#34;-nb-cn4\u0026#34;\u0026#34;CSS=\u0026#34;\u0026#34;-c2-rub-cl0-os1-cc-cf-cfp0-rs2\u0026#34;\u0026#34;JSON=\u0026#34;\u0026#34;-cn3\u0026#34;\u0026#34;SQL=\u0026#34;\u0026#34;-cn2-el-ml0\u0026#34;\u0026#34;Verilog=\u0026#34;\u0026#34;-A1\u0026#34;\u0026#34;  建立快捷键\n进入菜单选Preferences-\u0026gt;Browse Packages，然后进CoolFormat，里面有个Default.sublime-keymap\n打开后，里面有快捷方式的按键,更改如下：\n1 2 3 4 5 6 7 8 9  [{\u0026#34;keys\u0026#34;: [\u0026#34;ctrl+q\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;coolformat\u0026#34;, \u0026#34;args\u0026#34;: {\u0026#34;action\u0026#34;: \u0026#34;quickFormat\u0026#34;}},{\u0026#34;keys\u0026#34;: [\u0026#34;ctrl+alt+shift+s\u0026#34;], \u0026#34;command\u0026#34;: \u0026#34;coolformat\u0026#34;, \u0026#34;args\u0026#34;: {\u0026#34;action\u0026#34;: \u0026#34;selectedFormat\u0026#34;}}]   这样以后写完的代码直接按 “Ctrl+Q” 便可以格式化代码\n 另一种格式化代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13  ;Pleasevisithttp://akof1314.github.io/CoolFormat/doc/index.htmlformoreinformation[SynTidy]C++=\u0026#34;\u0026#34;-A2-p-N-Y-o-T-N-k3\u0026#34;\u0026#34;Java=\u0026#34;\u0026#34;-A1-p-N-T-Y-k3\u0026#34;\u0026#34;C#=\u0026#34;\u0026#34;-A1-p-N-Y-T-k3\u0026#34;\u0026#34;Objective-C=\u0026#34;\u0026#34;-A1-p-N-Y-k3\u0026#34;\u0026#34;HTML=\u0026#34;\u0026#34;-aan-dep-fb-fbc-fu-js-ll-n-ox-pe-qa-qn-m-wa-wj-wp-ws-sw-fo-i0-d1-ce0-ie0-oe0-w0-sbo0\u0026#34;\u0026#34;XML=\u0026#34;\u0026#34;-aan-dep-fb-fbc-js-ll-n-ix-qa-qn-m-wa-wj-wp-ws-sw-fo-i1-ce0-ie0-oe0-w0\u0026#34;\u0026#34;PHP=\u0026#34;\u0026#34;-sas-icd-samt-salo-saeo-saro-sabo-saao-samp-aas-rsl-iel-rpc-rst-st\u0026#34;\u0026#34;JavaScript=\u0026#34;\u0026#34;-nb-cn4\u0026#34;\u0026#34;CSS=\u0026#34;\u0026#34;-c2-rub-cl0-os1-cc-cf-cfp0-rs2\u0026#34;\u0026#34;JSON=\u0026#34;\u0026#34;-cn3\u0026#34;\u0026#34;SQL=\u0026#34;\u0026#34;-cn2-el-ml0\u0026#34;\u0026#34;  ","description":"","id":107,"section":"posts","tags":[""],"title":"MinGW在Windows的使用","uri":"https://hugo.jiahongw.com/zh/posts/settings/mingw-use/"},{"content":"HUGO + Github + Github Action持续集成部署个人博客\nHUGO本地环境 首先在HUGO的官网下载Hugo的Windows安装包，然后将路径添加到环境变量即可。\nstep1:下载hugo\nstep2:配置环境变量\nHUGO站点配置及主题配置 创建站点 在目录下直接输入下面的代码即可创建一个名为blog的hugo站点(注意：新建的站点是没有自带主题的)\n1  hugo new site blog   或者进入blog文件夹内直接输入以下语句：\n1  hugo new site .   下载主题 可以在hugo theme下载主题，然后根据主题的文档进行配置\n放到站点文件夹themes内，配置config.toml\n本地测试运行 输入hugo server测试\nGithub配置 创建站点仓库并且设置GithubPage 可以在Setting中看见如下：\n创建一个存储项目的仓库 配置Github Action 首先在项目仓库点击action，选择Simple workflow，输入一下的配置代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28  name:CI#自动化的名称on:push:# push的时候触发branches:# 那些分支需要触发- masterjobs:build:runs-on:ubuntu-latest# 镜像市场steps:- name:checkout# 步骤的名称uses:actions/checkout@v1#软件市场的名称with:# 参数submodules:true- name:SetupHugouses:peaceiris/actions-hugo@v2.2.2with:hugo-version:\u0026#39;0.64.1\u0026#39;extended:true- name:Buildrun:hugo-D- name:Deployuses:peaceiris/actions-gh-pages@v2.5.1env:ACTIONS_DEPLOY_KEY:${{secrets.ACTIONS_DEPLOY_KEY}}EXTERNAL_REPOSITORY:redisread/redisread.github.ioPUBLISH_BRANCH:masterPUBLISH_DIR:./public  准备部署，我们开发的项目及github pages实际是分开的，一个用于保存项目，相当于源代码，另外一个用于保存最终的网页文件。\n  使用git生成ssh key(相当于生成对密钥)\n1 2 3 4  ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key)    假设 开发项目为 HUGO_blog 部署的项目为 redisread.github.io\n   打开HUGO_blog仓库的settings，再点击Secrets，然后添加刚刚生成的私钥，name为ACTIONS_DEPLOY_KEY\n  同理，打开redisread.github.io，点击Deploy keys，添加公钥，Allow write access一定要勾上，否则会无法提交\n  然后，你就可以提交代码了，push成功后，打开仓库actions，至此部署成功，大功告成！\n","description":"Guide to set Hugo site.","id":108,"section":"posts","tags":["Hugo","Github"],"title":"Hugo配置","uri":"https://hugo.jiahongw.com/zh/posts/hugo/hugo_setup/"},{"content":"使用Github+PicGo建立一个免费的个人图床。\nPicGo介绍 PicGo是一款图片上传的工具，目前支持微博图床，七牛图床，腾讯云，又拍云，GitHub等图床\n在Github创建图床 创建Repository 生成一个Token用于操作GitHub repository 步骤如下:\n{% note warning %}\n注：创建成功后，会生成一串token，这串token之后不会再显示，所以第一次看到的时候，就要好好保存\n{% endnote %}\n配置PicGo 下载PicGo Windows用户下载exe文件\n配置图床    设定仓库名的时候，是按照“账户名/仓库名的格式填写”\n  分支名统一填写“master”\n  将之前的Token黏贴在这里\n  存储的路径可以按照我这样子写，就会在repository下创建一个“img”文件夹\n  自定义域名的作用是，在上传图片后成功后，PicGo会将“自定义域名+上传的图片名”生成的访问链接，放到剪切板上https://raw.githubusercontent.com/用户名/RepositoryName/分支名，，自定义域名需要按照这样去填写\n   快捷键及相关配置  这里配置上传快捷键为ctrl+shift+c\n 使用 经过上面的配置就大功告成了，每次截图之后，只需要ctrl+shift+c一下就可以把剪切板上面的截图转化为在线网络图片链接。\n","description":"","id":109,"section":"posts","tags":["PicGo","Github","图床"],"title":"配置基于Github的PicGo图床","uri":"https://hugo.jiahongw.com/zh/posts/settings/image-bed/"},{"content":"写在源文件中的源代码是人类可读的源。它需要\u0026quot;编译\u0026rdquo;，转为机器语言，这样 CPU 可以按给定指令执行程序。C 语言编译器用于把源代码编译成最终的可执行程序。🐤\n安装 首先,到：https://sourceforge.net/projects/mingw-w64/files/latest/download，下载最新版本的 MinGW 安装程\n然后，运行 Download mingw-get-setup.exe ,点击\u0026quot;运行\u0026rdquo;，continue等，注意记住安装的目录，之后需要配置环境变量，例如D:\\MinGW\\bin\n假如网速不好，可以通过下面的链接进行离线下载，下载完成之后使用7Zip解压，然后把解压的文件移动到安装路径即可。\nhttps://pan.baidu.com/s/1W4fHsUeaw1C9vp1lvRygbw\n注：使用这种方式下面的步骤不需要执行了，已经在离线包中集成了。可直接输入gcc -v查看gcc版本。\n 验证安装：\n在开始菜单中，点击\u0026quot;运行\u0026rdquo;，输入 cmd,打开命令行:输入 mingw-get,如果弹出 MinGw installation manager 窗口，说明安装正常，然后关闭窗口。\n安装GCC等编译器 在cmd中输入如下命令进行安装：\n安装gcc\n1  mingw-get install gcc   安装g++\n1  mingw-get install g++   安装gdb\n1  mingw-get install gdb   使用 在桌面创建一个hello.c的程序\n1 2 3 4 5 6 7 8 9  #include \u0026lt;iostream\u0026gt;using namespace std; int main() { cout \u0026lt;\u0026lt; \u0026#34;Hello!\u0026#34; \u0026lt;\u0026lt; endl; return 0; }   在 cmd 中输入命令\n1  gcc hello.c   在当前目录下(记住是命令的当前目录)会生成 a.exe 的可执行文件，在 cmd 中输入 a.exe 就可以执行程序了。\n","description":"","id":110,"section":"posts","tags":["gcc","MinGW"],"title":"windows下gcc的安装和使用","uri":"https://hugo.jiahongw.com/zh/posts/settings/gcc-windows/"},{"content":"我是一个不够严谨的程序员🙉.\n我喜欢📖,还有🏓.\n或许有时候我想的不够远，但是有时候我想的很深入。\n我最喜欢的 Aaron Swartz 语录:\n 在长大的过程中，我才慢慢发现，我身边的所有事，别人跟我说的所有事，那些所谓本来如此，注定如此的事，它们其实没有非得如此，事情是可以改变的。更重要的是，有些事既然错了，那就该做出改变。\n我对学校十分失望，我觉得老师们根本不懂自己所讲的是什么，他们居高临下，管这管那；作业就像是种把戏，就好像知识一种强制所有学生一起庸庸碌碌的手段。于是我就开始去阅读那些关于教育史和这套教育体系演变的书籍。然后你就能发现，如果要真正学到东西，那就不能机械重复老师所教的，这有点儿使得我渐渐学会了质疑。我质疑我所上的学校，我质疑简历这所学校的这个社会，我质疑学校教人们追求的那套事理，我质疑建立起这整个体系的政府。\n我总是深入思考，我希望别人也能想远一点。我为理想而工作，并从别人身上学习，我不喜欢拒人于外。我是个完美主义者，但我不会要求出版界也精益求精。除了教育和娱乐以外，我不会浪费时间在那些不会有影响的事情上。我试着和每个人都友好相处，但我讨厌人们不认真对待我。我不记恨他人，因为这于创造无益。但我从自身经历中学习，我想让世界变得更美好。\n我深深地觉得，光安生与当下这世界是不够的，那样子知识别人给什么你就照收，大人们说什么你就照做，你照着父母说的去做，照着社会说的去做。我觉得你应该总持有质疑，我觉得从科学的角度看，你所学的一切都知识暂时性的，任何所学都有改口、驳斥、质疑的余地。我觉得这情况对社会也适用。当我意识到社会上有着我能尽份力去解决的真正严重的、基础性的问题时，我没法去遗忘它、回避它。\n ","description":"Zzo about page","id":111,"section":"","tags":null,"title":"About","uri":"https://hugo.jiahongw.com/zh/about/"},{"content":"盒子 支持Markdown语法的盒子 语法：\n或者：\n1  \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;This is \u0026lt;strong\u0026gt;boxmd\u0026lt;/strong\u0026gt; shortcode\u0026lt;/div\u0026gt;   渲染显示：\nThis is boxmd shortcode 简单盒子 语法：\n渲染显示：\nThis is **box** shortcode  代码选项卡 可以在不同的代码块之间切换，语法：\n渲染显示：\njava javascript  1  System.out.println(\u0026#39;Hello World!\u0026#39;);     1  console.log(\u0026#39;Hello World!\u0026#39;);       'use strict'; var containerId = JSON.parse(\"\\\"bbfc6d359a06a39f\\\"\"); var containerElem = document.getElementById(containerId); var codetabLinks = null; var codetabContents = null; var ids = []; if (containerElem) { codetabLinks = containerElem.querySelectorAll('.codetab__link'); codetabContents = containerElem.querySelectorAll('.codetab__content'); } for (var i = 0; i 0) { codetabContents[0].style.display = 'block'; }  常规选项卡 这个和代码选项卡类似，不同的是，这种选项卡更加“常规”。语法：\n渲染显示：\nWindows MacOS Ubuntu  Windows section 1  console.log(\u0026#39;Hello World!\u0026#39;);   ⚠️Becareful that the content in the tab should be different from each other. The tab makes unique id hashes depending on the tab contents. So, If you just copy-paste the tabs with multiple times, since it has the same contents, the tab will not work.\n MacOS section Hello world!  Ubuntu section Great!    'use strict'; var containerId = JSON.parse(\"\\\"f09fb25fccaa3686\\\"\"); var containerElem = document.getElementById(containerId); var tabLinks = null; var tabContents = null; var ids = []; if (containerElem) { tabLinks = containerElem.querySelectorAll('.tab__link'); tabContents = containerElem.querySelectorAll('.tab__content'); } for (var i = 0; i 0) { tabContents[0].style.display = 'block'; }  展开栏 语法：\n渲染显示：\n  Expand me  Title contents     Expand me2  Title2 contents2   彩色文本框 语法：\n渲染显示：\nthis is a text this is a text this is a text this is a text 彩色注意框 语法：\n渲染显示：\nsuccess text  info text  warning text  error text  图片描述 使用语法：\n渲染显示：\n Sample Image: Image with title, caption, alt, ...   按钮 语法：\n简单按钮：\nbutton   设置宽度高度：\nbutton   设置颜色：\nbutton   ","description":"tabs, code-tabs, expand, alert, warning, notice, img, box","id":112,"section":"posts","tags":["shortcode"],"title":"Shortcodes使用","uri":"https://hugo.jiahongw.com/zh/posts/hugo/shortcodes/"},{"content":"A Short Video：  ——以下 Aaron Swartz的宣言，我想这才是信息革命的真谛——\n信息就是力量。但就像所有力量一样，有些人只想占为己有。世界上所有的科学和文化遗产，已在书籍和期刊上发布了数个世纪，正渐渐地被少数私有的公司数字化并上锁。想要阅读那些有着最著名研究成果的论文？你必须支付给如 Reed Elsevier 这样的出版商大把钱。\n有人努力去改变这种状况。开放访问运动 (Open Access Movement) 奋勇斗争，确保科学家们没有将他们的版权签署给别人，而是将他们的成果发布到网络上，允许任何人访问它们。但即便是最好的情况，他们的行为也只作用于未来发布的东西。之前的都将失去。\n这样的代价实在太高。强制学者付钱以阅读他们同行的成果？扫描整个图书馆却只允许 Google 的人阅读它们？提供科学文章给那些第一世界的精英大学，却不给身在南半球的儿童？这实在蛮横且无法接受。\n“我同意，”有些人就说了，“但是我们能做什么呢？那些公司握有版权，他们靠限制访问赚取大把的钱，而且这是完全合法的 - 我们没有办法阻止他们。”但有些事我们能做，这些事我们已经在做：我们可以反击。\n那些能够访问这些资源的人 - 学生，图书管理员，科学家 - 你们被赋予了特权。你们能享受到这知识的盛宴，而其他人却被排除在外。但是你们不必 - 事实上，从道义层面来说，你们不能 - 为保留自己保留这份特权。你们有义务和全世界分享它。而且你们已经在做了：和同行们交换密码，回应朋友们的下载请求。\n同时，那些被拒之门外的人们并没有袖手旁观。你们溜过洞穴，翻越围墙，解放那些被出版商封锁的信息并分享给你的朋友们。\n但所有这些行动都是在黑暗中进行，隐藏于地底。它们被称作偷窃或盗版，仿佛分享大量的知识精神上等同于抢劫一艘船只并谋杀其船员。但是分享绝非不道德的，它是一种道德使命。只有那些利欲熏心的人才会拒绝让朋友复制一份。\n大公司，当然，就是利欲熏心。使它们运转的法律要求使然 - 稍微出点事投资人就得叛乱。它们收买的政治家们支持它们，通过法案让它们拥有专属的权力决定谁可以复制。\n遵从不公正的法律不会带来公正。步入光明的时候到了，在公民不服从的伟大传统下，宣告我们对这种私人盗窃公共文化的反抗。\n我们要夺回信息，无论它们被存在何处，制作我们的副本并和全世界分享。我们要取到版权到期的东西并将它们归档，我们要买下秘密的资料库并将它们放到网上。我们要下载科学期刊并将它们上传到文件分享网络。我们要为游击队开放访问而战。\n只要全世界有足够多的我们，那就不仅是传达了一个反对知识私有化的强有力信号，我们还将让它成为过去。你愿意和我们一起吗？\n亚伦·斯沃茨 (Aaron Swartz)\n2008 年 7 月，意大利 Eremo\nInformation is power. But like all power, there are those who want to keep it for themselves. The world\u0026rsquo;s entire scientific and cultural heritage, published over centuries in books and journals, is increasingly being digitized and locked up by a handful of private corporations. Want to read the papers featuring the most famous results of the sciences? You\u0026rsquo;ll need to send enormous amounts to\npublishers like Reed Elsevier.\nThere are those struggling to change this. The Open Access Movement has fought valiantly to ensure that scientists do not sign their copyrights away but instead ensure their work is published on the Internet, under terms that allow anyone to access it. But even under the best scenarios, their work will only apply to things published in the future. Everything up until now will have been lost.\nThat is too high a price to pay. Forcing academics to pay money to read the work of their colleagues? Scanning entire libraries but only allowing the folks at Google to read them? Providing scientific articles to those at elite universities in the First World, but not to children in the Global South? It\u0026rsquo;s outrageous and unacceptable.\n\u0026ldquo;I agree,\u0026rdquo; many say, \u0026ldquo;but what can we do? The companies hold the copyrights, they make enormous amounts of money by charging for access, and it\u0026rsquo;s perfectly legal - there\u0026rsquo;s nothing we can do to stop them.\u0026rdquo; But there is something we can, something that\u0026rsquo;s already being done: we can fight back.\nThose with access to these resources - students, librarians, scientists - you have been given a privilege. You get to feed at this banquet of knowledge while the rest of the world is locked out. But you need not - indeed, morally, you cannot - keep this privilege for yourselves. You have a duty to share it with the world. And you have: trading passwords with colleagues, filling download requests for friends.\nMeanwhile, those who have been locked out are not standing idly by. You have been sneaking through holes and climbing over fences, liberating the information locked up by the publishers and sharing them with your friends.\nBut all of this action goes on in the dark, hidden underground. It\u0026rsquo;s called stealing or piracy, as if sharing a wealth of knowledge were the moral equivalent of plundering a ship and murdering its crew. But sharing isn\u0026rsquo;t immoral - it\u0026rsquo;s a moral imperative. Only those blinded by greed would refuse to let a friend make a copy.\nLarge corporations, of course, are blinded by greed. The laws under which they operate require it - their shareholders would revolt at anything less. And the politicians they have bought off back them, passing laws giving them the exclusive power to decide who can make copies.\nThere is no justice in following unjust laws. It\u0026rsquo;s time to come into the light and, in the grand tradition of civil disobedience, declare our opposition to this private theft of public culture.\nWe need to take information, wherever it is stored, make our copies and share them with the world. We need to take stuff that\u0026rsquo;s out of copyright and add it to the archive. We need to buy secret databases and put them on the Web. We need to download scientific journals and upload them to file sharing networks. We need\nto fight for Guerilla Open Access.\nWith enough of us, around the world, we\u0026rsquo;ll not just send a strong message opposing the privatization of knowledge - we\u0026rsquo;ll make it a thing of the past.\nWill you join us?\nAaron Swartz\nJuly 2008, Eremo, Italy\n","description":"","id":113,"section":"talks","tags":[""],"title":"My Awesome links","uri":"https://hugo.jiahongw.com/zh/talks/mylinks/"},{"content":"Sample images about life.\n","description":"my gallery","id":115,"section":"gallery","tags":[""],"title":"life","uri":"https://hugo.jiahongw.com/zh/gallery/life/"},{"content":"between 70 and 240 in movies\ngood movies！🎥\n","description":"my gallery","id":116,"section":"gallery","tags":[""],"title":"movie","uri":"https://hugo.jiahongw.com/zh/gallery/movie/"},{"content":"一个测试视频:  ","description":"","id":120,"section":"talks","tags":[""],"title":"B站视频","uri":"https://hugo.jiahongw.com/zh/talks/blibli/"}]