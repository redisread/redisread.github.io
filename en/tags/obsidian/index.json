[{"content":"01 美团之初 王兴：团购是超完美的商业模式\n时间：2011年\n背景：千团大战，美团一周年\n1.金字塔结构下，小企业生意的机会 中国商业互联网的发展，有一个金字塔，分三层，代表不同规模、不同数量的企业。所有企业都是需要做推广的，互联网作为一个传播信息很好的平台，它可以作为商业推广的最好方式，但是不同的环境下面，不同规模的企业，它会找到不同的适合它的互联网推广方式。\n最早在2000年左右，中国商业互联网的开端，最大的企业在金字塔的塔尖有世界五百强，像宝洁、宝马，2000年开始做推广，新浪首页放展示广告，按展示付费，只有很少一部分企业参与。\n互联网继续发展，到2005年很多企业，制造企业、外贸企业，它们有推广需求，但是它们没有资金实力去门户投广告，或者效果不够精准，回报不够高，但是2005年它们发现有一种互联网网站，有一种新的商业模式可以帮助它们，那就是搜索，这些中小企业原来不可能按展示付费在门户网站投广告，但是它们可以在搜索引擎，在百度、谷歌里面搜索，按照点击率付费，这样离效果近很多。 所以按点击付费的商业模式的企业，通常来讲规模会比上面一层小一些，但是数量大很多。像新浪之类的门户网站，它的广告客户就那么几百家，或者在千家量级，但是像百度，它可以达到几十万个客户。所以，这5年间互联网往前走了一步，之前没法利用互联网做商业推广的企业，找到了新的商业模式。\n但是历史并没有就此停止，一直在往前。 又过了5年时间，到了2010年，到了3月4日，美团网在国内开创了团购的方式。这样我们可以满足更多的企业的需求，大家来看金字塔的塔基，在这里面的企业它可能单个规模都比较小，或者说它是本地的服务企业，它的销售半径超过5公里、10公里，客户就不太可能来到这里消费。\n这些企业，这些本地商家，虽然规模比较小，但是数量非常多，按照国家统计局的统计，有700万家（大V商业注：到2017年底，2017年底，中国中小企业数量达2726.3万家），这些企业都需要进行推广。以前门户网站帮不了这些企业，搜索引擎帮不了它们，搜索引擎虽然是按点击付费，但是这么多本地商家可能根本连网站都没有，点击量没有意义。他们不关心展示，不关心点击，他们关心有多少客人到他们店里消费，他们关心交易。\n所以他们希望有一种互联网推广方式能够直接帮助他们带来交易，完全按照效果付费，这个事情美团网可以帮助他们做到。\n我可以非常诚实地说，我衷心地认为团购的模式是人们有史以来最优美的商业模式之一。\n2.手机端的机会 我们认为手机非常重要，我们已经发布了Android美团客户端，在手机上使用美团网就会更加方便。智能手机里面还有一个重要的平台，iPhone，美团的iPhone已经提交申请。\n3.返利和裂变的创新 在过去一年里，从去年3月4日第一天上线起，我们首创一种方式，10元邀请返利，我们不想乱花钱砸广告，我们相信口碑相传。\n今天我们提出一个更劲爆的措施，不需要邀请，直接注册，直接返10元。\n4.用户体验的保证 但是现在美团网要推出“过期退”。所有过期的余额，我们会全额返还，百分之百返还，让之前所有信任美团网，参加美团网团购，到后面不管因为什么原因没有去的会员放心。他以为是损失的，其实没有损失。我们实行的种种措施就是希望消费者尽可能放心，消除消费者选择美团网的后顾之忧。 5.先进的商业模式最终会胜 关于对商业模式的理解，我想商业模式其实不是最关键的事情，因为一个模式可以非常简单、非常透明，商业模式是共通的，关键是看执行力，这是我对商业模式的理解。\n短期可以有各种各样的花招，但是长期来看生产力决定生产关系，效率高的商业模式一定会胜出，对处在金字塔塔基的这些商家来讲，美团网这种商业模式比门户展示付费和搜索引擎按点击付费更适合他们的需求。所以长期来看，更好的商业模式会胜出。 6.微创新 单个商家接单能力有限，我们不可能一个单有几十万单，所以这个时候，为了更好地满足客户需求，我们做了适当的划分，每天不止一个团购项目。（注：团购鼻祖Groupon当时还是每日一团）校内网有很多本地化的改动，但是因为它们比较细微，所以大家没有感觉。最早在国内是按邮箱后缀来识别大学的，这个非常简单，非常容易理解，但是我们在2005年做校内网时发现有些学校没有，北航这种很好的学校就没有，所以我们不可能按照这种方式操作，需要按其他方式，在校园里注册，或者按IP来做，这都是很小的差异。人群也是一样，也是一个金字塔。互联网普及最早是从受教育程度最高的人群入手，随着时间的推移，互联网普及会逐渐下沉，在人群上会下沉，越往下越接近本地，越接近线下，整个大的趋势是如此的。\n7.精or全 巨大的潮流当中，有很多的机会，每一个机会都会有足够的空间让公司去成长。所以这个阶段，我们没有必要说一下把所有东西糅合在一起，我们选好一个事情，把它做专做精，让在这个行业里面服务的各方都满意，我觉得一定会有很好的前景。\n8.重技术 另一方面，也可能是被很多人忽视的方面，是我们花在技术研发上面的资金。电子商务的核心是低成本、高效率，这个效率不是完全靠堆人，人要成长，人数要增加，而更多是靠技术平台的研发。不断积累消费者和商户数据，我们才能知道商家需要什么样的消费者，消费者需要什么样的项目。我们能够实现数据积累更精准的匹配，同时能够让客户很方便地用。\n9.长期价值 互联网企业发展至今，没有一个实施的本地化战略能够做大，所以很多人会质疑美团的战略。但是，搜索引擎，在1998年大家认为这是一个完全没有商业模式的行业，之前有那么多人做了，完全没有效果，完全没有商业模式。\n我有一个朋友，2000年读完研究生在北大天网。当时有两个人从国外回来，在北大资源楼租一个办公室，想做搜索引擎，想挖最好的人，很多人去了，他没有去。他认为：“搜索引擎我能做得很好，但是这个事情没有商业模式。”所以他没有去。这个公司就是百度，后来上市，再后来成为中国最大的互联网公司之一，也是全球第五大互联网公司。\n这个故事告诉我们，一个事情只要它长期有价值，虽然它很有难度，但是过去做不成，不代表将来做不成。\n本地电子商务是一个庞大市场，因为几百万家企业都需要营销，需要推广，需要销售，之前试过搜索方式不太行，试过评价方式似乎也不那么有效，我们终于到了一个很有趣的历史时间点，终于出现一个很好的商业模式，满足这些存在的需求。问题一直存在，可方法一直没有找到，现在我们可能接近找到了。\n10.团队建设 有些非常年轻的员工，现在22岁（注：王兴此处指的应该就是沈鹏，现水滴互助CEO沈鹏），从去年还没有毕业就加入美团网，到后面开拓外地市场，这样一些年轻人不到一年的成长历程给我们很大的惊喜，也让我们知道，在这个行业里面年轻人是有机会的，年轻人是有优势的。有激情，有干劲，这个事情并不难。\n在接下来的发展中，我们判断一个人是否来美团网，关键不是他的年龄，是他的状态——有干劲，能够理解消费者要什么；有冲劲，朝九晚五不适合我们。那些愿意认同这个目标，愿意投入一切努力去承担一切责任，承担更多责任的人是我们需要的人。\n团队建设，是靠心态，而不是靠年龄。 02 成长的策略 王兴：如何度过行业寒冬\n时间：2012年\n背景：拉手上市失败，千团大战结束前夕\n1.每天前进30公里 在1911年12月之前，没有哪个地球人到过南极点，所以这是一百年前所有最伟大的探险者、所有最有探险精神的人最想做到的事情。而在这个过程中有很有趣的故事，他们的故事和我们将要进行的事情有几分相似，他们的教训、他们的经验对我们来讲有借鉴意义。\n最后两个竞争团队，一个是来自挪威的阿蒙森团队，另一个是斯科特团队。\n阿蒙森团队五个人，斯科特十七个人。他们出发时间是差不多的，这是因为这个世界上竞争从来都非常激烈，当有一个大的机会的时候，没有可能只有你看到了，基本是差不多时候有一帮人也看到了，这跟其他无数的场合竞争都很像，一个真正有吸引力的机会，会在差不多同一时间有不止一个团队、不止一个公司或者不止一个人参与，一定会有激烈的竞争。\n阿蒙森团队在两个多月后，率先到达了南极点，而斯科特团队他们晚到了一个多月，这意味着什么？这就是成功跟失败的区别。\n阿蒙森率先到达南极点，并在21个月之后顺利地返回了原来的基地，一切都按他们原来的计划进行，因为他们做了非常充分的调研，非常精心的准备，储备了足够的物资，对困难有足够的预料，按计划进行。而斯科特团队不断地有人掉队，不断地碰到困难，最后他们没有任何人生还。\n成功跟失败的区别不光是你是否获得荣誉，是否完成目标，而已经是生与死的差别。\n这些前辈进行的探险比我们更困难、更刺激，赌注更大。那么是什么造成这么重大的区别，对我们在做的事情会有些帮助和启发。\n事后有人总结分析两个队的策略和准备，可以看到非常重要的区别。阿蒙森的团队人虽然少，但是物资准备非常非常充分，他们准备了三吨的物资；而斯科特团队的人多，但是准备的东西少，只有一吨的物资。一吨的物资够吗？如果你在这个过程中不犯任何错，完全不犯任何错，刚好够。物资确实是够的，但是前提是你在这两千两百多公里的路程中，不知道地形、不知道天气的情况下，你不能犯任何错。如果你不犯任何错，这一吨物资确实够。大家知道这是多么可怕的事情，理论上可行，但现实中碰到很大的压力、碰到很大的未知困难，你不可避免地会动作走形，会犯很多错。\n所以，当你的计划订得太紧的时候，当你的准备虽然貌似够，但是不充分、没有富余量的时候，其实是非常非常危险的。\n阿蒙森团队物资有极大的富余量，在行进过程中，他们可能会错过一个事先准备好的补给站，或者说丢掉一些东西，或者说碰到一些比原来想象的温度更低、暴风雨天气更长的时候，但他们依然能够有足够的物资储备。\n只有这种做法才是够的做法，不是将将够，而是充分预知到这个环境多么困难，要做多么多么充足的准备，要给自己留下犯错的空间，或者对我们来讲是学习的空间、成长的空间。\n所以这是一个非常非常大的区别，资源是否足够，是否有空间。\n另外还有很多区别，例如，他们采用的工具不一样，也就是说他们事先做的准备不一样。阿蒙森是挪威人，他为了去南极做了非常多的准备，首先要去哪个地方，要完成哪个目标，最好的工具是什么？最好的办法是什么？要学习最好的办法，采用最可靠的、最先进的工具。跟南极最像的地方就是北极，他跑去北极和爱斯基摩人住了很长一段时间，包括如何用冰天雪地里最好的工具——狗拉雪橇。\n而斯科特团队犯了很多错，一样要拉雪橇，他选择了比狗更壮、更强悍的马。事实上，这是一个很大的错误，狗和马有很多差别，狗在雪地里是不会出汗的，而马会出汗，一出完汗再一冻就被冻住了。所以马虽然比狗强悍很多，看起来快很多，但其实并不是一个合适的工具，看起来威猛，看起来快，其实它不适应这个环境。\n后来很快发现不行，他们想用更冒险的方法，用最先进的工具——雪地摩托。这是一百年前，雪地摩托整个内燃机都是非常不成熟的，如果雪地摩托这种最先进的工具能用的话，很可能非常快，非常威猛，但事实是，他们搞去的雪地摩托才走一段时间就被发现不行，因为这是一个太新的东西了，虽然理论上可能可行，但是从来没有人在这么严酷的环境下，在没有很完善的情况下用这个东西。\n最后他们不得不沦落为人拉着雪橇走。 这是一个很重要的区别，在同一个环境下面，目标大致相同，你选择什么样的路径，你用什么样的方法，你做什么样的准备，最后很有可能不光是成功与失败的区别，而是生与死的差别。\n还有一个非常非常重要的策略区别，就是不管天气好坏，阿蒙森团队坚持每天前进大概30公里，这句话听起来非常简单，但是事后总结，这个是阿蒙森团队能够不断成功而且生还的一个非常重要的原则。这里有很多讲究，在一个极限环境下面，你要做到最好，但是你要做到可持续的最好，你就不能太努力，一旦你出汗就非常非常糟糕，一兴奋，出汗了，那么待会儿风一吹就结成冰了。所以任何时候，**太激进其实很有可能会带来长期的负面影响。**做到这点需要高度严守既定的纪律，在事情容易的时候，在环境顺利的时候，不要得意忘形，坚守纪律，当情况好的时候，似乎容易的时候，前进30公里，然后扎营、休息。当天气不好的时候，阿蒙森也坚持带领他的团队，哪怕挪得很慢，也要前进30公里，完成这一天的目标。因为本身设的目标是有富余量的，天气不好就慢一点儿，路陡就慢一点儿，但坚持去完成。\n阿蒙森制订了一个可行的计划，有富余量的计划，虽然他们面对的几乎是一个完全未知的领域和未知的天气，但他们基本按计划执行。相反，斯科特团队，从他们的日志来看，是一个比较随心所欲的团队，天气很好，就走得非常猛，天气不好的时候，就睡在帐篷里，诅咒恶劣的天气，诅咒运气不好，希望尽快天转晴，尽快能够前进。\n这是很自然的反应，很多人容易有这样的想法，容易的时候多搞点儿，不容易的时候，季节不好、天气不好、市场环境不好，就歇一歇。但事后总结，这两种做法很可能是他们最大的区别。\n这个故事它跟今天我们所处的环境、我们要干的事情有很多相似之处。我们相信商品的电子商务和服务的电子商务最终规模是差不多的，它的最后规模都是上万亿，我们同样面临一个目标，要去做本地电子商务。\n最怕的是我们对自己估计不足，对这个情况认识不足，所有困难只要我们意识到它，我们相应地去做准备，去克服，都是有可能克服的，最怕的是我们对情况估计不足。\n我们应该像去探索南极的阿蒙森团队一样，充分利用、学习现有的一切最好的方法，适合我们的方法，对困难有足够的估计，目标清晰，同时制订计划，去坚定地执行。我们在2011年的目标是每个月增长20%，大概一年接近10倍。\n2.学习对手，学习一切先进，超越对手 我们要重视每一个对手，他们有许多可取之处。\n**我们可以从阿里学习很多东西，但是最终我们一定要超过阿里。**我们要向任何一个对手学习，任何一个同行学习，但我们最后目标应该是超越它们，这是整个公司的目标，也应该是每个人的目标，不管你在哪个岗位上，总有办法可以做得更好，学习新的东西，目标是超过它们。\n3.关于上市 上市不是我们的目标，应该是我们在到达一个更长远的目标的过程中，在合适的情况下发生的事情。\n你不能把上市作为目标，而是应该有更坚实的目标，要服务好消费者，服务好商户，让整个企业能够健康持续地运转。那个时候上市是水到渠成的事情。\n在上市之前，另一个事情非常重要，因为公司整个事情是大家一起做出来的，美团最重要的产品、最重要的资产都是人，我们希望上市的时候一方面给公司带来资金，另一方面能让大家分享这个胜利的果实。所以在去年下半年的时候，我们第一次有了全员持股计划，只要加入公司一段时间，足够长的时间，每个人都有的。\n4.冬天 2011年上半年大家疯狂投资，各种各样的高得离谱的估值，后来下半年如我们所料，冬天来了，可能不光是团购的冬天，不光是电子商务的冬天，甚至认为是整个互联网、整个投资的冬天。现在也一样，很多人认为市场环境不好，这一切其实都是像他们去南极探险时候的天气好坏变化，有的时候晴天，有的时候阴雨天一样，都大致在可控范围之内。\n我们不依赖运气，我们要像成功的阿蒙森团队一样，像他们每天不管天气好坏坚持前进30公里一样。\n只有这种看起来不那么激动人心的方式，其实是最考验毅力的，也可能是最有产出的。一个简单的事情重复做，越做越好，越做越专业，不管是在哪个岗位上，这个事情听起来似乎很枯燥，但是它其实蕴含着无数的激情，这是真正的激情，并不是莫名其妙的不同的变化，而是你做成的事情，你要希望把它做到最好，做到越来越好，要做到比最好还更好，每天越来越好。\n这是一个很难的事情，但是是一个很激动人心的事情，也是非常值得努力的事情。\n03 定目标 王兴：从美团的三年到O2O的十年\n时间：2013年\n背景：美团成为全国团购的老大，美团外卖年底上线\n1.每一次花钱都是在投票，投票选择你想要支持的那个世界 大概三年前，当美团规模还非常小的时候，曾经有朋友问我，你之前做校内网，做饭否，它是一个社交媒体、社交网络，看起来是不是更能影响信息传播，更有社会意义的事情；做电子商务做美团也很好，但是不是有一点儿俗了。我毫不犹豫地，而且非常理直气壮地告诉他：不俗！\n我觉得一个非常重要的事情是，每个人都有花钱的自由，所以，我们每一次花钱都像在投票，在用钞票投票，投票给你想要的那个世界。你用你手里的钞票，没有人能够阻挡你，它作为你的选票，决定你要支持什么样的公司，支持什么样的企业，你要跟什么样的人做生意，你要到什么样的地方消费，你认为什么企业应该在这个竞争中获得更多选票，赚更多钱，能够发展得更好。\n这是每个人的自由，每个人都有选择的权利，有消费的民主，而美团干的就是这样的事情。它给每个人更多选择、更多自由，然后也让那些诚信的、提供优质服务的商家能够在这种投票的选择中获胜，而发展得更好。\n所以，我想反复强调这一点，我们每一次花钱都是在投票，投票选择你想要支持的那个世界。那么每一次投票就是一次交易，交易额代表投票的多少，代表你影响了多少消费者，我认为交易额对美团非常重要。\n2.从大趋势中看产业机会 淘宝天猫发展得非常好，它的主力是做商品的电子商务，我们完全有理由相信服务的电子商务是一个规模完全不逊于商品的电子商务，甚至更大，是需求更充分的一个市场，这一点也可以从另外一个报告中看出来。\n大家关注宏观形势的话，就可以看得出刚刚2012年全国的GDP和各个产业的分布，我相信2012年是第三产业产值小于第二产业产值的最后一年，第三产业就是服务业，跟第二产业工业的产值差距在飞速地缩小，2012年应该是最后一年第三产业小于第二产业，从2013年开始，统计报告肯定会是第三产业服务业总产值大于第二产业，而美团恰恰做的是第三产业，是服务业的电子商务。 3.55亿时，敢下1,000亿目标 回顾过去三年，展望未来一年，还要展望未来三年。所以，这里我想跟大家分享另一个目标：2015年我认为美团应该实现全年1,000亿的目标。（2012年美团55.5亿）\n2015年全年1,000亿，1,000亿是什么意思，难吗？听起来是个很大的数字，但其实并不是遥不可及，因为再难的事情你只要把它分解、分解，再分解，然后每一步都有人负责，都有团队负责，每个人都靠谱，那整个事情就都靠谱。\n如果把1,000亿这个看起来很大的数字稍微分解一下，我们就会发现，只要我们顺利地完成今年188亿的目标，后面2014年、2015年，平均每年只要增长140%，也就是每年2.4倍，到2015年我们就能顺利地完成1,000亿的目标（注：2015年美团交易额1,611亿）。每年增长140%，这是比我们所有过去几年都要慢得多的数字，10倍、3.8倍、3.4倍，完全有理由相信，只要我们不犯错误，只要我们产品方面更加深入，商品选择更加丰富，能够始终保证高质、低价格，然后保证非常便利，不光在PC方面，更在手机方面，因为消费者需求是如此旺盛，而商家的需求也是如此强烈，我们有理由非常快速地发展，到2015年我们希望美团全年交易额能够超过1,000亿。\n大家注意看，我的标题是“从美团的三年到O2O的十年”。基本上，本世纪第一个十年是传统电子商务蓬勃发展的十年，到2010年年初，随着团购的发展，O2O才真正开端。\n大胆地展望一下，到这个十年，O2O的前十年结束的时候，到2020年的时候，我相信美团全年的交易额能超过一万亿（注：2019年美团交易额为6,821亿，YoY 32.3%）。\n我希望跟大家分享一下最简单的事情，从1,000亿到10,000亿是十倍，如果我们给自己五年的时间，平均每年只要增长60%，也就是1.6的5次方是超过10，当整个第三产业是数十万亿的时候，当五年后互联网普及进一步提高，消费者手机上网的普及度进一步提高的时候，我们没有理由不相信这整个产业会是一个巨大的产业，而我们作为这个产业的领跑者，有理由相信应该把目标设定在超过10,000亿上面。所以，这是目标，目标不管宏伟不宏伟，其实你只要去分解它，就可以理解它，而且我相信一个高的目标是会对每个人有激励作用的，这是过去三年给我最大的感受。\nO2O的十年将注定是一个既牛×又苦×的十年，为什么说苦×呢？是因为大家都知道，我们不管在哪一个部门，哪一个环节，竞争都非常激烈，消费者、商家各种各样的需求，而这个事情注定是一个高品质、低价格、低毛利的事情。\n这里我们要记住一句话：你对未来越有信心，你对现在越有耐心。可能现在过去的三年，接下来一年，接下来两年、三年，都会是非常煎熬的、苦×的事情，但是，整个事情是有非常光明、巨大前景的事情。 04 美团离破产只有6个月 王兴：“危机”与“成长”\n时间：2014年\n背景：美团成为团购老大\n1.危机 2013年年初制定了三个目标，我们完成了其中两个，但另一个指标我们没有完成，就是全年交易额188亿，我们完成了160亿。我觉得这个事情没必要隐瞒，它是什么样就是什么样。\n今天当我展望2014年的时候，我想重点说两个词，第一个词是——“危机”。如果你希望在一个好的创业公司一路高歌猛进的话，每一年都是关键的一年，这一句话每一年都是对的。\n虽然我们已经做到了团购市场超过50%市场份额，但是我们做的事情是本地电子商务，我们要的不只是全国的领导位置，我们要的是在每个城市都占有领导位置。\n我们现在占据了50%多市场份额的领域，只是300多亿、400亿的份额，Offline有几万亿，Online只占了1%左右，在这个1%里面，我们只占了50%多，这又算什么呢？\n不管是传统互联网的巨头，还是像万达这样传统商业里的巨头，他们都喊O2O，大家都在往这个行业进入的时候，我们需要做得更好，如果我们不能做得更好，我们就处在一个非常危险的状态。甚至可以毫不夸张地说，美团这个公司永远离破产只有6个月时间。\n如果你在另一个公司，它认为它可以高枕无忧的话，那么它离死不远。这个行业、这个时代、这个世界变化特别快。凡是没有危机意识的公司，不战战兢兢的公司，不管它现在看起来多么强大，都是非常危险的，而且它比那些虽然小，但是始终保持非常警惕状态的公司和人更危险。\n在现在的互联网行业里面，腾讯被认为是最强大的公司，但腾讯的leader马化腾曾经说：“巨人倒下的时候，身体都可能还是温暖的。”想要在这个时代、这个行业生存下去，我认为每个人、每个公司都要有这样的危机意识。\n2.成长 第二个词是“成长”。很多问题，正是我们成长太快带来的。单从交易额来看，阿里、京东、小米，没有我们快。\n这样一个快速成长的环境带来了很多很多问题。因为人的成长是需要时间和机会的，但公司的业务是每年两倍、三倍成长的时候，会带来很多问题，并不是每个人的每一步都能跟上。\n这时候我们需要轮岗的方式，需要更有耐心的方式，能够更好地解决这个问题。 05 决战之年 王兴：2015年是O2O决战年\n时间：2015年\n背景：O2O泡沫破灭\n5年前，那是在美团正式上线之前，在北京海淀区清华东门的华清嘉园，一个三居室，十几个人开了一个简单的座谈会，那时我们还面临很多困难，在那个会上，不少人落泪了，包括我。\n在2012年，我们狂开站、狂上单、狂拜访，这一系列事情做下来，2012年底，美团已经初步确定了我们在团购的优势地位。我相信今天大家可以看到，我们之前坚持每天行进三十公里，三年累积下来我们取得了什么样的成绩。\n1.鸵鸟原理（追求绝对强大） 在遇到问题时，我觉得不管对个人、团队，对整个公司来讲，有一个很多年前长辈告诉我的道理。\n可能很多人听过鸵鸟原理。火鸡比母鸡要大一些，如果从旁观者的角度来看，确实火鸡比母鸡是要大一圈或者大两圈。但是，母鸡看火鸡，其实会觉得大家差不多，母鸡也是不太服气火鸡比我大的，它觉得你可能就比我大那么一点。\n但是，当一只鸵鸟过来的时候，不管是母鸡还是火鸡，不管它们再不服气，在一个强大的反差面前它们都会认同鸵鸟确实确实比我大。这个道理非常深刻，人和人的对比，团队和团队的对比，公司和公司的对比，这个道理同样存在的。\n所以在早期，可能我们认为我们的价值观比对手更正，我们团队比对手更好，我们的基础比别人更好，对手却不服，不要紧，这个时候争论是没有用的，我们要做的是什么？还是回到根本问题，消费者第一、商户第二、团队第三、股东第四，我们有足够的资源，足够好的团队，我们去合作足够多足够好的商户，然后和商户一起去把消费者服务好。如今，美团在全国有两亿多用户，在手机上面美团是仅次于淘宝的最大的电商营销平台，比天猫大，比京东大。所以，只要我们能坚持往前走，坚持走得比对手更快，大家可以看到，曾经认为是我们对手的已经被我们远远的甩在身后。\n2.BAT进入O2O，美团到了该建平台、生态的一年 面对未来的挑战，我认为今年会是O2O真真正正大决战的一年。团购的事情我们占60%的市场份额或者更高一些，但还没有完全的结束。\n在电影这个领域，BAT或者其他各种各样的公司，线上线下他们和我们一样，都在做很多尝试。\n**我认为今年应该是美团重点去建平台、建生态的一年。因为我们需要越来越多的产品服务去满足用户的需求，去满足商户的需求，而且不同的产品、不同的业务需要平台。**我们还需要跟外部各种各样的合作伙伴有各种各样的合作方式。所以，今年不管是内部的发展还是外部的发展都需要我们有建平台、建生态的意识。\n我相信今年的竞争会非常激动人心，而建平台、建生态这个事情在今年也是一个开端，是一个非常重要的开端。\n3.不要高估两年能发生的变化，不要低估十年能发生的变化 我相信比尔·盖茨的话，他说得非常对，“人们总是倾向于高估两年能发生的变化，但是低估十年能发生的变化”（We always overestimate the change that will occur in the next two years and underestimate the change that will occur in the next ten years），五年也是如此，特别是在这个时代，两年看起来是很长的时间，而五年基本上回头看，我相信所有人都会同意发生的变化比大家想象的更多。\n06 互联网下半场 王兴：2016年回归服务根本、下半场\n时间：2016年\n背景：美团点评刚完成合并\n2015年是中国互联网历史上一个非常特殊的年份。这一年发生了很多互联网公司的合并，包括滴滴和快的，58和赶集，携程和艺龙、去哪儿。在这个大环境中，美团和大众点评也于2015年10月8号宣布合并。\n1.消费者第一、商户第二 我认为最简单的判断标准就是你觉得某个服务够好吗？你觉得你可以把它推荐给你的家人和朋友吗？如果我们期望真正做好这个事情，成为一个长远有价值、令人尊敬的，大家也乐于在此工作的公司，我们必须解决好这个问题，回答好这个问题，需要确保我们提供的服务，自己是自豪的，我们是有信心推荐给家人、朋友使用的。（这个判断标准）对各行各业也是如此，而且对我们这个行业尤其如此。因为我们提供的不再是一个简单的信息服务，而是实际接触到他们生活方方面面的服务、各种吃喝玩乐，所以回答这个问题的答案就尤其的重要。我们目前最大的业务是到店餐饮，这个巨大的市场还处在初期，几乎可以非常清楚地看到一个大潮即将到来，这个行业将会有巨大变化。在过去一年里，手机买单是往前迈了一步，部分的形成闭环，部分的改进了体验。\n2.少谈一点颠覆，多谈一点创新 互联网在中国发展了十几年，已经到达了一个阶段。我想大胆地做一个判断：**纯互联网创业的黄金时代已经过去，“互联网+”这个更大的机会正在到来。**互联网依然会对人们的生活产生广泛剧烈的影响，但它提供的将是“互联网+各个行业”的服务模式。\n要做好这一点的话，我们要少谈一点颠覆，多谈一点创新。如果要谈颠覆的话，最需要担心的是我们自己会不会被一个更新的模式颠覆。我们应该多谈一点创新，创新的最终目标是创造价值，降低行业运作成本，提高行业运作效率，提升用户体验。\n2016年，我们要开始构建开放合作的能力。\n最后，如果大家只能记住我今天谈到的一个事情，我希望大家记住的是：判断我们的服务是否足够好的标准是，我们是否愿意、放心地把它推荐给我们的家人。\n3.中国互联网已经进入“下半场” 整个中国的互联网也是刚刚进入“下半场”。之前中国互联网的发展，在很大程度上靠的是人口红利。但是现在这个时代已经过去了，智能手机的年销量已经不增长了，总体网民的增长也大幅趋缓。\n这个时候两条路：开拓海外市场、精耕细作。对于整个中国互联网的发展而言，需要增长模式的转变，接下来考验的是大家的真功夫。往后看，“互联网＋”要做的是各个行业从上游到下游的产业互联网化，不是仅仅停留在最末端做营销、做交易那一小段，而是真正能够用互联网、用IT全面提升整个行业的效率。我之前说过“少谈一些颠覆，多谈一些创新”，我认为整天讲“颠覆”是没有意义的，“互联网＋”根本上还是要靠创新服务于各行各业，靠互联网、靠IT技术为各行各业的各个环节提升体验、提高效率、降低成本。\n如果以此为目标，那“互联网＋”需要的能力和之前就不太一样了。之前我们的发展基本还是“上半场模式”，就是猛抓用户、猛接商户，然后做“营销交易”这比较薄的一层。现在进入“下半场”的时候，就需要新的能力，之前我们并没有太多的积累，只能说有一些探索。但总体看，这种积累是有限的，目前我们还没有很完整的深入行业的能力，当然这对我们是巨大的挑战。\n与此同时，我们也要看到，这对我们而言也是机遇，因为绝大部分互联网公司目前也没有这个能力，尤其是一些互联网巨头，他们也没有这方面的能力，甚至某些巨头由于历史原因，更难具备这样的能力，这对我们而言是个好事情。\n07 ToB，供给侧 王慧文：我对宏观经济和产业的判断\n时间：2017年2月\n背景：互联网红利殆尽\n下半场是几个层面，一个是我们美团点评这家公司要进入下半场，一个是互联网和移动互联网这个行业我们认为要进入下半场，一个是中国的产业、中国的经济要进入下半场，全球的经济和政治，我们认为也要进入下半场。\n1.宏观经济背景对企业精细化经营的要求 我举一个例子，你们就知道宏观有多重要了。 大家知道人在这个地球上已经生存了很多年了，但是在人的生存环境里面有很多东西是非常根本性的东西，只不过在地球上这么多年没怎么变，所以，大家不觉得。比如说空气，比如说水，还有一个比较重要的就是温度。\n人生存对温度有多敏感呢？就是人的大脑，温度上限是42度，如果人的大脑的温度超过42度，人的大脑里面的用来思考记忆的那一部分蛋白质就发生化学反应了。一旦发生化学反应，就永远不可逆，就变成了一个没有生命力的固态物体，就变成痴呆。\n现在很少人看到这种情况，要年纪稍微大一点的人，可能有人说这个人发烧烧痴呆了，发烧烧痴呆了就是大脑超过42度以后，那部分蛋白质发生化学反应。所以，这是人大脑的温度上限。人心脏的对温度也比较敏感，人心脏的温度下限据我了解应该是35度，心脏如果低于35度，就停了，就不泵血了。\n所以，人生存的那个温度带其实非常窄，那这个窄的温度带在整个宇宙里面大概是一个什么水平呢？就是地球离太阳的距离如果变近1%，如果变远了1%，1%就超出那个温度带了，人就没了，整个人类社会就没了。\n宏观一小点点的波动，其实对于微观，对于我们每个生存的实体，我们的人类，我们的企业都是致命的打击，致命的伤害，所以我们这家企业是极度关注宏观的一家企业。\n2013年的时候，当时有两个概念非常火，一个是O2O，一个是互联网思维。这两个词都火的一塌糊涂，非常巧的是，我在那个时间点去美国搜索O2O和互联网思维的相关资料，发现一个让我非常震惊的事情，这两个词都是中国人造出来的。\n中国人创新能力还挺强，中国人创新的事，中国人不知道自己在创新。美国人真正知道O2O这个词，是怎么知道的呢？是李彦宏说他要花200亿进入O2O这个市场，然后美国资本市场就问，什么是O2O，怎么出现一个O2O的东西，李彦宏要花200亿？美国人完全蒙了：突然出来一个叫O2O的东西，然后一个市值五六百亿美金的公司说要花一半的资金干这个事情，这到底是一个什么事情。\n所以，当时李彦宏花了大量的时间跟他们解释什么是O2O。所以，我们在国内搞了很长时间的O2O，真正把O2O出口到美国的主要就是Robin（李彦宏）。\n所以O2O这个词是中国传播到美国去的，是中国人在教育美国人。我们在世界科技领域的创新里面第一次领先全世界了。回来观察中国的情况。我发现了一个让我非常震惊的事情，O2O这个词不仅是在互联网圈内，投资界、媒体火，而且出现了一个新现象，在传统行业非常火。而且在传统行业比互联网科技和媒体圈还火，这是中国互联网上的第一次。\n中国互联网历史上所有的新概念，新名词的传播规律都是什么？都是投资圈、媒体圈和互联网圈、创业圈先火，火完了之后，然后才是传统行业有选择的跟进。也就是这个传播过去一直是这样一个路径，但是在O2O这个词火的时候，路径反过来了，传统行业这帮人比我们还热衷。\n而且很有意思的是在O2O之前，我去参加所有的互联网会议，很少见到传统行业的人来参加。即便来参加，他们也说是来学习的。O2O这个词火了之后，发现很多传统行业的人来参加，而且他们也在大谈O2O。而且很有意思的是，我们说到底什么是O2O，他给我解释半天，发现两个人说得还不太一样。\n这就是2012年、2013年发生在中国一个非常奇葩的事情。那么到底是什么导致O2O这个词在中国这么火呢？在中国传统行业这么火呢？其实原因非常简单，2012年发生的事情，2012年中国的自有服装品牌都出现了大规模的整个全行业的库存积压。服装行业的库存积压是非常恐怖的，基本上出不了就倒闭。\n那服装行业为什么在2012年出现库存积压呢？中国的服装品牌基本上都是在90年代成立的，在过去的这些年，他们活的太滋润了，他们活的方法太简单了。\n服装企业基本上就做几件事这个公司就能成，第一，在央视打广告。第二，扩张发展开店。\n但是变化出现了。第一，新一代的90后成为消费主体的时候，他们的个人追求跟我们这一代，不是不一样，是走到了完全相反的方向。第二，消费者的注意力从电视里走出，玩游戏，在网上看小说，在网上看视频。传播消费者消费的注意力的平台发生了变化。\n2.很多你们想象不到的公司会死掉 而现在2012年之后，互联网公司终于可以在A股上市了。\n比如说暴风影音，某企业，全都鸡犬升天，估值高的一塌糊涂。我当时就问了投行的人，我说怎么出现这种情况，估值怎么这么高呢？投行的人给了我一个答复，我认为这个答案是非常深刻的。他说你觉得估值高对不对？那我问你一个问题，你去看一下传统企业他们的增长评估。\n比如说你看美国，某著名连锁餐饮品牌的增长率是多少你知道吗？\n2%。\n资本市场有非常多的钱，但是传统行业又不涨。**钱没有地方可去的时候，就是有个人跟他讲一个可能性，他都愿意去掏钱。**因为传统行业是没有可能性了，是注定死亡，所以钱就不会去了。\n钱可投资的标的变少了，比如说，欧洲多个经济体出现了负利率。整个互联网在A股被炒上天了。某企业的老板跟我说他完全没有想到他能上市，他感觉这家公司都快倒闭了，他在A股上市是700亿人民币，对应100亿美金。这是中国2012年、2013年发生的事情，整个中国传统经济走到2012年、2013年的时候，掉了一个非常深的坑。其实从那之后，会出现互联网的泡沫，在2014年、2015年出现了非常大的互联网泡沫，原因非常简单。\n就是当整个传统经济都不涨的时候，钱没有地方可去，所以他们就开始投互联网，大家不懂市场，网民、投资人都不懂互联网市场。因为钱没有地方可去，这时候看互联网公司都做得很好，就投资互联网。一开始在二级市场买股票，就在A股买股票。\n后来发现在A股买股票，股票没啥买，就不去A股买了，咱们去买没上市公司的股票。所以，他们组基金，人民币组基金买没上市公司的股票。没上市公司的股票过了一段价格也搞上去了，公司融资是天使ABCDE轮，然后一直往下，最后上市。\n所以，就会出现一个公司还什么都没有，刚起一个团队，估值就2亿美金了。光一个团队刚开始就2亿美金了。\n走到2015年到2016年，整个互联网和移动互联网出现了新的症状。\n第一，从互联网到移动互联网的转型基本完成了，智能手机用户量不怎么增加了。事实上整个移动互联网的体量就是几个数乘起来的，一是手机数，二是手机上的APP数，三是每个APP的使用时长，就这几个数乘出来的。所以最大的第一个数手机数没了。\n第二，我们观察到了一种非常可怕的现象，用户在手机上，过去一段时间里是不断地装APP，现在在不断地删APP。\n我们给非常牛逼的投资人做了非常广泛的调研，只有11个APP能稳定在留在消费者手机上。\n所以最近一段时间大家看风投都不投钱了，因为没有新兴公司出来能拿到钱。还有一个非常恐怖的，在互联网时代，因为它是浏览器模式使用网站，所以用浏览器打开一个网站的时候，是从一个网站跳转到另外一个网站的门槛是非常低的，很多时候你都不知道你跳到另外一个网站，随便一点链接就跳过去了，这是其一。\n其二，有搜索引擎这么奇葩的东西，可以把用户的流量分发到各个网站上去，但是到了移动互联网时代里面，你想从一个APP跳到另外一个APP，门槛是非常高的，大量的APP之间是不支持跳转的。因为不支持跳转，导致用户都被留在一个APP上去了，因为没有这种搜索引擎的分布式、去中心化的流量分发渠道，现在在移动互联网上的流量分发渠道，APP你要不下载怎么办？只有两个途径，一是买电子市场排名，二是买手机厂商预装。只有这两个选择，这两个渠道能推的量非常非常少，所以马太效应非常强。\n手机厂商业务不涨的时候就要赚钱，赚钱怎么赚呢？因为消费者买了手机，手机就那么贵，他赚钱的方式就是向预装和电子市场要做推广的人收费，而且每年涨得非常厉害。\n我们估测2017年预装费和电子市场费用会比2016年涨30%，这些要素加在一起，对移动互联网公司来说是非常恐怖的，第一，手机数不涨了，第二，消费者的卸载，第三，推广费用涨30%。所以整个中国移动互联网在2016年我认为就是一个分水岭，未来中国的移动互联网，明年移动互联网会非常惨烈，很多你们想象不到的公司会死掉。\n3.To B 企业发展是三个阶段，是市场驱动发展、领导力驱动发展和创新驱动发展。全球、中国的互联网的话，全球经济、中国经济和互联网经济都是同一个问题就是市场驱动的发展结束了。\n市场驱动的发展有另外一个词叫红利，全球经济体在过去这些年的红利就是全球化和科技。\n糟糕的是，从2012年到现在为止，这两个引擎熄火了，科技已经很久没有突破了，如果科技在未来的十年里没有突破，未来的二十年就一定会有战争。\nPeter Thiel在二零零几年的时候就说到我们的科技很久没有突破了，我们要出问题了。\n中国经济在过去一段时间市场红利第一是人口红利，第二是房地产，第三是消费。糟糕的是，这三个驱动力都没了，因为我们的房地产老涨，出口的红利没了，人口红利没了，我们现在人口老龄化非常严重，人口红利没了。我们的劳动力在飞快地减少。\n互联网也是一样，过去这些年，全都靠网民增长，靠CPU速度变快，互联网的第一大红利是网民增长，第二大增长是摩尔定律，现在网民增长到头了，所以市场红利全都结束了，红利期结束。\n在面临这些问题的时候，如果按照企业发展三段论的话，应该从市场驱动切换到领导力驱动和创新驱动。\n如果看领导力驱动和创新驱动这两个解药的话，这两个方案里面，欧洲都已经用过了，欧洲他们已经非常发达了，创新也没了，所以欧洲是无解了。美国还有几年，因为美国没有把它自己的牌拿过来，所以美国应该问题不太大，欧洲注定要完蛋了，你们如果心怀梦想打算去欧洲旅游的话尽早去，晚了可能去了就有生命安全问题了。现在就已经有了，巴黎已经是一个很危险的城市了。\n供给侧改革。整个产业都是两部分，一部分是需求侧，一部分是供给侧，需求侧就是消费者和市场，供给侧就是企业和供应商，就是商家。做哪些变化呢？效率提升，成本降低，创新业务，提升用户体验。我在2013年的时候做了一个事，美国科技界或者互联网圈的资本市场、科技业和互联网信息产业，美国的上市公司，我把它拉了一个名单，中国也拉一个名单，事实上中国从总体上来说发展是跟着美国走的，因为美国可能很多创新技术先到了，所以我当时看说有哪些产业在美国已经产生了很牛逼的公司在中国还没被真正做起来，而且这个产业将来如果时机具备的话也会在中国是很牛逼的公司。\n这个方法论非常简单，我就把美国拉一个名单，把中国拉一个名单，来对比，我这个对比完了之后发现一个让我非常震惊的事，美国的互联网公司，很牛逼的比如Facebook、Google、亚马逊，都是非常牛逼的，但是美国上市的科技公司里还有另外一派，也非常牛逼，只不过是这一派没有像互联网公司这种曝光多，名气大。\n但是这一派其实都很挣钱，比如说Salesforce，他们基本占据科技业的另外一半，在科技业的一半是toC的公司，他们占了一半的市值，在2012、2013年的时候，to B的这些公司占了另外一半市值，比如说Oracle，他们占了另外一半市值。所以其实还有很多很牛逼的公司，但是我们把这个来看中国的话发现中国to C的公司都很牛逼，最大的是阿里，然后是腾讯、百度，to B的公司居然找不到，就是说有活着的，但是活得很惨。\n所以我就很纳闷，为什么中国这些to B的企业活这么惨呢？我就找了一些我认为比较有真知灼见的人交流，其中有一个人还是比较牛逼的，给了我一个答案，我认为这个答案是比较真实的，他说你看这是美国的toB科技企业做出来的，都是给企业或者给商家提供解决方案的。\n我刚才说的Salesforce是销售团队管理解决方案，Workday是HR解决方案，都是给企业和商家提供解决方案的。为什么这些提供解决方案的公司在美国活得很好，在中国活得不好呢？原因非常简单，就是美国这个国家商业周期非常长，因为商业周期长，所以任何一个企业所有能用来竞争和发展的东西基本上都用光了，他们的发展出现瓶颈了，当他们出现瓶颈的时候就开始搞内部提高效率，降低成本，创新服务。而他们要搞内部提高效率、降低成本、创新服务的时候，他们没有这些技术支持做不了，所以说白了就是美国的企业在过去这些年率先遇到了市场红利枯竭的状态，因为遇到市场红利枯竭，它就要寻求自己的效率成本和创新，它要寻求自身的效率成本和创新的时候就对各种新式的能提高效率降低成本的各种工具开始产生兴趣。\n而过去中国这些年是什么情况呢？傻逼经营一个企业都能赚钱，这么说好像我们比傻逼还不如，我们还亏钱呢，我们是战略性亏损。中国过去这些年实在是赚钱太容易了，大部分人存在的问题是不具备可能知道这个事情很容易赚钱的认知或者不具备进入这个行业的资本，其实中国过去很多行业是极其赚钱的，非常多。\n过去这些年整个中国市场、中国企业的发展特别容易，靠市场红利驱动就能发展，就能赚钱，所以他们对于新工具、新方法的采用意愿特别特别低。\n走到今天，我认为这个事情发生变化了，所有的企业，所有的商家的经营因为遇到障碍了，所以当它的销售额不涨、利润不涨。\n最近一段时间里面，我的判断是下一波中国互联网如果想回暖的话，一个非常重要的方向是供应链和to B行业的创新，是他们驱动的。供给侧如果要做改革的话，可能有哪些变化。\n08 上市前夕 王兴：上天、入地、全球化\n时间：2017年4月\n背景：第二年，美团上市\n三个大方向是最激动人心的，上天、入地、全球化。 1.上天：从商业模式创新到科技创新 二十年前，互联网本身就是高科技，但到今天，多数互联网企业只是传统科技。不管是20多年互联网的发展，还是更长时间接近50年的信息和通信技术的发展，底层都是有它的原理的，这是摩尔定律，65年因特尔创始人之一摩尔提出来，大概半导体的密度，平均每18个月或者24个月翻一番。\n摩尔定律在传统意义上已经到一个相对的固定临界，将来的全球增长的要素，可能是不同的方式，现在总的芯片数量越来越多，因为全世界的能力不外乎整个芯片的计算能力，要看是不是芯片数量的增长，这个有点抽象，在底层跟我们的所有事情都相关。\n每一个人需要很多的芯片，手机、电脑，但是车更多，一辆车近百个芯片，所以会有越来越多的数据，越来越多的计算和需求。\n这里还只是高科技的一部分，我经常跟朋友交流，有一些朋友说，每次去硅谷回来，就觉得我们干的事情很low。\n高科技方面创业，中国会有越来越多的空间，有越来越多的需求，这个创业不太一样，这不再是一个学生在车库里，或者在宿舍里捣鼓几天，就能做出翻天覆地的事情，他可能需要很多底层的积累，还有很大的投入，这个也需要耐心。\n中国互联网有很大的成功，但更多人认为是商业模式的创新，而不是科技的创新，这个在过去是对的，因为中国总体是落后的，现在发展到这个阶段，甚至可能会超越美国，往后可能确实在底层上有很多投入，有很多AI专家说，AI方面国内并不落后，但是还有更多领域是需要更长时间投入的，因为我们说，摩尔定律以外，我们总体人才是在增加，这是需要国家投入的支持。\n高科技是未来五到十年一个很大的驱动力，但是并不是单做，就像互联网跟各行各业结合在一起。 2.人造肉 或者另一个例子高科技，因为美团是做吃的事情，2017年春节的时候，我看过一家公司，是不可能的食物，是一个教授创始的，当了26年的生物化学教授，他认为人们都喜欢吃肉，我们为了吃肉，需要草，去喂牛羊，他觉得这个效率很低，浪费是很严重的，他觉得应该用科技，把直接的食物蛋白变成动物蛋白，跳过饲养动物这个环节，他做出来了，他现场推出来一个，用他们做出来的肉吃了一下，很好吃，在美国六七家餐厅集中用他们的人造肉的汉堡很好吃。\n这个是一个完全颠覆性的事情，因为牛羊不会进化的，几万年来，牛肉吃草产生肉的速度基本固定的，进化很慢，而这家公司用高科技的技术去突破的话，就是革命性的事情，瞬间他会颠覆饲养牛肉的方面，也是更健康的肉，之前养牛羊，有抗生素，有什么添加剂，他们在实验室里会控制更精确，所以这是跟吃相关的，看起来是最基础的事情，但是有可能是很高科技的突破，当然中国作为最大的农业产品消耗国，我们知道我们在这方面的技术，我觉得这个是很值得关注的。 3.入地：不只是C端，要深入B端和产业链 创业需要接地气，所谓接地气不光是你触及地下，而是要到达充分养分的地底下去。现在如果你还在C端联系是不够的，这是一个无奈，也是一个现实。\n现在共享单车非常火爆，我觉得回头看，摩拜我相信他们是正确的。真正好的事情，根据客户需求，根据新的场景和模式，你的车从体验上，成本上（来看），我认为创造这样的人，不光需要接地气，还是要陆地。\n以美团为例，餐饮行业大众点评2003年做最早的第三方餐厅评价，美团2011年做团购，2013年做外卖，我们做C端，我们不能停留在连接上，所以在餐饮的B端，服务的各行各业的B端，我们已经做了很多投入，包括餐饮的压力系统，收银系统，也包括酒店里面的系统，在B端，他的PMS，客房管理。\n4.全球化：中美两强竞争，发展中国家机会广阔 全球互联网在下半场，我认为是中美的竞争，因为互联网最早是美国发明的，二十年后，只有中美两国出了互联网公司，我们看到腾讯非常厉害，已经是光靠中国一个市场，就做到前段时间全球十大。\n但这是不够的，真的放开来看的话，企业的价值取决于问题价值大小，取决于市场大小，取决于经济体的大小，中国虽然经济体越来越发达，但我们是全世界六分之一的人，如果只做这个事情，做到头，你也是不如另一部分大，因为美国的强大在于，美国互联网公司不光做美国市场，他做几乎全球的市场，除了中国市场以外，所以如果中国的企业不能真的很好的走出去，不能更好的服务更大的经济体的话，长期来看是缺乏竞争力的，因为我们回到上天这个事情，高科技是需要高投入的，如果你没有足够大的市场和规模，你就无法有足够大的投入去竞争，长期来看你是没有竞争力的。\n对比来看，全球化是中国企业很大的机会，也是中国未来必须要做的事情。\n另一方面我觉得有机会的是，虽然在高科技领域，美国比中国强，但是在很多商业模式方面，尤其创新方面，中国已经做出了很多的努力，已经在很多地方领先。\n往海外做，我觉得简单来看是往上做还是往下做，底是人均经济比重更发达的，还是经济比重更落后的，我觉得在座的中国行业都可以尝试，我们可能更大的机会是在于第三世界国家，发展中国家，跟中国比较类似的国家，或者比中国落后的国家，我们知道那里发生了什么事情，在什么阶段，我们在那个地方更好落地这个事。\n日本的扩展海外，有日本的银行，日本的媒体，日本的企业，他们一起去做，我觉得中国互联网企业也应该如此，因为不可能一个人做出去了，有做分发的，有做电商的，有做金融的，有做O2O的，一起的话会有更强的战斗力，这里我认为是非常好的一个机会，中国现在GDP增速不是那么快，你看印度，东南亚，他们市场也不小，东南亚有六亿人，有中国的一半，这里面他们基础设施比我们落后一点，但也在蓬勃发展，我2016年去了各国看了一下，一个很大的感触，中国大量的人才，很多国家的人才是不够的，他们计算能力是不够的，我觉得这是我看到的互联网下半场最激动的三条，上天、入地、全球化。\n","description":"","id":2,"section":"zh","tags":["美团百科","科技","零售","王兴","王慧文","零售","O2O","电子商务"],"title":"美团演讲","uri":"https://hugo.jiahongw.com/en/zh/talks/%E7%BE%8E%E5%9B%A2%E5%86%85%E9%83%A8%E6%BC%94%E8%AE%B2/"},{"content":"今天重点讲验证和开拓市场，后续还有获得良好的市场地位、建立商业模式两个环节，今天时间受限讲不了了。\n一、从市场定义开始 从市场定义开始：\n一个市场一定是满足了某类人或组织的某种需求\n动态：需求本质可能没有变，但是满足需求的方式会经常变 模糊：某个市场往往会随时间推移被分解或者融合，市场定义是有〝保质期”的 如何有效定义市场：关键是需求的颗粒度和精准度\n颗粒度：出行\u0026gt;乘车出行\u0026gt;乘用车\u0026gt;新能源车\u0026gt;40万的新能源大中型SUV 精精准度：twitter vs blog 淮确计算TAM (Total Addressable Market)\n做一个新的业务、新的产品，一般来说都是从一个市场开始。虽然很多人说更早期的创新、创业从一个idea开始，但是那是太基础的门槛了，你真正动手做的时候还是从一个市场开始。Twitter（现在的“X”）之前创始人是Jack Dorsey，他在8~10岁的时候住在纽约很繁华的公寓里面，每天就能听到非常多热闹的声音，救护车、警车等等，当时他的idea就是把自己听到的、看到的以及想法分享给全世界。但是这只是一个想法，他那个时候太小了，做不了任何东西，所以这个想法一直在他脑袋里。等到他读大学了之后，他有了编程能力，所以写了一个Twitter的原始版本，允许任何人发email给一个指定邮箱，他就会把这个内容post出来。当时还没有移动互联网的基础设施，因此这个idea没有变成一个有效的产品，也谈不上市场这一说，没有流行起来。后来iPhone出来了，很多人就开始做第一代应用。当时流行做LBS，每个人可以随时发东西。Twitter这个产品是在有这个idea十几年之后，碰到合适场合变成了产品，开创了一个“社交媒体”的市场，自己也成为了社交媒体的参与者。我想说的是，一个idea并不能真正的创业的开始，idea更像是一个种子，需要合适的土壤才能长成一棵树。真正要动手做，还是要从idea再想一步，到底在做什么市场，在满足什么需求。一个市场怎么定义，一定是满足了某一类人、某一类组织的某一种需求。组织也重要，因为有2B的收入，微软从来都是2B的公司，虽然大家每天在用各种微软的产品，但是个人很少付费，主要是电脑公司和组织在付费。\n这里有两个特别容易搞混的地方，或者是特别重要的特点。一个是动态性，需求本质上可能是没有变的，但是满足需求的方式会变。\n比如拍照，手机之前是数码相机，数码相机之前是胶卷相机，胶卷相机之前是专业的镁光灯的相机。如果拍摄像机是一个市场，这个市场的规模在过去100年大了无数倍。iPhone在2021年公布了一个数据，全球的iPhone用户拍了3万亿照片。这还只是iPhone，简单来看全球用智能手机应该拍了十几万亿照片，这在胶卷时代是不可想象的，要不然柯达、富士早就发财了。所以需求没有变，满足需求的方式变了，市场就变了，围绕市场的上下游就会发生很多变化。如果智能手机没有变化，就不会出现很多修图软件，也不会出现ins。所以市场不是固定的，是动态的，会经常变化。\n科创A有一个叫沙特阿美的公司，是全球最大的石油公司，上市的时候是2万亿，全球市值第一名。但是石油公司在19世纪末遇到了很大的危机，内燃机没有发明的时候（奔驰在20世纪初才发明了内燃机），石油到底要用来干什么？当时石油主要用来炼煤油，煤油用来点灯，但是当时爱迪生的电灯已经发明出来了，所以石油公司非常危险。后来好在汽车产业起来了，石油公司发财了，但是发财并不是因为自己牛逼，而是因为内燃机发明了。燃料用来干啥，取决于下游用来干啥。\n大家的课本告诉大家爱迪生发明了点电灯，但是这种说法其实不太严谨，在爱迪生发明以前，有据可查的白炽灯发明者至少有十几位。但是为什么爱迪生要执着地发明电灯吗？真实情况是他之前发明了发电机，但是不知道这个电用来干啥。你回到19世纪末，用来干嘛呢？就像有大模型，没有应用，Killer App是什么？就是点灯啊！电用来照明，替代煤油灯，当时有钱人是用鲸鱼炼出的油来点灯，没有油烟，后来在那几十年鲸鱼都快灭绝了。因此爱迪生真正商用的小型电网是部署在JP Morgan他们家，他们家很大，而且是爱迪生的投资人，创立的公司是赫赫有名的GE。所谓通用电气，就是跟电有关的都干，跟今天字节说和互联网有关的都干是一样的。\n所以市场会动态变化，但是需求从来没变过。吃跑肚子的需求没变，但是从自己做饭到下馆子，到点外卖，到吃预制菜，满足的方式会变，每次变化都会诞生新的市场。\n第二是模糊性，很多市场会随着技术条件和市场的变化会融合，市场定义是有保质期的。我们讲一个市场被解构了，被替代了，被融合了都很正常。不是柯达不努力，而是大家不需要胶卷了。每一个地方差一点点可能会差很多的，所以千万别觉得你的市场是固定的，你拥有一个市场，这个市场的钱就该你赚。如果你满足需求的过程的效率不行，或者别的手段满足更好，你的市场就会崩塌。最典型的就是中国线下的超市，中国的超市基本都是90年代开始发展的，沃尔玛进中国。民营超市是2000年左右，大润发台湾人黄明端开的，永辉两位兄弟从福建卖菜开始起家。物美创始人张文忠本来是写超市系统的软件工程师，想卖给超市。但是超市不买单，他一气之下自己开了一个超市，想做个Demo，结果发现开超市比写软件赚钱多了，歪打正着做起来了。望京有一个做内衣的叫爱慕，老板原来是研究合金的，发明了一种记忆金属，找不到可以干啥。后来去国外考察的时候发现了这个合金可以用来做大家都懂的东西，所以回来做了内衣。但是大润发现在市值只有100多亿了，高峰期有1000亿，原因是市场被解构了。之前6000坪以上的大商超，每一层有分工，一层金银珠宝化妆品、二层日用品、三层生鲜、四层家具用品和音像制品，是模仿美国的超市。但是后来中国电商发展起来了，便利店各种东西冲击，导致大商超慢销品不好卖，只剩下了生鲜和快消品。市场被解构以后，只留下了最差的市场，当然就生存不下去了。\n所以很多时候，我发现我们的产品经理和业务同学，很容易把市场定义搞得不是很清楚，第一步就搞错了，在这个上面花很多时间。\n怎么有效定义市场呢，首先要非常理解这个需求，需求中间有很多深的东西，跟直观体验和逻辑的东西搞清楚。**两个关键容易出问题的地方，一个是颗粒度。**有的时候市场定义的颗粒度太粗也不行，之前有的团队17~18年的时候去做无人货架，当时是很简单粗暴的，真正的敞开式的无人货架，放个二维码在旁边，然后告诉我是万亿市场。宝洁、联合利华、伊利在中国卖多少亿？消费品在中国做到百亿是很牛逼的，在脑子里没有这个概念。新能源三宝，为什么都要做大车呢？因为他要把自己市场定位的颗粒度放在非常合适的位置，这是聪明的做法。出行是需求，出行也有很多解决办法，可以打车、开车、蹭同事的车、市政交通，理想做的是40万增程式大中型的车，目标市场是卖给计划有2个娃的人，为什么理想毛利比较高呢？因为这是中国最有购买力的一批人。大家不要以为高档车是毛利高的，很多高档车都是公司买的，用来抵税的，正经人谁花自己钱买个劳斯莱斯呢。这是一个颗粒度的问题，市场的颗粒度要定义准确一些，越是竞争激烈的市场越是要定义准确。\n另外就是精准度，就是刚才我说的Twitter的例子。大家知道blog是什么？为什么微博能火，博客火不了？当时有一个博客女王徐静蕾，当然现在有公众号，是另外一种博客，和当年还不太一样。当然你也可以认为朋友圈是另外一种微博，但是这两个不是一个量级，朋友圈至少大十倍。为什么流行度差这么多？微博是博客的功能子集，当时他们做了一个新浪朋友，当时抄袭了人人网，但是在上线的时候管理层来开会，说这个玩意我们可能搞不好，说要砍掉。所以当时心情很差，说要不然SNS做不了，所以保留了里面最简单的功能，然后把别的功能都砍掉，就是发feed的功能，就是新浪微博的雏形。写博客的门槛太高了，高考作文都只用写800字，当然我们公司的文档能力都行。而且文档写多了，不一定有人看的。所以文笔比较好的博客女王，还要配很好看的图片，多数人根本到不了这个水平。川普抢个冰激凌都要发Twitter，Twitter的创造成本是极其低的。所以兴哥后来也做了饭否，饭否到被拔网线都没有发图片的功能。有的时候你把标准拉得足够低，防止那些装逼犯出现，就可以达到很好的效果。都是自我表达，但是Twitter是面向普通人，普通人没有太好的才华和文笔。所以大家羡慕董宇辉，他说出了一辈子说不出来的排比句，普通人也就只能说“今天的羊肉串真好吃”，这是真正的普通人的需求。博客主要两种人，一个是博客型产品经理，天天分析各种趋势；另一个是研发，喜欢贴源代码，这两种人都比较无聊，所以流行不起来。后来有一个产品是轻博客，上面最后沦为大量的情色内容，只有那种内容吸引人，是另一种方式生存下来了，所以国内也上不了。\n最下面是你们擅长的，怎么计算TAM。这个很重要，对大多数人来讲都是容易算高的，尤其是各种新项目各种千亿、百亿，最后发现几千万都搞不到。不要动不动把中国14亿人口都当做你的用户，Top-down通常是天花板线，但是正经都是你能掌握的资源出发的细分市场。做汽车如果有人说每年2,000万车都是我的市场，那趁早把股票卖了，最后要精准到每年100~250万车里面占多少，这才是正经做业务。TAM不要把所有的都加起来，比亚迪的市场不是你的市场，你的市场可能就是40万。\n二、设计你的PMF PMF：Product Market Fit\n用产品创造新市场 用更好/更便宜的产品潢足老市场 用更适配的产品满足老市场中的细分 理解PMF和STP(Segmenting、Targeting.Positioning）的关系\n一句话讲清楚PMF：为xxx客户，提供xxx的产品/服务\nPMF和STP不是一码事，这是一个很好的理念，但关键问题是没有很好的定义。每次产品没做成，都说没有PMF，感觉是一个万能钥匙。今天讲市场定义，如果把市场搞清楚了，PMF才能搞清楚。如果市场定义没搞清楚，可能不是产品的问题，而是市场的问题。你想用博客去抢微博的市场，这是没有意义的，因为不是一类人，也不是一类需求。基本概念大家都理解，P是产品经理，M是商分，怎么匹配起来。\nPMF怎么设计其实比较复杂，我讲几个基本的原则，或者几种方式。\n第一种方式是用产品创造一个新的市场，比如用数码相机替代胶卷相机，数码相机无限拍，胶卷相机只有36片，这两个就完全不一样。\n第二种方式是用更好的、更便宜的，更好VNOS产品去满足老市场。拼多多打败淘宝就一个词，便宜。拼多多最开始创造了一个下沉市场，然后发现真香，白领也用起来了，我们也不想被阿里和京东收税。比如克里斯坦森讲的颠覆式创新，是用低端颠覆高端，俗称“内卷”。\n第三种方式是细分市场，刚才我们讲市场很模糊，很多东西你觉得满足的也不错，但是有一些特殊的场景，或者说是niche market，产品还是可以填进去的。我前东家百度做了一个东西叫“闺蜜机”，比电视小、比iPad大，等移动、能旋转的大Pad，这个产品洞察很牛逼。现在电视机在中国贼便宜，买个80寸的红米才4,000块钱。比iPad大，下面还有导轨，还能移动还能转。当时我看这东西能卖掉？结果卖的得很好。这东西直男能理解吗？其实就是一个屏幕带个架子，卖4,000块，还不便宜。雷总看到可能很生气。这种东西还有很多，这是一个市场细分的案例。如果市场确定了，那还是要用STP理论去细分、去定位。但如果是全新的市场，还是要用产品来开拓这个市场。\n怎么用PMF，其实就一句话，为谁，提供什么产品或者服务，可以加很多定语。我先拿美团买药举例子，现在美团买药是中国正经药品订单的第一名，三年就做到，当然我们有很好的的外卖配送基础。但是怎么能涨的更快呢？后来我们就想我们的市场是什么？我们到底提供什么产品？仔细一分析，发现这个原因说出来也很简单，因为我们的供给都是线下的药店，线下药店的TAM大概是7,000-8,000亿，但问题是有一半是刷医保的老头老太太，我们还不支持医保，这部分打掉就只有4,000亿了；还有1/3是保健品和中成药，这再打掉我们的渗透率其实很高的。所以美团买药到底提供什么PMF呢？套用一下公式。美团买药是为中青年提供自费、应急的购药（及成人用品）服务，我们这里基本没有老头老太太，人家有的是时间，拿着医保卡去医院去药店都可以。所以我们的重点是自费，前两年都是应急的，基本没人在我们这里买保健品。\n这就是我们的PMF，有什么用呢？首先你知道自己在干啥了，比飞轮简单多了，飞轮太复杂了。那么如果我要扩大PMF，就要改变PMF。能不能把自费改成公费呢？所以我们在青岛、上海，开始部分接入医保了，一下子量就起来了。能不能不是应急呢？所以我们做了快递电商，我们还做了自营，现在也占20%了。你要买那些慢性药，高血压、高血脂的，我们天津发货明天也能到。我们拓展了我们的服务，不仅仅是应急，便宜也行。这些东西搞定了之后，我们发现也不仅仅是中青年了，至少中青年可以给爸妈买药，老年人谁没有三高呢？甚至也可以卖保健品啊，场景也多起来了，所以TAM要重新算一下。\n一些现场交互：\n风控策略产品：为到家的产品提供紧急及日常的风险控制解决方案。好，这里可以加很多定语。到家要拓展了，你做境外吗？B2C做吗（主要还是做外卖）？管不管霸王餐（对，我就是管霸王餐的）？所以你的精准定位是，为霸王餐的商业增值产品部提供风险控制解决方案。所以想升职怎么办，需要扩大你的PMF（笑）。\n某境外产品：为不太懂互联网操作的白领商家提供外卖门店的线上运营服务。挺好的，挺准确的。不要讲复杂的理论，所有复杂的理论背后抽象出来就一两句话，发明并简化。\n这个工具门槛很低，但是做好很难，大家要反复打磨这句话。\n三、产品与营销 TAM + Marketing\n乔布斯也谈过这个问题，因为我们要花很多钱嘛。刚才我们讲了TAM，就是市场有多大。你能吃到多大的饼取决于产品定位，但是目标市场不一定都能吃到。Marketing很重要，决定了你多快能吃到，这也很重要，毕竟有竞争。Marketing是助燃剂、加速剂，但不是决定性要素。但很多时候，为什么市场营销没有效果，不是因为营销没做好，而是产品没做好。很多时候产品PMF没问题，可能确实是助燃剂不够，这个是要思考的问题。\n今天时间不够了，本来有很多案例，但是因为问题比较多，我们还是下次再讲罢。\n四、供给、流量和履约 再附赠两个吧，刚才讲了怎么定义市场和PMF，现在讲一下和我们公司相关的事情，和我们未来5~10年要做的事情有关。美团这个公司的主体业务到底是干什么的？按兴哥的定义，通俗来讲，美团就是一个买产品、买服务的地方。我们抽象一下，过去做了什么，未来要做什么，我简单展开一下思考。我们2015年左右，提出了一个简单的模型——外卖三要素，为了管理大规模团队。一个是流量、一个是供给、一个是履约，基本适用于所有交易平台，其实是一个亚马逊飞轮的精炼版。我们当时招了很多乌泱泱的人，在搭建销售体系。映射到所有交易平台，我们到店业务是到店履约，去淘宝、拼多多是快递履约，履约是实现产品和服务消费的过程，因为购买不等于马上消费了，不核销就没有消费，付钱归付钱嘛。\n我们先把履约撇开不管，我们先看中国主要的电商平台是怎么做供给和流量的，供给和流量是怎么组织的。不同的平台的供给有差异，为什么手机到京东买？其实闪购也能买，又快又好？因为用户觉得京东是正品、发货快、售后好。为什么有这个心智？因为京东号称是自营，当然也和履约有关系，但是现在你去天猫发顺丰也一样，本质上没区别。\n从电商发展逻辑来看，最早是eBay和亚马逊，一个是C2C一个是B2C，eBay可能在中国没有那么有影响力，更多还是个体卖家卖给个人用户。亚马逊做了Marketplace，把其他卖家引入了，其实和天猫一样，然后继续延伸到全球化的商家。在中国，最早淘宝和eBay一样，后来2009年做了淘宝商城，后来改名为天猫，因为卖便宜货不赚钱。因此天猫其实有点像亚马逊的感觉。但是这是C店和B店的区别吗？其实C店也有很多专业卖家，只是发生了一点分化，淘宝强调的是中小卖家，有买手店、海淘店、各种集合店；天猫是中大卖家，主要是品牌卖家。京东在同样的时间（2003~2004年）做了亚马逊自营业务，后来也做了POP，但是POP门店数是很少的，也就20~30万体量。京东有没有试过C2C呢？其实有拍拍，但是后来没做好关掉了。如果京东里面有拼多多的货，其实你也不敢买。这里就是一个维度的东西，就是卖家的大小。最大的卖家是自营，然后是品牌卖家，然后是中小卖家，最后是个体卖家。闲鱼就是纯个体，包括淘宝上有代购的，基本也是个体卖家。淘宝上还有有意思的店，比如卖陨石的卖动物标本的，其实都很小。卖家越大，越有组织、越有保障、越专业。\n这里有一个之前被忽略的，也是京东踩坑最大的地方。流量组织有两种基本的方式，最常见的方式是按店铺，做淘宝要经营几星几钻，做美团要经营四个九，商家按店铺经营是很合理的，越大的卖家越按店铺经营，因为店铺代表了一种品牌导向，一种品位。进入无印良品、进入NIKE、进入Burberry的风格是不一样的，有自己的装修风格、有产品组合和定价。这是过去电商主流的组织方式，如果按照这种方式阿里是最好的平台，有很多方法论，什么营销工具、用户经营、会员运营。但问题是，店铺运营所代表的品牌主张，是不是一种普适的需求？或者能不能代表全部的需求。举个例子，如果要购买山东某种品种的梨，一定要去某个店铺吗？要给小朋友买练习册，一定要去某个店铺吗？很多男生买体育用品，19.9包邮的袜子，什么店铺重要吗？便宜就行啊！这世界上有很多商品，是不需要品牌价值的，这恰恰是拼多多打开市场和销量的法宝，拼多多常年销售最高的品类就是卫生纸。\n这就是一个根本的问题了，到底货盘怎么组织。拼多多用了按商品的方式来组织，这样做有什么好处？这样做可以直奔你的需求，你并不care是哪个店铺卖的，反正包退。很多商品品牌不重要，物美价廉比较重要。首先，它很直接；其次，按商品的方式来组织特别容易产生爆品。9.9包邮的纸巾可以直接买爆，苹果丰产了各种比价也可以买爆，爆发力很强。大家要注意，短视频或者视频电商也有这两种模式。直播间更像一个店铺，尤其是IP的，董老师卖什么不重要，小杨哥还有各种，在哪儿买不是买，你奔着IP去的。但是还有一种是卖商品的，在特定的时候推出来，有诱惑力、表现力的产品需要用短视频的方式来推，但是拼多多把这种方式用到了极致。这种方式在线下也不罕见，有些超市只有1,000多个SKU，每个SKU的销量和同城市比都是10倍以上，因此单商品起来之后它就具备了某种结构上的优势，这就是毛利了。\n过去我们的组织方式，其实既有大品牌（肯德基、麦当劳），也有小店（黄焖鸡米饭、沙县小吃），这是一个良好的生态。既有有号召力的大品牌满足高消费的人群，也有便宜的，所以在供给这一层我们还好。但是我们过去很大的问题是我们的流量组织基本都是店铺模式，所以不容易爆发。所以到店为什么做特价团购，就是要搞起来，2.9的炸鸡腿、9.9的瑞幸等等。但是这里没有那么简单，这两种模式背后代表了非常不一样的运营理念，是把店铺做四个九，还是某个商品卖爆？拼好饭就是在小微领域的这个领域做大，一天500~600万单，小微型店卖爆品。这样做的好处是非常明显的，原来一个汉堡店可能有10~20个SKU，而拼好饭的新型供给只有5~6个SKU（炸鸡块、炸鸡腿、炸鸡腿堡、薯条、可乐，没了，可以再组合一下），省了1~2个操作员、1天出200单，这就是商品模式的魅力，能够把流量聚集在某个品上。可能这一家专供炸鸡腿，那一家专供卤肉饭，那一家专供牛肉汤，也就3个SKU，操作非常简单。item维度上商品的竞争更接近于消费者需求，更有利于供应链的优化。拼多多上面很多卷王出来，我专门做牛仔裤得了，优化到极限，还能赚钱。但是天猫的卷法只能卷出会做营销、会讲故事的玩家，但是现在是消费分层的时代，我没钱，不想听故事。\n所以回到美团来讲，本质上我们是要做所有的卖家。每年给美团付费的大中小店铺加起来有1,000多万，绝对体量是很大的。但是我们要做的是，在原有店铺模式上增加各种服务，要增加做爆品的能力，在供应链上能进行优化，或者在我们的设计上可以优化，可以催生更多有效率的商家。因此对整个公司来讲，商品能力很重要，要建立很多新的能力，包括推荐、搜索、排序、价格控制、促销等等，背后很多东西都不一样。服务型零售也一样，99.9捏头标准化，聚焦在某些商品上，长期训练后面的供应链，选择出最有性价比。性价比不是最低价，有人喜欢39.9的，也有人喜欢59.9，来满足这个时代消费分层的需求。现在给你弄几片菜叶子就卖你60块的沙拉是不是有点傻，这个钱都白花了。消费就是在不断变化的，我们要和所有商家都要不断思考，自己的PMF。比如日本核污染以后，很多日料店马上就说我们从来不用日本产品，实际上上个月还在说自己从日本进口，实际上是赚了很多不该赚的钱，时代浪潮下大家都要迭代。\n五、Q\u0026amp;A Q\u0026amp;A环节知识比较零散，不做逐字稿整理了，记录一些有意思的话题。\n万物到家未来3~5年：2万亿的盘子，中国最好的人群盘子。最后还是快的打败慢的，我相信分布式的仓会打败中心仓，是未来。\n创新更多的是从下向上的，是来源于生活的体验。比如极速达就是这样，大家都有开会开得很晚吃不到饭的需求，但是这个方案不是我提的，是一线的同学想出来的。所以大家多给我写PRFAQ。\n本地生活服务竞争：我们只能让产品和服务本身成为流量，让大家想到这个商品的时候首先想到我们，把流量运营好。\n外卖怎么增长：很无聊的还是很重要，重视用户体验。俞军说用户体验是两条河流，当你体验好的时候，你的河流就不断流入，对方的河流不断流出。用户切换一个网站只用几秒钟，越是没有门槛的东西越是需要心智的确定性。为什么我们要建配送，不是为了壁垒，起步的时候就是你不建配送，你的体验就没法保障。那个时代商户根本不会鸟你，这一单30分钟，下一单60分钟，不可控，谁知道呢？自己建立了配送，就能管理每一个骑手，知道每个骑手的轨迹。建配送就是为了体验。\n同样的，我还有另外一个思路，当你在竞争的时候，两个玩家的用户都是一个水池，都有入水口（新客）和出水口（流失）。当你体验好的时候，相当于你有一个抽水机，到别人的水池里把别人的水抽过来。一旦天气不好，用户一看美团30分钟，饿了么60分钟，这不自然就过来了吗？当你每天有几百万、几千万DAU的时候，这就不是一个小事情。如果你有1000万笔订单，你的瑕疵率是3%，对方是1%，那一天就伤害20万人，每天流过去2万人，你就输了。道理很简单，但是做起来很难。今天我和客户体验的团队开会，说万服下降多少，这是一个系统工程。每一个瑕疵的背后都是无数的能力，能想到在大冷天30分钟准时送到热腾腾的餐，这在10年前根本不可能，我现在说服大家出去转一圈都难，怎么让几百万人愿意出去，这是一个复杂系统的管理。\n新的机会点和增长点：其实有很多，内部也有讨论，整体不脱离这个框架，根本上提供高性价比、靠谱的产品和服务给消费者，只是how确实很难，因为体量已经很大了，1%的优化就是几十万的订单，确实是不容易。不过我认为我们比快递电商还是有好处，因为电商的品类比较多，增长方式是A品类不行做B，B不行做C，但是每一个品类都做不深。这个我们吸取了教训和经验，我们一定要把主要的品类都做深，帮助产业链提升效率，最后给消费者提供性价比高的产品。\n壁垒：我刚才讲过了，管理好体验是最大的壁垒。抖音上一个商品5,000条评论3,500条差评，是不可能做好的。大家可能都看过巴菲特的书，他讲了五个护城河。第一个是无形资产，我们的无形资产是品牌，想到外卖先想到美团。我们的冬装是多个会场Cosplay的常客，一看到黄色，很多人都说千万不能买黄色的冲锋衣。这就是我们的品牌策略，占领一个颜色的品牌是很少的，很多品牌只能占领一个logo，比如钩子、苹果。但我们在中国基本上是占领了黄色，尤其是衣服的颜色。第二个是高切换成本，体验就是最好的切换壁垒。三是网络效应，我们有网络效应，但不是全国性的网络效应，这里有一个弱弱的护城河。四是规模，是有效率的规模，不是盲目的规模。这个规模一定是能支撑整个体系的经济性的，我们的规模和竞对大概3:1，而且我们的利润远高于他们。我们的竞争对手经历了3次合并，最近还有传言说抖音要买，但是如果真的70亿美金买就太亏了，要知道阿里18年买的时候95亿美金，累计投入了100亿美金。这也反映出美团外卖累计投入只有20亿美金，投入20亿美金之后就赚钱了，一直到现在，所以有效率是非常重要的。\n因此巴菲特的理论讲的是结构性优势，是不看管理团队的。最好是管理团队全挂了，公司没事，某种意义上是对的，但是这个不符合我们的现在的阶段。这是视角的不同，巴菲特是长期持仓的角度看这个事，但是对创业公司想蓬勃发展不一样，要有创新精神。上次我们股价迭到40块是5年前的附近，但是过了大概6个月我们就恢复了，又过了6个月就超过发行价50%了。所以最终股价做的好不好还是取决于自己做的好不好，当然我也要负很大责任。\n自营：自营是手段，不是目的。我们有自营业务，比如歪马、小象，优选属于半自营。自营还是卖场是一个光谱，不是非黑即白的。当然有货权肯定是最强的控制，但是没有货权、可以定价也是有点像自营的，定义商品、选品这算不算自营呢？所以这是一个光谱。能确定性的告诉大家，我们在商品颗粒度上应该有很多产品和运营的逻辑出来。\n神抢手、拼好饭对主站订单的抢夺：一方面我们有好的测试结果，另一方面拼好饭其实是对我们自己的一个自我颠覆，用商品模式做高性价比的产品，这是之前没有的。我们先把这个做了，把这个市场占住，我们也学会了很多做这类产品的经验，同时也培育了很多为拼好饭生产的商家，我长期起来看应该是几千万单的规模。肯定有存量的转移，但是更重要的是不要被别人颠覆，被自己颠覆。\n产品被抄袭怎么办：做好你的PMF，我们的会员红包被全行业抄袭，神券也是，更重要的是我们的自己PMF是什么，持续地创新。\n如何管理不同分层用户的购买行为：当拼多多崛起的时候，淘宝中的商品是否一定比拼多多贵？其实不一定，因为商家基本是一样的。但是你在淘宝搜不到，排在特别后面。淘宝有一个巴菲特系统，可以让小二把特定的价格带屏蔽了，比如某一类人群搜索某个品类的时候，根本搜不到便宜的供给，这样可以把GMV做大。\n所以一方面我们要有效的目标引导，不要乱搞运营；我们的推荐策略要看全盘，不是只看GMV，也要看订单、购买等。但是我觉得更重要的是这**两个模式要统一，在不同的场去运用它，可能是不同的入口，不同的心智**。为什么把聚划算废了？这个问题很有意思，要想好到底要服务哪部分用户的生意，如果要服务所有用户，那就要设计适应价格带的产品来满足他们的需求，比如唯品会就是服务“精致穷”。**产品组合重要，但关键的是用户定位要做好。** AI与电商：我们收购了光年，韩建他们也在搞自己的大模型。一个很重要的发现是，大模型本身没有那么难，但是最尖端的大模型比较难，比如OAI和智谱他们要探索大模型的边界，但是所有考虑应用的公司都陷入了找不到PMF。我两周和他们开一次会，大家都长吁短叹地在迭代自己的产品。大家最开始都想到用bot做导购和推荐，但实际上挺难的，我甚至都不认为在目前的阶段是一个合适的产品形态。国外有做陪聊的，Charater.ai，美团平台也发布了WoW，最大的问题是模型的缺陷没有记忆力，导致你今天倾注的情感他明天忘记了，很尴尬。渣男，大模型的记忆只有24小时，反正有很多问题要解决。 大模型与本地生活的结合我们在探索，客服、对骑手的服务，有一些AIGC的东西我们在做。正好我说一说对AI这一波的理解，AI很多年了，最新的一波比较大的浪潮来自于2012年Hinton团队用显卡训练搞出深度学习，这一波大浪起起伏伏。最近一波应用的成果就是ChatGpt爆火，这说明人类还是缺乏想象力，因为懂行的人2018年Google发论文之后就在猛搞了，但是一直没有成型的产品，直到最近产品出来之后才爆火。所以ChatGPT实际上用来干甚么呢？就是学生写论文、写发言稿、写打油诗、RD搞点代码……整体来说是做生产力工具来偷懒，没毛病，人是懒惰驱动的。但是抽象一层，本质上真正的应用是GC，内容生成，用AI来做GC。 为什么AIGC这么重要？**互联网发明就是用来消费内容的**。第一代互联网、第二代、第三代本质上就是内容的生产和消费。第一代，门户网站解决了不花钱看新闻，PGC生产的内容让人消费比较容易，解决的是内容消费的问题，代替的是报纸；搜索引擎改变的也是内容消费，搜两个关键字就能出来一大堆东西。第二代是把内容生产改变了，从PGC变成了UGC，人人都可以发内容；内容消费也升级了，不仅消费文字，还消费图片、视频。抖音打败了电视台、打败了长视频，在内容的生产和消费上进行了巨大的变革，生产的门槛通过滤镜、剪辑工具下降了，消费的门槛也下降了。**AIGC可能是有史以来内容生产成本最低的一个领域**，有一个小产品团队在探索怎么用真人一样的方式来推荐餐厅，形式不是chat了。 商分的价值和定位：商分首先是商业，大模型不能分析PMF。不是智能的问题，是它不了解真实世界、没有体感。大模型是工具，不能替代你的判断力。商分不可替代的是商业能力及对生活、从事行业的观察和理解，可以帮助你少跑数、帮助你寻找数之间的规律。曹老师在和基础研发合作做数据的Copilot，一大堆表长得又很像，这些复杂的事情还是让AI来做吧。我希望我们的商分能真正地进入真实世界，一部分在数字世界，但是更多的时间在真实世界去理解商业的原理和逻辑，并推动事情发生。之前商分叫BI，明明都在跑数还说自己智能，所以我们先变成BA，强调分析，真正要做智能的事情，做商业中最宝贵的事情，做有创造力的事情。 我觉得推动事情发生很重要，模不模糊一点都不重要。如果真的很模糊，说明中间有间隙，有间隙可能是没有人补位的问题。另外我分享一个职场上的秘诀，很多时候你的影响力是因为你对这个事情了解的深度和拿结果的能力决定的。你不要bb别人不行，你行你做出来，至少证明他就可以了。我们做BM的有很多种类型，有产品、有商分、有运营、有研发，不是由原来的序列决定的，是表现出的领导力、判断力、责任心和最后的结果决定的。如果模糊度很高，大家没活干，影响你了，赶紧找个新的活、合适的活，发挥价值，做好当下。 当时为什么设立商分，是因为长链条的业务希望在做决策的时候能更有科学性。但确实有商分滥用的问题，这就是熵增原理，我们现在商分的人数是蛮多的，但是价值创造没有那么强。我觉得最重要的原因是更多在跑数、在论证，没有真正参与。你们要自己思考市场、思考解决方案对不对，我特别鼓励你们写PRFAQ要资源，不管你们什么岗位。做增长的罗震是RD，仍然做的不亦乐乎。 大浪潮固然很重要，但并不是每个人都能参与。大浪潮来的时候，多数人其实不在那个浪上，可能是随波逐流。**但是大浪潮抓不住，小的循环应该抓住，重点在你能改变的事情上。**中国互联网的红利已经到顶了，这也没什么不好承认的。我们需要更多地是，在现在做的事情上做得更好。没有任何行业能每年50%增长，当然我们还有很多业务线还是50%的增长，大家不要丧失信心、自怜自爱，我们的增速不算慢，而且你们能影响的到底是什么？今天我搞个1,000亿目标，你们也不敢干啊，谁想干谁举手，单敲我也行。当然组织的迭代，更希望你们能自己做事情，也给你们这样的权力。\n职业发展：无论是在美团，还是去创业，给你的回报和你发挥的价值基本是一致的。职业初期至少先变成一个多面手，然后从只是分析到推动事情发生，以及你对你的peers到底是不是感兴趣。做中国最好的商分，在美团还是很大希望的，我们也有挑战赛。\n职业发展的终局还是取决于你想成为什么，多数人对社会发挥的价值不一定随着时间持续上升的，可能有的人在高考时达到顶点，有的人可能在刚入职场的几年达到顶点，有的人在35岁达到顶点。巴菲特99%的钱都是60岁以后挣得，这个足够励志吧？你在60岁以后才转到这辈子99%的钱，这该高兴还是悲哀呢？所以他的人生曲线是持续往上涨的。你千万得知道自己要什么，职场是你的一部分，不是全部，你要想自己在生活中要什么。我希望大家的人生曲线是持续向上的，无论是工作还是生活，至少别再30~40岁就达到顶点了。 我刚工作3~4年的时候很迷茫，2008~09年正是互联网起飞的时候，当时我在五道口上班，没有人不迷茫，但是还是要反复想自己的优势是什么。前三年不要想太多，就是把手头的事情做好，至少要有一个硬技能，除非你家里有矿。思考自己擅长做什么，认知自己的长处比认知自己的短板更难，填特长、填爱好都没有什么。运气好一点可以找到自己的长板，差一点没找到，这个事很难。 ","description":"","id":3,"section":"zh","tags":["美团","科技","零售"],"title":"从0到100——如何做成新业务","uri":"https://hugo.jiahongw.com/en/zh/talks/%E4%BB%8E0%E5%88%B0100%E5%A6%82%E4%BD%95%E5%81%9A%E6%88%90%E6%96%B0%E4%B8%9A%E5%8A%A1%E6%96%B0%E4%BA%A7%E5%93%81/"},{"content":"词条概要 “零售+科技”是美团的业务战略，定义了美团的“What+How”（“做什么事+如何做事”），于2021年9月正式发布。“零售”包括商品零售和服务零售。“零售”与“科技”之间是双向关系、缺一不可：科技支撑并驱动变革零售，零售为科技提供持续的资源投入和丰富的场景支持。\n战略的演进：从“Food+Platform”到“零售+科技” 升级前——“Food+Platform”：2018年美团在香港上市后，于11月进行组织升级，聚焦“Food+Platform”战略，以“吃”为核心，建设生活服务业从需求侧到供给侧的多层次科技服务平台。\n升级后——“零售+科技”：在2021年9月的沟通会上，美团CEO王兴宣布公司业务战略从“Food+Platform”升级为“零售+科技”。\n有什么不同？——“What+How”（“做什么事+如何做事”）对于一个公司而言是最为重要的问题，“Food+Platform”和“零售+科技”是在公司不同发展阶段对这一问题所作出的回答。美团CEO王兴对于这一战略上的升级解释道：零售分为商品零售和服务零售，“对美团而言，其实我们从一开始做的就是零售的事情，只是一开始是服务零售，后面扩展到商品零售”。此外，“平台（Platform）也不是我们创造价值的唯一方式。即使在科技这个范畴里面，可以用平台的方式创造价值，也可以用其他方式创造价值，所以科技是一个比平台更广的概念。”\n“零售+科技”的含义 在2022年9月的沟通会上，兴哥分享了他对于“零售+科技”战略的思考：“我们要坚定地去推进做零售，不仅是服务零售，也包括商品零售。商品零售中不但是包括卖场型的模式，也包括自营型的模式。”兴哥认为零售和科技的关系是“双向和双重的”：“零售是What，科技可以理解为是实现零售这个What的一个非常重要的How。”\n在2023年7月的公司技术委员会（Technical Committee，TC）沟通会上，兴哥进一步阐释了“零售+科技”的深层次含义。\n王兴在2023年7月美团技术委员会（Technical Committee，TC）沟通会上对“零售+科技”的阐释：\n我认为零售和科技是双向的关系，不然的话不宜把它们放在一起，它们不是简单的两个没有关系的并列组合，而是有必然联系。而且这个联系是双向的，不光是科技对零售的促进，还有零售对科技的促进。\n科技对零售有什么帮助呢？我觉得至少有两重，是有区别的。一重，我更愿意称它为“支撑”——原来很多事情能够发生，但我们用科技手段，能够使它发生得更有效率、体验更好、成本更低或者能支撑更大规模。我举个例子，以我们最主力的业务——餐饮外卖为例。其实在2013年甚至2009年就有外卖，只是规模小很多，零散很多，既没有平台配送，也没有线上订单，可能就到周边拿了餐厅的一些单子让你记电话，直接打电话，所以这个事情是原来一直有的。那我们后面在它上面加了科技成本，使它变得更有效率，大家能够更快地发现更多的选择，而且加订单的过程也更方便，同时下完订单之后我们整个配送过程也更有效率。所以这个是使原来已经在发生的事情，我们通过科技手段能够增强它——enhance，让它能发生的体验更好，效率更高，成本更低，这是一个比较主体的事情，它可以发生在方方面面。\n**另一重是用“enable”来讲是更准确的——原来它近乎不能发生，但因为科技发生了足够大的进步，使它现在能够发生，**当然这两个之间可能会存在量变引起质变的关系。还是以外卖配送为例，原来我们从大家零散的配送到我们做了移动物流平台，包括平台的自配送，这是跟别人enhance的关系。但我们有另一个团队一直在做自动车或者是无人机，这个无人机大家会感觉更玄妙一点，可能都不能实现。这个东西在没有足够强的技术enable之前，它完全是科幻性质的东西，它是没有发生的。现在我们也是在很小的范围，例如深圳和上海有些地方初步在做，但我们已经看到了科技上的一个路径。当我们逐步地提升，并做了一定的结合，这不光是我们自己做，还帮政府协同建设公管系统之后，以及说从M-Port最后到接收者，那么有可能出现原来大家完全没有体验过的城市物流，这是有点量变引起质变的关系。虽然主要是送东西，但是有一整套非常高效自动化，近乎原来科幻体系里面的一个物流。这是一个原来不存在的不可能发生的事情，现在变可能发生了，这是enable。所以我觉得科技对零售的关系，它是两重的，一重是这个enhance，一个是enable。\n反过来零售跟科技的关系也是两重：一重是搞科技要有持续的投入，而且要解决一些比较大的问题，可能是有比较大的而且是比较长时间的投入。这在商业里面是最直接的成本，它需要有足够的资金投入，需要有足够的资本。这个我觉得大家一定不要低估这个事情的重要性，尤其是解决很多大问题的时候，虽然三个人或者小团队的天才非常重要，但最后要在大规模把它变成现实是需要很大投入的。如果做得好的话，能够体量很大，能够产生很好的点，那么理论上我们要投入科技研发，不管是继续提升这个enhance，还是我们有更大胆的想法，需要去做一些突破，需要做enable里面的事情，是提供了财务上的可能性。我觉得这挺重要，有些事情它可能是厚积薄发，大家如果只看它那个突破点，觉得好像完成得很短，但其实是要很长时间持续去投入。所以在资金上面，一方面是要扩大，第二是要足够长。对我们公司而言，我们把零售做好，在这个服务我们的客户方面做出很大贡献的同时，我们是能够有可能获得比较好的、大的正现金流，那么我们是有可能支持大投入和长期投入的，这是很重要的一点。所以我觉得第一个零售与科技的关系是提供资金的支持。\n另一重是场景的支持，我觉得这个也是非常重要的，因为大家是需要反馈的。你不能够完全凭空在这个真空里闭门造车搞很长时间。有些技术可以比较容易的凭空构建一个应用场景、使用场景，但有些技术其实很难。如果它需要长期打磨的话，那就更难，所以它这个技术也需要一个很大的业务系统、业务场景去打磨。当然科技可以有很多的应用，不一定是在零售方面，但我觉得在零售方面，它本身因为跟足够多人打交道，整个链条足够长，所以它是可以给很多科技提供一个很好的使用场景、打磨场景。\n以我们最熟悉的配送为例，不管是自动车还是无人机，国外也有一些人想尝试，但大概率没有使用场景。做自动驾驶有很多类型，有的是载人，有的是载货。在载货的里面，尤其是比较低速、少量的载货跟我们最相近的一家是美国的公司，它有不错的软硬件研发团队，但自己没有使用场景，所以就只能找行业内其他公司使用。但一般公司还不愿意跟它合作，别人不太愿意为它去打磨流程，麻烦很多。而我们的自动车团队就有优势可以跟美团买菜的站点进行各种对接，虽然也有对接成本，但我们使用场景灵活很多。无人机也是，国外很多公司是只做研发的，做使用场景的运营方是另一家公司，但我们是有机会把它打通做全链条的改进，所以我觉得这是比较清晰的零售对科技的价值。\n","description":"","id":4,"section":"zh","tags":["美团百科","科技","零售"],"title":"美团-零售+科技","uri":"https://hugo.jiahongw.com/en/zh/talks/%E9%9B%B6%E5%94%AE%E7%A7%91%E6%8A%80/"},{"content":"使用 Obsidian 编写 Hugo 博客的原因之一是，Obsidian 有插件能够支持配置模板，这样我新建文章的时候，只需要一个指令就能够帮我构建好一个文章的基本框架内容了。而这个支持快速配置模板进行创建文章的插件，就是 QuickAdd 插件。\nQuickAdd 插件配置 首先在插件市场里面找到 quickAdd 这个插件，下载之后进入插件的设置页面，点击新建 template 的 choice，然后在选择对应的模板文件地址，并且配置新建文件所在的文件夹，我这里配置的新建文件所在的文件夹设置的是项目目录下的content/zh/posts下。\n对应的模版文件是：\n--- title: {{NAME}} subtitle: date: {{DATE:YYYY-MM-DD HH:mm:ss}} publishDate: {{DATE:YYYY-MM-DD HH:mm:ss}} aliases: [] description: image: draft: false hideToc: false enableToc: true enableTocContent: false tocPosition: inner # outer author: VictorHong authorEmoji: 🪶 authorImageUrl: tocLevels: [\u0026#34;h2\u0026#34;, \u0026#34;h3\u0026#34;, \u0026#34;h4\u0026#34;] libraries: [katex, mathjax, mermaid, chart, flowchartjs, msc, viz, wavedrom] tags: [] series: [] categories: [] --- --- ***Reference***: 其中，文章的名称是我在输入新建指令的时候输入的。\n使用插件直接在 Obsidian 中输入Commond + P ，输入QuickAdd\n然后选择新建博客，输入文件名就会在指定文件夹下面出现对应的文件\n其他插件 其他插件例如图片上传的插件Obsidian Image Auto Upload Plugin以及自动 git 提交的插件Obsidian Git，目前来看都不是必须的，暂且不安装使用。\nObsidian Pangu 这个插件还可以，可以在英文与中文之间自动添加空格，使用方法为Commond + Shift + S\nReference:\nHugo 博客写作最佳实践 | 胡说 Hugo With Obsidian :: 木木木木木 ","description":"之前使用的是Typora，感觉没有特别好，虽然简洁，但是模版或者提交等操作繁杂，最终还是选择功能强大的Obsidian，虽然功能多，但我只需要我要的就够了。","id":5,"section":"zh","tags":["Obsidian","笔记","效率"],"title":"使用Obsidian编写Hugo博客","uri":"https://hugo.jiahongw.com/en/zh/posts/hugo/use-obsidian-write-hugo/"},{"content":"多条件查询优化 ES 在进行联合索引查询的时候，使用多个条件去进行筛选，那么多个筛选条件会获得多个倒排列表，如果这两个条件是一个\u0026quot;且\u0026quot;的操作，就需要将两个倒排列表进行合并取交集；如果这两个条件是一个\u0026quot;或\u0026quot;的操作，就需要将这两个倒排列表进行取\u0026quot;并集\u0026quot;。\n这个理论上的“与”合并的操作可不容易。对于 mysql 来说，如果你给两个字段都建立了索引，查询的时候只会选择其中最 selective 的来用，然后另外一个条件是在遍历行的过程中在内存中计算之后过滤掉。那么要如何才能联合使用两个索引呢？有两种办法：\n跳表：同时遍历多个字段查询条件的倒排列表，互相 skip。 bitset 结构：多多个字段筛选的的条件构建 bitset，然后多个 bitset 进行 AND 操作。 Elasticsearch 支持以上两种的联合索引方式，如果查询的 filter 缓存到了内存中（以 bitset 的形式），那么合并就是两个 bitset 的 AND。如果查询的 filter 没有缓存，那么就用 skip list 的方式去遍历两个 on disk 的 posting list。 跳表合并查询 跳表也是一个有序列表，但是它和有序列表最大的区别是，它是平衡稳定的。\n跳表的结构：\n当元素数量较多时，索引提高的效率比较大，近似于二分查找。跳表是可以实现二分查找的有序链表。 ES 中对于跳跃表的使用，一般是在合并倒排列表的时候，也即联合索引查询的时候。\n假设我们使用三个索引进行查询筛选，得到三个倒排列表，此处我们需要对三个倒排列表进行取\u0026quot;交集\u0026quot;：\n以上是三个 posting list。我们现在需要把它们用 AND 的关系合并，得出 posting list 的交集。首先选择最短的 posting list，然后从小到大遍历。遍历的过程可以跳过一些元素，比如我们遍历到绿色的 13 的时候，就可以跳过蓝色的 3 了，因为 3 比 13 要小。\nNext -\u0026gt; 2 Advance(2) -\u0026gt; 13 Advance(13) -\u0026gt; 13 Already on 13 Advance(13) -\u0026gt; 13 MATCH!!! Next -\u0026gt; 17 Advance(17) -\u0026gt; 22 Advance(22) -\u0026gt; 98 Advance(98) -\u0026gt; 98 Advance(98) -\u0026gt; 98 MATCH!!! 最后得出的交集是 [13,98]，所需的时间比完整遍历三个 posting list 要快得多。但是前提是每个 list 需要指出 Advance 这个操作，快速移动指向的位置。\nbitset 合并查询 Bitset 是一种很直观的数据结构，对应 posting list 如：[1,3,4,7,10]\n对应的 bitset 就是：[1,0,1,1,0,0,1,0,0,1]\n每个文档按照文档 id 排序对应其中的一个 bit。Bitset 自身就有压缩的特点，其用一个 byte 就可以代表 8 个文档。所以 100 万个文档只需要 12.5 万个 byte。但是考虑到文档可能有数十亿之多，在内存里保存 bitset 仍然是很奢侈的事情。而且对于个每一个 filter 都要消耗一个 bitset，比如 age=18 缓存起来的话是一个 bitset，18\u0026lt;=age\u0026lt;25 是另外一个 filter 缓存起来也要一个 bitset。\n需要有一个数据结构能满足：\n可以很压缩地保存上亿个 bit 代表对应的文档是否匹配 filter； 这个压缩的 bitset 仍然可以很快地进行 AND 和 OR 的逻辑操作。 Lucene 使用的这个数据结构叫做 Roaring Bitmap（RoaringBitmap 是高效压缩位图，简称 RBM）：\n其压缩的思路其实很简单。与其保存 100 个 0，占用 100 个 bit。还不如保存 0 一次，然后声明这个 0 重复了 100 遍。上面这张图可以看出，如果没有某个桶下没有文档 id 匹配，这个桶是不会占用空间的。\nRoaring Bitmap 的实现思路(假设在 32bit 系统上)：\n将 32bit int（无符号的）类型数据 划分为 2^16 个桶，即最多可能有 216=65536 个桶，内称为 container。用 container 来存放一个数值的低 16 位\n在存储和查询数值时，将数值 k 划分为高 16 位和低 16 位，取高 16 位值找到对应的桶，然后在将低 16 位值存放在相应的 Container 中（存储时如果找不到就会新建一个） 当桶下面的元素大于 65536 个时，会转换成 bitmapcontainer；小于 65536 是一个最大值为 4096 的 short 数组。\n跳表和 bitset 的性能比较：\n上面两种合并使用索引的方式都有其用途。Elasticsearch 对其性能有详细的对比（https://www.elastic.co/blog/frame-of-reference-and-roaring-bitmaps ）。简单的结论是：因为 Frame of Reference 编码是如此 高效，对于简单的相等条件的过滤缓存成纯内存的 bitset 还不如需要访问磁盘的 skip list 的方式要快。\n排序和聚合的优化 我们知道倒排索引能够解决从词到文档的快速映射，但当我们需要对检索结果进行分类、排序、数学计算等聚合操作时需要文档号到值的快速映射，而原先不管是倒排索引还是行式存储的文档都无法满足要求。\n假设我要根据 content 搜索，然后根据 time 字段排序，因为倒排索引是一个字段对应一个 docId 集合的，所以 query 阶段我只能取回 docId，没有更多字段的值，所以需要有一个地方获取 time 的值。倒排索引如下：\nterm docId 10 2 13 3 14 1、5、8 16 7、9、10 这样的结构是没法直接获取到 time 字段的，所以只有遍历看看我这些 docId 的 time 值都对应是多少，所以这一步是要通过 docId 获取 fieldvalue的，遍历倒排索引效率会很低。因为一般来我们并不需要整个结果集，只需要按一定条件 topK。\n原先 Lucene 4.0 版本之前，Lucene 实现这种需求是通过 FieldCache，它的原理是通过按列逆转倒排表将（field value -\u0026gt;doc）映射变成（doc -\u0026gt; field value）映射，也就是构建文档 id 到字段值的正排索引。\nFieldCache 简单抽象的理解就是一个大数组，数组的下标表示 docId，数组中的值表示这个 field 的 value。上面的步骤当我需要按照 time 排序时，假设过滤出 100 个 docID，就可以拿他们去数组中直接取到 time 值然后排序，获取排序字段的时间复杂度瞬间变成 O(n) (n 为 doc 个数)，效率好多了。\n但这种实现方法有着两大显著问题：\n构建时间长。 内存占用大，易 OutOfMemory，且影响垃圾回收。 因此 4.0 版本后 Lucene 推出了DocValues来解决这一问题，它和 FieldCache 一样，都为列式存储，但它有如下优点：\n预先构建，写入文件。 基于映射文件来做，脱离 JVM 堆内存，系统调度缺页。 DocValues 这种实现方法只比内存 FieldCache 慢大概 10~25%，但稳定性却得到了极大提升。\nLucene 目前有五种类型的 DocValues：NUMERIC、BINARY、SORTED、SORTED_SET、SORTED_NUMERIC，针对每种类型 Lucene 都有特定的压缩方法。\nFieldCache 和 DocValue 的区别：\nFieldCache 不会在索引（写入数据）的时候创建，而是在查询运行时动态填充；并且 FieldCache 是存储在内存中的。 DocValue 会在索引的时候写入磁盘（在索引时与倒排索引同时生成的，并且是不可变的，与倒排表一样，保存在 lucene 文件中（序列化到磁盘）），在使用字段聚合或者排序的时候可以从磁盘直接加载。\n（这样看来，牺牲了部分写入的时间，但是获得了查询的高效） ES5 之后目前 fileldCache 默认不开启，需要设置 fielddata=true 才开启。因为 text 类型的字段不支持 doc_values，对于 text 类型的需要扫描倒排索引，建立 Filedata 数据结构。 范围查询的优化 没有 BKD 树的时候，Lucene 是如何对数值类型进行范围查询是下面这样的：\n假设有上面的一个数值类型的倒排表，这种结构对于精确的数值查询速度还是比较快的，直接从倒排索引根据查找的 term 拿到 postings list 就好了。 但类似 range: [50, 100]这样的范围查找就比较麻烦了，Lucene 在找到对应的 term 后，只能将其转换成类似 50 OR 51 OR 52 \u0026hellip; OR 100 这样的 Bool 查询。\n可想而知，这个多条件 OR 查询开销很高，执行很慢。所以 Lucene 在创建索引的时候，会自动产生一些类似50x75 这样的特殊 Term，指向包含在该范围的文档列表，从而可以将查询优化成类似 50x75 OR 76x99 OR 100 这种形式。但是这种优化在字段的不同值很多，查询范围很大的时候，依然很无力。 因此早期版本的 Lucene 和 ES 的范围查询性能一直被诟病。\nES5 之后使用 Lucene6.0，Lucene6.0 对数字类型的范围查询优化，使用 BKD 树优化数值类型的范围查询。\n具体参考：b-k-d 树 原理 图文解析_stevewongbuaa 的博客-CSDN 博客_bkd 树 和 number?keyword?傻傻分不清楚\n下面看下 BKD 树是如何提高数字类型的范围查询的：\nb-k-d 树（多维树）\n用于多维度搜索的。例如在二维平面搜一个点，在三维空间搜一个点，在多维空间搜一个点。\n下面是一个二维的图示 理论上 k-d 树可以继续到 4 维，5 维… 作为一个三维空间里的生物，就没法用图来展示这样的元素了 😅 第一级：按照 X 维度划分，划分点是(7,2)，左子树都要在 X 维度比(7,2)小，也就是 x\u0026lt;7。也就是，左子树都在(7,2)这个点的左边。右子树都在(7,2)这个点的右边\n第二级：按照 Y 维度划分，划分点是(5,4)，他的左子树在 Y 维度上都要比(5,4)小，也就是 y\u0026lt;4\n（想要查找年龄在 20 岁以上并且身高在 170 到 180 之间的所有人，用 B-K-D 树就能很好的解决。）\nLucene 实现的这种 BKD 树在进行一些多数值类型的范围查询性能较好，对于一些大数据量的地理位置查询场景表现的极为出色。 需要注意的是，因为数值型字段在 5.x 里没有采用倒排表索引， 而是以 value 为序，将 docid 切分到不同的 block 里面。对应的，数值型字段的 TermQuery 被转换为了 PointRangeQuery。这个 Query 利用 Block k-d tree 进行范围查找速度非常快，但是满足查询条件的 docid 集合在磁盘上并非向 Postlings list 那样按照 docid 顺序存放，也就无法实现 postings list 上借助跳表做蛙跳的操作。 要实现对 docid 集合的快速 advance 操作，只能将 docid 集合拿出来，做一些再处理。\n所以对于 term 查询，不需要进行一些数值计算或者范围计算的字段最好都定义为 keyword。\nEagle 官方文档认为对于数值类型的大量 term 查询是一个 ES Bad Case，推荐使用 ES multi-field进行优化。\n","description":"ES基于lucene的倒排索引能够达到比较好的检索效果，但是对于大数据的检索和查询，还需要做更多的优化。","id":6,"section":"zh","tags":["elasticsearch","lucene"],"title":"ES原理和实践:底层查询优化","uri":"https://hugo.jiahongw.com/en/zh/posts/elasticsearch/es-query-optimization/"},{"content":"ES 和 lucene 的关系 lucene: lucene 是一个 Java 信息检索程序库。可以类比为封装的底层 API，程序引用这个库之后可以使用其中的一些功能。 ES: ES 是基于 lucene 这个包基础上进行构建的一个满足高可用、高性能、高可拓展的分布式存储中间件。 Lucene 的底层数据结构设计 Lucene 是一个高效的，基于 Java 的全文检索库。主要包括下面的一些核心操作：\n倒排索引 什么是倒排索引？\n首先看下什么是正排索引:\nMySQL 中，根据 id 可以直接查找到数据行，那么 id 这个查询条件使用的就是正排索引；可以理解为，正排索引就是从文档 id 到文档内容映射。\n那什么是倒排索引？\nES 将数据进行分词之后，存储到倒排索引中。分词之后会分成多个字符串值，倒排索引存储的就是这些字符串值到文档 id 的映射。可以理解为，倒排索引就是从字段到文档 id 的映射。\n为什么使用倒排索引呢？倒排索引最后不也是拿到文档 id 进行查询文档，使用正排索引不是也能满足需求吗？\n案例1-搜索引擎 案例2-电商搜索系统 搜索引擎通常用于搜索网页内容，而网页内容多为文章。我们通常使用关键字来查询相关文章。由于文章内容较长，若使用 MySQL 数据库进行查询，需采用类似like %关键字%的方式，这种方式会导致全表扫描，查询性能极低。即便尝试构建索引，对文章内容进行索引也是不切实际的。\n使用 Elasticsearch（ES）可以先对文章进行分词，然后将每个词项对应的倒排列表存入 ES 的倒排索引中。这样，通过关键字查找相关网页文章的速度就像哈希查找一样快，避免了线性全表扫描。ES 的倒排索引将非结构化的文章内容分词整理，转换成结构化的倒排列表存储，从而在进行关键字的全文索引时能达到极佳的效果。\n电商搜索系统通常需要快速的查询响应速度，以确保良好的用户体验和较高的商品销量。通常，电商搜索系统，例如淘宝、京东、咸鱼、拼多多等，在进行商品搜索的时候，可以按照商品的名称进行模糊搜索，除此之外，还能对商品进行各种各样的筛选：分类、品牌、价格、特征、尺码、包装形式、是否折扣、发货地\u0026hellip;\u0026hellip;\n首先，为了保证搜索速度，是否应在 MySQL 中为各种筛选项添加索引是一个问题。如果添加索引，MySQL 的索引可能会过度膨胀，影响写入性能。相比之下，Elasticsearch（ES）默认所有字段都是索引，更适合处理多条件查询。此外，商品名称的模糊查询也不适合使用 MySQL。(MySQL 对于模糊查询最多做到前缀匹配)\n在上述两个案例中，我们了解到在实际业务中，最终都需要获取文档 ID。关键在于如何高效地获取这些 ID，以及采用何种数据结构。MySQL 通过全表扫描来获取 ID，而 Elasticsearch（ES）则利用倒排索引快速检索 ID。两者的优劣显而易见。\n这也说明了使用正排索引的局限：模糊查询和多条件筛选查询能力的欠缺。而这两个正是 ES 的强项。\n简单描述下倒排索引，下面是一个倒排索引进行构建的例子：\n左图是一个正排索引，记录文档 id 到文档内容的映射；右图是倒排索引，记录了单词（由文档内容分词而成）到文档 id 的映射，每个单词有自己的单词 id，另外，倒排索引不仅记录了单词所在的文档 id，还记录了单词在文档出现的频率和出现在文档的单词次序（文档内容的第几个单词）。\n倒排索引: 以单词“谷歌”为例子，文档频率为5表示在五个文档都出现了这个单词，对应其中的两个倒排列表为{(1;1;\u0026lt;1\u0026gt;)，(2;1;\u0026lt;1\u0026gt;)},表示在文档1和文档2出现了这个单词，单词频率都为1，都在两个文档中的出现位置都是1 词典-FST 很多人仅仅知道 ES 中的底层是倒排索引，其实 ES 的索引构建由词典和倒排表构成，其中词典结构尤为重要。\n参考各种词典结构的优点和缺点（参考：Lucene 底层原理）：\n数据结构 优缺点 排序列表 Array/List 优点：实现简单\n缺点：不平衡；性能差，且依赖数据的顺序性 HashMap/TreeMap 优点：性能高，查询快\n缺点：内存消耗大，几乎是原始数据的三倍 Skip List（跳跃表） 优点：可快速查找词语（在 lucene、redis、Hbase 等均有实现），相对于 TreeMap 等结构，特别适合高并发场景（Skip List 介绍）、占用内存小且可调\n缺点：模糊查询支持不好。一般作为等值查询的索引 Trie 优点：适合英文词典，如果系统中存在大量字符串且这些字符串基本没有公共前缀，则相应的 trie 树将非常消耗内存\n缺点：对于后缀搜索不友好 Finite State Transducers (FST) 一种有限状态转移机，Lucene 4 有开源实现，并大量使用。共享前缀，内存消耗少，但要求输入有序，更新不易 上面列出的一些词典的结构，最简单如排序数组，可以通过二分查找来检索数据；更快的有在内存直接使用的哈希表；磁盘查找有 B 树、B+树，其中 MySQL 是使用 B+树作为词典；而 Redis 使用跳跃表和哈希表等。\n但一个能支持 TB 级数据的倒排索引结构需要在时间和空间上有个平衡，主要有如下的三种主要实现方式提供 ES 进行选择：\n结构 图 优点 缺点 B+树 外存索引（在磁盘上）、可更新（在原来数据的基础上更新 占用空间大、速度不够快 跳跃表 结构简单、跳跃间隔、级数可控。\n（Lucene3.0 之前使用的也是跳跃表结构，后换成了 FST，但跳跃表在 Lucene 其他地方还有应用如倒排表合并和文档号索引。） 模糊查询支持不好 FST 节省内存，查询快，支持前缀和后缀查询 更新难，构建复杂 lucene 从 4.x 开始大量使用的数据结构是 FST（Finite State Transducer,有限状态转换器）。FST 有两个优点：\n空间占用小。通过对词典中单词前缀和后缀的重复利用，压缩了存储空间。 查询速度快。O(len(str))的查询时间复杂度。（str 是输入的查询字符串长度） FST 类似一种 TRIE 树。但是和字典树有什么区别呢？参考：关于 Lucene 的词典 FST 深入剖析\n假设我们有一个这样的 Set: mon,tues,thurs。FST 是这样的：\n相应的 TRIE 则是这样的，只共享了前缀，如下图：\nTRIE 有重复的 3 个 final 状态 3，8，11. 而 8，11 都是 s 转移，是可以合并的。\nFST 支持后缀，字典树只支持前缀查询。\n除了在 Term 词典这块有应用，FST 在整个 lucene 内部使用的也是很广泛的，基本把 hashmap 进行了替换。\nES 倒排索引实现细节 通过结合 FST 和倒排索引，我们可以得到下面这张 Lucene 对于倒排索引实现的大概结构：\n假设查询 Allen，查询过程会先从 Term-Index 查询这个词在 Term Dictonary 的大概位置，及从 Ada 开始遍历查询，然后精确的查询到 Allen 的具体位置，得到倒排列表。\nFST 相当于是倒排索引的一个二级缓存索引树。 建立 FST 这个二级索引，可以实现倒排索引的快速定位，不需要经过多次的磁盘 IO，搜索效率大大提高了。不过需要注意的是 FST 是存储在堆内存中的，而且是常驻内存，大概占用 50%-70%的堆内存，因此这里也是我们在生产中可以进行堆内存优化的地方。\n这个时候我们分析下“为什么 Elasticsearch/Lucene 检索可以比 mysql 快”（注意，这里说的是检索，并不是写入）\nMysql 只有 term dictionary 这一层，是以 B+树 排序的方式存储在磁盘上的。检索一个 term 需要若干次的 random access 的磁盘操作。而 Lucene 在 term dictionary 的基础上添加了 term index 来加速检索，term index 以 FST 的形式缓存在内存中（并且能够压缩）。从 term index 查到对应的 term dictionary 的 block 位置之后，再去磁盘上找 term，大大减少了磁盘的随机访问次数。 （实际上，ES 的写入因为需要构建许多结构化的数据，如倒排表、docValue 等，提供后续进行查找，并且还需要考虑分布式同步等操作，写入应该是会比 MySQL 慢 的，所以 ES 比较适合 OLAP）\n","description":"ES是基于Lucene这个库实现的一个搜索引擎，我的理解是，Lucene主要实现一些底层结构设计和查询、写入的极致优化；而ES是对Lucene进行封装使用，实现分布式、高可用、高可拓展等特性。","id":7,"section":"zh","tags":["elasticsearch","lucene"],"title":"ES原理和实践:底层lucene","uri":"https://hugo.jiahongw.com/en/zh/posts/elasticsearch/es-lucene-inside/"},{"content":"使用云进行部署的好处是，我们不需要负责云主机的相关运维；在使用部署平台进行服务的部署时，我们还能省去部署的一系列操作。\n下面介绍使用 Railway 部署 memos（Dockerfile 部署）\nRailway 地址：https://railway.app/\nmemos 地址：https://github.com/usememos/memos 注册并且登录 Railway 注册就按照注册流程进行注册即可，进入首页：\n每个月 Railway 是有 5 美元的免费额度的，在右上角下拉的 Project Usage 可以查看\n新建项目 选择新建项目按钮，然后选择 Deploy from Github repo 。然后会让你登录 Github 账号并且验证。\n验证完成之后选择需要部署的代码仓库（注意，这里是需要自己的代码仓库，需要将 memos 的 Github 仓库 fork 一份到自己的仓库下）。选择仓库下的 memos 仓库进行立即部署：\n立即部署之后还不能直接使用，还需要进行后面的一些配置。\n配置端口 点击 memos 项目，然后配置 Variables 中添加变量 PORT，值为 5230\n在进行完上面的端口配置之后，Railway 会自动进行重新部署，部署完成之后就可以访问了。访问的域名在 Deployment 的最新部署记录中：\n之后只要有新代码的提交或者是执行 fork sync，都能够触发 Railway 的自动部署。\n其他部署平台：\nvercel：前端开发人员的平台，提供创新者在灵感迸发时所需的速度和可靠性。 render：统一的云服务，提供多种服务进行部署和构建应用程序和网站。也能部署数据存储服务和静态网站。 fly.io：基于 Docker 的全栈部署工具。 Supabase：数据库部署服务网站，也能构建其他应用服务。 [2023-07-09]更新，使用 Railway 的 Volume 可不丢失数据进行更新，下面的具体的指导教程\nRailway 不丢失数据更新：\n参考https://docs.railway.app/reference/volumes这里的说明，使用volume功能需要优先登机会员，参考Priority Boarding | Railway Docs可知道加入的方法即连接官方的Discord即可。 访问您的 Railway General Settings 滚动到 Account Settings，连接您的 Railway 帐户到 Discord 在 Discord 中打开任何频道，输入“/beta”命令并按照提示操作 现在您应该可以访问“#priority-boarding”频道，并且您的帐户设置中应该显示新的 Priority Boarding 状态 从此时起，您将自动启用 Priority Boarding 功能\n在项目界面，按Commond + K新建一个volume\nvolume 的地址填写为/var/opt/memos，名字随便。 因为 VOLUME 关键字在 Railway 被禁用了，需要修改 memos 的 Dockerfile 文件，将 VOLUME 那一行删除\n重新部署，记得配置 Variables 中添加变量 PORT，值为 5230，就可以了。 Reference:\nLife after Heroku: What\u0026rsquo;s a dev to do? - Reaktor Dockerfiles | Railway Docs ","description":"Railway是一个提供基础设施的部署平台，可以方便的在本地使用该基础架构进行开发，然后部署到云端。支持Docker、Java、JS等程序的部署，并且集成了CICD。","id":8,"section":"zh","tags":["Railway","memos"],"title":"使用Railway部署memos","uri":"https://hugo.jiahongw.com/en/zh/posts/%E6%8A%98%E8%85%BE/railway-deploy-memos/"},{"content":" ","description":"","id":9,"section":"zh","tags":null,"title":"Memos","uri":"https://hugo.jiahongw.com/en/zh/memos/"},{"content":"什么是Elasticsearch？ ES的全称是ElasticSearch（下面简称ES），是一个分布式、高扩展、近实时的搜索与数据分析引擎（底层基于Apache Lucene）。Elasticsearch 为各种数据类型提供接近实时的搜索和分析，不论你有结构化或非结构化的文本、数字数据，还是地理空间数据，Elasticsearch 都可以支持快速搜索的方式高效地存储和索引它。你可以远超简单数据检索和聚合信息的方式去发现你数据中的趋势和模式。而且，随着你数据和查询量的增长，Elasticsearch 分布式的特性允许你的部署能随着它无缝地增长。（参考：ES官方文档-ES介绍）\nES作为一种非关系型数据库，他和传统的关系型数据库有什么区别呢？\n底层的数据结构不同，ES使用倒排索引，而MySQL使用B+树 MySQL支持事务，ES不支持事务，可以这么认为，MySQL更加适合OLTP，ES更适合OLAP MYSQL是单机的，ES是分布式的，支持水平拓展以及高可用的特性 MySQL支持多表关联，ES多表关联有限 ES拥有灵活的数据类型，能创建更多的索引（默认都是索引）。 Elasticsearch的使用场景 ES常见的使用场景如下：\n搜索 日志处理 BI分析 数据异构 常见的搜索引擎以及电商搜索的场景，多是以模糊查询和多字段查询为主，如：百科搜索（百度百科、维基百科）、论坛博客（CSDN、简书、掘金、Stack Overflow）、电商网站（京东、淘宝、拼多多） 在进行服务系统管理的时候，监控日志或者对日志进行分析，这些数据量比较大的处理，也能用ES来进行处理： BI系统进行数据分析，ES也能作为一种数据分析的工具，尤其是在大数据分析的场景下： 数据异构和宽表构建主要是利用了ES可以处理很多结构化或者非结构化数据的特性，对一些原来的数据结构进行处理，例如MySQL的多表关联比较慢，可以对多个表进行组合成一张表，写入ES中，然后使用ES中的宽表进行查询，这样查询就能够比较快。并且ES中不会因为字段的个数上升而出现性能问题。 Reference:\nelasticsearch-vs-mysql ","description":"ES是一个功能强大、高效稳定的搜索和分析引擎，具有广泛的应用场景和业界的认可度。无论是企业内部的数据分析，还是面向公众的搜索服务，ES都能够提供高性能和可靠性的支持.","id":10,"section":"zh","tags":["elasticsearch"],"title":"ES原理和实践:ElasticSearch简介","uri":"https://hugo.jiahongw.com/en/zh/posts/elasticsearch/es-intro/"},{"content":"工作💻 作为Java后端开发，开发仓储库存管理系统。\n看书📚 正在看 《创造：用非传统方式做有价值的事》\nWhat else? 还没想到\u0026hellip;\n","description":"","id":11,"section":"zh","tags":null,"title":"我现在在做什么？","uri":"https://hugo.jiahongw.com/en/zh/now/"},{"content":"欢迎留言 ~~ ","description":"欢迎留言","id":12,"section":"zh","tags":null,"title":"留言","uri":"https://hugo.jiahongw.com/en/zh/message/"},{"content":" Freenom 是目前为数不多的免费域名提供商，提供 .ga, .ml, .gq, .tk, .cf 五个免费顶级域。当然也有一些付费的域名，对于普通人来说，免费域名就够了。😏\n另外，本文后面还提供了一种自动续租 Freenom 免费域名的方法。\n1 找域名 Freenom 地址：freenom.com\n打开Freenom，登陆后直接在搜索栏搜索自己想要的域名名字，然后系统会返回可以使用的免费域名，选择一个结算即可\n2 配置解析服务 这一步是可选的，也可以直接使用 Freenom 自己的 DNS 解析服务，或者不使用 cloudflare，用其他的 DNS 解析服务也可以。\n使用cloudflare解析服务 Cloudflare 网址：cloudflare.com\n打开cloudflare，首先需要注册一个账号。然后他会要求输入需要解析的域名\n填写相应的 DNS 信息，并且将下面的 NS 信息填写到 freenom 的custom nameservers\n等待个几分钟就好了。Over 🤞\n3 自动续租 参考：\nluolongfei/freenom: Freenom 域名自动续期。Freenom domain name renews automatically. 常见问题：\nfreenom 域名注册失败的解决办法_未名编程的博客-CSDN 博客_some of your domains could not be registered becau 参考这个github 仓库进行下面的操作：\n通过 Koyeb 部署：通过 Koyeb 部署 · luolongfei/freenom Wiki\n注册 Koyeb 账户\n在新标签页打开链接 https://app.koyeb.com/auth/signup ，完成注册，并登录\n一键部署\n右击在新标签页打开链接 ，来到部署画面：\n主要填写 token 和 freenom 的账号和密码，token 是登陆后台的密码，需要自己保存。\n然后点击 deploy 或者 create service。\n点击应用地址，跳到工具管理画面：\n输入 token 值进行验证（点击送信）：\n返回类似下面的结果：\n默认会周期进行定时调用，不需要手动触发，上面只是为了展示进行触发的。\nReference：\nThe fastest way to deploy applications globally - Koyeb ","description":"","id":13,"section":"zh","tags":["域名","freenom"],"title":"Freenom 免费域名申请 \u0026 自动域名续费","uri":"https://hugo.jiahongw.com/en/zh/posts/hugo/freenom-domain/"},{"content":" 原则 设计原则 单一职责原则\nSingle Responsibility Principle，一个类应该只负责一个职责。\n开闭原则\nOpen-Closed Principle, OCP，一个软件实体应当对扩展开放，对修改关闭。即软件实体应尽量在不修改原有代码的情况下进行扩展。\n里氏替换原则\nLiskov Substitution Principle, LSP，所有引用基类（父类）的地方必须能透明地使用其子类的对象。（其实就是使用多态）\n依赖注入原则\nDependence Inversion Principle, DIP，抽象不应该依赖于细节，细节应当依赖于抽象。换言之，要针对接口编程，而不是针对实现编程。\n关键点为：\n高层模块不应该依赖低层模块，两者都应该依赖其抽象 抽象不应该依赖细节 细节应该依赖抽象 接口分离原则\nInterface Segregation Principle, ISP，使用多个专门的接口，而不使用单一的总接口，即客户端不应该依赖那些它不需要的接口。\n迪米特原则\nLaw of Demeter 又名Least Knowledge Principle, LoD，一个软件实体应当尽可能少地与其他实体发生相互作用。\n体现了封装的思想。\n设计模式分类一览 单例模式 单例模式: 单例模式是一种创建型设计模式， 让你能够保证一个类只有一个实例， 并提供一个访问该实例的全局节点 定义：\n单例设计模式（Singleton Design Pattern）理解起来非常简单。一个类只允许创建一个对象（或者实例），那这个类就是一个单例类，这种设计模式就叫作单例设计模式，简称单例模式。\n架构：比较简单，不画了。\n使用场景：\n线程池 缓存 对话框 注册表对象 日志对象 状态模式 状态模式: 状态模式允许对象在内部状态发生改变时改变它的行为 定义：\n状态模式允许对象在内部状态发生改变时改变它的行为。（对象看起来好像改变了它的类）\n架构：\n实现方法：\n分支逻辑法 查表法 状态模式 使用场景：\n状态模式一般用来实现状态机，而状态机常用在游戏、工作流引擎等系统开发中。或者在一些单据的流转上也可以使用状态模式。 状态模式可以随着时间改变状态，从而执行不同的行为；但是策略模式是事先准备好多种策略，在开始的时候选择了一种策略就是一直使用这种策略进行处理。（可以说，状态模式运行时使用了所有的状态，而策略模式在运行时只使用了一种策略） 策略模式 策略模式: 策略模式定义了算法族，分别封装起来，让他们之间可以互相替换 定义：\n策略模式定义了算法族，分别封装起来，让他们之间可以互相替换。此模式让算法的变化独立于使用算法的客户。\n架构：\n策略定义：\nclassDiagram Strategy \u0026lt;|-- StrategyA : implements Strategy \u0026lt;|-- StrategyB : implements Strategy : algorithmInterface() StrategyA : algorithmInterface() StrategyB : algorithmInterface() 策略创建：\nclassDiagram Strategy \u0026lt;|-- StrategyA : implements Strategy \u0026lt;|-- StrategyB : implements Strategy : algorithmInterface() StrategyA : algorithmInterface() StrategyB : algorithmInterface() StrategyFactory --\u0026gt; Strategy : 关联 StrategyFactory : getStrategy(type) 无状态策略：无状态的策略因为不会变，可以进行缓存，一开始就创建好所有的策略即可。（直接从map中拿取） 有状态策略：有状态的策略因为会改变，所以每次创建都需要是一个最新的策略对象。（在工厂类中存在if-else判断） 策略使用：\n​\ngraph TD; 拿取策略:getStrategy--\u0026gt;使用策略接口:algorithmInterface; 从工厂类中拿取策略。 调用策略对应的接口函数。 使用场景：\n避免冗长的if-else或switch分支判断 提供框架的扩展点 模版方法模式 模版方法模式: 模板方法模式是对抽象的有一种体现，这次，抽象的是算法流程。模板方法定义了一个算法的步骤，将允许子类为一个或者多个步骤提供实现 定义：\n模板方法模式在一个方法中定义一个算法的架构，而将一些步骤延迟到子类中。模板方法使得子类可以在不改变算法结构的情况下，重新定义算法中的某些步骤。\n架构：\n使用场景：\n复用\n因为模板方法是基于继承实现，可以将固定的算法步骤封装在抽象类，抽象类可以实现一些固定的步骤，子类直接进行复用就可以了。\n框架拓展性\nHttpServlet的service()方法就是一个模板方法，它实现了整个http请求的执行流程，而doGet()和doPost()是模板中可以由子类自定义的部分。相当于框架为用户提供了拓展点，使得不需要修改框架源码就能将拓展点添加到框架中。 Junit框架也提供了一些功能拓展点setUp()和setDown()，可以在开始和结束的时候做一些事情，而runBase()函数是一个模板方法，定义了执行测试用例的整体流程。 策略模式和模板方法模式都封装算法，但是一个组合，一个继承。 工厂方法是模板方法的一个特殊版本。 适配器模式 适配器使得新的调用可以适配老的接口而不需要修改旧的代码。达到了对拓展开发，对修改关闭的设计原则。\n定义：\n适配器将一个类的接口，转换成客户端期望的另一个接口。适配器让原本不兼容的类达到兼容。（可以让客户从实现的接口解耦）\nUSB转接头就是一个适配器！\n架构:\n在支持多重继承的语言中，可以使用类适配器是这样的：\n使用场景：\n一般来说，适配器模式可以看作是一宗“补偿模式”，用来补救设计上的缺陷，也是一种无奈之举。一般也不会优先推荐使用这种模式。 封装有缺陷的接口\n例如外部引入的接口都是静态方法，会影响代码的可测试性。此时使用适配器进行适配接口，将静态方法都“封装“起来，这样就可以进行测试了。\n”缺陷“可以理解为在某些方面不足。通过封装之后达到解决问题的效果就是适配器作用。\n替换依赖的外部系统\n当需要将外部依赖的一个系统替换成另一个系统的时候，也就是一些系统迁移或者接口切换的场景，使用适配器模式可以减少对代码的改动。\n兼容老版本的接口\n在进行一些版本升级的时候，对于一些废弃的接口，我们不会直接删除，而是暂时保留，并且标注为deprecate，并且将内部实现逻辑委托为新的实现逻辑。\n例如JDK中包含一个遍历集合容器的类Enumeration，JDK2.0对这个类进行了重构，将它改名为Iterator类，并且对它的代码实现做了优化。但是如果将Enumeration直接从JDK2.0删除，那么那些从JDK1.0升级到JDK2.0的项目，就会编译报错。但是修改散落在各处的Enumeration调用又多又杂，导致升级困难。为了避免这种情况，可以暂时保留Enumeration类，并且将其内部实现替换为Iterator的实现。\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 public class Collections { public static Emueration emumeration(final Collection c) { return new Enumeration() { Iterator i = c.iterator(); public boolean hasMoreElments() { return i.hashNext(); } public Object nextElement() { return i.next(): } } } } 装饰器包装一个实现同一个接口的类对象，添加一些责任，并且接口不变；适配器则包装实现不同接口的被适配的对象，进行接口的转换和适配，以达到兼容的效果。 工厂方法模式 工厂方法模式: 相对于直接new来创建对象，用工厂模式来创建会更加灵活 当我们使用new创建一个对象的时候，需要指定一个具体类，这就是针对实现进行编程。当我们将创建对象的过程封装成一个方法或者接口的时候，就可以避免针对实现编程，变成针对接口编程。\n定义：\n工厂方法模式定义了一个创建对象的接口，但由子类决定要实例化的类是哪一个。工厂方法将实例化推迟到子类。\n核心在将创建对象的过程解耦出来。\n架构：\n工厂模式体现了一个原则：依赖倒置原则。（Spring叫依赖反转）\n关键点:\n工厂只有一个功能——创建指定的类。（单一职责） 将原来的if-else判断，转换成对象进行处理。 抽象成一个方法 -》 抽象成一个类 -〉 抽象成一个接口 抽象工厂模式\n定义：抽象工厂模式提供一个接口，用于创建相关或者依赖对象的家族，而不需要明确指定具体类\n架构：\nclassDiagram class AbstractFactory { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + createProductA() + createProductB() } class ConcreteFactoory1 { + createProductA() + createProductB() } class ConcreteFactoory2 { + createProductA() + createProductB() } class AbstractProductA { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttA1 class ProducttA2 ProducttA1 ..|\u0026gt; AbstractProductA : 实现 ProducttA2 ..|\u0026gt; AbstractProductA : 实现 class AbstractProductB { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; } class ProducttB1 class ProducttB2 ProducttB1 ..|\u0026gt; AbstractProductB : 实现 ProducttB2 ..|\u0026gt; AbstractProductB : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory1 : 实现 AbstractFactory \u0026lt;|.. ConcreteFactoory2 : 实现 ConcreteFactoory1 --\u0026gt;ProducttA1 : 创建 ConcreteFactoory1 --\u0026gt;ProducttB1 : 创建 ConcreteFactoory2 --\u0026gt;ProducttA2 : 创建 ConcreteFactoory2 --\u0026gt;ProducttB2 : 创建 抽象工厂模式类似于一个二维的分类，将更加复杂的系统进行整理并且划分。以达到解耦的效果。\n使用场景：\n建造者模式 建造者模式: 建造者模式主要是为了解决调用构造函数的时候，参数太多，并且有一些是可选参数不填的情况。这种情况下，使用建造者模式会更加灵活。 待补充\u0026hellip;\u0026hellip;\n命令模式 命令模式: 命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。 定义：\n命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象。命令模式也可以支持撤销的操作。\n命令模式主要是将“命令的请求者”从“命令的执行者”对象中解耦。\n架构：\n命令模式对象可以包含接受者的引用，也可以不包含，因为在远程调用的情况下，不能获取引用。\n使用场景：\n异步、延迟、排队执行命令、撤销重做命令、存储命令、命令记录日志 Hystix熔断框架就用到了命令模式 redis使用命令模式处理指令 组合模式 z组合模式: 组合模式跟我们之前讲的面向对象设计中的“组合关系(通过组合来组装两个类)”，完全是两码事。这里讲的“组合模式”，主要是用来处理树形结构数据 定义：\n组合模式允许你将对象组合成树形结构来表示“整体/部分”的层次结构。组合能够让客户以一致的方式处理个别对象以及对象组合。\n架构：\n使用场景：\n使用组合模式的前提在于，你的业务场景必须能够表示成树形结构。所以，组合模式的应用场景也比较局限，它并不是一种很常用的设计模式。\n需要理解“整体和部分”的关系。\n装饰器模式 装饰器模式: 装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案 定义：\n装饰器模式动态的将责任附加到对象上，若要拓展功能，装饰者提供了比继承更有弹性的替代方案。\n架构：\nclassDiagram class Component { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateComponent { + methodA() + methodB() } class Decrator { \u0026lt;\u0026lt;abstract\u0026gt;\u0026gt; + methodA() + methodB() } class ConcreateDecratorA { + methodA() + methodB() + newMethod() } class ConcreateDecratorB { + methodA() + methodB() } ConcreateComponent --|\u0026gt; Component : 继承 Decrator --|\u0026gt; Component : 继承 ConcreateDecratorA --|\u0026gt; Decrator : 继承 ConcreateDecratorB --|\u0026gt; Decrator : 继承 装饰的技巧可以在不修改任何底层代码的情况下增强功能。\n使用场景：\nJava IO类库（InputStream、OutputStream）\n在不影响其他对象的情况下，以动态、透明的方式给单个对象添加职责。\n使用装饰器模式，常常造成设计中有大量的类 迭代器模式 迭代器模式: 迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示 定义：\n迭代器模式提供了一种方法顺序访问一个聚合对象中的各个元素，而不暴露其内部的表示。\n迭代器模式封装了遍历。并且迭代器模式还将在元素之间进行游走的责任交给迭代器，使得职责更加单一。\n架构：\n使用场景：\nJava Iterator 解耦容器代码和遍历代码，使得职责更加单一 观察者模式 观察者模式: 一个比喻，报纸订阅（出版者和订阅者） 定义：\n观察者模式定义了对象之间的一对多依赖，这样一来，当一个对象改变状态时，它的所有依赖者都会收到通知并且自动更新。\n一个比喻：报纸订阅（出版者和订阅者）\n架构：\nclassDiagram class Subject { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + registerObserver() + removeObserver() + notifyObserver() } class ConcreteSubject { - List\u0026lt;Observer\u0026gt; observers + registerObserver() + removeObserver() + notifyObserver() } class Observer { \u0026lt;\u0026lt;interface\u0026gt;\u0026gt; + update() } class ConcreteObeserver { - Subject subject + update() } Subject --\u0026gt; Observer : 多个观察者 ConcreteSubject ..|\u0026gt; Subject : 实现 ConcreteObeserver ..|\u0026gt; Observer : 实现 ConcreteObeserver --\u0026gt; ConcreteSubject : 订阅主题 观察者依赖主题。观察者模式提供了一种对象设计，让主题和观察者之间松耦合。他们依然可以交互，但是不必清楚彼此的细节。\n使用场景：\n消息队列 回调就是一种观察者模式 Google EventBus 邮件订阅 RSS 反应式RxJava JDK(CompletableFuture) 代理模式 代理模式: 代理模式为另一个对象提供一个替身或者占位符以控制这个对象的访问 定义：\n代理模式为另一个对象提供一个替身或者占位符以控制这个对象的访问。\n架构：\n使用场景：\n远程代理：远程代理可以作为另一个JVM上对象的本地代表。常见的是RPC框架。 虚拟代理：虚拟代理作为创建开销大的对象的代表。当对象没有得到的情况下执行一些操作。常见的是图片的加载。 缓存代理：缓存代理会维护之前的对象，在可能的情况下会返回缓存对象。 保护代理：可以根据客户的角色来决定是否允许客户访问特定的方法。（Java动态代理） 其他代理：\n防火墙代理：控制网络资源的访问，保护访问坏网络。 智能引用代理：例如计算一个对象被引用的次数。 同步代理：在多线程的情况下为主题提供安全的访问。 写入时复制代理：用于控制对象的复制，方法是延迟对象的复制，发那个客户真的需要（也就是需要写入时）才进行复制。是虚拟代理的变体。（Java5的CopyOnWriteArrayList） 装饰器模式是为对象增加行为，而代理模式是控制对象的访问。 适配器会改变对象适配的接口，而代理则实现相同的接口 外观模式 外观模式: 外观模式也叫做门面模式，外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用 定义：\n外观模式定义了一个统一的接口，用来访问子系统中的一群接口。外观定义了一个高层接口，让子系统更容易使用。\n外观模式可以解决接口的复用性和易用性的问题，并且，外观模式可以让层级更加清晰，满足最少知识原则，让暴露的接口或者函数更加少。\n架构：\n使用场景：\n解决易用性\n当接口越来越多，越来越复杂的时候，提供一层更加简单易用，更加高层的接口。例子：Linux系统调用函数封装了Linux内核调用、Linux的Shell命令封装了复杂的系统调用。\n单独起起一个API网关层服务做转发和聚合也很类似门面设计模式。\n解决性能问题\n将多个接口调用封装成一个简单的门面接口，在一些需要多次请求的网络通信中可以减少通信的次数，降低网络通信的成本，提高APP响应的速度。\n解决分布式事务问题\n门面接口可以将一个事务的多个接口封装在一个接口中，方面进行事务的回滚或者重试。\n适配器是做接口转换，解决的是原接口和目标接口不匹配的问题。门面模式做接口整合，解决的是多接口调用带来的问题。 适配器模式注重的是兼容性，而门面模式注重的是易用性。 复合模式 复合模式属于是模式的模式了。复合模式在一个解决方案中结合两个或者多个模式，以解决一般或者重复发生的问题。\nMVC架构（模型、视图、控制器）就使用了多种设计模式的复合。其中包括：观察者模式、策略模式、组合模式。\n观察者模式：模型通知视图和控制器关于自己的改变。 策略模式：视图和控制器实现了策略模式，视图可以有多个控制器，相当于有多个策略行为可以互相替换。 组合模式：视图内通过组合模式管理窗口显示。 Reference:\n","description":"设计模式是前人总结的经验。","id":14,"section":"zh","tags":["设计模式","开发方法论"],"title":"理解设计模式","uri":"https://hugo.jiahongw.com/en/zh/posts/dev/design-pattern/"},{"content":"出发前的准备 我这里列了一个大致的攻略（虽然最后崂山没去成）：\n青岛攻略\n还准备了一个行程路线：\n第一站 我们下车的地方是青岛站，一下来，就是一种欧式建筑的感觉，这就是青岛的特色吗\n看海 来青岛怎么能不看海，青岛三面环海，来的这几天，海浪还挺大，吹着挺舒服\n波涛汹涌\n有意境的一瞬间\n青岛标志性建筑——栈桥\n吃海鲜 在青岛吃海鲜🦞，喝🍺啤酒。\n买海鲜\n找别人加工\n逛青岛街头 在十月份的青岛树木非常绿，而且青岛的街道也很有特色，就是那种林荫道的感觉，让人很舒服\n青岛的道路命名很有意思，都是拿其他省名作为道路名，据说青岛的版图就是一个小型的中国\n夜晚在教堂还有人组织一起看电影，好久没有这样的文艺活动了\n光圈内的人\n夜晚的街道和行人\n总结 青岛是一个非常漂亮的城市，非常适合旅游。青岛不仅有海，有海鲜，还有很多美女。此行前前后后也做了一些攻略，其实攻略是次要的，不一定非要将攻略中的各个景点都逛了才算完美，在行程中享受过程才是更重要的。\n彩蛋～\n","description":"国庆期间，去了一趟青岛。","id":15,"section":"zh","tags":["青岛","生活","旅行"],"title":"青岛之旅","uri":"https://hugo.jiahongw.com/en/zh/posts/life/qingdao-travel/"},{"content":"The photo about Beijing with me.📹\n","description":"记录北京的照片生活","id":16,"section":"zh","tags":[null],"title":"北京","uri":"https://hugo.jiahongw.com/en/zh/gallery/beijing/"},{"content":"配置信息 git的config的信息又一个全局的配置文件，也有一个局部（当前git项目）的配置文件。他们的位置分别在：\n全局配置文件.gitconfig：~/.gitconfig(用户根目录下)\n局部配置文件.gitconfig：.git/config(当前项目下相对路径)\n配置文件内容：\n[core] editor = vim [color \u0026#34;diff\u0026#34;] whitespace = red reverse [include] path = ~/.gitconfig.user [user] name = xxx email = xxx@xxx.com 配置文件的信息主要包括：\ngit使用的编辑器\ndiff的配置\ninclude可以包括用户的自定义信息\n用户的信息（用户名和邮箱）\n配置多个账号：\nMac配置多个Git账号，例如一个公司账号，一个个人账号。\nhttps://www.jianshu.com/p/698f82e72415\n首先unset全部全局的数据，然后参考上面的分别设置多个账号的公钥。最后设置config的时候，公司的不设置，直接设置成global的。\n其他无需更改。\n通过命令行进行配置 设置用户信息：\n1 2 3 # 设置提交代码时的用户信息 $ git config [--global] user.name \u0026#34;[name]\u0026#34; $ git config [--global] user.email \u0026#34;[email address]\u0026#34; 查看git配置信息：\n1 2 3 4 # 局部配置信息 git config --list # 全局配置信息 git config --global --list 编辑git配置信息可以使用命令行打开：\n1 2 # 编辑Git配置文件 $ git config -e [--global] 修改远程仓库的地址信息：\n1 2 3 4 5 6 # 设置远程地址 git remote set-url origin [url] # 删除本地地址 git remote rm origin # 没有设置远程地址的情况下使用此命令添加远程仓库地址 git remote add origin [url] 通过配置文件进行修改 [user] name = 用户名 email = 邮箱 [remote \u0026#34;origin\u0026#34;] url = 远程仓库地址 fetch = +refs/heads/*:refs/remotes/origin/* [branch \u0026#34;master\u0026#34;] remote = origin merge = refs/heads/master 配置git代理源 常见的 github 加速方法如修改 hosts 文件、魔法上网、设置 proxy 等方法。\n加速地址一览 **fastgit.org：**https://doc.fastgit.org/ **cnpmjs.org：**https://github.com.cnpmjs.org/ **gitclone.com：**https://gitclone.com/ **gitee：**https://gitee.com/mirrors GitHub 文件加速：https://gh.api.99988866.xyz/ Github 仓库加速：https://github.zhlh6.cn/ Github 仓库加速：http://toolwa.com/github/ github 国内镜像服务加速 不进行多余网络配置的情况下，直接使用提供了 github 国内镜像服务的网站进行 github 各种资源拉取加速。\n加速clone：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # 方法一：手动替换地址 #原地址 $ git clone https://github.com/kubernetes/kubernetes.git #改为 $ git clone https://github.com.cnpmjs.org/kubernetes/kubernetes.git #或者 $ git clone https://hub.fastgit.org/kubernetes/kubernetes.git #或者 $ git clone https://gitclone.com/github.com/kubernetes/kubernetes.git # 方法二：配置git自动替换 $ git config --global url.\u0026#34;https://hub.fastgit.org\u0026#34;.insteadOf https://github.com # 测试 $ git clone https://github.com/kubernetes/kubernetes.git # 查看git配置信息 $ git config --global --list # 取消设置 $ git config --global --unset url.https://github.com/.insteadof 加速 release:\n1 2 3 4 5 6 # 原地址 wget https://github.com/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgz # 加速下载方法一 wget https://download.fastgit.org/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgz # 加速下载方法二 wget https://hub.fastgit.org/goharbor/harbor/releases/download/v2.0.2/harbor-offline-installer-v2.0.2.tgz 加速 raw:\n1 2 3 4 5 6 # 原地址 $ wget https://raw.githubusercontent.com/kubernetes/kubernetes/master/README.md # 加速下载方法一 $ wget https://raw.staticdn.net/kubernetes/kubernetes/master/README.md # 加速下载方法二 $ wget https://raw.fastgit.org/kubernetes/kubernetes/master/README.md 设置proxy 命令行设置和取消代理：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 git config --global https.proxy http://127.0.0.1:1080 git config --global https.proxy https://127.0.0.1:1080 git config --global --unset http.proxy git config --global --unset https.proxy #只对github.com git config --global http.https://github.com.proxy socks5://127.0.0.1:1080 #取消代理 git config --global --unset http.https://github.com.proxy) npm config delete proxy 配置文件配置：\n[http] proxy = socks5://127.0.0.1:1080 [https] proxy = socks5://127.0.0.1:1080 #只对github.com 方案2 [http \u0026#34;https://github.com\u0026#34;] proxy = socks5://192.168.10.120:7890 注意：\n1, https.proxy设置是无用的, 只需要设置http.proxy\n2, socks5h://更好, 远端DNS\nRef：\n无需代理直接加速各种 GitHub 资源拉取 | 国内镜像赋能 | 助力开发 - Frytea\u0026rsquo;s Blog git 设置和取消代理 Linux安装并使用ssr客户端 - 灰鹦鹉 关键命令 下图展示了常用的git命令：\n基本操作 1 2 3 4 5 6 7 8 9 # 初始化git仓库 git init # 添加文件到暂存区域 git add filename #添加所有更改的文件到暂存区 git add . (git add --all) # 提交 git commit # 提交到远程仓库 删除git add操作的文件\n1 2 3 4 # 删除工作区文件，并且将这次删除放入暂存区 git rm [file1] [file2] .. # 改名文件，并且将这个改名放入暂存区 git mv [file-original] [file-renamed] 撤销更改 未commit，需要取消更改 已经git add的情况下，使用git checkout . 取消更改。\n已commit，需要取消更改 关键字：checkout，clean\n$ git checkout # 撤销项目下所有的修改 $ git checkout . # 撤销当前文件夹下所有的修改 $ git checkout xx/xx.py xx/xx2.py # 撤销某几个文件的修改 $ git clean -f # untracked状态，撤销新增的文件 $ git clean -df # untracked状态，撤销新增的文件和文件夹 最好不要使用git clean这个命令。\n删除commit\n版本回退 hash_value是在git log查询到的对应提交的哈希值。\ngit reset --hard hash_value 也可以\n$ git reset --hard origin/master # 回退与本地远程仓库一致 $ git reset --hard HEAD^ # 回退到本地仓库上一个版本 $ git reset --hard \u0026lt;hash code\u0026gt; # 回退到任意版本 $ git reset --soft/git reset # 回退且回到已修改状态，修改仍保留在工作区中。 Git标签tag的使用 git stash使用 Git区域 工作区(Working Area) 暂存区(Stage) 本地仓库(Local Repository) 远程仓库(Remote Repository) 状态 未修改(Origin) 已修改(Modified)\u0026amp;未追踪(Untracked) 已暂存(Staged) 已提交(Committed) 已推送(Pushed) git add . 是把文件添加到暂存区中。\ngit commit 把暂存区中的所有内容提交到当前分支。\ngit push 是将本版本库库中的当前的修改版本推送到远程仓库。\ngit pull 将远程仓库的修改版本推送到本地版本库中\n取消commit：\n# 不删除工作空间改动代码 git reset --soft HEAD^ 几个参数：\n–mixed：不删除工作空间改动代码，撤销conmit，并且撤销git add .操作。（这个参数为默认参数） –soft：不删除工作空间改动代码，撤销commit，不撤销git add . –hard：删除工作空间改动代码，撤销commit，撤销git add . 添加远程仓库：\n冲突解决 强制提交：git push origin branch-name \u0026ndash;force 在进行pull和push的时候或者merge的时候，可能会发生冲突，这个时候需要我们手动进行修改冲突的内容。\ngit 合并多个commit 最简单的单步操作方法：\n# 使用一次新的commit，替代上一次提交 # 如果代码没有任何新变化，则用来改写上一次commit的提交信息 $ git commit --amend -m [message] 重置上次commit的信息：\n# 重做上一次commit，并包括指定文件的新变化 $ git commit --amend [file1] [file2] ... 压缩当前版本到指定版本之间的commit为一个commit（不包括命令中的commit）：\ngit log git rebase -i 版本 版本不参与合并，文件中最上边的commit不需要修改s。\n可以删除不需要的commit\n之后选择需要合并的commit的前面的pick改为s，然后保存推出，有冲突按照提示修改即可。\nGit将单个commit拆分成多个commit 参考：Git : 如何将一个commit拆分成多个 | 一个程序员的自我修养\nGit查看某次提交的内容 1 git show commitId 查看某个文件某次提交的内容:\n1 git show commitId fileName git 分支操作 游戏学习分支操作：https://learngitbranching.js.org/?locale=zh_CN\nHEAD表示当前的分支节点：\n使用 ^ 向上移动 1 个提交记录 使用 ~\u0026lt;num\u0026gt; 向上移动多个提交记录，如 ~3 我使用相对引用最多的就是移动分支。可以直接使用 -f 选项让分支指向另一个提交。例如:\ngit branch -f main HEAD~3 上面将main分支移动到当前节点的前三个提交。\nclone指定分支：\n1 git clone -b master http://gitslab.yiqing.com/declare/about.git 更新远程分支：\n1 git remote update origin --prune rebase的坑\n撤销操作：\n虽然在你的本地分支中使用 git reset 很方便，但是这种“改写历史”的方法对大家一起使用的远程分支是无效的哦！\n为了撤销更改并分享给别人，我们需要使用 git revert。来看演示：\n这里要注意下，如果你的remote branch不是在origin下，按你得把origin换成你的名字。\n合并分支到此分支:\n1 2 # 合并master分支到此分支 git merge master 合并到目标分支：\n1 2 # 合并此分支到master分支 git rebase master 列出所有分支：\n# 列出本地所有分支 git branch # 列出本地和远程所有分支 git branch -a 删除分支：\n# 删除分支 $ git branch -d [branch-name] # 删除远程分支 $ git push origin --delete [branch-name] $ git branch -dr [remote/branch] 新建和切换分支：\n1 2 3 4 5 6 7 8 9 10 # 创建dev分支 git branch dev # 切换到dev分支 git checkout dev # 创建dev分支并且切换到该分支 git checkout -b dev # 新建一个分支，指向指定commit git branch [branch] [commit] # 切换到上一个分支 git checkout - 重命名分支（本地不存在feature/ones分支）：\n# 把远端feature/ones分支名称重命名为feature/12345/ones git checkout -b feature/ones origin/feature/ones git pull 重命名feature/ones分支\ngit branch -m feature/ones feature/12345/ones 提交分支 提交到feature/12345/ones分支\ngit push origin feature/12345/ones 删除远端分支 删除远端feature/ones分支\ngit push -d feature/ones 合并分支 将文件合并到master，即合并dev分支到master中去\ngit merge dev 拉取远程分支：\n1 2 3 4 # 拉取远程分支并创建本地分支 git checkout -b 本地分支名x origin/远程分支名x # 拉取远程分支，但是不切换到该分支 git fetch origin 远程分支名x:本地分支名x 查看本地分支与远程分支的映射关系\n1 git branch -vv 建立当前分支与远程分支的映射关系:\n1 2 git branch -u origin/addFile git branch --set-upstream-to origin/addFile 撤销本地分支与远程分支的映射关系:\n1 2 git branch --unset-upstream ref:git upstream\n\u0026lt;++\u0026gt;\n代码回滚 冲突解决 生成发布压缩包\ngit archive 标签使用 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 # 列出所有tag $ git tag # 新建一个tag在当前commit $ git tag [tag] # 新建一个tag在指定commit $ git tag [tag] [commit] # 删除本地tag $ git tag -d [tag] # 删除远程tag $ git push origin :refs/tags/[tagName] # 查看tag信息 $ git show [tag] # 提交指定tag $ git push [remote] [tag] # 提交所有tag $ git push [remote] --tags # 新建一个分支，指向某个tag $ git checkout -b [branch] [tag] Git规范 分支命名 master 分支\nmaster 为主分支，也是用于部署生产环境的分支，确保master分支稳定性\nmaster 分支一般由develop以及hotfix分支合并，任何时间都不能直接修改代码\ndevelop 分支\ndevelop 为开发分支，始终保持最新完成以及bug修复后的代码\n一般开发的新功能时，feature分支都是基于develop分支下创建的\nfeature 分支\n开发新功能时，以develop为基础创建feature分支\n分支命名: feature/ 开头的为特性分支， 命名规则: feature/user_module、 feature/cart_module\nrelease分支\nrelease 为预上线分支，发布提测阶段，会release分支代码为基准提测 当有一组feature开发完成，首先会合并到develop分支，进入提测时，会创建release分支。\n如果测试过程中若存在bug需要修复，则直接由开发者在release分支修复并提交。\n当测试完成之后，合并release分支到master和develop分支，此时master为最新代码，用作上线。\n复制代码\nhotfix 分支\n分支命名: hotfix/ 开头的为修复分支，它的命名规则与 feature 分支类似\n线上出现紧急问题时，需要及时修复，以master分支为基线，创建hotfix分支，修复完成后，需要合并到master分支和develop分支\n日志规范 当前业界应用的比较广泛的是 Angular Git Commit Guidelines\nCommit message格式：\n每次提交，Commit message 都包括三个部分：header，body 和 footer。\n\u0026lt;type\u0026gt;(\u0026lt;scope\u0026gt;): \u0026lt;subject\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;body\u0026gt; \u0026lt;BLANK LINE\u0026gt; \u0026lt;footer\u0026gt; 其中，header 是必需的，body 和 footer 可以省略。\ntype: 本次 commit 的类型，诸如 bugfix docs style 等\nscope: 本次 commit 波及的范围\nsubject: 简明扼要的阐述下本次 commit 的主旨，在原文中特意强调了几点 1. 使用祈使句，是不是很熟悉又陌生的一个词，来传送门在此 祈使句 2. 首字母不要大写 3. 结尾无需添加标点\nbody: 同样使用祈使句，在主体内容中我们需要把本次 commit 详细的描述一下，比如此次变更的动机，如需换行，则使用 |\nfooter: 描述下与之关联的 issue 或 break change，详见案例\nHeader部分只有一行，包括三个字段：type（必需）、scope（可选）和subject（必需）。\nfeat: 添加新特性 fix: 修复bug docs: 仅仅修改了文档 style: 仅仅修改了空格、格式缩进、都好等等，不改变代码逻辑 refactor: 代码重构，没有加新功能或者修复bug perf: 增加代码进行性能测试 test: 增加测试用例 chore: 改变构建流程、或者增加依赖库、工具等 使用gitmoji：🔨 [git]: Write better commits with Gitmoji - DEV Community\n最佳实践 本地代码双分支，一个提交分支，一个开发分支。\n假如从远程仓库那边拉取的分支是\ngit commit \u0026ndash;amend修改push到远程分支的提交\nhttps://blog.csdn.net/ecjtuhq/article/details/80358656\n参考：\nhttps://blog.csdn.net/ivan820819/article/details/78816578\nhttps://segmentfault.com/a/1190000007748862\nhttps://www.jianshu.com/p/964de879904a\nhttps://blog.csdn.net/huangjhai/article/details/109557946\nhttps://juejin.cn/post/6844903635533594632\nhttps://segmentfault.com/a/1190000009048911\nhttps://www.cnblogs.com/jiuyi/p/7690615.html\nhttps://www.ruanyifeng.com/blog/2015/12/git-cheat-sheet.html\n","description":"记录git的常用操作和一些实际遇到的问题。","id":17,"section":"zh","tags":["git","开发方法论"],"title":"git使用笔记","uri":"https://hugo.jiahongw.com/en/zh/posts/dev/git-note/"},{"content":" Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否解决一些初级的编程问题，解决问题的能够得到100美元，非常有意思。对于我们来说这些问题非常的简单，但是对于普通人来说，还是有一定的难度的。似乎在芝加哥的街头上也会编程的也不是挺多人，或者，程序猿都在上班吧🐶。\n在第二期的问题变得比较难一点，是college水平的，解决问题的能够得到200美元。后面那个熟悉的判断回文串😄。\n想象这个活动要是在中国试一试，感觉街头很多人能够做出来，因为中国的程序员越来越多了。\n","description":"Youtube中的一个非常有意思的视频活动。在芝加哥的大街上，看看路人能否姐姐一些初级的编程问题。","id":18,"section":"zh","tags":["编程","youtube"],"title":"街头代码编程","uri":"https://hugo.jiahongw.com/en/zh/posts/see/code-problem-solving-onstreet/"},{"content":"极化编码的基本思想是：只在$Z\\left( W_{N}^{\\left( i \\right)} \\right)$近于0的坐标信道$W_{N}^{\\left( i \\right)}$上发送数据比特。极化码具有一般的二元线性分组码的基本编码要素，因而可以通过显示地写出其生成矩阵来完成编码：\n$$\nx_{1}^{N}=u_{1}^{N}{G_{N}}\n$$\n其中，编码生成矩阵${G_{N}}\\text{=}{B_{N}}{F^{\\otimes n}}$，$B_{N}$是排序矩阵，完成比特的反序操作，$F^{\\otimes n}$表示矩阵$F$进行$n$次$Kronecker$积操作，有递归公式${F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}$且${F^{\\otimes 1}}\\text{=}F=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]$。\n主要的步骤为：\n可靠性估计 可靠性估计就是极化码的构造，这个过程我们选出信道容量高的子信道进行传输，信道容量低的子信道传输冻结比特。\n常见的几种可靠性估计的方法（极化码构造方法）有：\n巴士参数估计法。\n蒙特卡洛法。\n密度进化法。\n高斯近似法。\n比特混合 假设通过错误概率进行极化码构造之后得到极化序列为$\\left{ 3,5,6,7,0,1,2,4 \\right}$ ，选择前面K个信道即$A=\\left{ 3,5,6,7\\right}$发送信息比特；另外的信道集合${A^{c}}=\\left{ 0,1,2,4\\right}$作为固定比特传输。设信息比特集合为$\\left( {i_{0}},{i_{1}},{i_{2}},{i_{3}} \\right)=\\left( 1,1,1,1 \\right)$，固定比特设置为0，则最终得到待编码的信息比特：\n$$\nu_{0}^{7}=\\left[ 0,0,0,{i_{0}},0,{i_{1}},{i_{2}},{i_{3}} \\right]=\\left[ 0,0,0,1,0,1,1,1 \\right]\n$$\n经过上面的过程我们就完成了对信息位和冻结位的比特混合。\n构造生成矩阵 首先我们求出排序矩阵$B_{N}$，其有递归式：\n$$\n{B_{N}}={R_{N}}\\left( {I_{2}}\\otimes {B_{N/{2};}} \\right)\n$$\n$$\n{B_{2}}={I_{2}}\n$$\n我们得到排序矩阵$B_{N}$，对输入序列完成奇序元素和偶序元素的分离，即先排奇序元素，再排偶序元素，其作为效果如下:\n$$\n\\left( {u_{1}},{u_{2}},{u_{3}},{u_{4}},\u0026hellip;,u{}{N} \\right)\\times {R {N}}=\\left( {u_{1}},{u_{3}},{u_{5}},\u0026hellip;,{u_{N-1}},{u_{2}},{u_{4}},{u_{6}},\u0026hellip;,{u_{N}} \\right)\n$$\n$F$矩阵我们可以根据下面的递归式进行求解：\n$$\n{F^{\\otimes n}}=F\\otimes {F^{\\otimes \\left( n-1 \\right)}}\n$$\n$$\nF=\\left[ \\begin{matrix}\n1 \u0026amp; 0 \\\n1 \u0026amp; 1 \\\n\\end{matrix} \\right]\n$$\n最后，我们将求得的排序矩阵和$F$矩阵相乘，得到生成矩阵$G_{N}$：\n$$\n{G_{N}}={B_{N}}{F^{\\otimes n}}\n$$\n假设我们求得的生成矩阵是：\n生成极化码 将信息比特与生成矩阵$G_{N}$相乘得到最终编码后的极化码，例如：\n参考：\nPolar Code（2）编码原理 | Marshall - Comm. Tech. Blog ","description":"极化码的编码就是一些简单的线性运算，通过矩阵进行简化多维的运算，归根到底还是基于基本的异或操作。","id":19,"section":"zh","tags":["极化码"],"title":"极化码-编码","uri":"https://hugo.jiahongw.com/en/zh/posts/polarcode/polar-code-encode/"},{"content":"基本概念 信噪比 信噪比，英文名称叫做SNR（SIGNAL-NOISE RATIO )，是指一个电子设备或者电子系统中信号与噪声的比例。信噪比的计算可以为有用信号功率与噪声功率的比 ：\n$$\nSNR = \\frac {P_{signal}} {P_{noise}}\n$$\n它的单位一般使用分贝，其值为十倍对数信号与噪声功率比:\n$$\nSNR(dB) = 10\\log_{10}(\\frac {P_{sibnal}} {P_{noise}})\n$$\n其中，$P_{signal}$为信号功率，$P_{noise}$为噪声功率。\n转移概率 一个二进制输入离散无记忆信道（B-DMC）可表示为$W:X\\to Y$，$X$是输入符号集合，$Y$是输出符号集合，转移概率为$W\\left( y|x \\right),x\\in X,y\\in Y$。由于信道是二进制输入，集合$X=\\left{ 0,1 \\right}$；$Y$和$W\\left( y|x \\right)$是任意值。对信道$W$的$N$次使用后的信道可表示为${W^{N}}$，则信道${W^{N}}:{X^{N}}\\to {Y^{N}}$的转移概率为：\n$$\n{W^{N}}\\left( y_1^{N}|x_{1}^{N} \\right)=\\prod\\nolimits_{i=1}^{N}{W\\left( y|x \\right)}\n$$\n对称容量 对称容量是对信道速率的度量，记作$I(W)$，表示信道$W$在等概率输入下的可靠传输时的最大速率,计算公式如下：\n$$\nI\\left( W \\right)\\triangleq \\sum\\limits_{y\\in Y}{\\sum\\limits_{x\\in X}{\\frac{1}{2}}}W\\left( y|x \\right)\\log \\frac{W\\left( y|x \\right)}{\\frac{1}{2}W\\left( y|0 \\right)+\\frac{1}{2}W\\left( y|1 \\right)}\n$$\n当码长$N$趋近于无穷的时候，信道容量趋近于1的分裂信道比例约为$K=N×I(W)$，这部分是用来传输信息比特的信道数量，而信道容量趋近于0的比例约为$N×(1−I(W))$，这部分表示冻结比特的信道数量。对于信道容量为1的可靠信道，可以直接放置消息比特而不采用任何编码，即相当于编码速率为$R=1$；而对于信道容量为0的不可靠信道，可以放置发送端和接收端都事先已知的冻结比特，即相当于编码速率为$R=0$。那么当码长$N \\to\\infty$时，极化码的可达编码速率$R= \\frac {K}{N}= \\frac {N×I(W)}{N}=I(W)$，即在理论上，极化码可以被证明是可达信道容量的。\n信道极化 信道极化分为信道联合和信道分裂两个阶段。对于长度为$N={2^{n}}$（$n$为任意整数）的极化码，它利用信道$W$的$N$个独立副本，进行信道联合和信道分裂，得到新的$N$个子信道$\\left{ W_{N}^{\\left( 1 \\right)},W_{N}^{\\left( 2 \\right)},\u0026hellip;,W_{N}^{\\left( N \\right)} \\right}$。随着码长的增加，分裂之后的信道将向两个极端发展：其中一部分分裂信道会趋近于完美信道，即信道容量趋近于1的无噪声信道；而另一部分分裂信道会趋近于完全噪声信道，即信道容量趋近于0的信道。\n我们主要研究二进制离散无记忆信道，将上面的信道模型（包括BEC、BSC、AWGN）进行抽象，我们可以得出下面的信道传输模型：\n图中的W可以是BEC信道，也可以是BSC信道或者AWGN信道，其中I(W)为信道容量。\n信道联合 信道联合是将多个子信道进行蝶形的异或操作的过程。对于码长为N=2的极化码，我们可以通过下面的蝶形异或操作将两个信道进行混合：\n由上图可以发现，进行信道联合之后，坐标不同信道的信道容量发生了极化现象，有一个比特的信道信道容量$I(W)$增加了，另外一个比特的信道容量$I(W)$减少了。信道容量小的，我们称为差信道，信道容量大的，我们称为号好信道。因为进行了信道联合之后，因为要求得左边的信道$u1$，必须是在右边的信道$y1$和$y2$同时都收到的情况下才能够得出$u1$，所以$u1$的信道容量就是信道$y1$和$y2$的信道容量乘积；相应的，对于信道$u2$，只有$y1$和$y2$都收不到的情况下，才接收不到信道，所以它的信道容量$I(W)$为$2*0.5 - 0.5^{2}$。\n我们也可以使用一个二维表格来计算它们传输的概率：\ny1 y2 u1 u2 √ √ √ √ √ x x √ x √ x √ x x x x 由表格1可以发现，对于接收方收到的信号y1和y2，总共有4种情况，X表示该信道发生错误，未收到信道；√表示该信道收到了信道。对于子信道u1，在四种情况中，只有一种情况能够接受得到u1，也就是同时接收到y1和y2的情况,所以信道容量为1/4；而对于u2,只要能够收到y1或y2的任意一个它就能够解出来,根据信道极化理论，我们在进行极化的过程中，就已经知道信道u1的信道容量比较小，我们会把它作为冻结比特，填充为0，不传输信息比特，仅传输冻结比特，所以在没有接收到y2的情况下我们也能够得出u2。\n对于N=4的码长，我们可以递归的进行信道联合，如图，只不过相比于N=2的码长的极化码，我们需要增加一次的信道联合过程：\n按照这样不断的递归下去，到n级之后，可以得到递归的一般式：${W_{N/{2};}}$的2个独立副本联合产生信道${W_{N}}$，我们可以的到任意码长为$N=2^{n}$的极化码。\n信道分裂 信道分裂体现在信道联合之中 ，参考文献中对于信道分裂的解释，其大致过程是将两个信道$W_{N/2}$联合成一个信道$W_N$之后，再将联合的信道$W_N$分裂成两个子信道$W_{N/2}$，此时，这两个子信道的转移概率也改变了，这样极化码就完成了信道分裂。更具体的来说，它存在以下两个递推公式计算子信道的转移概率：\n$$\nW_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},u_{1}^{2i-2}|{u_{2i-1}} \\right)=\\sum\\limits_{u_{2i}}{\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)}\n$$\n$$\nW_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},u_{1}^{2i-1}|{u_{2i}} \\right)=\\frac{1}{2}W_{N/{2};}^{\\left( i \\right)}\\left( y_{1}^{N/{2};},u_{1,o}^{2i-2}\\oplus u_{1,e}^{2i-2}|{u_{2i-1}}\\oplus {u_{2i}} \\right)\\cdot W_{N/{2};}^{\\left( i \\right)}\\left( y_{N/{2};+1}^{N},u_{1,e}^{2i-2}|{u_{2i}} \\right)\n$$\n参考：\n《“太极混一”——极化码原理及5G应用》 ","description":"介绍关于极化码的一些基本的数学与计算原理，包括如何进行概率的转移的。","id":20,"section":"zh","tags":["极化码"],"title":"极化码-基本原理","uri":"https://hugo.jiahongw.com/en/zh/posts/polarcode/polar-code-fundamentals/"},{"content":"在通信过程中，物理层传输的就是电信号，假如我们只用0和1传输信号，并且这些信道互相都没有关系，我们称为二进制离散无记忆信道。信道模型是研究信道编码的基础，常见的几种信道模型分别有：二进制删除信道（BEC）、二进制对称信道（BSC）、高斯信道（AWGN）。设信道的输入和输出分别是长为N的序列，输入是x，输出是y，其信道的转移概率满足：\n$$\np\\left( {y|x} \\right) = \\sum_{i=1}^N p\\left( {y_{i} | x_{i}} \\right)\n$$\n无损信道 无论发送任何消息，接受方都能够准确无误的接收到，并且不会发生错误，那么这个信道就可以说是一个无损信道。最简单的的就是下面这个模型，不管发送者发送的是0还是1，接收者接受的都是一致的。\n假如我们随机进行传输0或者1的数据，其传输的数值图为下面：\n二进制删除信道 二进制删除信道，简记为BEC（Binary Erasure Channel ）。ϵ称为删除概率，表示有ϵ的概率这个信号会丢失。当接收方得到一个位，它是100%确定的位是正确的。只有当位被擦除时，才会出现唯一的混淆。对于二进制离散无记忆信道，我们有ϵ的概率丢失0或者1的比特位。\nBEC的信道容量为：\n$$\nC= 1 - \\epsilon\n$$\n二进制对称信道 二进制对称信道，简记为BSC（Binary Symmetric Channel ）。p称为交叉概率，表示有p的概率会导致传输过程中0信号和1信号的错乱。（错乱的意思是发送0，收到却是1；或者发送1，收到却是0）\nBSC的信道容量为：\n$$\nC = \\log n + q\\log q + (1-q) \\log \\frac {1-q}{n-1}\n$$\n加性高斯白噪声信道 高斯信道，常指加权高斯白噪声（AWGN）信道。这种噪声假设为在整个信道带宽下功率谱密度（PDF）为常数，并且振幅符合高斯概率分布。\n一般来说，高斯信道需要配合BPSK机制进行调制，在传输之前，我们对0和1比特进行变换，比特0会变成1，比特1变成-1，而这个将比特进行转换的过程就是BPSK调制，最后在BPSK调制后再加上高斯噪声，实际的模型如下：。\n通过BPSK调制之后0比特和1比特都会向1和-1这两个临界线靠经，在这个情况下传入高斯信道，即使存在高斯噪声进行影响，我们也能够减小它的影响，在解码端对码字进行BPSK解调，能够得到较高的准确率。\n由图可以发现，值靠近1的信号表示原来的信号是0，值靠近-1的信号表示原来的信号是1。这样的好处是在传输过程中减少高斯噪声的干扰，让传输的信号更加稳定。\n特别的，5G标准要求信道编码至少能够在加性高斯白噪声信道（AWGN）下进行传输。\n","description":"在信息论中，信道是指信息传输的通道。我们在实际通信中所利用的各种物理通道是信道的最典型的例子，如电缆、光纤、电波传布的空间、载波线路等等。但是极化码的信道模型将他们进行了抽象，将信道分成了几类：BEC、BSC、AWGN。","id":21,"section":"zh","tags":["极化码","信道模型"],"title":"极化码-信道模型","uri":"https://hugo.jiahongw.com/en/zh/posts/polarcode/polar-code-channel-model/"},{"content":"Arıkan教授在文献[1]提出了串行抵消SC译码算法。SC译码算法类似一个深度优先搜索的算法，其根据两个判决函数进行迭代计算最大似然对数比LLR，两个判决函数分别叫做f函数和g函数。下面是这两个公式的计算方法：\n$$\n\\begin{align}\nf\\left( a,b \\right)=\\ln \\left( \\frac{1+{ {e}^{a+b}}}{ { {e}^{a}}+{ {e}^{b}}} \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\ng\\left( a,b,{ {u}{s}} \\right)={ {\\left( -1 \\right)}^{ { {u} {s}}}}a+b\n\\end{align}\n$$\n其中，$a,b\\in R,{ {u}_{s}}\\in \\left{ 0,1 \\right}$。LLR的递归运算借助函数f和g表示如下：\n$$\n\\begin{align}\nL_{N}^{\\left( 2i-1 \\right)}\\left( y_{1}^{N},\\hat{u}{1}^{2i-2} \\right)=f\\left( L {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}{1,o}^{2i-2}\\oplus \\hat{u} {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}_{1,e}^{2i-2} \\right) \\right)\n\\end{align}\n$$\n$$\n\\begin{align}\nL_{N}^{\\left( 2i \\right)}\\left( y_{1}^{N},\\hat{u}{1}^{2i-1} \\right)=g\\left( L {N/2}^{\\left( i \\right)}\\left( y_{1}^{ {N}/{2};},\\hat{u}{1,o}^{2i-2}\\oplus \\hat{u} {1,e}^{2i-2} \\right),L_{N/2}^{\\left( i \\right)}\\left( y_{ {N}/{2};+1}^{N},\\hat{u}{1,e}^{2i-2} \\right),{ { {\\hat{u}}} {2i-1}} \\right)\n\\end{align}\n$$\n递归的终止条件为当$N=1$时，即到达了信道$W$端，此时$L_{1}^{\\left( 1 \\right)}\\left( { {y}{j}} \\right)=\\ln \\frac{W\\left( { {y}{j}}|0 \\right)}{W\\left( { {y}_{j}}|1 \\right)}$。\nSC译码算法依靠一个蝶形单元，如图10，在计算的时候不断进行递归，但是必须是先计算出蝶形单元的上行比特，才能够调用g函数求出下行比特。即图10中必须使用f函数计算出u1，之后才能够通过g函数求出u2。在实际的计算过程中，从接收的比特进行递归执行f函数和g函数，其中假如编码每次进行一次极化，在译码阶段都会多一次递归的计算，中间的计算值就是进行极化的临时值，在一整个蝶形结构中体现，是一个深度优先的算法。\nSCL译码算法[3]类似树的广度优先遍历，它的好处就是能够进行剪枝操作，不用计算所有的节点。它从根节点开始往树底部进行广度遍历搜索，每一层会计算出一个估计比特，然后在这个估计比特的基础上往下进行估计下一个比特的值，另外，SCL译码算法还增加了惩罚因子，对于惩罚因子过高的节点，我们可以直接跳过它以及它子节点的计算，因为它是正确的码的可能性极低，这样排除了不可能的路径，同时，这也能达到对树进行剪枝的效果，提高译码的速度。图11展示了进行SCL译码的基本过程：\n","description":"译码和编码类似，基于递归的结构。","id":22,"section":"zh","tags":["极化码"],"title":"极化码-译码","uri":"https://hugo.jiahongw.com/en/zh/posts/polarcode/polar-code-decode/"},{"content":"出发前的准备 冲锋衣（防风，防晒，防雨，防寒） 登山鞋或者越野鞋 登山杖 帽子 防晒霜 一次性内裤和一次性雨衣 相机 厚的衣服 口罩 学生证 身份证 驾驶证 基本路线 小环线+稻城亚丁\n川西美景 合照 some word 大学四年一下就过去了，很高兴遇见了一群很棒的朋友。希望未来的我们也更加优秀！旅游真是一件又累又让人重新认识世界事情啊！\n","description":"在大学的最后一次和朋友的旅行......","id":23,"section":"zh","tags":["生活"],"title":"毕业旅行-川西","uri":"https://hugo.jiahongw.com/en/zh/posts/life/biyeluxing/"},{"content":"川西毕业旅行的图片。\n","description":"川西毕业旅行","id":24,"section":"zh","tags":null,"title":"川西旅行","uri":"https://hugo.jiahongw.com/en/zh/gallery/chuanxi/"},{"content":"5G下的极化码 这个专栏介绍极化码的相关原理，一方面是因为我目前的毕业设计是关于5G极化码方向的，另一方面我想将自己所学的一些知识记录或者分享起来。\n首先，我想要说的是，极化码是一种编码方式，它的目的是为了使得在传输过程中传输更多有效的消息，也可以理解为让传输更可靠的编码方式。当然，对于信道编码来讲，那最主要的就是编码和解码这两个板块。那什么是信道编码呢？可以这样理解：发送方先对发送的信息进行编码，通过信道进行传输，然后在接受方那边进行解码，得到消息，这就是信道编码的基本过程。我会在之后的文章中分析这些过程。\n主要分为如下几个板块：\n信道模型 极化码基本原理 极化码的编码 极化码的译码 极化码的构造（信道的选择） 极化码实现 ","description":"极化码已经入选5G的标准，是唯一一个被证明可以达到香农极限的一种编码方式。","id":25,"section":"zh","tags":["PolarCode"],"title":"5G下的极化码","uri":"https://hugo.jiahongw.com/en/zh/posts/polarcode/polar-code-intro/"},{"content":"需要从 UGameViewportClient 类继承 修改返回值为true,路径：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n1 virtual bool RequiresHitProxyStorage() override { return true; } 在FViewportClient类中新建DrawHitProxy函数 文件UnrealClient.h\n在GameViewportClient类中声明并且实现 声明：\\Source\\Runtime\\Engine\\Private\\GameViewportClient.h\n将GameViewportClient类中的函数Draw()内容复制到该函数DrawHitProxy，修改下面的的地方：\n修改FViewport类中的GetRawHitProxyData函数 在GetRawHitProxyData函数中进行以下的修改：Engine\\Source\\Runtime\\Engine\\Private\\UnrealClient.cpp\n调用\u0026ndash;获取屏幕坐标Hitproxy 相关类型 HHitProxy：用于检测用户界面命中的基类\nFHitProxyMap：从2D坐标到缓存命中代理的地图。\n参考：\nHow to select an actor in-game using GetHitProxy? UE4 编辑器的光标拾取 编辑器Viewport窗口中的鼠标拾取原理 场景基本对象 渲染总流程 https://docs.unrealengine.com/zh-CN/Programming/Rendering/MeshDrawingPipeline/index.html Unreal Mesh Drawing源码分析 白袍笑道 ","description":"","id":27,"section":"zh","tags":["c++","UE4","游戏引擎"],"title":"UE编辑器下模拟使用HitProxy","uri":"https://hugo.jiahongw.com/en/zh/posts/ue/ue-hitproxy/"},{"content":"在UE4中获取深度缓存，调用渲染命令读取。\n获取深度缓存 深度像素格式 键入命令vis scenedepthz uv0以查看实际使用的深度缓冲区。UE4对场景使用“反向”深度缓冲区。\nWay1：直接使用ENQUEUE_RENDER_COMMAND命令获取(效率较低) 在任意tick函数或者其他函数添加以下的命令：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 struct DepthPixel\t//定义深度像素结构体 { float depth; char stencil; char unused1; char unused2; char unused3; }; float* cpuDataPtr;\t// Texture深度值数组首地址 TArray\u0026lt;DepthPixel\u0026gt; mydata;\t//最终获取色深度值数据 FIntPoint buffsize;\t//深度长宽大小X和Y ENQUEUE_RENDER_COMMAND(ReadSurfaceFloatCommand)(\t// 将读取深度数据的命令推给渲染线程进行执行 [\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize](FRHICommandListImmediate\u0026amp; RHICmdList) //\u0026amp;cpuDataPtr, \u0026amp;mydata, \u0026amp;buffsize为传入的外部参数 { FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, 1); FTexture2DRHIRef uTex2DRes = FSceneRenderTargets::Get(RHICmdList).GetSceneDepthSurface();\tbuffsize = uTex2DRes-\u0026gt;GetSizeXY(); uint32 sx = buffsize.X; uint32 sy = buffsize.Y; mydata.AddUninitialized(sx * sy); uint32 Lolstrid = 0; cpuDataPtr = (float*)RHILockTexture2D(uTex2DRes,0,RLM_ReadOnly,Lolstrid,true);\t// 加锁 获取可读depth Texture深度值数组首地址 memcpy(mydata.GetData(), cpuDataPtr, sx * sy * sizeof(DepthPixel));\t//复制深度数据 RHIUnlockTexture2D(uTex2DRes, 0, true);\t//解锁 FSceneRenderTargets::Get(RHICmdList).AdjustGBufferRefCount(RHICmdList, -1);\t}); FlushRenderingCommands();\t//等待渲染线程执行 mydata; //最终获取深度数据 最终返回的mydata数据就是最终的深度值数组，其中每个深度值的结构是DepthPixel，其中一个成员为depth，另外四个不不使用。其中使用上面的几个命令需要添加\u0026quot;RHI.h\u0026ldquo;头文件\nWay2：写个请求类读取 UML图：\n流程图：\n1. 首先在项目的build.cs文件添加： 添加引擎源码地址\n1 2 3 4 5 6 7 8 9 // 添加引擎源码地址 string EnginePath = \u0026#34;C:/Program Files (x86)/UE4+VS2017/UnrealEngine/\u0026#34;; PrivateIncludePaths.AddRange( new string[] { EnginePath + \u0026#34;Source/Runtime/Renderer/Private\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/CompositionLighting\u0026#34;, EnginePath + \u0026#34;Source/Runtime/Renderer/Private/PostProcess\u0026#34; } ); 添加引依赖项\n2. 类实现 将下面类代码复制到PostProcessing.h文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 /*****************************************Get Depth Class*******************************************************/ /*\t存储一个像素的缓存 depth 深度缓存 stencil （抠图缓存）*/ struct DepthPixel { float depth; char stencil; char unused1; char unused2; char unused3; }; /*\t存储整个视窗的缓存 data\t像素缓存数组 bufferSizeX\t缓存大小X bufferSizeY\t缓存大小Y pixelSizeBytes\t像素缓存字节数*/ struct DepthResult { TArray\u0026lt;DepthPixel\u0026gt; data; int bufferSizeX; int bufferSizeY; int pixelSizeBytes; }; /*\t获取深度缓存的类\t*/ class RENDERER_API DepthCapture { public: /*\t静态成员，当用户发出一个获取深度缓存的请求后，waitForCapture长度加1，新增DepthResult内容为空 当系统完成一个深度缓存的请求后，waitForCapture长度减一 */ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; waitForCapture; /*\t静态成员，当系统完成一个深度缓存的请求后，finishedCapture长度加1， 新增DepthResult含有深度缓存信息\t*/ static TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; finishedCapture; public: /*用户发出一个获取深度缓存的请求时调用*/ static void AddCapture() { waitForCapture.Enqueue(new DepthResult()); } /*系统完成一个深度缓存请求后调用*/ static void FinishedCapture(DepthResult *result) { finishedCapture.Enqueue(result); } /*返回是否存在已经完成的请求*/ static bool HasFinishedCapture() { return !finishedCapture.IsEmpty(); } /*如果存在已完成的请求，返回一个深度结果*/ static DepthResult* GetIfExistFinished() { DepthResult* result = NULL; if (!finishedCapture.IsEmpty()) { finishedCapture.Dequeue(result); } return result; } /*返回是否存在等待系统执行的请求*/ static bool HasCaptureRequest() { return !waitForCapture.IsEmpty(); } /*如果存在待完成的请求，返回一个深度结果（为空）*/ static DepthResult* GetIfExistRequest() { DepthResult* result = NULL; if (!waitForCapture.IsEmpty()) { waitForCapture.Dequeue(result); } return result; } //friend void AddPostProcessingPasses(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, const FPostProcessingInputs\u0026amp; Inputs); }; /*****************************************end******************************************************/ 将下面类中静态成员初始化和添加执行获取代码代码复制到PostProcessing.cpp文件任意位置：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 /*类静态成员的定义*/ TQueue\u0026lt;DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::waitForCapture; TQueue\u0026lt; DepthResult *, EQueueMode::Mpsc\u0026gt; DepthCapture::finishedCapture; /*获取深度缓存*/ void AddDepthInspectorPass(FRDGBuilder\u0026amp; GraphBuilder, const FViewInfo\u0026amp; View, DepthResult* result) { RDG_EVENT_SCOPE(GraphBuilder, \u0026#34;DepthInspector\u0026#34;); { // 获取渲染对象 FSceneRenderTargets\u0026amp; renderTargets = FSceneRenderTargets::Get(GRHICommandList.GetImmediateCommandList()); // 定义拷贝参数 uint32 striped = 0; FIntPoint size = renderTargets.GetBufferSizeXY(); result-\u0026gt;bufferSizeX = size.X; result-\u0026gt;bufferSizeY = size.Y; result-\u0026gt;data.AddUninitialized(size.X * size.Y); // 获取视窗某一帧的深度缓存对象 FRHITexture2D* depthTexture = (FRHITexture2D *)renderTargets.SceneDepthZ-\u0026gt;GetRenderTargetItem().TargetableTexture.GetReference(); // 执行拷贝深度缓存操作，将GPU显存中的缓存信息拷贝到CPU内存中，返回指向这块CPU内存的首地址 void* buffer = RHILockTexture2D(depthTexture, 0, EResourceLockMode::RLM_ReadOnly, striped, true); // 将缓存结果拷贝到result，用于输出 memcpy(result-\u0026gt;data.GetData(), buffer, size.X * size.Y * 8); // 必须执行解锁语句，否则被锁住的GPU缓存信息将不能释放 RHIUnlockTexture2D(depthTexture, 0, true); // 拷贝结果入队 DepthCapture::FinishedCapture(result); } } //////////////////////////////////////// PostProcessing.cpp中该位置添加以下代码：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 // Capture depth buffer，otherwise the buffer will be changed if (DepthCapture::HasCaptureRequest()) { DepthResult *reuslt; reuslt = DepthCapture::GetIfExistRequest(); if (reuslt) { AddDepthInspectorPass(GraphBuilder, View, reuslt); } } 3. 调用 使用以下的代码可以获取深度值，获取的结果为result：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 int tickcount = 0; // Called every frame void ATestPawn::Tick(float DeltaTime) { tickcount++; if (tickcount % 2 == 0)\t// 设计几帧调用 DepthCapture::AddCapture(); // 定时发出获取深度缓存的请求 // 如果存在已完成的深度缓存请求 if (DepthCapture::HasFinishedCapture()) { DepthResult *result; // 获取已完成的深度缓存结果 result = DepthCapture::GetIfExistFinished(); if (result) { int n = result-\u0026gt;data.Num(); //this is test GEngine-\u0026gt;AddOnScreenDebugMessage(-1, -1, FColor::Blue, FString::Printf(TEXT(\u0026#34;Get Depth Size: %d \u0026#34;), n)); } } } ","description":"","id":28,"section":"zh","tags":["c++","UE4","游戏引擎"],"title":"UE4获取深度值","uri":"https://hugo.jiahongw.com/en/zh/posts/ue/ue-depth/"},{"content":"探索UE4游戏线程的进入\n游戏线程 \u0026amp; 渲染线程 UE4游戏线程启动 游戏线程每一帧更新所有内容。\n这个tick是哪里打开的？\n头文件：Engine\\Source\\Runtime\\Launch\\Private\\Launch.cpp\nLauch.cpp定义了一个全局的变量FEngineLoop GEngineLoop;\n该类路径：Engine\\Source\\Runtime\\Launch\\Public\\LaunchEngineLoop.h，继承一个接口类IEngineLoop，定义如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 /** * Implements the main engine loop.\t*/ class FEngineLoop #if WITH_ENGINE : public IEngineLoop #endif { public: /** Default constructor. */ FEngineLoop(); virtual ~FEngineLoop() { } public: /** * Pre-Initialize the main loop, and generates the commandline from standard ArgC/ArgV from main(). * * @param ArgC The number of strings in ArgV. * @param ArgV The command line parameters (ArgV[0] is expected to be the executable name). * @param AdditionalCommandLine Optional string to append to the command line (after ArgV is put together). * @return Returns the error level, 0 if successful and \u0026gt; 0 if there were errors. */ int32 PreInit(int32 ArgC, TCHAR* ArgV[], const TCHAR* AdditionalCommandline = nullptr); /** * Pre-Initialize the main loop - parse command line, sets up GIsEditor, etc. * * @param CmdLine The command line. * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ int32 PreInit(const TCHAR* CmdLine); /** First part of PreInit. */ int32 PreInitPreStartupScreen(const TCHAR* CmdLine); /** Second part of PreInit. */ int32 PreInitPostStartupScreen(const TCHAR* CmdLine); /** Load all modules needed before Init. */ void LoadPreInitModules(); /** Load core modules. */ bool LoadCoreModules(); /** Clean up PreInit context. */ void CleanupPreInitContext(); #if WITH_ENGINE /** Load all core modules needed at startup time. */ bool LoadStartupCoreModules(); /** Load all modules needed at startup time. */ bool LoadStartupModules(); /** * Initialize the main loop (the rest of the initialization). * * @return The error level; 0 if successful, \u0026gt; 0 if there were errors. */ virtual int32 Init() override; /** Initialize the timing options from the command line. */ void InitTime(); /** Performs shut down. */ void Exit(); /** Whether the engine should operate in an idle mode that uses no CPU or GPU time. */ bool ShouldUseIdleMode() const; // Advances the main loop.推进主循环 virtual void Tick() override; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() override; #endif // WITH_ENGINE /** RHI post-init initialization */ static void PostInitRHI(); /** Pre-init HMD device (if necessary). */ static void PreInitHMDDevice(); public: /** Initializes the application. */ static bool AppInit(); /** * Prepares the application for shutdown. * * This function is called from within guarded exit code, only during non-error exits. */ static void AppPreExit(); /** * Shuts down the application. * * This function called outside guarded exit code, during all exits (including error exits). */ static void AppExit(); private: /** Utility function that processes Slate operations. */ void ProcessLocalPlayerSlateOperations() const; protected: /** Holds a dynamically expanding array of frame times in milliseconds (if FApp::IsBenchmarking() is set). */ TArray\u0026lt;float\u0026gt; FrameTimes; /** Holds the total time spent ticking engine. */ double TotalTickTime; /** Holds the maximum number of seconds engine should be ticked. */ double MaxTickTime; /** Holds the maximum number of frames to render in benchmarking mode. */ uint64 MaxFrameCounter; /** Holds the number of cycles in the last frame. */ uint32 LastFrameCycles; #if WITH_ENGINE /** Holds the objects which need to be cleaned up when the rendering thread finishes the previous frame. */ FPendingCleanupObjects* PendingCleanupObjects; #endif //WITH_ENGINE private: #if WITH_ENGINE /** Holds the engine service. */ FEngineService* EngineService; /** Holds the application session service. */ TSharedPtr\u0026lt;ISessionService\u0026gt; SessionService; #endif // WITH_ENGINE FPreInitContext PreInitContext; }; 该文件只需#include \u0026quot;CoreMinimal.h\u0026quot;，最多加上#include \u0026quot;UnrealEngine.h\u0026quot;\n接口类，位于路径Engine\\Source\\Runtime\\Engine\\Public\\UnrealEngine.h：\n1 2 3 4 5 6 7 8 9 /** Public interface to FEngineLoop so we can call it from editor or editor code */ class IEngineLoop { public: virtual int32 Init() = 0; virtual void Tick() = 0; /** Removes references to any objects pending cleanup by deleting them. */ virtual void ClearPendingCleanupObjects() = 0; }; 开启Tick函数之前需要初始化，初始化函数在Launch.cpp这个文件中：\n1 2 3 4 5 6 /* Inits the engine loop */ int32 EngineInit() { int32 ErrorLevel = GEngineLoop.Init(); return( ErrorLevel ); } GEngineLoop.Init()函数：\n其中会判断是进入那种引擎模式，分为Game模式与Editor模式。\n结束引擎的函数为：\n1 2 3 4 5 6 7 8 9 10 /** * Shuts down the engine */ void EngineExit( void ) { // Make sure this is set RequestEngineExit(TEXT(\u0026#34;EngineExit() was called\u0026#34;)); GEngineLoop.Exit(); } 也在Launch.cpp\nLaunch.cpp中的函数多次使用GEngine这个外部变量，这个变量在上面的初始化函数会自定设置为相应的引擎，即Game引擎或者Editor引擎：\n所在文件Engine.h\n在FEngineLoop::Tick()函数会调用GEngine的Tick函数：\n也就是本文开始的那个Tick函数。\n","description":"","id":29,"section":"zh","tags":["c++","UE4","游戏引擎"],"title":"UE游戏、渲染线程","uri":"https://hugo.jiahongw.com/en/zh/posts/ue/ue-game-render/"},{"content":"大概介绍以下UE4的主要渲染过程。\nUE4渲染过程 延迟渲染 所谓延迟渲染，是指将一个场景的几何体（3D模型、多边形）的光照、阴影、质感搁置到一旁，先着手于绘画，然后在后半段再对光照、阴影、质感进行处理的处理方式。即给人一种把原本的多边形先绘制出来的印象，实际上不仅要绘制多边形，前者的参数还需要配合后面光照和阴影的处理。其输出目标，在成为复数缓冲时具有普遍性，但是这里的缓冲我们称之为\u0026quot;物理缓冲\u0026quot;。物体缓冲是指使用后照明和后处理特效的中间过渡环节\n相关术语 RHI\n渲染硬件接口，是为不同平台抽象出不同图形API的一层。所有渲染命令均通过RHI层传递，以转换为适用的渲染器。\n延迟渲染\n虚幻引擎4中的默认渲染器。它因将照明/阴影计算推迟到全屏过程而不是绘制每个网格时而得名。\n顶点工厂\n顶点工厂是封装顶点数据源并链接到顶点着色器上的输入的类。静态网格物体，骨架网格物体和过程网格组件均使用不同的顶点工厂。\n着色器\n在虚幻引擎中，着色器是HLSL代码（以.ush / .usf文件的形式）和材质图的内容的组合。在Unreal中创建材质时，它会根据设置（如着色模式）和用法来编译多个着色器排列。\n渲染数据 相关的渲染的数据包括深度值及一些Gbuffer，如下图：\n几个Pass Z Pre Pass UE4的渲染管道，是在Bass Pass的物体缓冲写出来之前，在仅预处理深度值（Z值）之后，运行Z预阶段。\n事先预处理深度值的目的，是将最终影像和同一深度缓冲的内容结果，在透视前获得。Z预阶段之后的Base Pass则是，参考预先得出的深度值缓冲进行Z预测试，因此通过在最终的画面里不留下像素痕迹（即编写后又被消去的像素），以回避像素着色器的运行。\nBase Pass\n使用Base Pass输出物体缓冲需要注意的两点：\n不绘制没进入视线的对象\n这种\u0026quot;投影剔除\u0026quot;（Frustum Culling），一般是通过CPU端来处理；为了整体覆盖被称为\u0026quot;包围球\u0026quot;（Bounding sphere）的各个3D对象，对象是否在视野内的判定标准，是通过预先设定的包围球来实行的。\n什么程度的剔除会成功，可以通过Stat初始视图（Stat InitViews）指令的\u0026quot;视锥体裁剪基元（Frustum Culled Primitives）\u0026ldquo;进行确认。\n不计算多余的像素\n在图像处理的流程中，使用像素着色器实际处理前，会有运行深度测试（Z 测试）的\u0026quot;Pre Z 测试\u0026quot;这一步骤。从这里着手处理的像素，会因为被某个东西所遮挡而无法绘制出来，这时可以进行撤销处理。\n但是，像半透明对象这种会伴随α测试的绘制、视差遮蔽映射这种像素着色器处理后会重新编写深度值的情况，就不进行Pre Z测试，而通过处理实行分路迂回。\nUE4 绘制策略DrawingPolicy\n绘制策略在UE4渲染中使用很多， 中文也不好翻译。 其实就是根据策略 使用了哪些 着色器 。\n\u0026hellip;\u0026hellip;\u0026hellip;.\nUE4渲染一帧 渲染管道 首先，虚幻的渲染由三个线程共同完成。分别是CPU线程，DRAW线程，和GPU线程。\n知乎：https://zhuanlan.zhihu.com/p/57158725\nRender模块 调用Render()函数在Render模块RendererModule.h中，以下函数：\n1 2 3 4 5 class FRendererModule : public IRendererModule { // 开始渲染视图族 virtual void BeginRenderingViewFamily(FCanvas* Canvas,FSceneViewFamily* ViewFamily) override; } ==谁最终调用了Render？==\n实时渲染流程图： part1:https://i.loli.net/2020/05/30/qU8vN2WZVbt9hkF.jpg\npart2:https://i.loli.net/2020/05/30/3trKVpOMU5sTQfB.jpg\n渲染函数Render 路径：Engine \\ Source \\ Runtime \\ Renderer \\ Private \\ DeferredShadingRenderer.cpp（660）\n函数：FDeferredShadingSceneRenderer :: Render（）渲染路径\n全局系统纹理初始化 DeferredShadingRenderer.cpp（677） GSystemTextures.InitializeTextures（） 保护 必要的渲染目标您是否已确保可以保护的最大目标数目？ DeferredShadingRenderer.cpp（680） GSceneRenderTargets.Allocate（） 初始化每个视口 设置视口显示的对象，选择使用动态阴影时显示的对象，对半透明对象进行排序 DeferredShadingRenderer.cpp（683） InitViews()（） FXSystem预处理 GPU粒子正在被仿真 DeferredShadingRenderer.cpp（758） FXSystem-\u0026gt; PreRender（） 启用Z Pre-Pass时执行的早期Z绘制 不绘制Tile渲染的硬件（移动设备，Android或iOS）对于 PC或PS4，将生成深度缓冲区和HiZ，因此后续绘制速度很快成为？ DeferredShadingRenderer.cpp（768） RenderPrePass（） 安全GBuffer DeferredShadingRenderer.cpp（774） GSceneRenderTargets.AllocGBufferTargets（） 透明光传播量 DeferredShadingRenderer.cpp（779） ClearLPVs（） 使用DBuffer时绘制延期贴图单击此处获取 DBuffer和延期贴图 DeferredShadingRenderer.cpp（796） GCompositionLighting.ProcessBeforeBasePass（） 如有必要，请 在绘制线框图时清除GBuffer透明颜色缓冲区， 有些游戏在发行游戏时无法清除GBuffer或屏幕。 DeferredShadingRenderer.cpp（805） SetAndClearViewGBuffer（） DeferredShadingRenderer.cpp（816） RHICmdList.Clear（） 渲染不透明的对象渲染 项目，这些项目根据它们是Masked还是Default，是否有LightMap等按每种排序顺序进行了精细分类 DeferredShadingRenderer.cpp（828） RenderBasePass（） 清除 GBuffer 的未绘制部分如果事先清除GBuffer，则不必要。 DeferredShadingRenderer.cpp（851） ClearGBufferAtMaxZ（） 绘制 自定义深度请参见此处以获取自定义深度 DeferredShadingRenderer.cpp（860） RenderCustomDepthPass（） 在这里再次模拟GPU粒子除了在这里 处理使用深度缓冲区执行碰撞检测的 粒子外，还对GPU粒子进行排序 DeferredShadingRenderer.cpp（865） 场景-\u0026gt; FXSystem-\u0026gt; PostRenderOpaque（） 为SceneDepthTexture创建一个半分辨率（每个方面为1/4分辨率）的缓冲区 DeferredShadingRenderer.cpp（875） UpdateDownsampledDepthSurface（） 执行阻塞测试 HZB的构建，执行提交 的HZB Attotempkinder的这篇文章指 DeferredShadingRenderer.cpp（881） BeginOcclusionTests（） 开始写 因为有点复杂，所以要写一些细节 DeferredShadingRenderer.cpp（890） 不使用DBuffer绘制延迟的贴图 CompositionLighting.cpp（293） AddDeferredDecalsBeforeLighting（） 在屏幕空间中绘制环境光遮挡 CompositionLighting.cpp（300） AddPostProcessingAmbientOcclusion（） 后期处理环境立方体贴图 CompositionLighting.cpp（305） AddPostProcessingAmbientCubemap（） 到这里为止的一系列处理 DeferredShadingRenderer.cpp（904） GCompositionLighting.ProcessAfterBasePass（） 透明的体积光缓冲液可提高透明度 DeferredShadingRenderer.cpp（908） ClearTranslucentVolumeLighting（） 从此处开始的主要照明设备 收集要绘制的灯光并将其排序 不要投影，不使用灯光功能的灯光将使用“ 基于图块” 绘制（如果可能）如果不能使用“ 基于图块”关于延迟渲染，这是味o，但请参见此处 LightRendering.cpp（312-348） LightRendering.cpp（423） RenderTiledDeferredLighting（） LightRendering.cpp（429） RenderSimpleLightsStandardDeferred（） 它不会阴影，也不会使用灯光功能，但是似乎无法使用TBDR绘制的灯光 被称为标准延迟灯光。 LightRendering.cpp（445） RenderLight（） 如果用于半透明的体积光是有效的，则将每个光注入到体积光中 ，从而在3D纹理上绘制光效果。 LightRendering.cpp（455） InjectTranslucentVolumeLightingArray（） LightRendering.cpp（461） InjectSimpleTranslucentVolumeLightingArray（） 使用灯光功能投射阴影的灯光将单独处理 LightRendering.cpp（468-552） 首先，我在投射阴影时 绘制了一个阴影贴图；在这里我还绘制了一个 半透明的阴影贴图；我记得半透明的当然是傅立叶不透明度贴图。 LightRendering.cpp（495） RenderTranslucentProjectedShadows（） LightRendering.cpp（497） RenderProjectedShadows（） 使用LPV时绘制反射阴影贴图 LightRendering.cpp（508） RenderReflectiveShadowMaps（） 灯光功能图 阴影指示器图 LightRendering.cpp（515） RenderLightFunction（） LightRendering.cpp（522） RenderPreviewShadowsIndicator（） 衰减缓冲器中的分辨 光的衰减信息是否曾经被吸入另一个缓冲器中？ LightRendering.cpp（534） GSceneRenderTargets.FinishRenderingLightAttenuation（） 注入体积光以获得半透明 LightRendering.cpp（541） InjectTranslucentVolumeLighting（） 这 是使用光功能投射阴影的光处理的结束。 LightRendering.cpp（550） RenderLight（） 这 是每个光的LPV 的主要注入照明过程的结尾 LightRendering.cpp（561-593） Lpv-\u0026gt; InjectLightDirect（） 注入体积光以实现环境立方体贴图的半透明 DeferredShadingRenderer.cpp（916） InjectAmbientCubemapTranslucentVolumeLighting（） 过滤体积光以获得半透明 DeferredShadingRenderer.cpp（919） FilterTranslucentVolumeLighting（） LPV传输过程 此外，第921行的注释上写有“ copypimis”，例如“ Clear LPV buffer”。 DeferredShadingRenderer.cpp（924） PropagateLPVs（） 动态天光绘图 DeferredShadingRenderer.cpp（928） RenderDynamicSkyLighting（） 延迟的反射图形 捕获的反射图形而不是屏幕空间 DeferredShadingRenderer.cpp（931） RenderDeferredReflections（） LPV的GI绘图 CompositionLighting.cpp（344） AddPostProcessingLpvIndirect（） 屏幕空间次表面散射（SSSSS）的后处理 CompositionLighting.cpp（347-376） 如果启用了“光轴”，则绘制“光轴遮挡” DeferredShadingRenderer.cpp（953） RenderLightShaftOcclusion（） 大气雾图 DeferredShadingRenderer.cpp（977） RenderAtmosphere（） 绘图雾 这是高度雾吗？ DeferredShadingRenderer.cpp（986） RenderFog（） 画一个半透明的物体 在这里也画一个单独的半透明的东西 DeferredShadingRenderer.cpp（1000） RenderTranslucency（） 折射变形处理 DeferredShadingRenderer.cpp（1008） RenderDistortion（） 光轴的起霜处理 DeferredShadingRenderer.cpp（1013） RenderLightShaftBloom（） 距离场AO处理不能在 当前不支持多个视口 的分屏游戏中使用吗？ DeferredShadingRenderer.cpp（1019） RenderDistanceFieldAOSurfaceCache（） 它只是在查看网格的“距离场”的可视化处理结果吗？ DeferredShadingRenderer.cpp（1024） RenderMeshDistanceFieldVisualization（） 由于速度模糊而绘制运动对象的速度 DeferredShadingRenderer.cpp（1034） RenderVelocities（） 从这里到最后的发布过程， 这也很复杂而且很长 DeferredShadingRenderer.cpp（1047） GPostProcessing.Process（） 使用BeforeTranslucency设置绘制后处理材料 PostProcessing.cpp（878） AddPostProcessMaterial（） 景深处理 通过高斯模糊进行DOF 处理之后，正在执行散焦处理（使用指定的光圈形状的纹理进行绘制）， 在此阶段似乎合并了单独的半透明缓冲区 PostProcessing.cpp（888） AddPostProcessDepthOfFieldGaussian（） PostProcessing.cpp（898） AddPostProcessDepthOfFieldBokeh（） PostProcessing.cpp（905） FRCPassPostProcessBokehDOFRecombine （如果未启用模糊） 使用BeforeTonemapping设置绘制后处理材料 PostProcessing.cpp（913） AddPostProcessMaterial（） 如果要使用TemporalAA ，请在此处绘制，如果使用FXAA，请稍后再绘制 PostProcessing.cpp（921） AddTemporalAA（） PostProcessing.cpp（928） AddTemporalAA（） （如果不使用速度缓冲区，请单击此处） 运动模糊处理 设置，分辨率下采样，高斯模糊，运动模糊绘制，组合处理 PostProcessing.cpp（932-994） FRCPassPostProcessMotionBlurSetup FRCPassPostProcessDownsample RenderGaussianBlur（） FRCPassPostProcessMotionBlur FRCPassPostProcessMotionBlurRecombine SceneColor下采样 PostProcessing.cpp（1000） FRCPassPostProcessDownsample 直方图 PostProcessing.cpp（1006-1040） FRCPassPostProcessHistogram FRCPassPostProcessHistogramReduce 此处需要眼睛适应图直方图 PostProcessing.cpp（1046） AddPostProcessEyeAdaptation（） 布卢姆绘图 PostProcessing.cpp（1057） AddBloom（） PostProcessing.cpp（1060-1148） （对于移动设备，请单击此处） 色调映射 仅替换ReplacecingTonemapper设置工程图的一种后处理材料，但是 如果存在该材料，则执行默认色调映射 PostProcessing.cpp（1155） AddSinglePostProcessMaterial（） PostProcessing.cpp（1171） AddTonemapper（） （默认色调映射） 如果启用了FXAA，请在此处处理 PostProcessing.cpp（1177） AddPostProcessAA（） 绘制一些编辑器（如选定的轮廓）， 然后使用AfterTonemapping设置绘制后期处理材料 PostProcessing.cpp（1244） AddPostProcessMaterial（） 用于地下和GBuffer的可视化 调试 PostProcessing.cpp（1246-1254） 用于HMD的后处理 Oculus或Morpheus PostProcessing.cpp（1256-1277） FRCPassPostProcessHMD FRCPassPostProcessMorpheus 之后，调试和高分辨率屏幕截图功能等。 之后，进行后处理并结束！ 谢谢！ PostProcessing.cpp（1279-） 哦，很长。\n参考链接：\n如何在C ++中从UTexture2D读取数据\nhttps://forums.unrealengine.com/development-discussion/c-gameplay-programming/1422920-casting-converting-frhitexture-to-utexture\nUnreal渲染相关的缓冲区\nhttps://qiita.com/mechamogera/items/a0c369a3b853a3042cae\nhttps://answers.unrealengine.com/questions/17862/access-color-and-depth-buffer-of-each-frame.html\nhttps://segmentfault.com/a/1190000012737548\nGbuff数据\n渲染系统概述 图片\n","description":"","id":30,"section":"zh","tags":["c++","UE4","游戏引擎"],"title":"UE4渲染过程","uri":"https://hugo.jiahongw.com/en/zh/posts/ue/ue4-render/"},{"content":"RSA算法 RSA加密算法是一种非对称加密算法，在公开密钥加密和电子商业中被广泛使用。\n对极大整数做因数分解的难度决定了 RSA 算法的可靠性。换言之，对一极大整数做因数分解愈困难，RSA 算法愈可靠。假如有人找到一种快速因数分解的算法的话，那么用 RSA 加密的信息的可靠性就会极度下降。但找到这样的算法的可能性是非常小的。今天只有短的 RSA 钥匙才可能被强力方式破解。到当前为止，世界上还没有任何可靠的攻击RSA算法的方式。只要其钥匙的长度足够长，用RSA加密的信息实际上是不能被破解的。\n公钥/双密钥/非对称 加密 涉及到两个密钥的使用:\n一个公钥, 可以被任何人知道，用于加密消息和验证签名 一个私钥, 只有接收方才知道，用于解密消息和创造签名 RSA实现过程 1. 公钥与私钥的产生 生成公钥e和私钥d的步骤如下：\n随意选择两个大的质数$p$和$q$，$p$不等于$q$，计算$n=pq$。 根据欧拉函数，求$r = \\varphi (N) = \\varphi (p)\\varphi (q) = (p - 1)(q - 1)$ 选择一个小于$r$的整数$e$，使$e$与$r$互质。并求得$e$关于$r$的模反元素，命名为$d$(求$d$令$ed \\equiv 1(\\bmod ;r)$)。(模反元素存在，当且仅当$e$与$r$互质) 将$p$和$q$的记录销毁 经过上面四个步骤最终可以得到公钥$(n,e)$和私钥$(n,d)$。\n接收消息的人将自己的公钥$(n,e)$发送给发送消息的人,发送的人使用这个公钥加密信息发送给接收方，而接收方将私钥$(n,d)$保存起来用于解密。\n下面实现RSA类\n参考资料：\n米勒-拉宾素性检验 RSA加密算法 C++实现 实验步骤与结果 1.实现大整数类 因为该加密算法涉及的数可能很大，而C++中并没有像Java一样，内置大整数类BigInteger，故需自己实现，这里我参考了网上的一些资料设计了BigInteger类，实现了加减乘除以及模幂等运算，也实现了运算符重载，具体参考实现的方法如下：\n2. 设计RSA类 编写rsa.h头文件，定义RSA类，其中包含的成员以及成员函数如下：\n下面分别实现上述的各个方法\n首先要生成密钥对，即生成公钥和私钥，那么，我们首先需要生成两个大素数p和q,显然，素数是不可能是偶数的，故定义一个生成随机奇数的函数BigInteger createOddNum(unsigned len)参数为奇数的长度。\n使用16进制的随机字母，然后随机选取其中的len/4个得到一个随机的大奇数，只需要末尾那个数为奇数即可，最后返回BigInteger类型的奇数大整数，关键代码如下：\n然后定义一个生成素数的函数，其中用到米勒-拉宾素性检验算法判断生成的素数是否为素数素数：\n米勒-拉宾素性检测算法 基于以下定理：\n费马小定理 要测试$N$是否为素数，首先将$N−1$分解为$2^{s}d$。在每次测试开始时，先随机选一个介于$[1,N−1]$的整数$a$，之后如果对所有的$r∈[0,s−1]$，若${a^d}\\bmod N \\ne 1$且${a^{{2^r}d}}\\bmod N \\ne - 1$，则$N$是合数。否则，$N$有$3/4$的概率为素数。\n关键代码如下：\n生成素数的逻辑就是首先使用函数createOddNum生成一个大奇数，然后调用isPrime判断是否为一个素数，是的话就可以return，不然继续寻找，知道生成一个素数。\n接下来计算n值，n值的计算很简单，直接使用$n = p * q$ 这个式子就能够计算出来；计算欧拉值也一样，可以使用$\\varphi(n) = (p-1) * (q-1)$得出。其中比较难的是生成的私钥d。\n下面定义一个RSA类的初始化函数init()​，生成p、q以及密钥对，如下：\n在创建公钥e和私钥d的函数createExponent(eul)中，首先创建一个比欧拉值小的公钥e，其中e为一个素数，直接调用函数createPrime()生成，然后使用大整数类中的求模逆元，即求出私钥d。\n扩展欧几里得算法 逆元\n逆元是模运算中的一个概念，我们通常说 A 是 B 模 C 的逆元，实际上是指 A * B = 1 mod C，也就是说 A 与 B 的乘积模 C 的余数为 1。可表示为 A = B^(-1) mod C。\n打个比方，7 模 11 的逆元，即：7^(-1) mod 11 = 8，这是因为 7 × 8 = 5 × 11 + 1，所以说 7 模 11 的逆元是 8。\n扩展欧几里得算法是欧几里得算法（又叫辗转相除法）的扩展。已知整数a、b，扩展欧几里得算法可以在求得a、b的最大公约数的同时，能找到整数x、y（其中一个很可能是负数），使它们满足贝祖等式\n$$\nax{\\rm{ }} + {\\rm{ }}by{\\rm{ }} = {\\rm{ }}gcd\\left( {a,b} \\right).\n$$\n在RSA算法中求私钥中的整数d时，需要使得 (e * d ) % n = 1，该方程等价于 e * d = 1 + y * n （y为整数），也等价于 e * d - y * n = 1。\n因此求解d的过程就是求解该二元一次方程组（e和n已知，求解d），即求e模n的逆元。\n关键代码如下：\n我们知道，RSA的加密与解密其实就是一个模幂的运算，而这个模幂的运算已经在大整数类中实现了，如下：\n使用RSA类进行加密解密的函数只需要调用这个模幂运算即可，例如私钥加密可以这样调用：\n以上就设计完了RSA类的相关操作，主要是包括密钥的生成。下面将RSA加密解密的操作封装在一个类中。\n3. 设计加密解密类EncryptDecrypt 主要的方法及成员如下：\n实现RSA加密解密字符串 加密字符串的逻辑是，先将字符串以每两个字符 一组，转化为一个16进制数据序列，使用vector容器保存，之后调用rsa的公钥加密函数进行加密，如下是关键代码：\n解密函数其实是接受一个加密后的16进制序列，然后对这个序列调用RSA的私钥解密函数进行解密，然后得到解密后的16进制数据序列，最后还有一步就是需要将这个16进制序列最终转化为原来的字符串，只需要根据ascii码的数值即可得到，这里编写了一个hex2string函数，关键代码如下：\n实现效果\n首先显示密钥：\n加密字符串\n解密字符串\n实现RSA加密解密文件 实现RSA加密解密文件时基于RSA加密解密字符串实现的，其中主要的加密逻辑就是将一个文件看作是一行一行的字符串文本，没每读取一行，就调用加密字符串的函数进行加密，然后将加密得到的16进制序列写入到另外一个文件中，而这个文件也就是加密后的文件，主要关键代码如下：\n解密文件的函数稍微有点不一样，是从打开的待解密文件中循环读取每一个16进制数据，然后对每一个16进制数据调用解密函数得到解密后的16进制数据，将16进制数据转为字符串后再相继的写到另外一个文件中，即解密后的文件，关键代码如下：\n实现效果\n加密文件\n解密文件\n加密文件解密文件对比\n实现RSA数字签名及验证 实现数字签名方案，按照以下的流程图进行操作。\n首先需要对文件进行信息的摘要，得到Hash值，这里选择的Hash算法是SHA512算法，可以直接对文件进行信息摘要。\n可以直接include C++ 实现的\u0026quot;sha512.h\u0026quot;文件头，然后使用以下的语句就能够生成一个长度为512的Hash值，如下：\n可以在命令行输出文件的Hash摘要值如下:\n数字签名的实现类似字符串加密，对文件的hash值进行加密得到后面的16进制序列，然后将16进制序列伴随文件发送出去，签名的关键代码就是对hash值进行加密，如下：\n验证函数直接将16进制序列进行解密，然后还原成字符串再与收到的文件的hash值进行比较，如果相等，那么验证成功；否则验证失败，关键代码如下：\n实现效果\n数字签名\n验证数字签名\n","description":"","id":31,"section":"zh","tags":["rsa","密码学"],"title":"RSA加密算法","uri":"https://hugo.jiahongw.com/en/zh/posts/cryptography/rsa/"},{"content":"AES算法是继DES之后比较快且比较简单的加密算法.⚖\n对称加密 对称加密模型 如下图，发送者和接收者共享一个一样的密钥，相当于现实生活中的锁，\n对称加密的使用要求 一个强加密算法 只有发送发和接收方知道私钥 加密算法是公开的，不需保密；并且解密算法本质上是加密算法的反向执行。\n但是，如何安全的分发安全密钥呢？——————安全分发不可能单靠对称加密算法，常常使用的是非对称加密算法。\n所以，对称加密的安全性取决于密钥的保密性而非算法的保密性，通常认为已知密文和加密/加密算法的基础上不能够破译信息。\nAES算法 算法原理： AES密码与分组密码Rijndael基本上完全一致，Rijndael分组大小和密钥大小都可以为128位、192位和256位。然而AES只要求分组大小为128位，因此只有分组长度为128Bit的Rijndael才称为AES算法。\n下面是分组长度为128位的AES算法,而key位数可以是128/192/256,本次实验选择key的大小位128位.\n特点 明文分组被描述为一个字节方阵并复制到状态数组，在每轮替换和移位时都并行处理整个状态分组。 矩阵中字节的顺序是按列排序的，例如128比特的明文分组的前4个字节占输入矩阵的第一列，接下来的4个字节占第二列，依次类推。扩展子密钥数组也类似操作。 假设AES使用128比特的密钥，其密钥被描述为一个字节方阵并将扩展成为一个子密钥数组w[i]（具有44个32比特字），4个不同的字（共128比特）用作每轮的轮密钥。 AES在每轮运算中将进行4个不同的步骤，1个是移位，3个是替换。 数学知识 在AES算法中的MixColumn层中会用到伽罗瓦域中的乘法运算，而伽罗瓦域的运算涉及一些数学知识。\n素域 有限域有时也称伽罗瓦域，它指的是由有限个元素组成的集合，在这个集合内可以执行加、减、乘和逆运算。而在密码编码学中，我们只研究拥有有限个元素的域，也就是有限域。域中包含元素的个数称为域的阶。只有当m是一个素数幂时，即$m=p^n$(其中n为正整数是p的次数，p为素数)，阶为m的域才存在。p称为这个有限域的特征。\n例如，有限域中元素的个数可以是11(p=11是一个素数,n=1)、可以是81(p=3是一个素数，n=4)、也可以是256(p=2是一个素数，n=8)\u0026hellip;..但有限域的中不可能拥有12个元素，因为12=2·2·3，因此12也不是一个素数幂。因此满足p是一个素数且满足$m = p^n$这个公式，m才是一个素数幂。\n有限域中最直观的例子就是阶为素数的域，即n=1的域。域GF(p)的元素可以用整数0、1、\u0026hellip;、p-1l来表示。域的两种操作就是模整数加法和整数乘法模p。加上p是一个素数，整数环Z表示为GF(p)，也成为拥有素数个元素的素数域或者伽罗瓦域。GF(p)中所有的非零元素都存在逆元，GF(p)内所有的运算都是模p实现的。\n素域内的算数运算规则如下 加法和乘法都是通过模p实现的； 任何一个元素a的加法逆元都是由a+(a的逆元)=0 mod p得到的； 任何一个非零元素a的乘法逆元定义为a·a的逆元=1。 举个例子，在素域GF(5)={0、1、2、3、4}中，2的加法逆元为3，这是因为2+(3)=5，5mod5=0,所以2+3=5mod5=0。2的乘法逆元为3，这是因为2·3=6，6mod5=1，所以2·3=6mod5=1。(在很多地方a的加法逆元1用$-a$表示，a的乘法逆元2用$1/a$表示)\n注：GF(2)是一个非常重要的素域，也是存在的最小的有限域，由于GF(2)的加法，即模2加法与异或(XOR)门等价，GF(2)的乘法与逻辑与(AND)门等价，所以GF(2)对AES非常重要。\n模2加法与异或(XOR)门等价:\n$$\n(1 + 0) \\mod 2 = 1\\\\\n(0 + 1) \\mod 2 = 1\\\\\n(0 + 0) \\mod 2 = 0\\\\\n(1 + 1) \\mod 2 = 0\\\\\n$$\n乘法与逻辑与(AND)门等价:\n$$\n(1 \\times 0) \\mod 2 = 0\\\\\n(0 \\times 1) \\mod 2 = 0\\\\\n(0 \\times 0) \\mod 2 = 0\\\\\n(1 \\times 1) \\mod 2 = 1\\\\\n$$\n扩展域 如果有限域的阶不是素数，则这样的有限域内的加法和乘法运算就不能用模整数加法和整数乘法模p表示。而且m\u0026gt;1的域被称为扩展域，为了处理扩展域，我们就要使用不同的符号表示扩展域内的元素，使用不同的规则执行扩展域内元素的算术运算。\n在扩展域$GF(2^m)$中，元素并不是用整数表示的，而是用系数为域$GF(2)$中元素的多项式表示。这个多项式最大的度(幂)为m-1​，所以每个元素共有m个系数，在AES算法使用的域$GF(2^8)$中，每个元素$A∈GF(2^8)$都可以表示为：\n$$\nA(x) = a_7x^7 + a_6x^6 + a_5x^5 + a_4x^4 + a_3x^3 + a_2x^2+a_1x + a_0,x_i \\in GF(2) = 0,1\n$$\n注意：在域GF(2^8)中这样的多项式共有256个，这256个多项式组成的集合就是扩展域GF(2^8)。每个多项式都可以按一个8位项链的数值形式存储：\n$$\nA = (a_7,a_6,a_5,a_4,a_3,a_2,a_1,a_0)\n$$\n像$x^7$、$x^6$等因子都无需存储，因为从位的位置就可以清楚地判断出每个系数对应的幂。\n扩展域$GF(2^m)$内的加减法 在AES算法中的密钥加法层中就使用了这部分的知识，但是不是很明显，因为我们通常把扩展域中的加法当作异或运算进行处理了，因为在扩展域中的加减法处理都是在底层域GF(2)内完成的，与按位异或运算等价。假设$A(x)$、$B(x)∈GF(2^m)$，计算两个元素之和的方法就是：\n$$\nC(x) = A(x) + B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i + b_i) \\mod 2\n$$\n而两个元素之差的计算公式就是：\n$$\nC(x) = A(x) - B(x) = \\sum_{i=0}^{m-1}C_ix^i , c_i = (a_i - b_i) \\mod 2 = (a_i + b_i) \\mod 2\n$$\n注：在减法运算中减号之所以变成加号，这就和二进制减法的性质有关了，大家可以试着验算下。从上述两个公式中我们发现在扩展域中加法和减法等价，并且与XOR等价(异或运算也被称作二进制加法)。\n扩展域GF(2^m)内的乘法 扩展域的乘法主要运用在AES算法的列混淆层(Mix Column)中，也是列混淆层中最重要的操作。我们项要将扩展域中的两个元素用多项式形式展开，然后使用标准的多项式乘法规则将两个多项式相乘：\nAES步骤详解 AES算法主要有四种操作处理，分别是密钥加法层(也叫轮密钥加，英文Add Round Key)、字节代换层(SubByte)、行位移层(Shift Rows)、列混淆层(Mix Column)。而明文x和密钥k都是由16个字节组成的数据(当然密钥还支持192位和256位的长度)，它是按照字节的先后顺序从上到下、从左到右进行排列的。而加密出的密文读取顺序也是按照这个顺序读取的，相当于将数组还原成字符串的模样了，然后再解密的时候又是按照4·4数组处理的。AES算法在处理的轮数上只有最后一轮操作与前面的轮处理上有些许不同(最后一轮只是少了列混淆处理)，在轮处理开始前还单独进行了一次轮密钥加的处理。在处理轮数上，只考虑128位密钥的10轮处理。\n其中字节排列方式需要按照如下转换:\nAES算法流程图如下:\n实现步骤及代码 按照AES流程图,对每一层的代码进行实现.\n密钥加法层 在密钥加法层中有两个输入的参数，分别是明文和子密钥k[0]，而且这两个输入都是128位的。在扩展域中加减法操作和异或运算等价，所以这里的处理也就异常的简单了，只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n如下图：\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4 * 4], word k[4]) { for (int i = 0; i \u0026lt; 4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i + 4] = mtx[i + 4] ^ byte(k2.to_ulong()); mtx[i + 8] = mtx[i + 8] ^ byte(k3.to_ulong()); mtx[i + 12] = mtx[i + 12] ^ byte(k4.to_ulong()); } } AES密钥生成 首先定义位置变换函数RotWord(),作用是接受一个字 $[a0, a1, a2, a3] $作为输入，循环左移一个字节后输出$ [a1, a2, a3, a0]$,代码如下:\n1 2 3 4 5 6 word RotWord(const word \u0026amp;w) { word result(0x0); result = (w \u0026lt;\u0026lt; 8) | (w \u0026gt;\u0026gt; 24); return result; } 定义S盒变换函数SubWord()，接受一个字 $[a0, a1, a2, a3]$ 作为输入，然后每一个byte，例如a0，前四个字节为行，后四个字节为列，从S_Box中查找并且返回四个元素。，代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 word SubWord(const word\u0026amp; sw) { word temp; for(int i=0; i\u0026lt;32; i+=8) { int row = sw[i+7]*8 + sw[i+6]*4 + sw[i+5]*2 + sw[i+4]; int col = sw[i+3]*8 + sw[i+2]*4 + sw[i+1]*2 + sw[i]; byte val = S_Box[row][col]; for(int j=0; j\u0026lt;8; ++j) temp[i+j] = val[j]; } return temp; } 轮常数Rcon[]作为一个常量数组，每一轮生成密钥的时候需要作为参数异或\n1 2 3 // 轮常数，密钥扩展中用到。（AES-128只需要10轮） word Rcon[10] = {0x01000000, 0x02000000, 0x04000000, 0x08000000, 0x10000000, 0x20000000, 0x40000000, 0x80000000, 0x1b000000, 0x36000000}; 密钥拓展函数KeyExpansion(),接受一个参数为外部密钥，另外一个为需要拓展的轮密钥数组\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //密钥扩展函数 - 对128位密钥进行扩展得到 w[4*(Nr+1),Nr为轮数 void KeyExpansion(byte key[4 * N_key], word w[4 * (N_round + 1)]) { word temp; int i = 0; while (i \u0026lt; N_key)\t//前四个word就是输入的key { w[i] = ToWord(key[4 * i], key[4 * i + 1], key[4 * i + 2], key[4 * i + 3]); ++i; } i = N_key; while (i \u0026lt; 4 * (N_round + 1)) { temp = w[i - 1]; //记录前一个word if (i % N_key == 0) { //temp先位置表换RotWord，再S盒变换，然后与轮常数异或，最后w[i-N_key] 异或 w[i] = w[i - N_key] ^ SubWord(RotWord(temp)) ^ Rcon[i / N_key - 1]; } else { w[i] = w[i - N_key] ^ temp; } i++; } } 字节替换层 S盒字节替换，主要功能就是让输入的数据通过S_box表完成从一个字节到另一个字节的映射，读取S_box数据的方法就是要将输入数据的每个字节的高四位作为第一个下标，第四位作为第二个下标。然后返回数据，字节替换主要是为了扰乱数据。\nS盒：\n逆S盒：\n图解如下：\n正向S盒变换代码如下：\n1 2 3 4 5 6 7 8 9 10 //S盒变换 - 前4位为行号，后4位为列号 void SubBytes(byte mtx[4 * 4]) { for (int i = 0; i \u0026lt; 16; ++i) { int row = mtx[i][7] * 8 + mtx[i][6] * 4 + mtx[i][5] * 2 + mtx[i][4]; int col = mtx[i][3] * 8 + mtx[i][2] * 4 + mtx[i][1] * 2 + mtx[i][0]; mtx[i] = S_Box[row][col]; } } 反向S盒变换代码如下:\n1 2 3 4 5 6 7 8 9 10 // 逆S盒变换 void InvSubBytes(byte mtx[4*4]) { for(int i=0; i\u0026lt;16; ++i) { int row = mtx[i][7]*8 + mtx[i][6]*4 + mtx[i][5]*2 + mtx[i][4]; int col = mtx[i][3]*8 + mtx[i][2]*4 + mtx[i][1]*2 + mtx[i][0]; mtx[i] = Inv_S_Box[row][col]; } } 行移位层 将输入数据作为一个$4·4$的字节矩阵进行处理，然后将这个矩阵的字节进行位置上的置换。在加密时行位移处理与解密时的处理相反，我们这里将解密时的处理称作逆行位移。它之所以称作行位移，是因为它只在$4·4$矩阵的行间进行操作，每行4字节的数据。在加密时，保持矩阵的第一行不变，第二行向左移动8Bit(一个字节)、第三行向左移动2个字节、第四行向左移动3个字节。而在解密时恰恰相反，依然保持第一行不变，将第二行向右移动一个字节、第三行右移2个字节、第四行右移3个字节。最终结束。\n正向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 //正向行变换 - 按字节循环移位 void ShiftRows(byte mtx[4 * 4]) { // 第二行循环左移一位 byte temp = mtx[4]; for (int i = 0; i \u0026lt; 3; ++i) mtx[i + 4] = mtx[i + 5]; mtx[7] = temp; // 第三行循环左移两位 for (int i = 0; i \u0026lt; 2; ++i) { temp = mtx[i + 8]; mtx[i + 8] = mtx[i + 10]; mtx[i + 10] = temp; } // 第四行循环左移三位 temp = mtx[15]; for (int i = 3; i \u0026gt; 0; --i) mtx[i + 12] = mtx[i + 11]; mtx[12] = temp; } 反向行移位图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 // 逆行变换 - 以字节为单位循环右移 void InvShiftRows(byte mtx[4*4]) { // 第二行循环右移一位 byte temp = mtx[7]; for(int i=3; i\u0026gt;0; --i) mtx[i+4] = mtx[i+3]; mtx[4] = temp; // 第三行循环右移两位 for(int i=0; i\u0026lt;2; ++i) { temp = mtx[i+8]; mtx[i+8] = mtx[i+10]; mtx[i+10] = temp; } // 第四行循环右移三位 temp = mtx[12]; for(int i=0; i\u0026lt;3; ++i) mtx[i+12] = mtx[i+13]; mtx[15] = temp; } 列混淆层 列混淆子层是AES算法中最为复杂的部分，属于扩散层，列混淆操作是AES算法中主要的扩散元素，它混淆了输入矩阵的每一列，使输入的每个字节都会影响到4个输出字节。行位移子层和列混淆子层的组合使得经过三轮处理以后，矩阵的每个字节都依赖于16个明文字节成可能。\n在加密的正向列混淆中，我们要将输入的$4·4$矩阵左乘一个给定的$4·4$矩阵。而它们之间的加法、乘法都在扩展域$GF(2^8)$中进行，,在矩阵相乘计算中，出现了加法和乘法，而前面提到了在拓展域中加法等同于异或运算，而对于乘法，需要特殊的方式进行处理，于是将+号换成^号，然后将伽罗瓦域的乘法定义成一个有两个参数的函数，并让他返回最后计算结果，最后列混淆代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 //正向列变换 void MixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x02, arr[0]) ^ GFMul(0x03, arr[1]) ^ arr[2] ^ arr[3]; mtx[i+4] = arr[0] ^ GFMul(0x02, arr[1]) ^ GFMul(0x03, arr[2]) ^ arr[3]; mtx[i+8] = arr[0] ^ arr[1] ^ GFMul(0x02, arr[2]) ^ GFMul(0x03, arr[3]); mtx[i+12] = GFMul(0x03, arr[0]) ^ arr[1] ^ arr[2] ^ GFMul(0x02, arr[3]); } } 在解密的逆向列混淆中与正向列混淆的不同之处在于使用的左乘矩阵不同，它与正向列混淆的左乘矩阵互为逆矩阵，也就是说，数据矩阵同时左乘这两个矩阵后，数据矩阵不会发生任何变化。下面是图解：\n正向混淆处理：\n逆向混淆处理：\n反向列变换代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 //反向列混淆 void InvMixColumns(byte mtx[4*4]) { byte arr[4]; for(int i=0; i\u0026lt;4; ++i) { for(int j=0; j\u0026lt;4; ++j) arr[j] = mtx[i+j*4]; mtx[i] = GFMul(0x0e, arr[0]) ^ GFMul(0x0b, arr[1]) ^ GFMul(0x0d, arr[2]) ^ GFMul(0x09, arr[3]); mtx[i+4] = GFMul(0x09, arr[0]) ^ GFMul(0x0e, arr[1]) ^ GFMul(0x0b, arr[2]) ^ GFMul(0x0d, arr[3]); mtx[i+8] = GFMul(0x0d, arr[0]) ^ GFMul(0x09, arr[1]) ^ GFMul(0x0e, arr[2]) ^ GFMul(0x0b, arr[3]); mtx[i+12] = GFMul(0x0b, arr[0]) ^ GFMul(0x0d, arr[1]) ^ GFMul(0x09, arr[2]) ^ GFMul(0x0e, arr[3]); } } 密钥加法层 这一层主要是明文矩阵盒子密钥矩阵进行异或操作,在密钥加法层中有两个输入的参数，分别是明文和子密钥，而且这两个输入都是128位的。只需要将两个输入的数据进行按字节异或操作就会得到运算的结果。\n图解：\n代码如下：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 //轮密钥加变换 - 将每一列与扩展密钥进行异或 void AddRoundKey(byte mtx[4*4], word k[4]) { for(int i=0; i\u0026lt;4; ++i) { word k1 = k[i] \u0026gt;\u0026gt; 24; word k2 = (k[i] \u0026lt;\u0026lt; 8) \u0026gt;\u0026gt; 24; word k3 = (k[i] \u0026lt;\u0026lt; 16) \u0026gt;\u0026gt; 24; word k4 = (k[i] \u0026lt;\u0026lt; 24) \u0026gt;\u0026gt; 24; mtx[i] = mtx[i] ^ byte(k1.to_ulong()); mtx[i+4] = mtx[i+4] ^ byte(k2.to_ulong()); mtx[i+8] = mtx[i+8] ^ byte(k3.to_ulong()); mtx[i+12] = mtx[i+12] ^ byte(k4.to_ulong()); } } 实现加密函数 加密函数按照流程图,首先开始是先进行一次轮密钥加,然后开始9轮的字节替换+行移位+列混淆+轮密钥加的操作,循环之后再做一次字节替换+行移位+轮密钥加就完成加密操作了.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void encrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); for(int round=1; round\u0026lt;N_round; ++round) { SubBytes(in); ShiftRows(in); MixColumns(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); } SubBytes(in); ShiftRows(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); } 实现解密函数 解密函数与加密差不多,只不过将行移位变成反向行移位,列混淆变成反向列混淆,字节替换变成逆字节替换即可.\n代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 void decrypt(byte in[4*4], word w[4*(N_round+1)]) { word key[4]; for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*N_round+i]; AddRoundKey(in, key); for(int round=N_round-1; round\u0026gt;0; --round) { InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[4*round+i]; AddRoundKey(in, key); InvMixColumns(in); } InvShiftRows(in); InvSubBytes(in); for(int i=0; i\u0026lt;4; ++i) key[i] = w[i]; AddRoundKey(in, key); } 测试加密解密函数 可以发现上面面的测试中明文与解密之后的明文是完全正确的,说明加密函数与解密函数正确!\n测试代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 void Aes_test() { byte key[16] = {0x2b, 0x7e, 0x15, 0x16, 0x28, 0xae, 0xd2, 0xa6, 0xab, 0xf7, 0x15, 0x88, 0x09, 0xcf, 0x4f, 0x3c}; byte plain[16] = {0x32, 0x88, 0x31, 0xe0, 0x43, 0x5a, 0x31, 0x37, 0xf6, 0x30, 0x98, 0x07, 0xa8, 0x8d, 0xa2, 0x34}; // 输出密钥 cout \u0026lt;\u0026lt; \u0026#34;Key is : \u0026#34;; for (int i = 0; i \u0026lt; 16; ++i) cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; key[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; cout \u0026lt;\u0026lt; endl; word w[4 * (N_round + 1)]; KeyExpansion(key, w); // 输出待加密的明文 cout \u0026lt;\u0026lt; endl \u0026lt;\u0026lt; \u0026#34;the plaintext to encrypy:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 加密，输出密文 encrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;cipher : \u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; // 解密，输出明文 decrypt(plain, w); cout \u0026lt;\u0026lt; \u0026#34;plain arter decrypt:\u0026#34; \u0026lt;\u0026lt; endl; for (int i = 0; i \u0026lt; 16; ++i) { cout \u0026lt;\u0026lt; hex \u0026lt;\u0026lt; plain[i].to_ulong() \u0026lt;\u0026lt; \u0026#34; \u0026#34;; if ((i + 1) % 4 == 0) cout \u0026lt;\u0026lt; endl; } cout \u0026lt;\u0026lt; endl; } 实现加解密文件 加密文件函数,返回加密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 string encryptFile(string oname, string suffix, word w[4 * (N_round + 1)]) { string outputfilename = oname + \u0026#34;_cipher.bin\u0026#34;; bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining encrypy...........\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); // 将文件加密到 oname + cipher.bin 中 ifstream in; ofstream out; in.open(oname + suffix, ios::binary); //输入文件 out.open(outputfilename, ios::binary); //输出加密文件 while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); encrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0 } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;encrypy finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;encrypy cost time : \u0026#34; \u0026lt;\u0026lt; (end - start) \u0026lt;\u0026lt; \u0026#34; ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; //返回加密之后的文件 } 解密文件函数,返回解密后的文件名:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 string decryptFile(string filename, string oname, string suffix, word w[4 * (N_round + 1)]) { ifstream in; ofstream out; in.open(filename, ios::binary); string outputfilename = oname + \u0026#34;_decrypt\u0026#34; + suffix; out.open(outputfilename, ios::binary); bitset\u0026lt;128\u0026gt; data; byte plain[16]; cout \u0026lt;\u0026lt; \u0026#34;begining decrypt............\u0026#34; \u0026lt;\u0026lt; endl; clock_t start = clock(); while (in.read((char *)\u0026amp;data, sizeof(data))) { divideToByte(plain, data); decrypt(plain, w); data = mergeByte(plain); out.write((char *)\u0026amp;data, sizeof(data)); data.reset(); // 置0 } in.close(); out.close(); clock_t end = clock(); cout \u0026lt;\u0026lt; \u0026#34;decrypt finish!\u0026#34; \u0026lt;\u0026lt; endl; cout \u0026lt;\u0026lt; \u0026#34;decrypt cost time : \u0026#34; \u0026lt;\u0026lt; end - start \u0026lt;\u0026lt; \u0026#34; ms\u0026#34; \u0026lt;\u0026lt; endl; return outputfilename; } 实现效果:\n加密txt文件:\n加密jpg文件:\n加密mp3文件:\n加密doc文件:\nAES五种加密模式 实现五种加密方式的密钥是一个置换表unsigned char Table[4] = {0x12, 0xb1, 0x53, 0x28};,加密函数是原文与密钥的异或.\nECB模式(电子密码本模式) 加密前根据加密块大小（如AES为128位）分成若干块，之后将每块使用相同的密钥单独加密，解密同理。\nECB模式由于每块数据的加密是独立的因此加密和解密都可以并行计算，ECB模式最大的缺点是相同的明文块会被加密成相同的密文块，这种方法在某些环境下不能提供严格的数据保密性。\n流程图如下:\n实现代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 //电子密码本模式,分组大小为4 unsigned char* ECB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for(int j = 0;j \u0026lt; groupSize;++j) temp[j] = plain[count++]; //加密 encrypt(temp,groupSize); for(int j = i*4;j \u0026lt; i*4 + 4;++j) cipher[j] = temp[j - i * 4]; } return cipher;//返回密文 } 解密方法也是让密文与密钥进行异或即可,实现效果如下:\nCBC模式(分组链接模式) CBC模式对于每个待加密的密码块在加密前会先与前一个密码块的密文异或然后再用加密器加密。第一个明文块与一个叫初始化向量的数据块异或。\n可用公式总结为:\n$$\nC_i = E_K(P_i XOR C_{i-1}) \\\nC_{-1} = IV\n$$\n流程图如下:\nCBC模式相比ECB有更高的保密性，但由于对每个数据块的加密依赖与前一个数据块的加密所以加密无法并行。与ECB一样在加密前需要对数据进行填充，不是很适合对流数据进行加密。\n代码如下:\n加密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //CCB加密函数 unsigned char *CCB(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = plain[count++]; //加密 for (int j = 0; j \u0026lt; groupSize; ++j) //先与初始向量异或 temp[i] ^= C[i]; encrypt(temp, groupSize); //加密 for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { cipher[j] = temp[j - i * 4]; C[j - i * 4] = temp[j - i * 4];//设置新向量 } } return cipher; } 解密函数:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 //CCB解密函数 unsigned char *dCCB(unsigned char *cipher, int N) { int gNum = N / groupSize; //分组数量 //明文 unsigned char *plain = new unsigned char[N]; //设置初始向量 unsigned char C[groupSize] = {0xe4, 0xa9, 0x5d, 0x99}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; for (int j = 0; j \u0026lt; groupSize; ++j) temp[j] = cipher[count++]; //解密 encrypt(temp, groupSize); //先解密 for (int j = 0; j \u0026lt; groupSize; ++j) //然后与初始向量异或 temp[i] ^= C[i]; for (int j = i * 4; j \u0026lt; i * 4 + 4; ++j) { plain[j] = temp[j - i * 4]; C[j - i * 4] = cipher[j];//设置新向量 } } return plain; } 实现效果:\nCFB模式(密文反馈模式) 与前面的模式不同,CFB模式可以将消息被当成是比特流.可以总结为如下的公式:\n$$\nC_i = P_i XOR E_K(C_{i-1})\\\nC_{-1} = IV\n$$\n流程图如下:\n加密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 //密文反馈模式,加密函数 unsigned char *CFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文,大小为2 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; gsize;++j){ temp[j] ^= C[j]; S[j] = temp[j]; //获取密文的2bit } //设置密文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; } 解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 //密文反馈解密 unsigned char *dCFB(unsigned char *cipher, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //明文 unsigned char *plain = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xe4, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组密文 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = cipher[count++]; //解密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; 2;++j){ S[j] = temp[j]; temp[j] = C[j] ^ temp[j]; } //设置明文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { plain[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j+gsize] = S[j]; } } return plain; } 实现效果:\nOFB模式(输出反馈模式) OFB是先用块加密器生成密钥流（Keystream），然后再将密钥流与明文流异或得到密文流，解密是先用块加密器生成密钥流，再将密钥流与密文流异或得到明文，由于异或操作的对称性所以加密和解密的流程是完全一样的。\nOFB与CFB一样都非常适合对流数据的加密，OFB由于加密和解密都依赖与前一段数据，所以加密和解密都不能并行。\n流程图如下:\n加密解密代码:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 //输出反馈模式,加密解密函数相同 unsigned char *OFB(unsigned char *plain, int N) { int gsize = 2; int gNum = N / gsize; //分组数量,分成8组,每组大小为2 //密文 unsigned char *cipher = new unsigned char[N]; //设置初始向量 unsigned char C[4] = {0xee, 0xa9, 0x5d, 0x99}; unsigned char S[2]; //前2个字节 int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[gsize]; //分组明文 for (int j = 0; j \u0026lt; gsize; ++j) temp[j] = plain[count++]; //加密 //先对初始向量进行加密 encrypt(C,4); //获取结果C的前两个bit,然后前2个bit S与明文进行异或 for(int j = 0;j \u0026lt; 2;++j){ S[j] = C[j]; //取向量加密后的前两位 temp[j] ^= C[j]; } //设置密文 for (int j = i * gsize; j \u0026lt; i * gsize + gsize; ++j) { cipher[j] = temp[j - i * gsize]; } //设置新向量,新向量左移 for(int j = 0;j \u0026lt; gsize;++j) { C[j] = C[j + gsize]; C[j + gsize] = S[j]; } } return cipher; } 实现效果:\nCTR模式(计数器模式) 类型于CFB，但是加密每个计数值，而不是任何反馈值,对每个明文分组，必须有不同的密钥和计数值 (从不重复使用),,可以用如下公式表示:\n$$\nO_i = E_K(i)\\\nC_i = P_i XOR O_i\n$$\n计数器模式流程图如下:\n计数器模式加密函数与解密函数一样,代码如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 //计数器模式,加密函数 unsigned char *CTR(unsigned char *plain, int N) { int gNum = N / groupSize; //分组数量 //密文 unsigned char *cipher = new unsigned char[N]; //设置随机值 unsigned char Counter[groupSize*groupSize] = {0x44, 0xa9, 0x5d, 0x99, 0xe5, 0xf1, 0x3d, 0x91, 0x16, 0xa6, 0xe1, 0x33, 0x22, 0xdd, 0xab, 0x1f}; int count = 0; for (int i = 0; i \u0026lt; gNum; ++i) { unsigned char temp[groupSize]; //明文分组 unsigned char C[groupSize]; //分组随机值 for (int j = 0; j \u0026lt; groupSize; ++j) { temp[j] = plain[count++]; C[j] = Counter[i*4+j]; } //加迷 //首先加密随机值C encrypt(C, groupSize); //然后与明文进行异或 for(int j = 0;j \u0026lt; groupSize;++j) temp[j] ^= C[j]; //设置密文 for(int j = i*groupSize;j \u0026lt; i*groupSize+groupSize;j++) cipher[j] = temp[j-i*groupSize]; } return cipher; } 实现效果如下:\n参考:\nhttps://www.cnblogs.com/RabbitHu/p/bitset.html bitset用法 https://blog.csdn.net/liushu1231/article/details/8844631 bitset的空间大小 http://c.biancheng.net/cpp/html/2834.html 文件处理 https://bbs.pediy.com/thread-253884.htm AES算法带图解 https://blog.csdn.net/lisonglisonglisong/article/details/41909813 AES算法 CSDN https://blog.csdn.net/sinat_23338865/article/details/72869841 AES五种加密模式 设“+”为一个交换性的二元运算，即对于所有x,y，x+y=y+x。若该集内存在一个元素0，使得对于所有x，x+0=0+x=x，则此元素是唯一的。如果对于一个给定的x，存在一个x\u0026rsquo;使得x+x\u0026rsquo;=x\u0026rsquo;+x=0，则称x\u0026rsquo;是x的加法逆元。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n乘法逆元，是指数学领域群G中任意一个元素a，都在G中有唯一的逆元a‘，具有性质a×a\u0026rsquo;=a\u0026rsquo;×a=e，其中e为该群的单位元。\u0026#160;\u0026#x21a9;\u0026#xfe0e;\n","description":"","id":32,"section":"zh","tags":["AES","密码学"],"title":"Aes-高级加密标准","uri":"https://hugo.jiahongw.com/en/zh/posts/cryptography/aes/"},{"content":"使用Scrapy爬取文章的一个小项目..\nScrapy 框架图：\n抓取小程序社区文章 创建爬虫项目 创建项目（项目名为MyTest）\n1 scrapy startproject MyTest 创建爬虫🪲(先进入到MyTest目录)\n1 scrapy genspider -t crawl wx wxapp-union.com wx为爬虫的名字，wxapp-union.com为爬取的域名，使用了模板crawl\n定义爬取的数据结构 爬取的数据结构类继承Item类，在items.py文件中，如下是设置需要爬取的数据结构，其中包括:标题、作者、时间、访问者、前言、正文。\n1 2 3 4 5 6 7 8 9 10 from scrapy import Item,Field # 定义文章数据结构 class ArticleItem(Item): title = Field() author = Field() _time = Field() visitors = Field() pre_talk = Field() article_content = Field() 编写爬虫规则与解析规则 爬虫的爬取网页的链接的规则和解析页面的规则都是在新建的spider文件中的类中，也即在wx.py中\n编写的spider类如下:\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import scrapy from scrapy.linkextractors import LinkExtractor from scrapy.spiders import CrawlSpider, Rule from MyTest.items import ArticleItem class WxSpider(CrawlSpider): name = \u0026#39;wx\u0026#39; allowed_domains = [\u0026#39;wxapp-union.com\u0026#39;] start_urls = [\u0026#39;http://www.wxapp-union.com/portal.php?mod=list\u0026amp;catid=2\u0026amp;page=255\u0026#39;] rules = ( Rule(LinkExtractor(allow=r\u0026#39;.+mod=list\u0026amp;catid=2\u0026amp;page=\\d\u0026#39;), follow=True), Rule(LinkExtractor(allow=r\u0026#39;.+article-.+\\.html\u0026#39;),callback=\u0026#34;parse_item\u0026#34;,follow=False) ) def parse_item(self, response): title = response.xpath(\u0026#39;//h1[@class=\u0026#34;ph\u0026#34;]/text()\u0026#39;).get() author = response.xpath(\u0026#39;//p[@class=\u0026#34;authors\u0026#34;]//a\u0026#39;).get() _time = response.xpath(\u0026#39;//span[@class=\u0026#34;time\u0026#34;]/text()\u0026#39;).get() visitors = response.xpath(\u0026#39;//div[contains(@class,\u0026#34;focus_num\u0026#34;)]//a/text()\u0026#39;).get() pre_talk = response.xpath(\u0026#39;//div[@class=\u0026#34;blockquote\u0026#34;]//p/text()\u0026#39;).get() article_content = response.xpath(\u0026#39;//td[@id=\u0026#34;article_content\u0026#34;]\u0026#39;).get() item = ArticleItem(title=title,author=author,_time=_time,visitors=visitors,pre_talk=pre_talk,article_content=article_content) print(\u0026#39;*\u0026#39;*40) print(title) print(\u0026#39;*\u0026#39;*40) return item 首先rules定义了爬取链接规则，有两个规则，第一个规则是爬取页面的链接，每一页有多个文章的链接，而第二个规则则是定义爬取的具体文章内容的链接。 第一个规则需要Follow，因为需要根据每一页的内容查找文章的链接；而第二个规则是文章链接，故不需要继续Follow 第一个页面链接规则不需要回调函数，因为不需要解析，只需要获取文章链接；第二个文章链接规则则需要设置回调函数来对返回的文章网页内容进行解析。 parse_item说明：\nparse_item是解析页面返回内容的函数，其返回Item数据结构，使用Xpath分别获取数据结构各个元素的内容并且返回Item\n保存数据 pipelines是一个最后处理Item的管道\n在pipelines.py文件中新建pipleline对返回的Item进行处理，可以保存为文件，或者存储到数据库。\n首先文件中需要导入必要的库‘\n1 2 3 4 5 import re\t# 正则处理 from html2text import HTML2Text\t# 将网页转化为Markdown格式 from scrapy.exporters import JsonLinesItemExporter\t# 输出Json文件输出器 from urllib.parse import urljoin\t# 补全URL，因为有些URL只显示相对位置 import pymongo\t# MongoDB操作库 第一个Pipeline：保存到Json文件 程序的构造函数新建一个Json文件输出器，process_item进行数据的存储，关闭的时候close_spider会调用关闭文件\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # 存储到Json文件中 class JsonPipeline(object): def __init__(self): self.f = open(\u0026#39;wxjc.json\u0026#39;,\u0026#39;wb\u0026#39;) self.exporter = JsonLinesItemExporter(self.f, ensure_ascii=False,encoding=\u0026#34;utf-8\u0026#34;) def process_item(self, item, spider): # 将内容转化为MarkDown格式 item[\u0026#39;article_content\u0026#39;] = convert_md(item[\u0026#39;article_content\u0026#39;]) self.exporter.export_item(item) return item def close_spider(self,spider): self.f.close() 第二个Pipeline：保存到Markdown文件 方法与第一发Pipeline类似，只是写文件使用最简单的追加方式\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # 写入Markdown class MDPipeline(object): def __init__(self): self.f = open(\u0026#39;wx_teaches.md\u0026#39;,\u0026#39;a\u0026#39;,encoding=\u0026#39;utf-8\u0026#39;) def process_item(self,item,spider): if self.f: self.f.write(\u0026#39;\\n\u0026#39;) self.f.write(\u0026#34;# \u0026#34; + item[\u0026#39;title\u0026#39;] + \u0026#39;\\n\u0026#39;) header_info = \u0026#34;作者:{} 发布时间:{} Visitors:{}\\n\u0026#34;.format(item[\u0026#39;author\u0026#39;],item[\u0026#39;_time\u0026#39;],item[\u0026#39;visitors\u0026#39;]) self.f.write(header_info) self.f.write(\u0026#39;\u0026gt; \u0026#39; + item[\u0026#39;pre_talk\u0026#39;] + \u0026#39;\\n\u0026#39;) self.f.write(item[\u0026#39;article_content\u0026#39;]) return item def close_spider(self,spider): self.f.close() 第三个Pileline：保存到MongoDB 其中使用了类方法装饰器@classmethod,意思就是直接用类名调用该函数，就能够直接返回一个MongoPipeline类了，还定义了打开spider与关闭spider的操作，就是连接数据库与关闭数据库\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # 存储到MongoDB数据库 class MongoPipeline(object): def __init__(self,mongo_uri,mongo_db): self.mongo_uri = mongo_uri self.mongo_db = mongo_db @classmethod def from_crawler(cls,crawler): return cls(mongo_uri = crawler.settings.get(\u0026#39;MONGO_URI\u0026#39;), mongo_db = crawler.settings.get(\u0026#39;MONGO_DB\u0026#39;)) def open_spider(self,spider): self.client = pymongo.MongoClient(self.mongo_uri) self.db =self.client[self.mongo_db] def process_item(self,item,spider): name = item.__class__.__name__ # \u0026lt;a href=\\\u0026#34;space-uid-17761.html\\\u0026#34;\u0026gt;Rolan\u0026lt;/a\u0026gt; item[\u0026#39;author\u0026#39;] = re.search(\u0026#39;\u0026lt;a.*?\u0026gt;(.*?)\u0026lt;/a\u0026gt;\u0026#39;,item[\u0026#39;author\u0026#39;]).group(1) self.db[name].insert(dict(item)) return item def close_spider(self,spider): self.client.close() 最后需要在settings.py中添加如下字段:\n1 2 MONGO_URI = \u0026#39;localhost\u0026#39; MONGO_DB = \u0026#39;WX\u0026#39; 最后需要在settings.py中添加如下字段 1 2 3 4 5 6 7 8 9 ITEM_PIPELINES = { \u0026#39;MyTest.pipelines.JsonPipeline\u0026#39;: 300, \u0026#39;MyTest.pipelines.MDPipeline\u0026#39;: 301, \u0026#39;MyTest.pipelines.MongoPipeline\u0026#39;: 400, } # 修改为False ROBOTSTXT_OBEY = False # 设置延迟1s DOWNLOAD_DELAY = 1 开始爬取 可以在项目目录中新建一个脚本start.py，文件内容如下，自动运行脚本\n1 2 from scrapy import cmdline cmdline.execute(\u0026#39;scrapy crawl test\u0026#39;.split(\u0026#39; \u0026#39;)) 爬取结果 Json结果 Markdown结果 Markdown文件由于太大了使用Markdown文件打不开，只好使用文本编辑器打开\nMongoDB结果 ","description":"","id":33,"section":"zh","tags":["爬虫","scrapy"],"title":"使用Scrapy框架编写爬虫","uri":"https://hugo.jiahongw.com/en/zh/posts/dev/scrapy-exercise/"},{"content":" HUGO + Github + Github Action 持续集成部署个人博客\n安装 HUGO 本地环境 首先在 HUGO 的官网下载Hugo的 Windows 安装包，然后将路径添加到环境变量即可。\nstep1:下载 hugo\nstep2:配置环境变量\n其他系统安装 HUGO 的方法：\nMac：brew install hugo HUGO 站点配置及主题配置 创建站点 在目录下直接输入下面的代码即可创建一个名为 blog 的 hugo 站点(注意：新建的站点是没有自带主题的)\n1 hugo new site blog 或者进入 blog 文件夹内直接输入以下语句：\n1 hugo new site . 下载主题 可以在hugo theme下载主题，然后根据主题的文档进行配置\n放到站点文件夹 themes 内，配置 config.toml\n本地测试运行 输入hugo server测试\nGithub 配置 创建站点仓库并且设置 GithubPage 可以在 Setting 中看见如下：\n创建另一个存储项目的仓库 创建另一个存储项目的仓库，存储写的博客文章\n配置 Github Action 首先在项目仓库点击 action，选择Simple workflow，输入一下的配置代码：\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 name: HUGO_CI #自动化的名称 on: push: # push的时候触发 branches: # 那些分支需要触发 - master jobs: build: runs-on: ubuntu-latest # 镜像市场 steps: - name: checkout # 步骤的名称 uses: actions/checkout@v3 #软件市场的名称 with: # 参数 submodules: true - name: Setup Hugo uses: peaceiris/actions-hugo@v2.2.2 with: hugo-version: \u0026#39;0.64.1\u0026#39; # 设置HUGO框架的版本 extended: true # 是否选择拓展版HUGO框架，选择是 - name: Build run: hugo -D - name: Deploy uses: peaceiris/actions-gh-pages@v2.5.1 env: ACTIONS_DEPLOY_KEY: ${{ secrets.ACTIONS_DEPLOY_KEY }} EXTERNAL_REPOSITORY: redisread/redisread.github.io PUBLISH_BRANCH: master PUBLISH_DIR: ./public 准备部署，我们开发的项目及github pages实际是分开的，一个用于保存项目，相当于源代码，另外一个用于保存最终的网页文件。\n使用 git 生成 ssh key(相当于生成对密钥)\n1 2 3 4 ssh-keygen -t rsa -b 4096 -C \u0026#34;$(git config user.email)\u0026#34; -f gh-pages -N \u0026#34;\u0026#34; # You will get 2 files: # gh-pages.pub (public key) # gh-pages (private key) 假设 开发项目为 HUGO_blog 部署的项目为 redisread.github.io\n打开HUGO_blog仓库的 settings，再点击Secrets，然后添加刚刚生成的私钥，name 为ACTIONS_DEPLOY_KEY\n同理，打开redisread.github.io，点击Deploy keys，添加公钥，Allow write access一定要勾上，否则会无法提交\n然后，你就可以提交代码了，push 成功后，打开仓库actions，至此部署成功，大功告成！\n后续可以自己写文章然后 push 了，github action会自动帮你部署。\n","description":"Guide to set Hugo site.","id":35,"section":"zh","tags":["hugo","github"],"title":"部署HUGO博客","uri":"https://hugo.jiahongw.com/en/zh/posts/hugo/hugo_setup/"},{"content":" 关于我 👋 Hi, I’m VictorHong.\n平时喜欢看电影，看美剧，上班路上听听博客和音乐\u0026hellip;\n喜欢自己折腾一些的东西，比较喜欢的产品是flomo.\n您可通过以下渠道订阅更新：\nRSS: https://hugo.jiahongw.com/zh/index.xml Find Me：\nGithub Twitter jike 技能 使用工具 MacBook 软件清单：\nRaycast（终端效率工具） ClashX（VPN工具） Edge（浏览器） Arc（浏览器） Notion（笔记软件） Obsidian（笔记软件，写博客） item2（命令行工具） Snipaste（复制粘贴工具） Reeder（RSS阅读器） SublimeText（文本编辑器） PicGo（图片上传） uPic（图片上传工具） 命令行终端工具：\nzsh + oh-my-zsh HomeBrew git vim ","description":"Zzo about page","id":36,"section":"zh","tags":null,"title":"关于","uri":"https://hugo.jiahongw.com/en/zh/about/"},{"content":"盒子 支持 Markdown 语法的盒子 语法：\n或者：\n1 \u0026lt;div class=\u0026#34;box\u0026#34;\u0026gt;This is \u0026lt;strong\u0026gt;boxmd\u0026lt;/strong\u0026gt; shortcode\u0026lt;/div\u0026gt; 渲染显示：\nThis is boxmd shortcode 简单盒子 语法：\n渲染显示：\nThis is **box** shortcode 代码选项卡 可以在不同的代码块之间切换，语法：\n渲染显示：\njava javascript 1 System.out.println(\u0026#39;Hello World!\u0026#39;); 1 console.log(\u0026#39;Hello World!\u0026#39;); 常规选项卡 这个和代码选项卡类似，不同的是，这种选项卡更加“常规”。语法：\n渲染显示：\nWindows MacOS Ubuntu Windows section 1 console.log(\u0026#39;Hello World!\u0026#39;); ⚠️Becareful that the content in the tab should be different from each other. The tab makes unique id hashes depending on the tab contents. So, If you just copy-paste the tabs with multiple times, since it has the same contents, the tab will not work.\nMacOS section Hello world! Ubuntu section Great! 展开栏 语法：\n渲染显示：\nExpand me Title contents Expand me2 Title2 contents2 彩色文本框 语法：\n渲染显示：\nthis is a text this is a text this is a text this is a text 彩色注意框 语法：\n渲染显示：\nsuccess text info text warning text error text 图片描述 使用语法：\n渲染显示：\nSample Image: Image with title, caption, alt, ... 按钮 语法：\n简单按钮：\nbutton 设置宽度高度：\nbutton 设置颜色：\nbutton ","description":"tabs, code-tabs, expand, alert, warning, notice, img, box","id":37,"section":"zh","tags":["shortcode","zzo","博客搭建"],"title":"Shortcodes使用参考","uri":"https://hugo.jiahongw.com/en/zh/posts/hugo/shortcodes/"},{"content":"A Short Video： ——以下 Aaron Swartz的宣言，我想这才是信息革命的真谛——\n信息就是力量。但就像所有力量一样，有些人只想占为己有。世界上所有的科学和文化遗产，已在书籍和期刊上发布了数个世纪，正渐渐地被少数私有的公司数字化并上锁。想要阅读那些有着最著名研究成果的论文？你必须支付给如 Reed Elsevier 这样的出版商大把钱。\n有人努力去改变这种状况。开放访问运动 (Open Access Movement) 奋勇斗争，确保科学家们没有将他们的版权签署给别人，而是将他们的成果发布到网络上，允许任何人访问它们。但即便是最好的情况，他们的行为也只作用于未来发布的东西。之前的都将失去。\n这样的代价实在太高。强制学者付钱以阅读他们同行的成果？扫描整个图书馆却只允许 Google 的人阅读它们？提供科学文章给那些第一世界的精英大学，却不给身在南半球的儿童？这实在蛮横且无法接受。\n“我同意，”有些人就说了，“但是我们能做什么呢？那些公司握有版权，他们靠限制访问赚取大把的钱，而且这是完全合法的 - 我们没有办法阻止他们。”但有些事我们能做，这些事我们已经在做：我们可以反击。\n那些能够访问这些资源的人 - 学生，图书管理员，科学家 - 你们被赋予了特权。你们能享受到这知识的盛宴，而其他人却被排除在外。但是你们不必 - 事实上，从道义层面来说，你们不能 - 为保留自己保留这份特权。你们有义务和全世界分享它。而且你们已经在做了：和同行们交换密码，回应朋友们的下载请求。\n同时，那些被拒之门外的人们并没有袖手旁观。你们溜过洞穴，翻越围墙，解放那些被出版商封锁的信息并分享给你的朋友们。\n但所有这些行动都是在黑暗中进行，隐藏于地底。它们被称作偷窃或盗版，仿佛分享大量的知识精神上等同于抢劫一艘船只并谋杀其船员。但是分享绝非不道德的，它是一种道德使命。只有那些利欲熏心的人才会拒绝让朋友复制一份。\n大公司，当然，就是利欲熏心。使它们运转的法律要求使然 - 稍微出点事投资人就得叛乱。它们收买的政治家们支持它们，通过法案让它们拥有专属的权力决定谁可以复制。\n遵从不公正的法律不会带来公正。步入光明的时候到了，在公民不服从的伟大传统下，宣告我们对这种私人盗窃公共文化的反抗。\n我们要夺回信息，无论它们被存在何处，制作我们的副本并和全世界分享。我们要取到版权到期的东西并将它们归档，我们要买下秘密的资料库并将它们放到网上。我们要下载科学期刊并将它们上传到文件分享网络。我们要为游击队开放访问而战。\n只要全世界有足够多的我们，那就不仅是传达了一个反对知识私有化的强有力信号，我们还将让它成为过去。你愿意和我们一起吗？\n亚伦·斯沃茨 (Aaron Swartz)\n2008 年 7 月，意大利 Eremo\nInformation is power. But like all power, there are those who want to keep it for themselves. The world\u0026rsquo;s entire scientific and cultural heritage, published over centuries in books and journals, is increasingly being digitized and locked up by a handful of private corporations. Want to read the papers featuring the most famous results of the sciences? You\u0026rsquo;ll need to send enormous amounts to\npublishers like Reed Elsevier.\nThere are those struggling to change this. The Open Access Movement has fought valiantly to ensure that scientists do not sign their copyrights away but instead ensure their work is published on the Internet, under terms that allow anyone to access it. But even under the best scenarios, their work will only apply to things published in the future. Everything up until now will have been lost.\nThat is too high a price to pay. Forcing academics to pay money to read the work of their colleagues? Scanning entire libraries but only allowing the folks at Google to read them? Providing scientific articles to those at elite universities in the First World, but not to children in the Global South? It\u0026rsquo;s outrageous and unacceptable.\n\u0026ldquo;I agree,\u0026rdquo; many say, \u0026ldquo;but what can we do? The companies hold the copyrights, they make enormous amounts of money by charging for access, and it\u0026rsquo;s perfectly legal - there\u0026rsquo;s nothing we can do to stop them.\u0026rdquo; But there is something we can, something that\u0026rsquo;s already being done: we can fight back.\nThose with access to these resources - students, librarians, scientists - you have been given a privilege. You get to feed at this banquet of knowledge while the rest of the world is locked out. But you need not - indeed, morally, you cannot - keep this privilege for yourselves. You have a duty to share it with the world. And you have: trading passwords with colleagues, filling download requests for friends.\nMeanwhile, those who have been locked out are not standing idly by. You have been sneaking through holes and climbing over fences, liberating the information locked up by the publishers and sharing them with your friends.\nBut all of this action goes on in the dark, hidden underground. It\u0026rsquo;s called stealing or piracy, as if sharing a wealth of knowledge were the moral equivalent of plundering a ship and murdering its crew. But sharing isn\u0026rsquo;t immoral - it\u0026rsquo;s a moral imperative. Only those blinded by greed would refuse to let a friend make a copy.\nLarge corporations, of course, are blinded by greed. The laws under which they operate require it - their shareholders would revolt at anything less. And the politicians they have bought off back them, passing laws giving them the exclusive power to decide who can make copies.\nThere is no justice in following unjust laws. It\u0026rsquo;s time to come into the light and, in the grand tradition of civil disobedience, declare our opposition to this private theft of public culture.\nWe need to take information, wherever it is stored, make our copies and share them with the world. We need to take stuff that\u0026rsquo;s out of copyright and add it to the archive. We need to buy secret databases and put them on the Web. We need to download scientific journals and upload them to file sharing networks. We need\nto fight for Guerilla Open Access.\nWith enough of us, around the world, we\u0026rsquo;ll not just send a strong message opposing the privatization of knowledge - we\u0026rsquo;ll make it a thing of the past.\nWill you join us?\nAaron Swartz\nJuly 2008, Eremo, Italy\n","description":"","id":38,"section":"zh","tags":[null],"title":"互联网之子的故事","uri":"https://hugo.jiahongw.com/en/zh/talks/aaron-swartz-story/"},{"content":"between 70 and 240 in movies\ngood movies！🎥\n","description":"记录电影精彩瞬间","id":40,"section":"zh","tags":[null],"title":"影视相册","uri":"https://hugo.jiahongw.com/en/zh/gallery/movie/"},{"content":"关于生活的点点滴滴\u0026hellip;\u0026hellip;\n","description":"记录生活","id":41,"section":"zh","tags":[null],"title":"生活相册","uri":"https://hugo.jiahongw.com/en/zh/gallery/life/"}]